scrub_df$tRace6 = factor(scrub_df$iRace6,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace7 = factor(scrub_df$iRace7,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace8 = factor(scrub_df$iRace8,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace9 = factor(scrub_df$iRace9,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
scrub_df$tRace10 = factor(scrub_df$iRace10,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
library(tidyverse)
glimpse(scrub_df)
scrub_df$count.BIPOC <- apply(scrub_df[c("tRace1", "tRace2", "tRace3", "tRace4", "tRace5", "tRace6", "tRace7", "tRace8", "tRace9", "tRace10")], 1, function(x) sum(x %in% c("Black", "nBpoc", "BiMulti")))
scrub_df$count.nMiss <- apply(scrub_df[c("tRace1", "tRace2", "tRace3", "tRace4", "tRace5", "tRace6", "tRace7", "tRace8", "tRace9", "tRace10")], 1, function(x) sum(!is.na(x)))
scrub_df$iBIPOC_pr = scrub_df$count.BIPOC/scrub_df$count.nMiss
scrub_df <-(select (scrub_df, ID, iBIPOC_pr, cmBlack, Belong_1:Belong_3, Blst_1:Blst_6))
scrub_df$nmiss <- scrub_df%>%
select(iBIPOC_pr:Blst_6) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
scrub_df<- scrub_df%>%
dplyr::mutate(prop_miss = (nmiss/11)*100) #11 is the number of variables included in calculating the proportion
saveRDS(scrub_df, 'scrubDF.rds')
psych::describe(scrub_df$prop_miss)
scrub_df <- dplyr::filter(scrub_df, prop_miss <= 90)  #update df to have only those with at least 90% of complete data
#further update to exclude the n_miss and prop_miss variables
scrub_df <- scrub_df %>%
dplyr::select (-c(ID, nmiss, prop_miss))
#what proportion of cells missing across entire dataset
formattable::percent(mean(is.na(scrub_df)))
#what proportion of cases (rows) are complete (nonmissing)
formattable::percent(mean(complete.cases(scrub_df)))
mice_out <- mice::md.pattern(scrub_df, plot = TRUE, rotate.names = TRUE)
mice_out
write.csv (mice_out, file="mice_out.csv") #optional to write it to a .csv file
mice_out <- mice::md.pattern(scrub_df, plot = TRUE, rotate.names = TRUE)
mice_out
write.csv (mice_out, file="mice_out.csv") #optional to write it to a .csv file
scrub_df<- scrub_df %>%
dplyr::mutate(rBlst_1 = 8 - Blst_1) #if you had multiple items, you could add a pipe (%>%) at the end of the line and add more until the last one
#Making the list of variables
Belonging_vars <- c('Belong_1','Belong_2','Belong_3')
ResponseBL_vars <- c('rBlst_1', 'Blst_4','Blst_6')
StigmaBL_vars <- c('Blst_2', 'Blst_3','Blst_5')
ClimateBL_vars <- c('rBlst_1', 'Blst_4','Blst_6','Blst_2', 'Blst_3','Blst_5' )
#Creating the new variables
scrub_df$Belonging <- sjstats::mean_n(scrub_df[,Belonging_vars], .65)
scrub_df$ResponseBL <- sjstats::mean_n(scrub_df[,ResponseBL_vars], .80)
scrub_df$StigmaBL <- sjstats::mean_n(scrub_df[,StigmaBL_vars], .80)
scrub_df$ClimateBL <- sjstats::mean_n(scrub_df[,ClimateBL_vars], .80)
scrub_df <- scrub_df %>% dplyr::mutate(ID = row_number())
#moving the ID number to the first column; requires
scrub_df <- scrub_df%>%dplyr::select(ID, everything())
write.table(scrub_df, file="BlStItmsScrs230902.csv", sep=",", col.names=TRUE, row.names=FALSE)
saveRDS(scrub_df, "BlStItmsScrs230902.rds")
scored <-dplyr::select(scrub_df, iBIPOC_pr, cmBlack, Belonging, ResponseBL, StigmaBL, ClimateBL)
ScoredCaseMiss <- nrow(scored) #I produced this object for the sole purpose of feeding the number of cases into the inline text, below
View(scored)
ScoredCaseMiss
saveRDS(scored, 'SCORED.rds')
#Create a variable (n_miss) that counts the number missing
scored$n_miss <- scored%>%
dplyr::select(iBIPOC_pr:ClimateBL) %>%
is.na %>%
rowSums
scored<- scored%>%
dplyr::mutate(prop_miss = (n_miss/6)*100)%>%
arrange(desc(n_miss))
psych::describe(scored$prop_miss)
scored <- dplyr::filter(scored, prop_miss <= 20)
scored <-(select (scored, iBIPOC_pr:ClimateBL))
#this produces the number of cases retained
nrow(scored)
#percent missing across df
formattable::percent(mean(is.na(scored)))
#percent of rows with nonmissing data
formattable::percent(mean(complete.cases(scored)))
mice_ScaleLvl <- mice::md.pattern(scored, plot = TRUE, rotate.names=TRUE)
mice_ScaleLvl
item_scores_df <- readRDS("BlStItmsScrs230902.rds")
#alpha for the belonging scale
psych::alpha(item_scores_df[c("Belong_1", "Belong_2", "Belong_3")])
#alpha for the campus climate for Black students scale
psych::alpha(item_scores_df[c("rBlst_1", "Blst_2", "Blst_3", "Blst_4", "Blst_5", "Blst_6")])
#alpha for the stigma scale of the campus climate for Black students scale
psych::alpha(item_scores_df[c("Blst_3", "Blst_2", "Blst_5")])
#alpha for the campus responsiveness scale of the campus climate for Black students scale
psych::alpha(item_scores_df[c("rBlst_1", "Blst_4", "Blst_6")])
str(item_scores_df)
#the script may look a little complicated; I could have simply written:
#describe(item_scores_df)
#because I only wanted only a few variables, I provided them in a concatenated: list [c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")]
#I used type =1 so that we can interpret skew and kurtosis along Kline's recommendations
#I created an object from the descriptive results, this can be used to export the results for easier table making or manipulation outside of R
descriptives <- psych::describe(item_scores_df[c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")], type = 1)
#When we capture results in an object, we need to write it below so the results will display
descriptives
#this can be useful if you wish to manually format the data for an APA style table
write.csv (descriptives, file="DataDx_descripts.csv")
#The shapiro-test is in base R; it's specification is simple:  shapiro.test(df$variable)
#I added the object (and had to list it below) so I can use the inline text function
shapiro.test(item_scores_df$cmBlack)
shapiro.test(item_scores_df$iBIPOC_pr)
shapiro.test(item_scores_df$Belonging)
shapiro.test(item_scores_df$ClimateBL)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
#The shapiro-test is in base R; it's specification is simple:  shapiro.test(df$variable)
#I added the object (and had to list it below) so I can use the inline text function
shapiro.test(item_scores_df$cmBlack)
shapiro.test(item_scores_df$iBIPOC_pr)
shapiro.test(item_scores_df$Belonging)
shapiro.test(item_scores_df$ClimateBL)
options(scipen=999)#eliminates scientific notation
#The shapiro-test is in base R; it's specification is simple:  shapiro.test(df$variable)
#I added the object (and had to list it below) so I can use the inline text function
shapiro.test(item_scores_df$cmBlack)
shapiro.test(item_scores_df$iBIPOC_pr)
shapiro.test(item_scores_df$Belonging)
shapiro.test(item_scores_df$ClimateBL)
psych::pairs.panels(item_scores_df[c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")], stars = TRUE, lm = TRUE)
item_scores_df$Mahal <- psych::outlier(item_scores_df[c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")])
View(item_scores_df)
psych::describe(item_scores_df$Mahal)
item_scores_df$MOutlier <- dplyr::if_else(item_scores_df$Mahal > (median(item_scores_df$Mahal) + (3*sd(item_scores_df$Mahal))), TRUE, FALSE)
#shows us the first 6 rows of the data so we can see the new variables (Mahal, MOutlier)
head(item_scores_df)
library(tidyverse)
#counts frequency TRUE and FALSE indicating outlier or not
OutlierCount<- item_scores_df%>%
dplyr::count(MOutlier)
#calculating how many outliers a slightly different way
nrow(item_scores_df) - OutlierCount
Climate_fit <- lm(ClimateBL ~ Belonging + cmBlack + iBIPOC_pr, data = item_scores_df)
summary(Climate_fit)
apaTables::apa.cor.table(item_scores_df[c("iBIPOC_pr", "cmBlack", "Belonging", "ClimateBL")], table.number = 1, show.sig.stars = TRUE, filename = "Table1_M_SDs_r_DataDx.doc")
library(apaTables)
apaTables::apa.reg.table(Climate_fit, table.number = 2, filename = "Climate_table.doc")
raw <- readRDS("ReC.rds")
nrow(raw)
View(raw)
#testing to see if my code worked
#raw <- dplyr::filter (raw, SPFC.Decolonize.Opt.Out != "Okay")
raw <- dplyr::filter (raw, SPFC.Decolonize.Opt.Out != "Opt Out")
View(raw)
raw <-(dplyr::filter(raw, Course == "Multivariate"))
nrow(raw)
raw <- dplyr::rename(raw, OptOut = 'SPFC.Decolonize.Opt.Out')
scrub_df <-(dplyr::select (raw, deID, StatsPkg, Centering,ClearResponsibilities, EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation, InclusvClassrm, EquitableEval, MultPerspectives, DEIintegration))
View(scrub_df)
str(scrub_df$StatsPkg)
scrub_df$StatsPkg <- factor(scrub_df$StatsPkg, levels = c("SPSS", "R"))
str(scrub_df$StatsPkg)
scrub_df$Centering <- factor(scrub_df$Centering, levels = c("Pre", "Re"))
str(scrub_df$Centering)
str(scrub_df)
scrub_df$nmiss <- scrub_df%>%
dplyr::select(StatsPkg:DEIintegration) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
library(tidyverse)#needed because the script has pipes
scrub_df$nmiss <- scrub_df%>%
dplyr::select(StatsPkg:DEIintegration) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
library(tidyverse)#needed because the script has pipes
#Calculating number and proportion of item-level missingness
scrub_df$nmiss <- scrub_df%>%
dplyr::select(StatsPkg:DEIintegration) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
scrub_df<- scrub_df%>%
dplyr::mutate(prop_miss = (nmiss/11)*100) #11 is the number of variables included in calculating the proportion
psych::describe(scrub_df$prop_miss)
scrub_df <- dplyr::filter(scrub_df, prop_miss <= 90)  #update df to have only those with at least 90% of complete data
#further update to exclude the n_miss and prop_miss variables
ItemMiss_df <- scrub_df %>%
dplyr::select (-c(deID, nmiss, prop_miss))
View(ItemMiss_df)
#what proportion of cells missing across entire dataset
formattable::percent(mean(is.na(ItemMiss_df)))
#what proportion of cases (rows) are complete (nonmissing)
formattable::percent(mean(complete.cases(ItemMiss_df)))
mice::md.pattern(ItemMiss_df, plot = TRUE, rotate.names = TRUE)
#this seems to work when I build the book, but not in "working the problem"
#TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#scrub_df$TradPed <- sjstats::mean_n(scrub_df[, TradPed_vars], .75)
#this seems to work when I "work the problem" (but not when I build the book)
#the difference is the two dots before the last SRPed_vars
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
scrub_df$TradPed <- sjstats::mean_n(scrub_df[, TradPed_vars], .75)
#this seems to work when I build the book, but not in "working the problem"
#SRPed_vars <- c('InclusvClassrm','EquitableEval', 'MultPerspectives', 'DEIintegration')
#scrub_df$SRPed <- sjstats::mean_n(scrub_df[, SRPed_vars], .75)
#this seems to work when I "work the problem" (but not when I build the book)
#the difference is the two dots before the last SRPed_vars
SRPed_vars <- c('InclusvClassrm','EquitableEval', 'MultPerspectives', 'DEIintegration')
scrub_df$SRPed <- sjstats::mean_n(scrub_df[, SRPed_vars], .75)
scored <- dplyr::select (scrub_df, StatsPkg, Centering, TradPed, SRPed)
ScoredCaseMiss <- nrow(scored) #I produced this object for the sole purpose of feeding the number of cases into the inline text, below
ScoredCaseMiss
scored$n_miss <- scored%>%
is.na %>%
rowSums
View(scored)
scored<- scored%>%
mutate(prop_miss = (n_miss/6)*100)%>%
arrange(desc(n_miss))
psych::describe(scored$prop_miss)
#update df to have only those with at least 20% of complete data (this is an arbitrary decision)
scored <- dplyr::filter(scored, prop_miss <= 20)
#the variable selection just lops off the proportion missing
scored <-(select (scored, StatsPkg:SRPed))
#this produces the number of cases retained
nrow(scored)
formattable::percent(mean(is.na(scored)))
#percent of rows with nonmissing data
formattable::percent(mean(complete.cases(scored)))
mice_ScaleLvl <- mice::md.pattern(scored, plot = TRUE, rotate.names=TRUE)
mice_ScaleLvl
View(scrub_df)
#alpha for the traditional pedagogy scale
psych::alpha(scrub_df[c("ClearResponsibilities", "EffectiveAnswers","Feedback", "ClearOrganization","ClearPresentation")])
#alpha for the traditional pedagogy scale
psych::alpha(scrub_df[c("InclusvClassrm", "EquitableEval", "DEIintegration", "DEIintegration")])
psych::describe(scored, type=1)
#The shapiro-test is in base R; it's specification is simple:  shapiro.test(df$variable)
#I added the object (and had to list it below) so I can use the inline text function
shapiro.test(scored$TradPed)
shapiro.test(scored$SRPed)
options(scipen=999)
#The shapiro-test is in base R; it's specification is simple:  shapiro.test(df$variable)
#I added the object (and had to list it below) so I can use the inline text function
shapiro.test(scored$TradPed)
shapiro.test(scored$SRPed)
psych::pairs.panels(scored, stars = TRUE, lm = TRUE)
scored$Mahal <- psych::outlier(scored[c("TradPed", "SRPed")])
psych::describe(scored$Mahal)
#creates a variable indicating TRUE or FALSE if an item is an outlier
scored$MOutlier <- dplyr::if_else(scored$Mahal > (median(scored$Mahal) + (3*sd(scored$Mahal))), TRUE, FALSE)
#shows us the first 6 rows of the data so we can see the new variables (Mahal, MOutlier)
head(scored)
scored <- dplyr::filter (scored, Mahal < "10")
SRPed_fit <- lm(SRPed ~ StatsPkg + Centering + TradPed, data = scored)
summary(SRPed_fit)
apaTables::apa.cor.table(scored[c("SRPed", "StatsPkg", "Centering", "TradPed")], table.number = 1, show.sig.stars = TRUE, filename = "Table1__DataDx_HW.doc")
apaTables::apa.reg.table(SRPed_fit, table.number = 2, filename = "SRPed_table.doc")
QTRX_df2 <- readRDS("QTRX_df230902b.rds")
library(tidyverse)
QTRX_df2 <- dplyr::filter(QTRX_df2, DistributionChannel != "preview")
QTRX_df2 <-dplyr::filter(QTRX_df2, Consent == 1)
QTRX_df2 <- dplyr::filter(QTRX_df2, USinst == 0)
library(tidyverse)
QTRX_df2 <- dplyr::filter(QTRX_df2, DistributionChannel != "preview")
QTRX_df2 <-dplyr::filter(QTRX_df2, Consent == 1)
QTRX_df2 <- dplyr::filter(QTRX_df2, USinst == 0)
QTRX_df2 <- readRDS("QTRX_df230902b.rds")
#QTRX_df <- read.csv("QTRX_df230902b.csv", header = TRUE)
library(tidyverse)
QTRX_df2 <- dplyr::filter(QTRX_df2, DistributionChannel != "preview")
QTRX_df2 <-dplyr::filter(QTRX_df2, Consent == 1)
QTRX_df2 <- dplyr::filter(QTRX_df2, USinst == 0)
QTRX_df2 <- readRDS("QTRX_df230902b.rds")
#QTRX_df <- read.csv("QTRX_df230902b.csv", header = TRUE)
QTRX_df2 <- readRDS("QTRX_df230902b.rds")
#QTRX_df <- read.csv("QTRX_df230902b.csv", header = TRUE)
QTRX_df2 <- readRDS("QTRX_df230902b.rds")
#QTRX_df <- read.csv("QTRX_df230902b.csv", header = TRUE)
library(tidyverse)
QTRX_df2 <- dplyr::filter(QTRX_df2, DistributionChannel != "preview")
QTRX_df2 <-dplyr::filter(QTRX_df2, Consent == 1)
QTRX_df2 <- dplyr::filter(QTRX_df2, USinst == 0)
View(QTRX_df2)
QTRX_df2 <- rename(QTRX_df2, iRace1 = '1_iRace', iRace2 = '2_iRace', iRace3 = '3_iRace', iRace4 = '4_iRace', iRace5 = '5_iRace', iRace6 = '6_iRace', iRace7 = '7_iRace', iRace8 = '8_iRace', iRace9 = '9_iRace', iRace10 = '10_iRace')
cmUnsure = Race_2)
QTRX_df2 <- dplyr::rename(QTRX_df2, cmBiMulti = Race_10, cmBlack = Race_1, cmNBPoC = Race_7, cmWhite = Race_8, cmUnsure = Race_2)
QTRX_df2 <- QTRX_df2 %>% dplyr::mutate(ID = row_number())
View(QTRX_df2)
#moving the ID number to the first column; requires
QTRX_df2 <- QTRX_df2%>%select(ID, everything())
#moving the ID number to the first column; requires
QTRX_df2 <- QTRX_df2%>%dplyr::select(ID, everything())
View(QTRX_df2)
mimp_df <-  dplyr::select(QTRX_df2, ID, iRace1, iRace2, iRace3, iRace4, iRace5, iRace6, iRace7, iRace8, iRace9, iRace10, cmBiMulti, cmBlack, cmNBPoC, cmWhite, cmUnsure, Belong_1:Belong_3, Blst_1:Blst_6, cEval_1, cEval_13, cEval_19, format)
#glimpse(mimp_df)
head(mimp_df)
mimp_df$iRace1 = factor(mimp_df$iRace1,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace2 = factor(mimp_df$iRace2,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace3 = factor(mimp_df$iRace3,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace4 = factor(mimp_df$iRace4,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace5 = factor(mimp_df$iRace5,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace6 = factor(mimp_df$iRace6,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace7 = factor(mimp_df$iRace7,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace8 = factor(mimp_df$iRace8,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace9 = factor(mimp_df$iRace9,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace10 = factor(mimp_df$iRace10,
levels = c(0,1,2,3,4),
labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
View(mimp_df)
head(mimp_df)
mimp_df$count.BIPOC <- apply(mimp_df[c("iRace1", "iRace2", "iRace3", "iRace4", "iRace5", "iRace6", "iRace7", "iRace8", "iRace9", "iRace10")], 1, function(x) sum(x %in% c("Black", "nBpoc", "BiMulti")))
#creating a count of all instructional  faculty identified by each respondent
mimp_df$count.nMiss <- apply(mimp_df[c("iRace1", "iRace2", "iRace3", "iRace4", "iRace5", "iRace6", "iRace7", "iRace8", "iRace9", "iRace10")], 1, function(x) sum(!is.na(x)))
#creating a count of BIPOC faculty identified by each respondent
mimp_df$count.BIPOC <- apply(mimp_df[c("iRace1", "iRace2", "iRace3", "iRace4", "iRace5", "iRace6", "iRace7", "iRace8", "iRace9", "iRace10")], 1, function(x) sum(x %in% c("Black", "nBpoc", "BiMulti")))
#creating a count of all instructional  faculty identified by each respondent
mimp_df$count.nMiss <- apply(mimp_df[c("iRace1", "iRace2", "iRace3", "iRace4", "iRace5", "iRace6", "iRace7", "iRace8", "iRace9", "iRace10")], 1, function(x) sum(!is.na(x)))
#calculating the proportion of BIPOC faculty with the counts above
mimp_df$iBIPOC_pr = mimp_df$count.BIPOC/mimp_df$count.nMiss
#we can assign more than one value to the same factor by repeating the label
mimp_df$format = factor(mimp_df$format,
levels = c(1,2,3,4,5),
labels = c("InPerson", "Blend", "Blend", "Online", is.na(5)))
mimp_df <-  select (mimp_df, ID, iBIPOC_pr, cmBlack, Belong_1:Belong_3, Blst_1:Blst_6, cEval_1, cEval_13, cEval_19, format)
p_missing <- unlist(lapply(mimp_df, function(x) sum(is.na(x))))/nrow(mimp_df)
sort(p_missing[p_missing > 0], decreasing = TRUE)
mimp_df$nmiss <- mimp_df%>%
dplyr::select(iBIPOC_pr:format) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
mimp_df<- mimp_df%>%
mutate(prop_miss = (nmiss/15)*100) #11 is the number of variables included in calculating the proportion
mimp_df <- dplyr::filter(mimp_df, prop_miss <= 50)
mimp_df <-  select (mimp_df, ID, iBIPOC_pr, cmBlack, Belong_1:Belong_3, Blst_1:Blst_6, cEval_1, cEval_13, cEval_19, format)
set.seed(210404) #you can pick any number you want, today I'm using today's datestamp
#These variables are left in the dataset, but setting them = 0 means they are not used as predictors.
#We want our ID to be retained in the df.  There's nothing missing from it, and we don't want it used as a predictor, so it will just hang out.
predM[, c("ID")]=0
library(mice)
# runs the mice code with 0 iterations
imp <- mice(mimp_df, maxit = 0)
# Extract predictor Matrix and methods of imputation
predM = imp$predictorMatrix
meth = imp$method
#These variables are left in the dataset, but setting them = 0 means they are not used as predictors.
#We want our ID to be retained in the df.  There's nothing missing from it, and we don't want it used as a predictor, so it will just hang out.
predM[, c("ID")]=0
#If you like, view the first few rows of the predictor matrix
#head(predM)
#We don't have any ordered categorical variables, but if we did we would follow this format
#poly <- c("Var1", "Var2")
#We don't have any dichotomous variables, but if we did we would follow this format
#log <- c("Var3", "Var4")
#Unordered categorical variables (nominal variables), but if we did we would follow this format
poly2 <- c("format")
#Turn their methods matrix into the specified imputation models
#Remove the hashtag if you have any of these variables
#meth[poly] = "polr"
#meth[log] = "logreg"
meth[poly2] = "polyreg"
meth
library(mice)
# runs the mice code with 0 iterations
imp <- mice(mimp_df, maxit = 0)
# Extract predictor Matrix and methods of imputation
predM = imp$predictorMatrix
meth = imp$method
# With this command, we tell mice to impute the mimp_df data, create 5 datasets, use predM as the predictor matrix and don't print the imputation process.
#If you would like to see the process (or if the process is failing to execute) set print as TRUE; seeing where the execution halts can point to problematic variables (more notes at end of lecture)
imp2 <- mice(mimp_df, maxit = 5,
predictorMatrix = predM,
method = meth, print =  FALSE)
View(imp2)
# First, turn the datasets into long format
# This procedure is, best I can tell, unique to mice and wouldn't work for repeated measures designs
mimp_long <- mice::complete(imp2, action="long", include = TRUE)
View(mimp_long)
p_missing_mimp_long <- unlist(lapply(mimp_long, function(x) sum(is.na(x))))/nrow(mimp_long)
sort(p_missing_mimp_long[p_missing_mimp_long > 0], decreasing = TRUE)#check to see if this works
mimp_long<- mimp_long %>%
mutate(rBlst_1 = 8 - Blst_1) #if you had multiple items, you could add a pipe (%>%) at the end of the line and add more until the last one
#Making the list of variables
Belonging_vars <- c('Belong_1','Belong_2','Belong_3')
ResponseBL_vars <- c('rBlst_1', 'Blst_4','Blst_6')
StigmaBL_vars <- c('Blst_2', 'Blst_3','Blst_5')
ClimateBL_vars <- c('rBlst_1', 'Blst_4','Blst_6','Blst_2', 'Blst_3','Blst_5' )
#Creating the new variables
mimp_long$Belonging <- sjstats::mean_n(mimp_long[,Belonging_vars], .65)
mimp_long$ResponseBL <- sjstats::mean_n(mimp_long[,ResponseBL_vars], .80)
mimp_long$StigmaBL <- sjstats::mean_n(mimp_long[,StigmaBL_vars], .80)
mimp_long$ClimateBL <- sjstats::mean_n(mimp_long[,ClimateBL_vars], .80)
# Convert to mids type - mice can work with this type
mimp_mids<-as.mids(mimp_long)
fitimp <- with(mimp_mids,
lm(ClimateBL ~ Belonging + cmBlack + iBIPOC_pr))
# to get the 5, individual imputations
summary(fitimp)
pool(fitimp)
summary(pool(fitimp))
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
summary(pool(fitimp))
options(scipen=999)
options(scipen=999)
raw <- readRDS("ReC.rds")
nrow(raw)
View(raw)
#testing to see if my code worked
#raw <- dplyr::filter (raw, SPFC.Decolonize.Opt.Out != "Okay")
raw <- dplyr::filter (raw, SPFC.Decolonize.Opt.Out != "Opt Out")
raw <-dplyr::filter (raw, Course == "Multivariate")
nrow(raw)
mimp_df <-dplyr::select (raw, deID, StatsPkg, Centering,ClearResponsibilities, EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation, InclusvClassrm, EquitableEval, MultPerspectives, DEIintegration, Dept, OvInstructor, MyContribution, IncrInterest, IncrUnderstanding)
str(mimp_df)
mimp_df$Dept <- factor(mimp_df$Dept, levels = c("CPY", "ORG"))
str(mimp_df$Dept)
mimp_df$nmiss <- mimp_df%>%
select(StatsPkg:IncrUnderstanding) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
library(tidyverse)
#Calculating number and proportion of item-level missingness
mimp_df$nmiss <- mimp_df%>%
select(StatsPkg:IncrUnderstanding) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
is.na %>%
rowSums
View(mimp_df)
mimp_df<- mimp_df%>%
dplyr::mutate(prop_miss = (nmiss/13)*100)
mimp_df <- filter(mimp_df, prop_miss <= 50)
mimp_df <-  dplyr::select(mimp_df, deID, StatsPkg, Centering,ClearResponsibilities, EffectiveAnswers, Feedback, ClearOrganization, ClearPresentation, InclusvClassrm, EquitableEval, MultPerspectives, DEIintegration, Dept, OvInstructor, MyContribution, IncrInterest, IncrUnderstanding)
set.seed(2309034) #you can pick any number you want, today I'm using today's datestamp
library(mice)
# runs the mice code with 0 iterations
imp <- mice(mimp_df, maxit = 0)
# Extract predictor Matrix and methods of imputation
predM = imp$predictorMatrix
meth = imp$method
log = imp$log
library(mice)
# runs the mice code with 0 iterations
imp <- mice(mimp_df, maxit = 0)
# Extract predictor Matrix and methods of imputation
predM = imp$predictorMatrix
meth = imp$method
log = imp$log
#These variables are left in the dataset, but setting them = 0 means they are not used as predictors.
#We want our ID to be retained in the df.  There's nothing missing from it, and we don't want it used as a predictor, so it will just hang out.
predM[, c("deID")]=0
#If you like, view the first few rows of the predictor matrix
#head(predM)
#We don't have any ordered categorical variables, but if we did we would follow this format
#poly <- c("Var1", "Var2")
#We have three dichotomous variables
log <- c("StatsPkg", "Centering", "Dept")
#Unordered categorical variables (nominal variables), but if we did we would follow this format
#poly2 <- c("format")
#Turn their methods matrix into the specified imputation models
#Remove the hashtag if you have any of these variables
#meth[poly] = "polr"
meth[log] = "logreg"
#meth[poly2] = "polyreg"
meth
# With this command, we tell mice to impute the anesimpor2 data, create 5vvdatasets, use predM as the predictor matrix and don't print the imputation process.
#If you would like to see the process (or if the process is failing to execute) set print as TRUE; seeing where the execution halts can point to problematic variables (more notes at end of lecture)
imp2 <- mice(mimp_df, maxit = 5,
predictorMatrix = predM,
method = meth,
log = log,
print =  FALSE)
View(imp2)
# First, turn the datasets into long format
# This procedure is, best I can tell, unique to mice and wouldn't work for repeated measures designs
mimp_long <- mice::complete(imp2, action="long", include = TRUE)
View(mimp_long)
p_missing_mimp_long <- unlist(lapply(mimp_long, function(x) sum(is.na(x))))/nrow(mimp_long)
sort(p_missing_mimp_long[p_missing_mimp_long > 0], decreasing = TRUE)#check to see if this works
#this seems to work when I build the book, but not in "working the problem"
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#mimp_long$TradPed <- sjstats::mean_n(mimp_long[, TradPed_vars], .75)
#this seems to work when I "work the problem" (but not when I build the book)
#the difference is the two dots before the last SRPed_vars
mimp_long$TradPed <- sjstats::mean_n(mimp_long[, TradPed_vars], .75)
#this seems to work when I build the book, but not in "working the problem"
#SRPed_vars <- c('InclusvClassrm','EquitableEval', 'MultPerspectives', 'DEIintegration')
#mimp_long$SRPed <- sjstats::mean_n(mimp_long[, SRPed_vars], .75)
#this seems to work when I "work the problem" (but not when I build the book)
#the difference is the two dots before the last SRPed_vars
SRPed_vars <- c('InclusvClassrm','EquitableEval', 'MultPerspectives', 'DEIintegration')
mimp_long$SRPed <- sjstats::mean_n(mimp_long[, SRPed_vars], .75)
# Convert to mids type - mice can work with this type
mimp_mids<-as.mids(mimp_long)
fitimp <- with(mimp_mids,
lm(SRPed ~ StatsPkg + Centering + TradPed))
# to get the 5, individual imputations
summary(fitimp)
summary(pool(fitimp))
