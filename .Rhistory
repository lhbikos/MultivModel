# runs the mice code with 0 iterations
imp <- mice(mimp_df, maxit = 0)
# Extract predictor Matrix and methods of imputation
predM = imp$predictorMatrix
meth = imp$method
log = imp$log
#These variables are left in the dataset, but setting them = 0 means they are not used as predictors.
#We want our ID to be retained in the df.  There's nothing missing from it, and we don't want it used as a predictor, so it will just hang out.
predM[, c("deID")]=0
#If you like, view the first few rows of the predictor matrix
#head(predM)
#We don't have any ordered categorical variables, but if we did we would follow this format
#poly <- c("Var1", "Var2")
#We have three dichotomous variables
log <- c("StatsPkg", "Centering", "Dept")
#Unordered categorical variables (nominal variables), but if we did we would follow this format
#poly2 <- c("format")
#Turn their methods matrix into the specified imputation models
#Remove the hashtag if you have any of these variables
#meth[poly] = "polr"
meth[log] = "logreg"
#meth[poly2] = "polyreg"
meth
# With this command, we tell mice to impute the anesimpor2 data, create 5vvdatasets, use predM as the predictor matrix and don't print the imputation process.
#If you would like to see the process (or if the process is failing to execute) set print as TRUE; seeing where the execution halts can point to problematic variables (more notes at end of lecture)
imp2 <- mice(mimp_df, maxit = 5,
predictorMatrix = predM,
method = meth,
log = log,
print =  FALSE)
View(imp2)
# First, turn the datasets into long format
# This procedure is, best I can tell, unique to mice and wouldn't work for repeated measures designs
mimp_long <- mice::complete(imp2, action="long", include = TRUE)
View(mimp_long)
p_missing_mimp_long <- unlist(lapply(mimp_long, function(x) sum(is.na(x))))/nrow(mimp_long)
sort(p_missing_mimp_long[p_missing_mimp_long > 0], decreasing = TRUE)#check to see if this works
#this seems to work when I build the book, but not in "working the problem"
TradPed_vars <- c('ClearResponsibilities', 'EffectiveAnswers','Feedback', 'ClearOrganization','ClearPresentation')
#mimp_long$TradPed <- sjstats::mean_n(mimp_long[, TradPed_vars], .75)
#this seems to work when I "work the problem" (but not when I build the book)
#the difference is the two dots before the last SRPed_vars
mimp_long$TradPed <- sjstats::mean_n(mimp_long[, TradPed_vars], .75)
#this seems to work when I build the book, but not in "working the problem"
#SRPed_vars <- c('InclusvClassrm','EquitableEval', 'MultPerspectives', 'DEIintegration')
#mimp_long$SRPed <- sjstats::mean_n(mimp_long[, SRPed_vars], .75)
#this seems to work when I "work the problem" (but not when I build the book)
#the difference is the two dots before the last SRPed_vars
SRPed_vars <- c('InclusvClassrm','EquitableEval', 'MultPerspectives', 'DEIintegration')
mimp_long$SRPed <- sjstats::mean_n(mimp_long[, SRPed_vars], .75)
# Convert to mids type - mice can work with this type
mimp_mids<-as.mids(mimp_long)
fitimp <- with(mimp_mids,
lm(SRPed ~ StatsPkg + Centering + TradPed))
# to get the 5, individual imputations
summary(fitimp)
summary(pool(fitimp))
set.seed(2023)
# sample size, M and SD for each group
Accurate <- c(rnorm(30, mean = 1.18, sd = 0.8), rnorm(30, mean = 1.83,
sd = 0.58), rnorm(30, mean = 1.76, sd = 0.56))
# set upper bound for DV
Accurate[Accurate > 3] <- 3
# set lower bound for DV
Accurate[Accurate < 0] <- 0
# IDs for participants
ID <- factor(seq(1, 90))
# name factors and identify how many in each group; should be in same
# order as first row of script
COND <- c(rep("High", 30), rep("Low", 30), rep("Control", 30))
# groups the 3 variables into a single df: ID, DV, condition
Acc_sim30B <- data.frame(ID, COND, Accurate)
write.table(Acc_sim30B, file = "to_CSVb.csv", sep = ",", col.names = TRUE,
row.names = FALSE)
saveRDS(Acc_sim30B, "to_RobjectB.rds")
from_CSV <- read.csv("to_CSVb.csv", header = TRUE)
from_rds <- readRDS("to_RobjectB.rds")
psych::describe(from_CSV)
psych::describe(from_rds)
set.seed(2025)
# sample size, M and SD for each group
Accurate <- c(rnorm(30, mean = 1.18, sd = 0.8), rnorm(30, mean = 1.83,
sd = 0.58), rnorm(30, mean = 1.76, sd = 0.56))
# set upper bound for DV
Accurate[Accurate > 3] <- 3
# set lower bound for DV
Accurate[Accurate < 0] <- 0
# IDs for participants
ID <- factor(seq(1, 90))
# name factors and identify how many in each group; should be in same
# order as first row of script
COND <- c(rep("High", 30), rep("Low", 30), rep("Control", 30))
# groups the 3 variables into a single df: ID, DV, condition
Acc_sim30B <- data.frame(ID, COND, Accurate)
write.table(Acc_sim30B, file = "to_CSVb.csv", sep = ",", col.names = TRUE,
row.names = FALSE)
saveRDS(Acc_sim30B, "to_RobjectB.rds")
from_CSV <- read.csv("to_CSVb.csv", header = TRUE)
from_rds <- readRDS("to_RobjectB.rds")
psych::describe(from_CSV)
psych::describe(from_rds)
raw <- readRDS("MADdf.rds")
nrow(raw)
View(raw)
raw <-(dplyr::filter(raw, Index == 1))
nrow(raw)
raw <- dplyr::rename(raw, myFMprop = 'Wearing_Prop')
raw <- dplyr::rename(raw, WearingProp = 'myFMprop')
raw <- dplyr::rename(raw, mCases = 'MetricCases')
raw <- dplyr::rename(raw, WearingProp = 'myFMprop')
options(scipen=999)
raw <- readRDS("MADdf.rds")
nrow(raw)
#testing to see if my code worked
#raw <- dplyr::filter (raw, Consent == "Yes")
#or, if the value is numerical
#raw <- dplyr::filter (raw, Consent == 1)
raw <-(dplyr::filter(raw, Index == 1))
nrow(raw)
raw <- dplyr::rename(raw, WearingProp = 'myFMprop')
raw <- dplyr::rename(raw, MetricCases = 'mCases')
raw <- readRDS("MADdf.rds")
nrow(raw)
raw <-(dplyr::filter(raw, Index == 1))
nrow(raw)
raw <- readRDS("dfl4.rds")
View(raw)
raw <- readRDS("maskdfl.rds")
View(raw)
View(raw)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
#will install the package if not already installed
if(!require(apaTables)){install.packages("apaTables")}
if(!require(lavaan)){install.packages("lavaan")}
if(!require(semPlot)){install.packages("semPlot")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(psych)){install.packages("psych")}
if(!require(jtools)){install.packages("jtools")}
set.seed(210410)
X <- rnorm(100)
Y <- -.5*X + rnorm(100)
Data <- data.frame(X = X, Y = Y)
regressionFig <- list()
emphCol <- rgb(0,0,1)
emphColLight <- rgb(.5,.5,1)
emphGrey <- grey(.5)
eps <- TRUE
colour <- TRUE
width <- 6
height <- 6
#load(file.path(projecthome, "data","parenthood.Rdata"))
drawBasicScatterplot <- function(dotcol,title) {
plot( Data$Y,
Data$X,
xlab = "Independent Variable",
ylab = "Dependent Variable",
col= dotcol,
main = title,
font.main=1,
pch=19)
}
#drawBasicScatterplot( emphGrey, "Illustration of Least Squares Criteria" )
good.coef <- lm( Y ~ X, Data)$coef
#abline( good.coef, col=ifelse(colour,emphCol,"black"), lwd=3 )
drawBasicScatterplot( emphGrey, "Illustration of Least Squares Criteria" )
abline( good.coef, col=ifelse(colour,emphCol,"black"), lwd=3 )
for(i in seq_along(Data$Y)) {
xval <- Data$X[i]*c(1,1)
yval <- c(Data$Y[i],good.coef[1]+good.coef[2]*Data$Y[i])
lines(xval,yval,type='l', col = emphGrey)
}
#?lm
#Entering the intercorrelations, means, and standard deviations from the journal article
mu <- c(.34, 3.00, 2.98, 2.36, 3.50, 1.64)
sd <- c(.16, .83, .99, .90, .90, .53)
r_mat <- matrix (c(1,   .59, .26,   .34,  -.25, -.02,
.59, 1.00, .12,   .19,  -.28, .00,
.26,  .12, 1.00, .66,  -.55, .07,
.34,  .19, .66,  1.00, -.66, .05,
-.25, -.28, -.55,-.66,  1.00, .08,
-.02,  .00,  .07, .05, .08,  1), ncol = 6)
#Creating a covariance matrix
cov_mat <- sd %*% t(sd) * r_mat
#Set random seed so that the following matrix always gets the same results.
set.seed(210409)
library(MASS)
Kim_df <- mvrnorm(n = 156, mu=mu, Sigma = cov_mat, empirical = TRUE)
#renaming the variables
as.data.frame(Kim_df, row.names = NULL, optional = FALSE, make.names = TRUE)
library(tidyverse)
Kim_df <- Kim_df%>%
as.data.frame %>%
rename(REMS = V1, CMI = V2, ANX = V3, DEP = V4, PWB = V5, HlpSk = V6)
#Checking our work against the original correlation matrix
#round(cor(Kim_df),3)
library(apaTables)
apa.cor.table(Kim_df)
# to write it to a word file, add this to the script:  filename = "ex.CorTable1.doc"
library(psych)
psych::pairs.panels(Kim_df)
library(jtools) #the summ function creates a terrific regression table
library(interactions)
library(ggplot2)
KimSimpMod <- lm(ANX~REMS*HlpSk, data=Kim_df)
#summary(KimSimpMod)
KimSimpMod_summ <- summ(KimSimpMod, digits = 3)
KimSimpMod_summ
#str(KimSimpMod_summ)
interact_plot(KimSimpMod, pred = HlpSk, modx = REMS)
interact_plot(KimSimpMod, pred = REMS, modx = HlpSk)
sim_slopes(KimSimpMod, pred = REMS, modx = HlpSk)
#sim_slopes(KimSimpMod, pred=GRIcntlty, modx = GRMS) #sometimes I like to look at it in reverse -- like in the plots
library(lavaan)
set.seed(210501)
KimSimpModMLE <- '
ANX ~ b1*REMS + b2*HlpSk + b3*REMS:HlpSk
#intercept (constant) of ANX
ANX ~ ANX.mean*1
#mean of W (HlpSk, in this case) for use in simple slopes
HlpSk ~ HlpSk.mean*1
#variance of W (age, in this case) for use in simple slopes
HlpSk ~~HlpSk.var*HlpSk
#simple slopes
SD.below := b1 + b3*(HlpSk.mean - sqrt(HlpSk.var))
mean := b1 + b3*(HlpSk.mean)
SD.above := b1 + b3*(HlpSk.mean + sqrt(HlpSk.var))
'
kMLE_fit <- sem(KimSimpModMLE, data = Kim_df, missing = 'fiml', se = "bootstrap", bootstrap = 1000)
k1summary <- summary(kMLE_fit, standardized = TRUE, rsq=T, ci=TRUE)
library(lavaan)
set.seed(210501)
KimSimpModMLE <- '
ANX ~ b1*REMS + b2*HlpSk + b3*REMS:HlpSk
#intercept (constant) of ANX
ANX ~ ANX.mean*1
#mean of W (HlpSk, in this case) for use in simple slopes
HlpSk ~ HlpSk.mean*1
#variance of W (age, in this case) for use in simple slopes
HlpSk ~~HlpSk.var*HlpSk
#simple slopes
SD.below := b1 + b3*(HlpSk.mean - sqrt(HlpSk.var))
mean := b1 + b3*(HlpSk.mean)
SD.above := b1 + b3*(HlpSk.mean + sqrt(HlpSk.var))
'
kMLE_fit <- sem(KimSimpModMLE, data = Kim_df,  se = "bootstrap", bootstrap = 1000)
k1summary <- summary(kMLE_fit, standardized = TRUE, rsq=T, ci=TRUE)
library(lavaan)
set.seed(210501)
KimSimpModMLE <- '
ANX ~ b1*REMS + b2*HlpSk + b3*REMS:HlpSk
#intercept (constant) of ANX
ANX ~ ANX.mean*1
#mean of W (HlpSk, in this case) for use in simple slopes
HlpSk ~ HlpSk.mean*1
#variance of W (age, in this case) for use in simple slopes
HlpSk ~~HlpSk.var*HlpSk
#simple slopes
SD.below := b1 + b3*(HlpSk.mean - sqrt(HlpSk.var))
mean := b1 + b3*(HlpSk.mean)
SD.above := b1 + b3*(HlpSk.mean + sqrt(HlpSk.var))
'
kMLE_fit <- sem(KimSimpModMLE, data = Kim_df, missing = 'fiml', se = "bootstrap", bootstrap = 1000)
k1summary <- summary(kMLE_fit, standardized = TRUE, rsq=T, ci=TRUE)
library(lavaan)
set.seed(210501)
KimSimpModMLE <- '
ANX ~ b1*REMS + b2*HlpSk + b3*REMS:HlpSk
#intercept (constant) of ANX
ANX ~ ANX.mean*1
#mean of W (HlpSk, in this case) for use in simple slopes
HlpSk ~ HlpSk.mean*1
#variance of W (age, in this case) for use in simple slopes
HlpSk ~~HlpSk.var*HlpSk
#simple slopes
SD.below := b1 + b3*(HlpSk.mean - sqrt(HlpSk.var))
mean := b1 + b3*(HlpSk.mean)
SD.above := b1 + b3*(HlpSk.mean + sqrt(HlpSk.var))
'
kMLE_fit <- sem(KimSimpModMLE, data = Kim_df, missing = 'fiml', se = "bootstrap", bootstrap = 1000)
#k1summary <- summary(kMLE_fit, standardized = TRUE, rsq=T, ci=TRUE)
k1ParamEsts <- parameterEstimates(kMLE_fit, boot.ci.type = "bca.simple", standardized=TRUE)
k1summary
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
#will install the package if not already installed
if(!require(apaTables)){install.packages("apaTables")}
if(!require(lavaan)){install.packages("lavaan")}
if(!require(semPlot)){install.packages("semPlot")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(psych)){install.packages("psych")}
if(!require(jtools)){install.packages("jtools")}
set.seed(210410)
X <- rnorm(100)
Y <- -.5*X + rnorm(100)
Data <- data.frame(X = X, Y = Y)
regressionFig <- list()
emphCol <- rgb(0,0,1)
emphColLight <- rgb(.5,.5,1)
emphGrey <- grey(.5)
eps <- TRUE
colour <- TRUE
width <- 6
height <- 6
#load(file.path(projecthome, "data","parenthood.Rdata"))
drawBasicScatterplot <- function(dotcol,title) {
plot( Data$Y,
Data$X,
xlab = "Independent Variable",
ylab = "Dependent Variable",
col= dotcol,
main = title,
font.main=1,
pch=19)
}
#drawBasicScatterplot( emphGrey, "Illustration of Least Squares Criteria" )
good.coef <- lm( Y ~ X, Data)$coef
#abline( good.coef, col=ifelse(colour,emphCol,"black"), lwd=3 )
drawBasicScatterplot( emphGrey, "Illustration of Least Squares Criteria" )
abline( good.coef, col=ifelse(colour,emphCol,"black"), lwd=3 )
for(i in seq_along(Data$Y)) {
xval <- Data$X[i]*c(1,1)
yval <- c(Data$Y[i],good.coef[1]+good.coef[2]*Data$Y[i])
lines(xval,yval,type='l', col = emphGrey)
}
#?lm
#Entering the intercorrelations, means, and standard deviations from the journal article
mu <- c(.34, 3.00, 2.98, 2.36, 3.50, 1.64)
sd <- c(.16, .83, .99, .90, .90, .53)
r_mat <- matrix (c(1,   .59, .26,   .34,  -.25, -.02,
.59, 1.00, .12,   .19,  -.28, .00,
.26,  .12, 1.00, .66,  -.55, .07,
.34,  .19, .66,  1.00, -.66, .05,
-.25, -.28, -.55,-.66,  1.00, .08,
-.02,  .00,  .07, .05, .08,  1), ncol = 6)
#Creating a covariance matrix
cov_mat <- sd %*% t(sd) * r_mat
#Set random seed so that the following matrix always gets the same results.
set.seed(210409)
library(MASS)
Kim_df <- mvrnorm(n = 156, mu=mu, Sigma = cov_mat, empirical = TRUE)
#renaming the variables
as.data.frame(Kim_df, row.names = NULL, optional = FALSE, make.names = TRUE)
library(tidyverse)
Kim_df <- Kim_df%>%
as.data.frame %>%
rename(REMS = V1, CMI = V2, ANX = V3, DEP = V4, PWB = V5, HlpSk = V6)
#Checking our work against the original correlation matrix
#round(cor(Kim_df),3)
library(apaTables)
apa.cor.table(Kim_df)
# to write it to a word file, add this to the script:  filename = "ex.CorTable1.doc"
library(psych)
psych::pairs.panels(Kim_df)
library(jtools) #the summ function creates a terrific regression table
library(interactions)
library(ggplot2)
KimSimpMod <- lm(ANX~REMS*HlpSk, data=Kim_df)
#summary(KimSimpMod)
KimSimpMod_summ <- summ(KimSimpMod, digits = 3)
KimSimpMod_summ
#str(KimSimpMod_summ)
interact_plot(KimSimpMod, pred = HlpSk, modx = REMS)
interact_plot(KimSimpMod, pred = REMS, modx = HlpSk)
sim_slopes(KimSimpMod, pred = REMS, modx = HlpSk)
#sim_slopes(KimSimpMod, pred=GRIcntlty, modx = GRMS) #sometimes I like to look at it in reverse -- like in the plots
library(lavaan)
set.seed(210501)
KimSimpModMLE <- '
ANX ~ b1*REMS + b2*HlpSk + b3*REMS:HlpSk
#intercept (constant) of ANX
ANX ~ ANX.mean*1
#mean of W (HlpSk, in this case) for use in simple slopes
HlpSk ~ HlpSk.mean*1
#variance of W (age, in this case) for use in simple slopes
HlpSk ~~HlpSk.var*HlpSk
#simple slopes
SD.below := b1 + b3*(HlpSk.mean - sqrt(HlpSk.var))
mean := b1 + b3*(HlpSk.mean)
SD.above := b1 + b3*(HlpSk.mean + sqrt(HlpSk.var))
'
kMLE_fit <- sem(KimSimpModMLE, data = Kim_df, missing = 'fiml', se = "bootstrap", bootstrap = 1000)
#k1summary <- summary(kMLE_fit, standardized = TRUE, rsq=T, ci=TRUE)
k1ParamEsts <- parameterEstimates(kMLE_fit, boot.ci.type = "bca.simple", standardized=TRUE)
#k1summary
k1ParamEsts
library(lavaan)
set.seed(210501)
KimSimpModMLE <- '
ANX ~ b1*REMS + b2*HlpSk + b3*REMS:HlpSk
#intercept (constant) of ANX
ANX ~ ANX.mean*1
#mean of W (HlpSk, in this case) for use in simple slopes
HlpSk ~ HlpSk.mean*1
#variance of W (age, in this case) for use in simple slopes
HlpSk ~~HlpSk.var*HlpSk
#simple slopes
SD.below := b1 + b3*(HlpSk.mean - sqrt(HlpSk.var))
mean := b1 + b3*(HlpSk.mean)
SD.above := b1 + b3*(HlpSk.mean + sqrt(HlpSk.var))
'
kMLE_fit <- sem(KimSimpModMLE, data = Kim_df, missing = 'fiml', se = "bootstrap", bootstrap = 1000)
k1summary <- summary(kMLE_fit, standardized = TRUE,  ci=TRUE)
k1ParamEsts <- parameterEstimates(kMLE_fit, boot.ci.type = "bca.simple", standardized=TRUE)
k1summary
k1ParamEsts
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(comment = NA) #keeps out the hashtags in the knits
options(scipen=999)#eliminates scientific notation
#will install the package if not already installed
if(!require(apaTables)){install.packages("apaTables")}
if(!require(lavaan)){install.packages("lavaan")}
if(!require(semPlot)){install.packages("semPlot")}
if(!require(tidyverse)){install.packages("tidyverse")}
if(!require(psych)){install.packages("psych")}
if(!require(jtools)){install.packages("jtools")}
set.seed(210410)
X <- rnorm(100)
Y <- -.5*X + rnorm(100)
Data <- data.frame(X = X, Y = Y)
regressionFig <- list()
emphCol <- rgb(0,0,1)
emphColLight <- rgb(.5,.5,1)
emphGrey <- grey(.5)
eps <- TRUE
colour <- TRUE
width <- 6
height <- 6
#load(file.path(projecthome, "data","parenthood.Rdata"))
drawBasicScatterplot <- function(dotcol,title) {
plot( Data$Y,
Data$X,
xlab = "Independent Variable",
ylab = "Dependent Variable",
col= dotcol,
main = title,
font.main=1,
pch=19)
}
#drawBasicScatterplot( emphGrey, "Illustration of Least Squares Criteria" )
good.coef <- lm( Y ~ X, Data)$coef
#abline( good.coef, col=ifelse(colour,emphCol,"black"), lwd=3 )
drawBasicScatterplot( emphGrey, "Illustration of Least Squares Criteria" )
abline( good.coef, col=ifelse(colour,emphCol,"black"), lwd=3 )
for(i in seq_along(Data$Y)) {
xval <- Data$X[i]*c(1,1)
yval <- c(Data$Y[i],good.coef[1]+good.coef[2]*Data$Y[i])
lines(xval,yval,type='l', col = emphGrey)
}
#?lm
#Entering the intercorrelations, means, and standard deviations from the journal article
mu <- c(.34, 3.00, 2.98, 2.36, 3.50, 1.64)
sd <- c(.16, .83, .99, .90, .90, .53)
r_mat <- matrix (c(1,   .59, .26,   .34,  -.25, -.02,
.59, 1.00, .12,   .19,  -.28, .00,
.26,  .12, 1.00, .66,  -.55, .07,
.34,  .19, .66,  1.00, -.66, .05,
-.25, -.28, -.55,-.66,  1.00, .08,
-.02,  .00,  .07, .05, .08,  1), ncol = 6)
#Creating a covariance matrix
cov_mat <- sd %*% t(sd) * r_mat
#Set random seed so that the following matrix always gets the same results.
set.seed(210409)
library(MASS)
Kim_df <- mvrnorm(n = 156, mu=mu, Sigma = cov_mat, empirical = TRUE)
#renaming the variables
as.data.frame(Kim_df, row.names = NULL, optional = FALSE, make.names = TRUE)
library(tidyverse)
Kim_df <- Kim_df%>%
as.data.frame %>%
rename(REMS = V1, CMI = V2, ANX = V3, DEP = V4, PWB = V5, HlpSk = V6)
#Checking our work against the original correlation matrix
#round(cor(Kim_df),3)
library(apaTables)
apa.cor.table(Kim_df)
# to write it to a word file, add this to the script:  filename = "ex.CorTable1.doc"
library(psych)
psych::pairs.panels(Kim_df)
library(jtools) #the summ function creates a terrific regression table
library(interactions)
library(ggplot2)
KimSimpMod <- lm(ANX~REMS*HlpSk, data=Kim_df)
#summary(KimSimpMod)
KimSimpMod_summ <- summ(KimSimpMod, digits = 3)
KimSimpMod_summ
#str(KimSimpMod_summ)
interact_plot(KimSimpMod, pred = HlpSk, modx = REMS)
interact_plot(KimSimpMod, pred = REMS, modx = HlpSk)
sim_slopes(KimSimpMod, pred = REMS, modx = HlpSk)
#sim_slopes(KimSimpMod, pred=GRIcntlty, modx = GRMS) #sometimes I like to look at it in reverse -- like in the plots
library(lavaan)
set.seed(210501)
KimSimpModMLE <- '
ANX ~ b1*REMS + b2*HlpSk + b3*REMS:HlpSk
#intercept (constant) of ANX
ANX ~ ANX.mean*1
#mean of W (HlpSk, in this case) for use in simple slopes
HlpSk ~ HlpSk.mean*1
#variance of W (age, in this case) for use in simple slopes
HlpSk ~~HlpSk.var*HlpSk
#simple slopes
SD.below := b1 + b3*(HlpSk.mean - sqrt(HlpSk.var))
mean := b1 + b3*(HlpSk.mean)
SD.above := b1 + b3*(HlpSk.mean + sqrt(HlpSk.var))
'
kMLE_fit <- lavaan::sem(KimSimpModMLE, data = Kim_df, missing = 'fiml', se = "bootstrap", bootstrap = 1000)
k1summary <- lavaan::summary(kMLE_fit, standardized = TRUE,  ci=TRUE)
k1ParamEsts <- lavaan::parameterEstimates(kMLE_fit, boot.ci.type = "bca.simple", standardized=TRUE)
k1summary
k1ParamEsts
