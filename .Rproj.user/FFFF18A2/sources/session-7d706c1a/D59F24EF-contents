```{r include = FALSE}
options(scipen=999)
```

## Homeworked Example


The one-sample test comes in handy when you want to compare your dataset to an external benchmark or standard. It can be a real helper in program evaluation

### Working the Problem with R and R Packages

#### Narrate the research vignette, describing the variables and their role in the analysis {-}

We learned from our review of the literature that the 90% of Americans were wearing facemasks. Unfortunately, there isn't a "comparable" number (that we can find). For the purpose of this comparison, we'll compare our data to a benchmark of 90%.

#### Simulate (or import) and format data {-}

First I will open the entire dataset.

```{r}
MADdf <- readRDS("MADdf.rds")
```

Participants in this study could contribute up to 24 pieces of data. I will just select wave one

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
w1MAD <- subset(MADdf, Index == 1) 
```


I will trim the dataset to our variable of interest.
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
library(tidyverse)
w1MAD <- w1MAD %>%
    dplyr::select (myFMprop)
```

And further trim to non-missing data
```{r}
w1MAD <- na.omit(w1MAD)
```

* Is the sample variable on a continuous scale of measurement and formatted as *num* or *int* in R?
* Is the external score evaluated on the same continuous scale?
```{r}
str(w1MAD$myFMprop)
```
Yes. The format for the proportion of time wearing a facemask variable is integer (which is numerical).


#### Evaluate statistical assumptions {-}

* Are the skew and kurtosis values within the range expected?
* Does the distribution of the variable differ significantly from a normal distribution?

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pastecs::stat.desc(w1MAD$myFMprop, norm=TRUE)
```


The skew value is -1.254 and is below the absolute value of 3. The skew.2SE is -3.309 and larger than the absolute value of 2.0. Thus, we might have some negative skew (with pileup of scores on the high-side -- most people wearing masks).

The kurtosis value is 0.156 and is below the absolute value of 10. The kurt.2SE value is 0.206 which is below the absolute value of 2.0. Thus, we are not concerned about kurtosis.

The Shapiro Wilk test value is 0.732 (*p* < 0.001). This significant value suggests a distribution that is not normally distributed.


#### Conduct a one sample *t* test (with an effect size) {-}

We will compare the overall instructor from the data to the CPY average of 4.4.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
rstatix::t_test(w1MAD, myFMprop ~ 1, mu = 90, detailed = TRUE)
```
We can begin to create our *t* string:

$t(163) = -5.156, p < 0.001, CI95(72.331, 82.118)$  

Let's interpret the results.  With 163 degrees of freedom, our *t* value is -5.156. Because the *p* value is less than .05, this is statistically significant. This means that in the early weeks of the pandemic,  participants were wearing facemasks less than the benchmark of 90% of the time.  We are 95% confident that the true mean of facemask wearing for participants in our study (in those early weeks of the pandemic) ranged between 72% and 82% of the time.

Let's calculate the effect size. We will use a Cohen's *d* which is interpreted in standard deviation units. 
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
rstatix::cohens_d(w1MAD, myFMprop ~ 1, ref.group = NULL, mu = 90)
```
Cohen's *d* was -0.403. This is a small effect. We can add it to the *t* string. 

$t(163) = -5.156, p < 0.001, CI95(72.331, 82.118), d = -0.403$  


#### APA style results with table(s) and figure {-}

* t-test results should include t, df, p, d-or-eta, and CI95%
* Table
* Figure
* Grammar/style

>A one-sample *t*-test was used to evaluate whether the proportion of time that research participants (in the early weeks of the pandemic) wore their facemasks in public spaces differed from a benchmark of 90% of the time. In our sample, participants wore facemasks 77.23% of the time (*SD* = 31.73). Although this mean was statistically significantly different from the average CPY course evaluation ratings of the same item, $t(163) = -5.156, p < 0.001, CI95(72.331, 82.118)$, the effect size was quite small $(d = -0.403)$. A distribution of the ANOVA course ratings is found in Figure 1.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
ggpubr::ggboxplot(w1MAD$myFMprop, ylab = "Facemask Wearing Proportion", xlab = FALSE, add = "jitter", title = "Figure 1. Wearing Facemasks in the COVID-19 Pandemic")
```

#### Conduct power analyses to determine the power of the current study and a recommended sample size {-}

A quick reminder that the *d* in the power analysis is the difference between the means divided by the pooled standard deviation. This is the same as Cohen's d that we just calculated.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pwr::pwr.t.test(d = -0.403	, n = 164, power = NULL, sig.level = 0.05, type = "one.sample", alternative = "two.sided")
```

For the comparison to the CPY departmental average, power was 99.9%. That is, given the value of the mean difference relative to the pooled standard deviation we had a 99.9% chance of detecting a statistically significant effect if there was one.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
pwr::pwr.t.test(d = 0.403, n = NULL, power = 0.8, sig.level = 0.05, type = "one.sample", alternative = "two.sided")
```
For the CPY departmental comparison, the recommended sample size would be 50 This means there would need to be 50 individuals to find a statistically significant difference, if one existed (at a power of 80%).

### Hand Calculations

#### Using traditional NHST (null hypothesis testing language), state your null and alternative hypotheses {-}

$$
\begin{array}{ll}
H_0: & \mu = 90 \\
H_A: & \mu \neq 90
\end{array}
$$

#### Calculate the mean of your sample; identify the mean of your benchmarking sample {-}

I will continue with the *w1MAD* dataset and calculate the mean of the myFMprop variable from my w1MAD df.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
mean(w1MAD$myFMprop, na.rm=TRUE)
```

The mean of my benchmarking sample is 90. I pulled this number as a benchmark and did not need to calculate it.

#### Using the steps from the previous lesson, hand-calculate the standard deviation of your sample. This should involve variables representing the mean, mean deviation, and mean deviation squared {-}

$$s=\sqrt{\frac{SS}{N-1}}=\sqrt{\frac{\sum_{i=1}^{n}(X_{i} - \bar{X})^{^{2}}}{N-1}}$$

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
#first the mean
w1MAD$M_myFMprop <- mean(w1MAD$myFMprop, na.rm=TRUE)
#second the mean deviation
w1MAD$Mdev_myFMprop <- (w1MAD$myFMprop-w1MAD$M_myFMprop)
#third the mean deviation squared
w1MAD$mdev2_myFMprop <- (w1MAD$Mdev_myFMprop  * w1MAD$Mdev_myFMprop)
#fourth the variance
var_myFMprop <- sum(w1MAD$mdev2_myFMprop /((nrow(w1MAD) - 1)))
var_myFMprop
#finally the standard deviation
sd_myFMprop <- sqrt(var_myFMprop)
sd_myFMprop

head(w1MAD)
```
The variance is 1006.789; the standard deviation is 31.72994.

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
sd(w1MAD$myFMprop)#checking my work
```

#### Calculate the one-sample *t*-test {-}

Here's the formula:  

$$
t = \frac{\bar{X} - \mu}{\hat{\sigma}/\sqrt{N} }
$$

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
(77.22561 - 90)/(31.72994/sqrt(164))
```

#### Identify the degrees of freedom associated with your *t*-test {-}     

For the one-sample *t*-test, $df = N - 1$. In our case

```{r}
164 - 1
```

#### Locate the test critical value for your test {-}
We can use a table of critical values for the one sample *t*-test:  https://www.statology.org/t-distribution-table/

A 2-tail test, when p - .05, with ~120 individuals is 1.98

Or, this code:

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
qt(p = 0.05/2, df = 163, lower.tail = FALSE)
```
#### Is the *t*-test statistically significant? Why or why not? {-}

Yes *t* = -5.155762 exceeds the (absolute) test critical value of 1.98.

#### What is the confidence interval around your sample mean? {-}

Here is a reminder of the formula:

$$\bar{X} \pm t_{cv}(\frac{s}{\sqrt{n}})$$

```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
(77.22561) - ((1.974625)*(31.72994/sqrt(164)))
(77.22561) + ((1.974625)*(31.72994/sqrt(164)))
```

We are 95% confident that the sample mean for the proportion of time research participants wore their facemasks in public (in the early weeks of the pandemic was between 72 and 82% of the time. 

#### Calculate the effect size (i.e., Cohen's *d* associated with your *t*-test {-}

A reminder of the two formula:

$$d = \frac{Mean Difference}{SD}=\frac{t}{\sqrt{N}}$$
```{r tidy=TRUE, tidy.opts=list(width.cutoff=70)}
#First formula
(77.2256 - 90)/31.72994
#Second formula
-5.155762/sqrt(164)
```
