---
title: "Hayes Ch3_Simple Mediation"
author: "Lynette H. Bikos, PhD, ABPP"
date: "April 15, 2019"
output: word_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

![image](No peaking phd comix.JPG){#id .class width=1200 height=500px}

SCREENCAST LINK:  simpleMed_1  https://spu.techsmithrelay.com/m3xV 

## navigating this lectuRe

###sReencast table
```{r Screencast Links Table, echo=FALSE, warning=FALSE, paged.print=TRUE}
#install.packages("kableExtra")
#install.packages("pander")
#library(knitr)
#library(kableExtra)
library(tidyverse)
library(pander)
sMed_screencasts <- read.csv("simpleMed_links.csv")
pandoc.table(sMed_screencasts, style = "multiline", split.table = Inf, justify = "left", format = docx)
```
About 1' 45" hour of lecture.  Add another 2 hoursfor taking your time, running, and understanding the scripts.


###quiz pRep
Be able to distinguish between definitions for mediator, moderator, covariates, and condition process analysis.  From *lavaan* output, be able to identify and interpret B weights, *p* values, and *CIs* for total, direc, and indirect effects.  Be able to calculate the total effects of X and M on Y.  Be able to identify the proportion of variance accounted for in predicting M and Y.

###planning for youR homewoRk
The homework assignment will be a culmination of the lectures devoted to mediation/estimating indirect effects.  Using any of the datsets provided by Hayes (including the ones demo'd in any of my lectures) you are to do "at least one thing more" (but different than what I did in the lecture) than a simple mediation.  That is, you could 
*  Add one or more covariates to either (or both) the mediator or DV
*  Add at least one variable as a parallel mediation
*  Add at least one variable in a serially mediated model

Extra credit for using 2YP or RVT data.

More complete instructions/grading rubric are in the SP folder in the form of an RMD file.

###Readings & ResouRces
```{r Readings Table, echo=FALSE, warning=FALSE, paged.print=TRUE}
sMed_readings <- read.csv("simpleMed_rdgs.csv")
pandoc.table(sMed_readings, style = "multiline", split.table = Inf, justify = "left", format = docx)
```


###Datasets
pmi.csv
estress.csv

### RMD hygiene RemindeRs

We will be usin R Markdown (RMD) for the base of most lectures and you should be turning in your homework as an RMD file.  My best advice:
1. I will knit (as a .docx) and post a copy of the lecture file.  This will be the community copy and you can ask questions and add comments there.
2. I recommend that you work directly from the RMD file -- you will then have the same format as my screencasted lectures and, so long as you download the associated files and put them in the same file as your RMD file(s), they *should* render without error.
3. Run the code "along with me," but don't stress about recreating it.  Spend your mental power trying to understand what each piece does so you can translate it for the homework assignments (that should be pretty parallel with no sneaky trix).
4. I will post your homework assignments in RMD files.  Complete your homework in these files. Don't stress about knitting them.  You can submit them as a pre-knitted file.
5. Remember to create separate, simple, lightly populated folders for each project (e.g., have a separate folder for your homework than for the leture notes).  Your RMD file(s) and data file(s) should be in that folder and nowhere else.

There are lots of great resources for R Markdown.  Here's a collection of some I liked:
RStudio has a ton of cheat sheets.  Here's the one for R Markdown:  https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf
https://libscie.github.io/rmarkdown-workshop/handout.html 


##Mediation:  Estimating Indirect Effects
SCREENCAST LINK:  simpleMed_2 https://spu.techsmithrelay.com/EHim 

###Just what are we doing with textbook chapters written for SPSS but working the problems in an R package???

**Prayes for Hayes**

*  Early 2000s, the bootstrapped CI was identifed as a more powerful approach to assessing indirect effects than the classic Sobell test...but no one was using it because it programs didn't produce it.
*  Preacher, Edwards, Lambert, Hayes (and colleagues) created these Excel worksheets that would create such (they were awful)
*  Hayes turned this process into a *series* of macros (to do a variety of things...check out his website http://afhayes.com/spss-sas-and-mplus-macros-and-code.html) for SPSS and other programs.  Because of his text, PROCESS probably has the most popularity.

**tRouble is**, we're transitioning from SPSS to R and won't be using SPSS/PROCESS.  But this isn't actually problematic because the package, *lavaan*, used for SEM can easily accomodate the models.  Why *lavaan*?  Yes, I looked at competing packages *processR* and *rockchalk*, but 

* most are trying to mimic the PROCESS format (numbered models), 
* they don't cover all the models,
* we are moving to SEM/CFA anyway, AND MOST IMPORTANTLY,
* turns out, *lavaan* is pretty straightforward. So we might as well get started.  

**But first...**, let's take a look at some of the nuances of the whole SEM world and how it relates to PROCESS.

**SEM** is broad term (that could include CFA and path analysis) but is mostly saved for models with some type of latent variable (some might excude path analysis from its definitions).  SEM typically uses some form of maximum likelihood estimation (not ordinary least squares); more on that in a later lecture (big ideas are that rather than minmizing the error to the regression line they look for the "most likely" solution through a repetitively iterative process).

*Latent variables* (circles in the model, below) are those that are "created" in the analytic process but will never appear as a column in your dataset. It may be easiest to think of a latent variable as a scale score -- where you sum (or average) the indicator item values to get the score (except we don't do that).  Rather, the LV is "indicated" by variance the indicator/observed/manifest variables share with each other.

The image below is of a simple mediation model but the variables in the model are latent, and indicated by each of the 3 observed/manifest variables.  PROCESS (in SPSS) could not assess this model because PROCESS uses ordinary least squares regression and SEM uses (usually) some sort of maximum likelihood estimator.

![image](SEMmod.JPG){#id .class width=300 height=300px}

**Confirmatory factor analysis**, CFA, is what we'll do in psychometrics.  Purely SEM, CFA is used to evaluate the structural validity of a scale or measure.  In pure CFA, first-order factors represent subscales and a second-order factor (not required) might provide support for a total scale score.  It's a little more complicated than this, but this will get you started.  Mediation/indirect effects are not assessed in a pure CFA.

![image](CFAmod.JPG){#id .class width=300 height=300px}

**Path analysis** is a form of SEM, but without latent variables.  That is, all the variables in the model are directly observed.  They are represented by squares/rectangles and each has a corresponding column in a dataset.  PROCESS in SPSS is entirely path analysis.

![image](SimpleMedMod.png){#id .class width=250 height=250px}

**Hybrid models** are a form of SEM that include observed/manifest variables as predictors along with other latent variables.  In the diagram below, you see tiny little measurement models (3 indicators that "create" or "inform" an LV, think baby CFA) and one predictor that is manifest.  An example might be a categorical predictor (e.g., treatment, control).

![image](HybridMod.JPG){#id .class width=300 height=300px}

**PROCESS**

So where does PROCESS fit into this world?

* Ordinary least squares regression.
* But with confidence intervals.
* Can be completed in an SEM program (as path analysis) with either OLS or maximum likelihood answers.
* Note that I used the same figure here as in the path analysis...b/c they are the same.
* Hayes is reluctant to turn us all lose in R world:  
* Found on his FAQ page: http://processmacro.org/faq.html 
*Question:  Is PROCESS available for any program other than SPSS or SAS?  Answer:  I have not produced a version of PROCESS for any other program.  There are some ambitious folks who have attempted to produce versions of PROCESS for R or who provide Mplus code for some of the preprogrammed models.  You can find those online, but they are outdated, in that they don't have any of the new features of PROCESS v3.  I do not attest to and cannot endorse the quality of these translations or their accuracy.*  

![image](SimpleMedMod.png){#id .class width=250 height=250px}


###The definitional and conceptual
SCREENCAST LINK:  simpleMed_3 https://spu.techsmithrelay.com/upcj 

As in Hayes text, we will differentiate between *moderation* and *mediation*.  *Conditional process analysis* is both! With each of these, we are seeking to understand the *mechanism* at work that leads to the relationship (be it correlational, predictive, or causal)

* Relatedly/unrelatedly, even though this process has sometimes been termed *causal modeling*, Hayes argues that his *statistical approach* is not claiming to determine *cause*; that is really left to the argument of the research design. 

**Moderation**:  

* Answers questions of *when* or *for whom* and is often the source of the answer, *it depends*.
* Remember *interaction* from ANOVA
* The effect of X on some variable Y is moderated by W if its size, sign, or strength depends on, or can be predicted, by W.  Then we can say, "W is a *moderator* of X's effect on Y" or "W and X *interact* in their influence on Y."
* In the image below, note the difference between *conceptual* and *statistical* diagrams.

![image](simpleMod.JPG){#id .class width=250 height=500}


**Mediation**:  

* Answers questions of *how* (I also think *through* and *via* to describe the proposed mediating mechanism)
* Paths in a mediation model are *direct* (X does not pass through M on its way to Y) and *indirect* (X passes through M on its way to Y). Once we get into the stats, we will also be focused on *total* effects.
* Hayes thinks in terms of *antecedent* and *consequent* variables. In a 3-variable, simple mediation, X and M are the antecedent variables; X and Y are the consequent variables.  
* Controversy about whether we can say "X is *mediated* through Y" or whether we should say, "There is a statistically significant indirect effect of X on Y thru M."  Hayes comes down on the "use mediation language" side of the debate.  Beware the social psychologists...
* In sum, a simple mediation model is any causal system in which at least one causal antecedent X variable is proposed as influencing an outcome Y through a single intervening variable, M.  In such a model there are two pathways by which X can influence Y.

![image](SimpleMedMod.png){#id .class width=250 height=250px}


**Conditional process analysis**:  Used when the research goal is to understand the boundary conditions of the mechanism(s) by which a variable transmits its effect on another.  Conditional process analysis typically, simultaneously, assesses the influence of mediating (indirect effects) and moderating (interactional effects) in a model-building fashion.

![image](model7pathdiagram.JPG){#id .class width=250 height=180}



### Simple Mediation in *lavaan* -- a focus on the mechanics
SCREENCAST LINK:  simpleMed_4 https://spu.techsmithrelay.com/uSgK


The lavaan tutorial provides a helpful model of how the code should be: http://lavaan.ugent.be/tutorial/index.html 

Several other resources add to the basic code so that the results are more "Hayes-esque.""
https://www.youtube.com/watch?v=-B37sK9NTfI


Running a mediation model involves multiple steps:
1. Create (or upload) the dataframe with the variables in the analysis.
2. Specify the model and translate it into script that R can understand.
3. Estimate the model.
4. View the output
5. Create a figure

Using the lavaan tutorial as our guide, let's start with just a super faky dataframe with variable names that represent X (predictor/IV/antecedent), M (mediator), and Y (outcome, DV, consequent).

The code below is asking to create a datase with a sample size of 100.  The dataset has 3 variables, conveniently named X (predictor, antecedent, IV), M (mediator), and Y (outome, consequent, DV).  The R code asks for random selection of numbers with a normal distribution.  You can see that the M variable will be related to the X variable by+ .5; and the Y variable will be related to the M variable by + .7.  This rather ensures a statistically significant indirect effect.

```{r Faky Daty}
set.seed(1234)
X <- rnorm(100)
M <- 0.5*X + rnorm(100)
Y <- 0.7*M + rnorm(100)
Data <- data.frame(X = X, Y = Y, M = M)
```


The package we are using is lavaan.  

Hayes' model is *path analysis* a form of structural equation modeling.  At the risk of oversimplification, in SPSS, PROCESS is limited to ordinary least squares regression.  Unless noted otherwise, we will use maximum likliehood estimators for the Hayes/PROCESS examples, but lavaan can take us further than PROCESS because
* We can (and will) do latent variable modeling.
* We can have more specificity than the PROCESS models allow.

Hayes text is still a great place to start because the conceptual and procedural information is clear and easily transferrable to the R environment.

```{r install n load lavaan}
#install.packages("lavaan", dependencies=TRUE)
library(lavaan)
```

Our atheoretical dataset makes it easy to identify which variable belongs in each role (X,Y,M).  When specifying the paths in lavaan, here's what to keep in mind: 

* Name your model (below is X, "<-" means "is defined by")
* The model exists between 2 single quotation marks (the odd looking ' and ' at the beginning and end).
* The # of regression equations you need depends on the # of variables that have arrows pointing to them.  In a simple mediation, there are 3 variables with 2 variables having arrows pointing to them -- need 2 regression equations:
  +  one for the Mediator
  +  one for the DV (Y)
* Operator for a regression analysis is the (tilde, ~)
* DV goes on left
  +  In first equation we regress M onto X
  +  In second equation, we regress both the X and M onto Y
* The asterisk (*) is a handy tool to label variables (don't confuse it as an interaction); this labeling as a, b, and c_p (in traditional mediation, the total effect is labeled with a and the direct effect is c'[c prime], but the script won't allow and extra single quotation mark, hence c_p) is super helpful in interpreting the ouput
* Indirect effect is created by multiplying the a and b paths.  
* The ":=" sign is used when creating a new variable that is a function of variables in the model, but not in the datset (i.e., the a and b path).

After specifying the model, we create an object that holds our results from the SEM.  To get all-the-things expected in an analysis of indirect effects, we also need to print a summary of the fit statistics, standardized estimates, r-squared, and confidence intervals.

*Other authors will write the model code more sensibly, predicting the mediator first, and then the Y variable.  However, I found that by doing it this way, the semPlot produces a more sensible figure.*

Also, because we set a random seed, you should get the same results, but if it differs a little, don't panic.
Also, in Hayes text the direct path from X to Y is c' ("c prime"; where as c is reserved for the total effect of X on Y).  *lavaan* code won't allow us to make that designation, so we go, simply, with "c".

SCREENCAST LINK:  simpleMed_5  https://spu.techsmithrelay.com/1sAj 

Before running the full model, I want to step through a more *traditional* way of evaluating indirect effects.  You'll never need to, independently, run this first piece again.  But I want to show you that regressing Y onto X (with no other predictors) produces what we call the *total* effect(traditionally noted with "c"); that is the *total effect of X on Y*.  This is important because in the *logic* (used to be rules/steps; no more) we will hopefully see the direct effect of X on Y be smaller.  Why?  Because the direct effect isolates the unique contribution of X on Y; the direct + indirect effect = the total effect.

```{r}
set.seed(1234)
XY <- '
       Y ~ c*X
      '
XYfit <- sem(XY, data = Data, se="bootstrap")
summary(XYfit, standardized=T, rsq=T, ci=TRUE)
```

So, we see that this c path, where only Y is regressed on X is .410 (*p* = .003).  We'll see this again.

Now, we run the whole model.

```{r Simple Med w Faky Daty}

set.seed(1234)
model <- '
          Y ~ b*M + c_p*X 
          M ~a*X

          indirect :=  a*b
          direct  := c_p
          total_c  := c_p + (a*b)
          '
fit <- sem(model, data = Data, se="bootstrap", missing= 'fiml')
summary(fit, standardized=T, rsq=T, fit=TRUE, ci=TRUE)
parameterEstimates(fit, boot.ci.type = "bca.simple", standardized=TRUE)
```

Note that in the script we ask (and get) two sets of parameter estimates.  The second set (in the really nice dataframe) includes bootstrapped, bias-corrected confidence intervals. We hope they have the advantage of being more powerul and "bias free" (can't tell you why...it's in the deep math).  Note, though, that when the CI crosses 0, the effect is NS.  

So let's look at this step-by-step.

*  a path = .474, *p* < .001
*  b path = .788, *p* < .001
*  the indirect effect is a product of the a and b paths (.474 * .788 = .374) = .374, *p* < .001
*  the direct effect (c', c prime, or c_p) is the isolated effect of X on Y when including M.  We hope this value is LOWER than the total effect we previously found because this means that including M shared some of the variance in predicting Y.  YES:  c' = .036, *p* = .754, and it is no longer signifcant.
*  we also see the total effect; this value is 
  +  identical to the value of simply predicting Y on X (with no M it the model)
  + the value of a*b + c_p:  .374 + .036 =  .410 (*p* = .003)

Hayes has great models for APA style tables.  The original is in your SP folder...missing, yet from the *lavaan* output are the F test associated with each stage of the model and the intercepts/constants (seem pretty important).  LMK if anyone finds how to get them!

```{r APA Table 1, echo=FALSE, warning=FALSE, paged.print=TRUE}
fd_APAtable <- read.csv("FakyDatyTbl.csv")
pandoc.table(fd_APAtable, style = "multiline", split.table = Inf, justify = "left", format = docx)
```


**Let's create figure with semPlot**

Official documentation for semPlot:  https://rdrr.io/cran/semPlot/man/semPaths.html
Here's what the base package gets us:  

```{r semPLOT pkg}
#install.packages("semPlot")
#When I ran library(semPLOT) command, it failed and said I needed the package "data.table".
#So, I installed it next.  Then library(semPLOT) worked just fine.
#install.packages("data.table")
library(semPlot)

semPaths(fit, "est", title=FALSE, rotation = 2)
```

OK, that was disappointing.  A little digging and we can do better.  

Best help here:  https://www.r-bloggers.com/statistics-sunday-using-semplot/
and here https://www.r-bloggers.com/s-is-for-semplot-package/ (and he probably has more)

Tips that mattered to me:  

* *semPlot* automatically fades based on size of the parameter estimates, so larger estimates are darker than smaller estimates. It also changes the width of paths based on size, including for error estimates; so larger error means a thicker, darker line, *fade=FALSE* turns this off
* Some other functions
  +  *Man* = manifest/observed/square variables, *Lat* = latent/round/theoretical variables
  +  *esize* is the error size
  +  *asize* is the arrow size
  +  *est* prints raw estimates; *std* prints standardized estimates
  +  *edge.label.cex* controls parameter size
  +  *rotation* is used to place the exogenous (predictor) variables at the top(1), left(2), bottom(3), or right(4)

```{r}
semPaths(fit,  "est", edge.label.cex = 1.00,  title=FALSE,  sizeMan=10, fade=FALSE, rotation = 2, esize=2, asize=3)
title("Faky Daty Simple Mediation Model")
```

**Results**
A simple mediation model examined the degree to which M mediated the relation of X on Y.  Using the *lavaan* package (v 0.6-3) in R, coefficients for  each path, the indirect effect, and total effects were calculated. These values are presented in Table 1 and illustrated in Figure 1.  Results suggested that 18% of the variance in M and 48% of the variance in Y were accounted for in the model.  The indirect was statistically significant (*B* = .374, *p* < .001) and the direct effect was non-significant (*B* = .036, *p* = .753). Comparing the effect of the direct effect to the total effect (*B* = .410, *p* = .003), providing some evidence for a complete mediation.  

**??? Did you just say "complete mediation"?**  I'm only likely to use the term "complete" (and never "partial"), when the evidence is compelling.  Hayes is not a fan of the distinctions (see Ch 4/A Critique of Complete and Partial mediation, ~pp. 119-121). He says 
*  Partial mediation implies that the mechanism through M does not entirely account for the association observed between X and Y.
*  Complete mediation implies that the association between X and Y is entirely accounted for by the indirect mechanism.
*  Establishing that the total effect is non-zero
*  Hayes suggests you can only use these terms when you first determine that the total effect (the X to Y relationship) is non-zero.
*  Hayes makes some other arguments that are irrationally psychological ("researchers seem 'happier' when there are complete mediations") and philosophical ("all effects are mediated by something") in that no model is ever complete.
*  Finally, Hayes notes the effects of power.  Two equivalent datasets (in values of the data) may differ by sample size; one might get *p* values that support "complete" mediation and the other, not.

###Motivating Example from Hayes (2018)
SCREENCAST LINK simpleMed_6 https://spu.techsmithrelay.com/DEqv 

Tal-Or, Cohen, Tsfati, and Gunther, 2010. 
* Study in Israel, 43 males and 80 female poli sci and communications students
* read one of two newspaper articles describing an economic crisis that may affect the price and supply of sugar in Israel
* IV:  58 told the story would be on the *front page*; 54 told it would appear on an *interior page*
* DV:   a composite *reaction* (when and how much sugar they intended to purchase)
* Mediator:  presumed media influence (PMI; an estimate of how much they believed others would be compelled to purchase sugar as a result of the article)

Tal-Or et all hypothesized that an article published on the front page woud contribute to PMI that would, in turn, lead to personal intention to purchase sugar.

Getting the data
```{r}
PMIdat <- read.csv ("pmi.csv", header = TRUE)
```


```{r}
set.seed(31216)
pmi_model <- '
          reaction ~ b*pmi + c_p*cond          
          pmi ~a*cond
          
          indirect :=  a*b
          direct  := c_p
          total_c  := c_p + (a*b)
          '
pmi_fit <- sem(pmi_model, data = PMIdat, se="bootstrap", missing = 'fiml')
summary(pmi_fit, standardized=T, rsq=T, fit=TRUE, ci=TRUE)
parameterEstimates(pmi_fit, boot.ci.type = "bca.simple", standardized=TRUE)
```
 

* *semPlot* just grabs the first 3 letters of the variable name to use as labels.  We can create new ones by first creating * Put the Y-variables in the order in which they appear in the equation(s), 
* followed by X-variables, again in the order in which they appear (check your work against the ouput). 
  
  
```{r APA Table 2, echo=FALSE, warning=FALSE, paged.print=TRUE}
PMItbl <- read.csv("PMITbl.csv")
pandoc.table(PMItbl, style = "multiline", split.table = Inf, justify = "left", format = docx)
```
  
```{r}
pmi_labels <- c("Reaction", "PMI", "Condition")

semPaths(pmi_fit,  "est", edge.label.cex = 1.00, nodeLabels=pmi_labels, title=FALSE,  sizeMan=10, fade=FALSE, rotation = 2, esize=2, asize=3)
title("Reaction by Condition via PMI")
```
 
Results
A simple mediation model examined the degree to which PMI mediated the relation of condition on reaction.  Using the *lavaan* package (v 0.6-3) in R, coefficients for the each path, the indirect effect, and total effects were calculated. These values are presented in Table 1 and illustrated in Figure 1.  Results suggested that 3% of the variance in PMI and 21% of the variance in reaction were accounted for by the model.  When the mediator was included in the model, the indirect approached significance (*B* = .241, *p* = .063) and the direct effect was non-significant (*B* = .254, *p* = .339).  Given the nonsignificant total effect of condition on reaction (*B* = .496, *p* = .077), this model is, overall, questionable and warrants further investigation. 

### Ch3 Example 2
SCREENCAST LINK simpleMed_7 https://spu.techsmithrelay.com/FmsO 

Also a simple mediation, but with a continuous predictor.

Study is Pollack et al. (2012).  Data is ESTRESS.

Entrepreneurs (*N* = 262) completed an online survey about recent performance of their business as well as their emotional and cognitive reactions to the economic climate.

In the mediation model, Pollack proposed that economic stress (X, estress) leads to a desire to disengage from entrepreneurial activities (Y, withdraw) as a result of the depressed affect (M, affect) such stress produces. 



```{r}
ESTRESSdat <- read.csv ("estress.csv", header = TRUE)

set.seed(100770)
ESTRESS_model <- '
          withdraw ~ b*affect + c_p*estress
          affect ~a*estress

          indirect :=  a*b
          direct  := c_p
          total_c  := c_p + (a*b)
          '
ESTRESS_fit <- sem(ESTRESS_model, data = ESTRESSdat, se="bootstrap", missing = 'fiml')
summary(ESTRESS_fit, standardized=T, rsq=T, fit=TRUE, ci=TRUE)
parameterEstimates(ESTRESS_fit, boot.ci.type = "bca.simple", standardized=TRUE)
```


```{r}
ESTRESSlabels <- c("AFFECT", "WITHDRAW", "ESTRESS")
semPaths(ESTRESS_fit,  "est", edge.label.cex = 1.00, nodeLabels=ESTRESSlabels, title=FALSE,  sizeMan=10, fade=FALSE, rotation = 2, esize=2, asize=3)
title("Affect from Economic Stress via Withdrawal Intentions")
```

###Considering Covariates
Hayes Chapter 4 considers the role of covariates (e.g., other variables that could account for some of the variance in the model).  When previous research (or commonsense, or detractors) suggest you should include them...its worth a try.  If they are non-significant and/or your variables continue to explain variance over-and-above their contribution, then you have gained ground in ruling out plausible rival hypotheses and are adding to causal evidence.

They are relatively easy to specify in *lavaan*.  Just look at to where the arrows point and then write the path!

```{r}

set.seed(100770)
ESTRESS_model_covs <- '
          withdraw ~ b*affect + c_p*estress
          affect ~ a*estress
          affect ~ c1m*ese
          withdraw ~ c1y*ese
          affect ~ c2m*sex
          withdraw ~ c2y*sex
          affect ~ c3m*tenure
          withdraw ~ c3y*tenure

          indirect :=  a*b
          direct  := c_p
          total_c  := c_p + (a*b)
          '
ESTRESSfit_covs <- sem(ESTRESS_model_covs, data = ESTRESSdat, se="bootstrap")
summary(ESTRESSfit_covs, standardized=T, rsq=T, fit=TRUE, ci=TRUE)
parameterEstimates(ESTRESSfit_covs, boot.ci.type = "bca.simple", standardized=TRUE)
```

Looking at these results, we see that ese has significant relations with both affect and withdraw and that tenure is approaching significance in its influence on affect. 

And now the figure:

```{r}
semPaths(ESTRESSfit_covs,  "est", edge.label.cex = 1.00, title=FALSE,  sizeMan=10, fade=FALSE, rotation = 2, esize=2, asize=3)
title("Affect from Economic Stress via Withdrawal Intentions and Covariates")
```

The path coefficients appear to be correct, but this is really a statistical map and doesn't relay the concept of mediation well.

How about a table and results:


```{r APA Table 3, echo=FALSE, warning=FALSE, paged.print=TRUE}
estTbl <- read.csv("estTbl.csv")
pandoc.table(estTbl, style = "multiline", split.table = Inf, justify = "left", format = docx)
```

**Results**
A simple mediation model examined the degree to which affect mediated the relation of economic stress on withdrawal intentions  Using the *lavaan* package (v 0.6-3) in R, coefficients for the each path, the indirect effect, and total effects were calculated. The effect of covariates (ese, sex, and tenure) were mapped onto both the mediator and dependent variable were included in the model.  These values are presented in Table 1 and illustrated in Figure 1.  Results suggested that 16% of the variance in affect and 21% of the variance in withdrawal intentions were accounted for by the model.  Supporting the notion of a mediated model, there was a statistically significant indirect effect (*B* = .113, *p* < .001).  in combination with a  non-significant direct effect (*B* = -0.094, *p* = .109). Curiously, though, the total effect (*B* = .019, *p* = .772) was also non-significant.


###Residual and Related Questions You Might Have (or at least I had; that if I answered earlier would disrupt the lecture flow)
SCREENCAST LINK:  simpleMed_8 https://spu.techsmithrelay.com/Stqa 

1.  Are you sure you can claim a significant indirect effect in the presence of a non-significant total effect?  Hayes is.  See his excellent argument in Chapter 4/What about Baron & Kenny? ~ p. 117-119.    

2.  Sometimes the output we get is different from the output in the Hayes text.  Why?  And should we worry about it?  Relatedly, you aren't reporting different statistics than Hayes.  Like, what happened to his *F* test and intercepts?

+  The default estimator for *lavaan* is maximum likelihood (ML) and Hayes uses ordinary least squares (OLS).  This affects both the values of coefficients, standard errors, AND the type of statistics that are reported. 
+  You can ask for OLS regression by adding the statement "estimator = "GLS"  (see below). Even with this option, I have not discovered a way to obtain the *F* tests for the overall model or report an intercept.  Researchers seem to be comfortable with this, even asking for less than we did (e.g., many do not request R square change).
+  Researchers who do want this (best I can tell) might use a combination of packages, using GLS estimators in *lavaan* (this easily gets them the bootstrapped CIs) and the move to a different regression package to get the intercepts and *F* tests.  If I did this I would triple check to make sure that all the output really lined up.
+  We could have asked for traditional SEM fit stats (e.g., CFI, RMSEA), but I have hesitancies for doing this with models that do not include latent variables.  Therefore, we asked for an "in-between" amount of info that should be sufficient for pub submission (any editor may have their own preferences and ask for more).
+  Am I comfortable with the differences?  Yep.  Other than being overly conscientious about it, my read is that we we've asked for is sufficient.


```{r Simple Med w Faky Daty2}

set.seed(1234)
model <- '
          Y ~ b*M + c_p*X 
          M ~a*X

          indirect :=  a*b
          direct  := c_p
          total_c  := c_p + (a*b)
          '
fit <- sem(model, data = Data, estimator = "GLS", se="bootstrap", missing = 'fiml')
summary(fit, standardized=T, rsq=T, fit=TRUE, ci=TRUE)
parameterEstimates(fit, boot.ci.type = "bca.simple", standardized=TRUE)
```


3.  You promised some magic statement (command/script) about missing data.  

+  When we enter the *lavaan* world we do get options other than multiple imputation.  In today's example we used the "sem" fitting function. Unless otherwise specified, listwise deletion (deleting the entire case when one of its variables is used to estimate the model) is the default in *lavaan*.  If data are MCAR or MAR, you can add the argument *missing = "ml"* (or its alias *missing = "fiml"*).  More here https://users.ugent.be/~yrosseel/lavaan/lavaan2.pdf on the 1.7/Missing data in lavaan slide.
+  Relatedly, the type of estimator matters.  If (for some reason) you estimate your data with GLS (generalized least squares) or WLS (weighted least squares), you are required to have complete data (however you got it)
+  I don't yet know about how or if it is possible to use multiply imputed data in *lavaan*.  More here:  http://lavaan.ugent.be/tutorial/est.html on the tab "Estimators and more."