---
title: "Dissertation"
output:
  word_document: default
  html_document: default
date: '2022-03-23'
---
```{r}
#will install the package if not already installed
#if(!require(qualtRics)){install.packages("qualtRics")} 
#if(!require(tidyverse)){install.packages("tidyverse")}
```

```{r}
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get diff
#library(qualtRics)
#qualtrics_api_credentials(api_key = "Q65NIelIWsnSBw0uUIJtKIm3oYmxBbWxgP6apCT9",
#base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
readRenviron("~/.Renviron")
```
```{r}
#QTRX_csv <- read_survey("KCSARC_VPS220323.csv", strip_html = TRUE, import_id = FALSE, time_zone = FALSE)
```
```{r}
#surveys <- all_surveys()
#surveys
```

There were 163 initial attempts (look at examples in text to say I used AIA approach to analyze and manage missing data)

```{r}
df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
``` 


```{r}
library(tidyverse)
library(processR)
#the identification key was three parts; the second used letters from their name
#the students were using a mix of upper and lowercase; this makes it all upper case (otherwise R would read them as different people).
#this code makes the second part of the identification key all upper case
df$Key_2 <- toupper(df$Key_2) 

#this combines the three parts of the key
df$StdID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)

#this assigns an index number (time1, time2, etc.) by the ID
df <- df%>%
  group_by(StdID)%>%
  mutate(index = order(order(EndDate, decreasing = FALSE)))
#this puts those variables we care about all at the front so we can check our work
#for your project I want to get rid of all those with a number 2,
#unfortunately, the students who took this survey all before we had the key/identification system all have NAs,
#so first I have to recode those kids with NA as NA before I can delete the "2s"
df <-(select (df, StdID, index, EndDate, everything()))
#this code recodes all the students with an ID of NA - NA - NA as NA
df$index <- ifelse(df$StdID == "NA - NA - NA", NA, df$index)
#this less us properly delete the students who took it a second time (it saved us one student)
df <- df[!(df$index =="2"),]
#I would have liked to keep the ID variable, but for some reason R was reading it as "very important" and insisted that it remain in all the remaining dataframes. This means it was messing up scoring and alpha coefficients
#I deleted it and things seem to work fine.  Weird. Really. Weird.
df <- subset(df, select = -(StdID))
```

```{r}
#dev.set(dev.next())
```

```{r}
library(tidyverse)
df %>%
    count(Gender)
```
```{r}
df$gender <- factor(df$Gender,
levels = c("1","2", "3"),
labels = c("Male", "Female", "Other"))

str(df$gender)
```
I scored my variables, if there were at least 80% nonmissing (part of AIA approach look for citation)
```{r}
library(sjstats)
Emp_vars <- c('emp1_1','emp1_2','emp1_3','emp1_4','emp2_1','emp2_2','emp2_3','emp2_4','emp2_5')

df$Empathy <- sjstats::mean_n(df[,Emp_vars], .80)

```

```{r}
Con_vars <- c('consent_1','consent_2','consent_3','consent_4','consent_5','consent_6')

df$Consent <- sjstats::mean_n(df[,Con_vars], .80)
```

```{r}
Mgrs_vars<- c('mgrs_1','mgrs_2','mgrs_3','mgrs_5','mgrs_7')
df$MGRS <- sjstats::mean_n(df[,Mgrs_vars], .80)

```

```{r}
EMPdf <- df%>%dplyr::select(emp1_1:emp2_5)
psych::alpha(EMPdf)
str(EMPdf)
```

```{r}
CONdf <- df%>%dplyr::select(consent_1:consent_6)
psych::alpha(CONdf)
```

```{r}
MGRSdf<- df%>%dplyr::select(mgrs_1:mgrs_7)
psych::alpha(MGRSdf)
```

```{r}
MODELdf<- df%>%dplyr::select(Age, Ethnicity, gender, Empathy, Consent, MGRS)
MODELdf <- rename(MODELdf, Gender = gender)
MODELdf<- dplyr::filter(MODELdf, rowSums(is.na(MODELdf)) != ncol(MODELdf))
```
Considering the variables in my study there were 163 cases with nonmissingness. 
I will conduct the missing analysis on the variables that I use in the study
```{r}
mice_out <- mice::md.pattern(MODELdf, plot = TRUE, rotate.names = TRUE)
mice_out
```
```{r}
MODELdf<-MODELdf[complete.cases(MODELdf), ]
```
Mean age is 15.5 with a standard deviation of 1.6.  The youngest participant age was 13 and the oldest was 19.  
```{r}
psych::describe(MODELdf)
```
```{r}
MODELdf$Mahal <- psych::outlier(MODELdf[c("Empathy", "Consent", "MGRS")]) 
```
```{r}
psych::describe(MODELdf$Mahal)
```
```{r}
MODELdf$MOutlier <- if_else(MODELdf$Mahal > (median(MODELdf$Mahal) + (3*sd(MODELdf$Mahal))), TRUE, FALSE)
library(dplyr)
OutlierCount <- MODELdf%>%  
  count(MOutlier)
OutlierCount
```


```{r}
ALLvars <- c('Gender','MGRS','Empathy','Consent')
apaTables::apa.cor.table(MODELdf[, c('Gender','MGRS','Empathy','Consent')],filename="mytable.doc", table.number=1, show.sig.stars=TRUE)
```
The code below removes all the rows with a Mahalanobis distance of 29 or greater (that was our outrageous outlier). 
```{r}
MODELdf<-subset(MODELdf,Mahal < 29)
```

05/18/22: I noticed that you were running the model with the "df" dataset, not the "MODELdf" dataset.  When I got to exploring, I realized that in the df dataset, Gender was 1,2,3 (numeric) and in the MODELdf it was properly a factor.

After several hours of struggles, I figured out that neither lavaan nor Hayes' process macro for R can handle a multi-categorical predictor.

SO!  (more hours), I decided that we should eliminate the 7 students who identified as "other" and dummy-code Gender (0 = male, 1 = female). Once dummy-coded, it's ok to enter the dichotomous variable in its numerical format.
```{r}
biGender <- subset(MODELdf, Gender != "Other") #subset data
#biGender$Gender2 <- dplyr::recode(biGender$Gender, "Male" = "0", "Female" = "1")
#biGender$Gender <- factor(biGender$Gender,
                     #levels = c("1","2"),
                     #labels = c("Male", "Female"))
biGender$Gender <- plyr::mapvalues(biGender$Gender, from = c("Male", "Female"), to = c(0, 1))
#biGender$Gender2 <- droplevels(biGender$Gender2)
biGender$Gender <- droplevels(biGender$Gender)
#biGender$Gender <- factor(biGender$Gender, ordered = TRUE,
                          #levels = c("0", "1"))
biGender$Gender <- as.numeric(biGender$Gender)
str(biGender)
```

I ran the whole big moderated mediation, but in doing so (and trying to figure it out), I realized that we weren't following the piecewise approach that Hayes recommends, and that I model in most of my lectures. If we do that, we'll have a much better chance of having something to say in the discussion.

Your model has a simple mediation and two simple moderations. Let's do them:

## Simple Mediation

```{r}
processR::pmacroModel(8)
processR::statisticalDiagram(8)

```
```{r}

simpmed_labels <- list(X = "Gender", M = "MGRS", Y = "Consent")
processR::pmacroModel(4, labels = simpmed_labels)
processR::statisticalDiagram(4, labels = simpmed_labels)
```
```{r}
simpmed <- tripleEquation(X = "Gender", M = "MGRS", Y = "Consent", data = biGender)
cat(simpmed)
```

```{r}
simpmed_fit <- lavaan::sem(model = simpmed, data=biGender)
summary(simpmed_fit)
```

```{r}
estimatesTable(simpmed_fit)
```

```{r}
parameterEstimates(simpmed_fit, boot.ci.type = "bca.simple", standardized=TRUE)
```

OK, wow.  Neither the a, b, c', nor total effect is significant.  Ughhhhhh....


```{r}
statisticalDiagram(4, labels=simpmed_labels, fit=simpmed_fit, whatLabel="est")
```



## Moderation #1:  Empathy*Gender moderation on Consent


```{r}
mod1_labs <- list(X = "Gender", Y = "Consent", W = "Empathy")
processR::pmacroModel(1, labels = mod1_labs)
processR::statisticalDiagram(1, labels = mod1_labs)
```

```{r}
mod1 <- '
   Consent ~ b1*Gender + b2*Empathy + b3*Gender:Empathy
   '
```

```{r}
mod1_fit <- lavaan::sem(mod1, data=biGender)
summary(mod1_fit)
```

```{r}
parameterEstimates(mod1_fit)
```



```{r}
statisticalDiagram(1, labels=mod1_labs, fit=mod1_fit, whatLabel="est")
```

If the moderation of the c' (direct) path had been significant, an interaction plot of this simple moderation would explain what's going on. Therefore, I wanted to graph this non-significant interaction.  I don't know how to do it with lavaan output, so here goes with regular regression. It's ok to use the plot -- the regression weights (and therefore the plot) would be the same.

```{r}
OLSmod1 <- lm(Consent ~ Gender*Empathy, data=biGender)
summary(OLSmod1)
```
```{r}
interactions::interact_plot(OLSmod1, pred=Gender, modx=Empathy) + ylim(0, 100)
```



## Moderation #2:  Empathy*MGRS moderation on Consent


```{r}
mod2_labs <- list(X = "MGRS", Y = "Consent", W = "Empathy")
processR::pmacroModel(1, labels = mod2_labs)
processR::statisticalDiagram(1, labels = mod2_labs)
```

```{r}
mod2 <- '
   Consent ~ b1*MGRS + b2*Empathy + b3*MGRS:Empathy
   '
```

```{r}
mod2_fit <- lavaan::sem(mod2, data=biGender)
summary(mod2_fit)
```
```{r}
parameterEstimates(mod2_fit)
```


```{r}
statisticalDiagram(1, labels=mod2_labs, fit=mod2_fit, whatLabel="est")
```
And now to get to an interaction plot of this second regression (the potential moderation of the b path).

```{r}
OLSmod2 <- lm(Consent ~ MGRS*Empathy, data=biGender)
summary(OLSmod2)
```
```{r}
interactions::interact_plot(OLSmod2, pred=MGRS, modx=Empathy) + ylim(0, 100)
```


## The final assembly


```{r}
library(processR)
processR::pmacroModel(15)
processR::statisticalDiagram(15)
```

```{r}
labels=list(X="Gender",M="MGRS",Y="Consent",W="Empathy")
processR::pmacroModel(15,labels=labels)
processR::statisticalDiagram(15,labels=labels)
```

```{r}
library(processR)
moderator=list(name="Empathy",site=list(c("b","c")))
model=tripleEquation(X="Gender",M="MGRS",Y="Consent",moderator=moderator)
cat(model)
```

```{r}
#with this model syntax, I can analyze moderated mediation with sem() function of lavaan package.

library(lavaan)
semfit=sem(model=model,data=biGender)
summary(semfit)
#se="bootstrap", estimator = "DWLS", 
```
```{r}
#I can extract parameter estimates of this model
estimatesTable(semfit)
```


```{r}
#The estimatesTable2 make a flextable object of this model.
estimatesTable2(semfit)
```

```{r}
#black and white table for dissertation writing purposes, set the argument vanilla=TRUE.
estimatesTable2(semfit,vanilla = TRUE)
```

```{r}
#I can draw statistical diagram with the analysis result.
statisticalDiagram(15,labels=labels,fit=semfit,whatLabel="est")
```

```{r}
#Analysis with simple regression models
#I can analyze this model using lm() function. You can make regression equations for moderator and dependent variables.
equations=regEquation(X="Gender",M="MGRS",Y="Consent",moderator=moderator)
cat(equations)
```


```{r}
MGRS ~ Gender
Consent ~  Gender+MGRS+Gender*Empathy
```

```{r}
#With this equation I can perform linear regression. First, you can use moderator as a dependent variable.
eq=unlist(strsplit(equations,"\n"))
fit=lapply(1:2,function(i) {
    lm(as.formula(eq[i]),data=biGender)
})
summary(fit[[1]])
```
```{r}
#The second regression model uses dependent variable.
summary(fit[[2]])
```
```{r}
#Making a table summarizing the 2 models 
x=modelsSummary(fit,labels=labels)
modelsSummaryTable(x)
```
```{r}
library(processR)
#Conditional direct and indirect effects
#I can make table summarizing the conditional direct and indirect effects. By default, the equation uses mean ± sd of moderator. The following table summarizes the direct and indirect effect when the moderator is mean, mean + sd and mean - sd.
x=modmedSummary(semfit,mod="Empathy")
modmedSummaryTable(x)

```

```{r}
#Plots for conditional direct and indirect effects
#I can draw summarizing the conditional direct and indirect effects.

conditionalEffectPlot(semfit,data=df,mod="Empathy")
guides(scale = "none")
```

# I checked in the Hayes' process program for R

Process for R is a complete pain. He doesn't use a macro. You have to download the appropriate file for your operating system, open the associated .rmd file and rerun process every time you turn on your computer (and want to do process) or restart R. The download site is here:  https://www.processmacro.org/download.html 

```{r}
process(data=biGender, y = "Consent", x = "Gender", m = "MGRS", w = "Empathy", model=15, plot=1, seed=220518)
```
