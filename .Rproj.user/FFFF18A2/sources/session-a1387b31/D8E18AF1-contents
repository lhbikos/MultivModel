---
title: "Initial Sample: Validity matrices"
author: "Lynette H. Bikos, PhD, ABPP"
date: "12/13/2019"
output: word_document
csl: apa-single-spaced.csl
bibliography: CFA.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
#CAN SKIP AHEAD TO GRAB THE READY-TO-ANALYZE DF (SEARCH FOR "START HERE")

#Initial Sample

## Importing Data, Naming Variables 

```{r Upload data}
#original data in SPSS, couldn't upload it (maybe an old version of SPSS?)
#Saved from SPSS to a .csv 
#The SPSS .csv didn't upload properly (first variable had an odd symbol as first character).  Must resave as an MS_DOS.csv
#init_raw <- read.csv("initial.csv", head = TRUE, sep = ",")
```

```{r Import raw data}
#original data in SPSS, couldn't upload it (maybe an old version of SPSS?)
#Saved from SPSS to a .csv then uploaded the .csv
Init_raw_df <- read.csv("InitialRaw.csv", head = TRUE, sep = ",")

```

###Renaming all the variables

```{r Rename variables}
library(tidyverse)
Init_named_df <- rename(Init_raw_df, date=q0001_0001, travelplans_1=q0002, noplans_country=q0003, no_ready=q0004, plans_countries=q0005_0001, traveldates=q0005_0002, yes_ready=q0006, SCASEE1=q0007_0001, SCASEE2=q0007_0002, SCASEE3=q0007_0003, SCASEE4=q0007_0004, SCASEE5=q0007_0005, SCASEE6=q0008_0001, SCASEE7=q0008_0002, SCASEE8=q0008_0003, SCASEE9=q0008_0004, SCASEE10=q0008_0005, SCASEE11=q0009_0001, SCASEE12=q0009_0002, SCASEE13=q0009_0003, SCASEE14=q0009_0004, SCASEE15=q0009_0005, SCASEE16=q0010_0001, SCASEE17=q0010_0002, SCASEE18=q0010_0003, SCASEE19=q0010_0004, SCASEE20=q0010_0005, SCASEE21=q0011_0001, SCASEE22=q0011_0002, SCASEE23=q0011_0003, SCASEE24=q0011_0004, SCASEE25=q0011_0005, SCASEE26=q0012_0001, SCASEE27=q0012_0002, SCASEE28=q0012_0003, SCASEE29=q0012_0004, SCASEE30=q0012_0005, SCASEE31=q0013_0001, SCASEE32=q0013_0002, SCASEE33=q0013_0003, SCASEE34=q0013_0004, SCASEE35=q0013_0005, SCASEE36=q0014_0001, SCASEE37=q0014_0002, SCASEE38=q0014_0003, SCASEE39=q0014_0004, SCASEE40=q0014_0005, SCASEE41=q0015_0001, SCASEE42=q0015_0002, SCASEE43=q0015_0003, SCASEE44=q0015_0004, SCASEE45=q0015_0005, SCASEE46=q0016_0001, SCASEE47=q0016_0002, SCASEE48=q0016_0003, SCASEE49=q0016_0004, SCASEE50=q0016_0005, SCASEE51=q0017_0001, SCASEE52=q0017_0002, SCASEE53=q0017_0003, SCASEE54=q0017_0004, SCASEE55=q0017_0005, SCASEE56=q0018_0001, SCASEE57=q0018_0002, SCASEE58=q0018_0003, SCASEE59=q0018_0004, SCASEE60=q0018_0005, IASE1=q0019_0001, IASE2=q0019_0002, IASE3=q0019_0003, IASE4=q0019_0004, IASE5=q0019_0005, IASE6=q0019_0006, IASE7=q0019_0007, IASE8=q0019_0008, IASE9=q0019_0009, IASE10=q0020_0001, IASE11=q0020_0002, IASE12=q0020_0003, IASE13=q0020_0004, IASE14=q0020_0005, IASE15=q0020_0006, IASE16=q0020_0007, IASE17=q0020_0008, IASE18=q0020_0009, IASE19=q0021_0001, IASE20=q0021_0002, IASE21=q0021_0003, IASE22=q0021_0004, IASE23=q0021_0005, IASE24=q0021_0006, IASE25=q0021_0007, IASE26=q0021_0008, IASE27=q0021_0009, NGSE1=q0022_0001, NGSE2=q0022_0002, NGSE3=q0022_0003, NGSE4=q0022_0004, NGSE5=q0022_0005, NGSE6=q0022_0006, NGSE7=q0022_0007, NGSE8=q0022_0008, AGLII1=q0023_0001, AGLII2=q0023_0002, AGLII3=q0023_0003, AGLII4=q0023_0004, AGLII5=q0023_0005, AGLII6=q0023_0006, AGLII7=q0023_0007, AGLII8=q0024_0001, AGLII9=q0024_0002, AGLII10=q0024_0003, AGLII11=q0024_0004, AGLII12=q0024_0005, AGLII13=q0024_0006, AGLII14=q0024_0007, PWB1=q0025, PWB2=q0026, PWB3=q0027_0001, PWB4=q0027_0002, PWB5=q0027_0003, PWB6=q0027_0004, PWB7=q0028_0001, PWB8=q0028_0002, PWB9=q0028_0003, PWB10=q0029, HomeState=q0030_0001, HomeCntr=q0030_0002, Abroad1=q0031_0001, Abroad2=q0031_0002, Abroad3=q0031_0003, Abroad4=q0031_0004, Abroad5=q0031_0005, Gender=q0032, RaceEth=q0033, BrthYr=q0034, Educ=q0035, Prfssn=q0036, Part2=q0037, UniqueID=q0038 )

#str(y2pr_named)
```

## Analyzing Missingness & Managing Missing Data

The *available item analysis* (AIA, [@parent_handling_2013] guided our approach to analyzing and managing missing data. The AIA approach recommends analyzing missinngness for each each scale or subscale (whatever the level of analysis), separately. Further each analysis utilizes whatever data is *available*; thus the *n* differ from analysis to analysis.  

We already determined missingness for the SCASEE, so now we need to do it for the other measures.

### Determining missingness for SCASEE

```{r SCASEE missingness}
#Create a variable (n_miss) that counts the number missing
Init_named_df$n_miss <- Init_named_df %>%
select(SCASEE1:PWB10) %>% 
is.na %>% 
rowSums

#Create a proportion missing by dividing n_miss by the total number of variables (80)
#Pipe to sort in order of descending frequency to get a sense of the missingness
Init_named_df<- Init_named_df%>%
mutate(prop_miss = (n_miss/119)*100)%>%
  arrange(desc(n_miss))
```

Of those with < 20% missing, individuals missed between 1 and 14 items.

```{r}
#Looking at the data, we see that once we drop below 20% missing, individuals are missing between 1 and 7 items.

Init_df <- filter(Init_named_df, prop_miss <= 20)  #update df to have only those with at least 80% of complete data
Init_df <- (select (Init_df, SCASEE1:PWB10)) #further update to include only the SCASEE items

#Writing an outfile to import and immediately start modeling if I don't want to repeat this whole thing
write.table(Init_df, file="Init_df.csv", sep=",", col.names=TRUE, row.names=FALSE)
```

# START HERE FOR QUICK ANALYSES

```{r}
Init_df <- read.csv ("Init_df.csv", head = TRUE, sep = ",")
library(tidyverse) #requires dplyr to calculate scale scores
library(psych)
```

In the initial sample, 263 individuals began the survey. For the analyses involving the SCALES used for the convergent/discrimniant analyses, we eliminated cases where more than 20% of the SCASEE items were missing [@parent_handling_2013]. This left a sample size of 202.


```{r df and case/row missingness}
mean(is.na(Init_df))#what proportion of cells missing across entire dataset
mean(complete.cases(Init_df))#what proportion of cases (rows) are complete (nonmissing)
```

Within our sample of 202 participants, 65% (*n* = 199) had complete data; the number of SCASEE items missing range from 1 to 14.  Missing values represented less than 1% of the dataset.  



```{r}
library(MissMech)

#Note -- make sure that when you run this you do not have extraneous variables in the mix (e.g,. num_miss, prop_miss)
#TestMCARNormality(SCASEEcfa_df1)
#Wouldn't run by simply specifying the dataset. From Jamshidian et al 2014 I llearned you could include the del.lesscases command.  They recommend 3 (but this throws out all cases for the MCAR analysis with 3 or more missing -- have no idea why this is ok.)
#i got this to run with del.lesscases=1

TestMCARNormality(data=Init_df, del.lesscases = 1)
```

The *TestMCARNormality()* funtion in the MissMech (v. 1.0.2) R package was used to determine if the dataset was different from MCAR.  Results suggested that we did not violate the MCAR assumption ($p = .195$). 


## Item analysis to Refine Item Pool

### First must calculate scale and subscale means for the within-scale (SCASEE) and concurrent/discriminant validity correlations

**Addressing recoding**

The AGLII (international interests is the only one with recoded variables).
We could do this different ways, but I will recode here so that I will know (in future syntax) what I've done (I hope).

```{r}
#Recoding (reverse-scoring) AGLII items
#the AGLII is a 4 point scale, subtracting 5 converts 4 to 1, 3 to 2, 2 to 3, and 1 to 4
Init_df<- Init_df %>%
  mutate(AGLII3r = 5 - AGLII3)%>%
  mutate (AGLII5r = 5 - AGLII5)%>%
  mutate (AGLII14r = 5 - AGLII14) %>%
  mutate (AGLII1r = 5 - AGLII1)

```


```{r Subscale scores}
#library(dplyr) #should already be on because it is part of tidyverse
#Creating means
#na.rm=TRUE means that it will create the mean even if some of the item-level data is missing and adjust the denominator to represet the number of scores included; can switch to FALSE and it will listwise delete that scale or subscale
Init_df <- Init_df %>%
  rowwise()%>%
  #---30 item version, test
  mutate(AE30 = mean (c(SCASEE2, SCASEE3, SCASEE4, SCASEE5, SCASEE8), na.rm=TRUE))%>%
  mutate(BE30 = mean (c(SCASEE10, SCASEE13, SCASEE14, SCASEE15, SCASEE17), na.rm=TRUE))%>%
  mutate(CE30 = mean (c(SCASEE20, SCASEE21, SCASEE22, SCASEE23, SCASEE28), na.rm=TRUE))%>%
  mutate(AI30 = mean (c(SCASEE31, SCASEE33, SCASEE35, SCASEE37, SCASEE39), na.rm=TRUE))%>%
  mutate(BI30 = mean (c(SCASEE42, SCASEE44, SCASEE45, SCASEE46, SCASEE49), na.rm=TRUE))%>%
  mutate(CI30 = mean (c(SCASEE54, SCASEE55, SCASEE57, SCASEE59, SCASEE60), na.rm=TRUE))%>%
  mutate(AFF30 = mean (c(SCASEE2, SCASEE3, SCASEE4, SCASEE5, SCASEE8, SCASEE31, SCASEE33, SCASEE35, SCASEE37, SCASEE39), na.rm=TRUE))%>%
  mutate(BEH30 = mean (c(SCASEE10, SCASEE13, SCASEE14, SCASEE15, SCASEE17, SCASEE42, SCASEE44, SCASEE45, SCASEE46, SCASEE49), na.rm=TRUE))%>%
  mutate(COG30 = mean (c(SCASEE20, SCASEE21, SCASEE22, SCASEE23, SCASEE28,SCASEE54, SCASEE55, SCASEE57, SCASEE59, SCASEE60), na.rm=TRUE))%>%
  mutate(ENV30 = mean (c(SCASEE2, SCASEE3, SCASEE4, SCASEE5, SCASEE8,SCASEE10, SCASEE13, SCASEE14, SCASEE15, SCASEE17,SCASEE20, SCASEE21, SCASEE22, SCASEE23, SCASEE28), na.rm=TRUE))%>%
  mutate(INT30 = mean (c(SCASEE31, SCASEE33, SCASEE35, SCASEE37, SCASEE39,SCASEE42, SCASEE44, SCASEE45, SCASEE46, SCASEE49,SCASEE54, SCASEE55, SCASEE57, SCASEE59, SCASEE60), na.rm=TRUE))%>%
  mutate(SCASEE_30 = mean (c(SCASEE2, SCASEE3, SCASEE4, SCASEE5, SCASEE8,SCASEE10, SCASEE13, SCASEE14, SCASEE15, SCASEE17,SCASEE20, SCASEE21, SCASEE22, SCASEE23, SCASEE28,SCASEE31, SCASEE33, SCASEE35, SCASEE37, SCASEE39,SCASEE42, SCASEE44, SCASEE45, SCASEE46, SCASEE49,SCASEE54, SCASEE55, SCASEE57, SCASEE59, SCASEE60), na.rm=TRUE))%>%
#---18 item version, test
  mutate(AE18 = mean (c(SCASEE2, SCASEE4, SCASEE8), na.rm=TRUE))%>%
  mutate(BE18 = mean (c(SCASEE13, SCASEE15, SCASEE17), na.rm=TRUE))%>%
  mutate(CE18 = mean (c(SCASEE20, SCASEE21, SCASEE23), na.rm=TRUE))%>%
  mutate(AI18 = mean (c(SCASEE31, SCASEE33, SCASEE39), na.rm=TRUE))%>%
  mutate(BI18 = mean (c(SCASEE44, SCASEE45, SCASEE46), na.rm=TRUE))%>%
  mutate(CI18 = mean (c(SCASEE55, SCASEE59, SCASEE60), na.rm=TRUE))%>%
  mutate(AFF18 = mean (c(SCASEE2, SCASEE4, SCASEE8, SCASEE31, SCASEE33, SCASEE39), na.rm=TRUE))%>%
  mutate(BEH18 = mean (c(SCASEE13, SCASEE15, SCASEE17,SCASEE44, SCASEE45, SCASEE46), na.rm=TRUE))%>%
  mutate(COG18 = mean (c(SCASEE20, SCASEE21, SCASEE23,SCASEE55, SCASEE59, SCASEE60), na.rm=TRUE))%>%
  mutate(ENV18 = mean (c(SCASEE2, SCASEE4, SCASEE8, SCASEE13, SCASEE15, SCASEE17, SCASEE20, SCASEE21, SCASEE23), na.rm=TRUE))%>%
  mutate(INT18 = mean (c(SCASEE31, SCASEE33, SCASEE39,SCASEE44, SCASEE45, SCASEE46,SCASEE55, SCASEE59, SCASEE60), na.rm=TRUE))%>%
  mutate(SCASEE_18 = mean (c(SCASEE2, SCASEE4, SCASEE8, SCASEE13, SCASEE15, SCASEE17, SCASEE20, SCASEE21, SCASEE23,SCASEE31, SCASEE33, SCASEE39,SCASEE44, SCASEE45, SCASEE46,SCASEE55, SCASEE59, SCASEE60), na.rm=TRUE))%>%
  #---IASE27
 mutate(IASE_in = mean(c(IASE1, IASE2, IASE3, IASE4, IASE5, IASE6, IASE7, IASE8, IASE9, IASE10, IASE11, IASE12,IASE13, IASE14, IASE15, IASE16, IASE17, IASE18, IASE19, IASE20, IASE21, IASE22, IASE23, IASE24, IASE25, IASE26, IASE27), na.rm=TRUE))%>%
  #---NGSE8
  mutate(NGSE_in = mean(c(NGSE1,NGSE2,NGSE3,NGSE4,NGSE5,NGSE6,NGSE7,NGSE8), na.rm=TRUE))%>%
  #---AGLI14
  mutate(AGLII_in = mean(c(AGLII1r, AGLII2, AGLII3r, AGLII4, AGLII5r,AGLII6,AGLII7,AGLII8,AGLII9, AGLII10, AGLII11, AGLII12, AGLII13, AGLII14r), na.rm=TRUE))%>%
  #---PWB10
   mutate(PWB_in = mean(c(PWB1, PWB2, PWB3, PWB4, PWB5, PWB6, PWB7, PWB8, PWB9, PWB10), na.rm=TRUE))
#Note there are some "NaN"s in the scored data, especially for CI.  These were at the end of the scale.  It shouldn't be a problem, but we'll make a mental note of this ad keep moving forward.
```

## Concurrent Validity Correlations

corr.object$r %>%
write.csv (corr.object$r, file="AEcorr.csv")

```{r}
#Running these separately so I can just copy the first column
#Using corr.test so I can get p values
#Using "pairwise" so it will calculate if each item in the pair is present
IASEw30 <- corr.test(Init_df[c("IASE_in", "SCASEE_30", "ENV30", "AE30", "BE30", "CE30", "INT30", "AI30", "BI30", "CI30", "AFF30", "BEH30", "COG30")], use = "pairwise")
write.csv (IASEw30$r, file="IASEw30r.csv")
IASEw30


NGSEw30 <- corr.test(Init_df[c("NGSE_in", "SCASEE_30", "ENV30", "AE30", "BE30", "CE30", "INT30", "AI30", "BI30", "CI30", "AFF30", "BEH30", "COG30")], use = "pairwise")
write.csv (NGSEw30$r, file="NGSEw30.csv")
NGSEw30

AGLIIw30 <- corr.test(Init_df[c("AGLII_in", "SCASEE_30", "ENV30", "AE30", "BE30", "CE30", "INT30", "AI30", "BI30", "CI30", "AFF30", "BEH30", "COG30")], use = "pairwise")
write.csv (AGLIIw30$r, file="AGLIIw30.csv")
AGLIIw30

PWBw30 <- corr.test(Init_df[c("PWB_in", "SCASEE_30", "ENV30", "AE30", "BE30", "CE30", "INT30", "AI30", "BI30", "CI30", "AFF30", "BEH30", "COG30")], use = "pairwise")
write.csv (PWBw30$r, file="PWBw30.csv")
PWBw30
```

```{r}
#Repeated, replacing "30" with "18"
#Running these separately so I can just copy the first column
#Using corr.test so I can get p values
#Using "pairwise" so it will calculate if each item in the pair is present
IASEw18 <- corr.test(Init_df[c("IASE_in", "SCASEE_18", "ENV18", "AE18", "BE18", "CE18", "INT18", "AI18", "BI18", "CI18", "AFF18", "BEH18", "COG18")], use = "pairwise")
write.csv (IASEw18$r, file="IASEw18.csv")
IASEw18

NGSEw18 <- corr.test(Init_df[c("NGSE_in", "SCASEE_18", "ENV18", "AE18", "BE18", "CE18", "INT18", "AI18", "BI18", "CI18", "AFF18", "BEH18", "COG18")], use = "pairwise")
write.csv (NGSEw18$r, file="NGSEw18.csv")
NGSEw18

AGLIIw18 <- corr.test(Init_df[c("AGLII_in", "SCASEE_18", "ENV18", "AE18", "BE18", "CE18", "INT18", "AI18", "BI18", "CI18", "AFF18", "BEH18", "COG18")], use = "pairwise")
write.csv (AGLIIw18$r, file="AGLIIw18.csv")
AGLIIw18

PWBw18 <- corr.test(Init_df[c("PWB_in", "SCASEE_18", "ENV18", "AE18", "BE18", "CE18", "INT18", "AI18", "BI18", "CI18", "AFF18", "BEH18", "COG18")], use = "pairwise")
write.csv (PWBw18$r, file="PWBw18.csv")
PWBw18
```

### Within-scale Convergent/Discriminant Validity Correlations

```{r}
#Using pairwise as deletion method.
#Together with our process for scoring scales (deleting those with 20% missing, then computing means), this is consistent w Person's AIA recommendations

wiSCASEE30r <- corr.test(Init_df[c("SCASEE_30", "ENV30", "AE30", "BE30", "CE30", "INT30", "AI30", "BI30", "CI30", "AFF30", "BEH30", "COG30")], use = "pairwise")
wiSCASEE30r
write.csv (wiSCASEE30r$r, file="wiSCASEE30r.csv")

wiSCASEE18r <- corr.test(Init_df[c("SCASEE_18", "ENV18", "AE18", "BE18", "CE18", "INT18", "AI18", "BI18", "CI18", "AFF18", "BEH18", "COG18")], use = "pairwise")
write.csv (wiSCASEE18r$r, file="wiSCASEE18r.csv")
wiSCASEE18r

```


### Descriptives

XVdescriptives <- (psych::describe(XV_scores)) # create an object because that's what you will write to the csv file
XVdescriptives #lets you view it, optional
write.csv (XVdescriptives, file="XVdescripts.csv")

```{r}
Init_scores <- (select (Init_df, AE30:PWB_in))
INITdescripts<- psych::describe(Init_scores)
write.csv (INITdescripts, file="INITdescripts.csv")
INITdescripts
```


### And make keys for getting the (within-subscale) corrected item-total correlations

We'll need to use the alpha function in the *psych* package to get the corrected item-total correlations.  This requires creating keys.

### Keys for getting the alphas

First the 30-item scales

```{r Keys for 30 item SCASEE}
#STEP 1:make a list of the keys
SCASEE30_keys_list <- list(AE30 = c("SCASEE2", "SCASEE3", "SCASEE4", "SCASEE5", "SCASEE8"), BE30 = c("SCASEE10", "SCASEE13", "SCASEE14", "SCASEE15", "SCASEE17"), CE30 = c("SCASEE20", "SCASEE21", "SCASEE22", "SCASEE23", "SCASEE28"), AI30 = c("SCASEE31", "SCASEE33", "SCASEE35", "SCASEE37", "SCASEE39"), BI30 = c("SCASEE42", "SCASEE44", "SCASEE45", "SCASEE46", "SCASEE49"), CI30=c("SCASEE54", "SCASEE55",  "SCASEE57", "SCASEE59", "SCASEE60"), AFF30 = c("SCASEE2", "SCASEE3", "SCASEE4", "SCASEE5", "SCASEE8","SCASEE31", "SCASEE33", "SCASEE35", "SCASEE37", "SCASEE39"), BEH30=c("SCASEE10", "SCASEE13", "SCASEE14", "SCASEE15", "SCASEE17","SCASEE42", "SCASEE44", "SCASEE45", "SCASEE46", "SCASEE49"), COG30=c("SCASEE20", "SCASEE21", "SCASEE22", "SCASEE23", "SCASEE28","SCASEE54", "SCASEE55",  "SCASEE57", "SCASEE59", "SCASEE60"), ENV30=c("SCASEE2", "SCASEE3", "SCASEE4", "SCASEE5", "SCASEE8", "SCASEE10", "SCASEE13", "SCASEE14", "SCASEE15", "SCASEE17","SCASEE20", "SCASEE21", "SCASEE22", "SCASEE23", "SCASEE28" ), INT30=c("SCASEE31", "SCASEE33", "SCASEE35", "SCASEE37", "SCASEE39","SCASEE42", "SCASEE44", "SCASEE45", "SCASEE46", "SCASEE49","SCASEE54", "SCASEE55",  "SCASEE57", "SCASEE59", "SCASEE60"), SCASEE_30=c("SCASEE2", "SCASEE3", "SCASEE4", "SCASEE5", "SCASEE8", "SCASEE10", "SCASEE13", "SCASEE14", "SCASEE15", "SCASEE17","SCASEE20", "SCASEE21", "SCASEE22", "SCASEE23", "SCASEE28","SCASEE31", "SCASEE33", "SCASEE35", "SCASEE37", "SCASEE39","SCASEE42", "SCASEE44", "SCASEE45", "SCASEE46", "SCASEE49","SCASEE54", "SCASEE55",  "SCASEE57", "SCASEE59", "SCASEE60" ))

#STEP 2
#extract an object for each subscale and scale to source each key
AE30key_source <- SCASEE30_keys_list$AE30
BE30key_source <- SCASEE30_keys_list$BE30
CE30key_source <- SCASEE30_keys_list$CE30
AI30key_source <- SCASEE30_keys_list$AI30
BI30key_source <- SCASEE30_keys_list$BI30
CI30key_source <- SCASEE30_keys_list$CI30

AFF30key_source <- SCASEE30_keys_list$AFF30
BEH30key_source <- SCASEE30_keys_list$BEH30
COG30key_source <- SCASEE30_keys_list$COG30

ENV30key_source <- SCASEE30_keys_list$ENV30
INT30key_source <- SCASEE30_keys_list$INT30

SCASEE30key_source <- SCASEE30_keys_list$SCASEE_30

library(psych)
#STEP 3:  apply the selectFromKeys function to christen it as a key; use this one in commands like alpha
AE30key <- selectFromKeys(AE30key_source)
BE30key <- selectFromKeys(BE30key_source)
CE30key <- selectFromKeys(CE30key_source)
AI30key <- selectFromKeys(AI30key_source)
BI30key <- selectFromKeys(BI30key_source)
CI30key <- selectFromKeys(CI30key_source)

AFF30key <- selectFromKeys(AFF30key_source)
BEH30key <- selectFromKeys(BEH30key_source)
COG30key <- selectFromKeys(COG30key_source)

ENV30key <- selectFromKeys(ENV30key_source)
INT30key <- selectFromKeys(INT30key_source)

SCASEE_30key <- selectFromKeys(SCASEE30key_source)
```

```{r}
#this code changes an entire df to numeric -- needed when running the alpha function in psych (among others)
library(tidyverse)
Init_df <- mutate_all(Init_df, function(x) as.numeric(as.character(x)))

#confirm by looking at structure
str(Init_df)
```

### Alphas
```{r Alpha SCASEE30}
psych::alpha(Init_df[SCASEE_30key])
```

```{r Alpha ENV30}
psych::alpha(Init_df[ENV30key])
```

```{r Alpha AE30}
psych::alpha(Init_df[AE30key])
```

```{r Alpha BE30}
psych::alpha(Init_df[BE30key])
```

```{r Alpha CE30}
psych::alpha(Init_df[CE30key])
```

```{r Alpha INT30}
psych::alpha(Init_df[INT30key])
```

```{r Alpha AI30}
psych::alpha(Init_df[AI30key])
```

```{r Alpha BI30}
psych::alpha(Init_df[BI30key])
```

```{r Alpha CI30}
psych::alpha(Init_df[CI30key])
```

```{r Alpha AFF30}
psych::alpha(Init_df[AFF30key])
```

```{r Alpha BEH30}
psych::alpha(Init_df[BEH30key])
```

```{r Alpha COG30}
psych::alpha(Init_df[COG30key])
```

**Next the 18-item SCASEE**

```{r Keys for 18 item SCASEE}
#STEP 1:make a list of the keys
SCASEE18_keys_list <- list(AE18 = c("SCASEE2", "SCASEE4", "SCASEE8"), BE18 = c("SCASEE13", "SCASEE15", "SCASEE17"), CE18 = c("SCASEE20", "SCASEE21", "SCASEE23"), AI18 = c("SCASEE31", "SCASEE33", "SCASEE39"), BI18 = c("SCASEE44", "SCASEE45", "SCASEE46"), CI18=c("SCASEE55","SCASEE59", "SCASEE60"), AFF18 = c("SCASEE2", "SCASEE4", "SCASEE8","SCASEE31", "SCASEE33", "SCASEE39"), BEH18=c("SCASEE13", "SCASEE15", "SCASEE17","SCASEE44", "SCASEE45", "SCASEE46"), COG18=c("SCASEE20", "SCASEE21", "SCASEE23", "SCASEE55","SCASEE59", "SCASEE60"), ENV18=c("SCASEE2", "SCASEE4", "SCASEE8", "SCASEE13", "SCASEE15", "SCASEE17", "SCASEE20", "SCASEE21", "SCASEE23"), INT18=c("SCASEE31", "SCASEE33", "SCASEE39", "SCASEE44", "SCASEE45", "SCASEE46","SCASEE55","SCASEE59", "SCASEE60"), SCASEE_18=c("SCASEE2", "SCASEE4", "SCASEE8", "SCASEE13", "SCASEE15", "SCASEE17", "SCASEE20", "SCASEE21", "SCASEE23", "SCASEE31", "SCASEE33", "SCASEE39", "SCASEE44", "SCASEE45", "SCASEE46","SCASEE55","SCASEE59", "SCASEE60"))

#STEP 2
#extract an object for each subscale and scale to source each key
AE18key_source <- SCASEE18_keys_list$AE18
BE18key_source <- SCASEE18_keys_list$BE18
CE18key_source <- SCASEE18_keys_list$CE18
AI18key_source <- SCASEE18_keys_list$AI18
BI18key_source <- SCASEE18_keys_list$BI18
CI18key_source <- SCASEE18_keys_list$CI18

AFF18key_source <- SCASEE18_keys_list$AFF18
BEH18key_source <- SCASEE18_keys_list$BEH18
COG18key_source <- SCASEE18_keys_list$COG18

ENV18key_source <- SCASEE18_keys_list$ENV18
INT18key_source <- SCASEE18_keys_list$INT18

SCASEE18key_source <- SCASEE18_keys_list$SCASEE_18

library(psych)
#STEP 3:  apply the selectFromKeys function to christen it as a key; use this one in commands like alpha
AE18key <- selectFromKeys(AE18key_source)
BE18key <- selectFromKeys(BE18key_source)
CE18key <- selectFromKeys(CE18key_source)
AI18key <- selectFromKeys(AI18key_source)
BI18key <- selectFromKeys(BI18key_source)
CI18key <- selectFromKeys(CI18key_source)

AFF18key <- selectFromKeys(AFF18key_source)
BEH18key <- selectFromKeys(BEH18key_source)
COG18key <- selectFromKeys(COG18key_source)

ENV18key <- selectFromKeys(ENV18key_source)
INT18key <- selectFromKeys(INT18key_source)

SCASEE_18key <- selectFromKeys(SCASEE18key_source)
```


### Alphas
```{r Alpha SCASEE18}
psych::alpha(Init_df[SCASEE_18key])
```

```{r Alpha ENV18}
psych::alpha(Init_df[ENV18key])
```

```{r Alpha AE18}
psych::alpha(Init_df[AE18key])
```

```{r Alpha BE18}
psych::alpha(Init_df[BE18key])
```

```{r Alpha CE18}
psych::alpha(Init_df[CE18key])
```

```{r Alpha INT18}
psych::alpha(Init_df[INT18key])
```

```{r Alpha AI18}
psych::alpha(Init_df[AI18key])
```

```{r Alpha BI18}
psych::alpha(Init_df[BI18key])
```

```{r Alpha CI18}
psych::alpha(Init_df[CI18key])
```

```{r Alpha AFF18}
psych::alpha(Init_df[AFF18key])
```

```{r Alpha BEH18}
psych::alpha(Init_df[BEH18key])
```

```{r Alpha COG18}
psych::alpha(Init_df[COG18key])
```


# redo
## Alphas for other scales

```{r Keys for 18 item SCASEE}
#STEP 1:make a list of the keys
Other_keys_list <- list(AGLII = c("AGLII1r", "AGLII2", "AGLII3r", "AGLII4", "AGLII5r", "AGLII6", "AGLII7", "AGLII8", "AGLII9", "AGLII10", "AGLII11", "AGLII12", "AGLII13", "AGLII14r"), PWB = c("PWB1", "PWB2", "PWB3", "PWB4", "PWB5", "PWB6", "PWB7", "PWB8", "PWB9", "PWB10"), IASE =c("IASE1", "IASE2", "IASE3", "IASE4", "IASE5", "IASE6", "IASE7", "IASE8", "IASE9", "IASE10", "IASE11", "IASE12", "IASE13", "IASE14", "IASE15", "IASE16", "IASE17", "IASE18", "IASE19", "IASE20", "IASE21", "IASE22", "IASE23", "IASE24", "IASE25", "IASE26", "IASE27"), NGSE =c("NGSE1", "NGSE2", "NGSE3", "NGSE4", "NGSE5", "NGSE6", "NGSE7", "NGSE8"))

#STEP 2
#extract an object for each subscale and scale to source each key
AGLIIkey_source <- Other_keys_list$AGLII
PWBkey_source <- Other_keys_list$PWB
IASEkey_source <- Other_keys_list$IASE
NGSEkey_source <- Other_keys_list$NGSE

#STEP 3:  apply the selectFromKeys function to christen it as a key; use this one in commands like alpha
AGLII_key <- selectFromKeys(AGLIIkey_source)
PWB_key <- selectFromKeys(PWBkey_source)
IASE_key <- selectFromKeys(IASEkey_source)
NGSE_key <- selectFromKeys(NGSEkey_source)
```

```{r}
library(psych)
```

```{r Alpha AGLII}
psych::alpha(Init_df[AGLII_key])
```

```{r Alpha PWBpre}
psych::alpha(Init_df[PWB_key])
```

```{r Alpha IASE}
psych::alpha(Init_df[IASE_key])
```

```{r Alpha NGSE}
psych::alpha(Init_df[NGSE_key])
```
