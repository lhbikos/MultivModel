---
title: "Dissertation"
output:
  word_document: default
  html_document: default
date: '2022-03-23'
---
```{r}
#will install the package if not already installed
if(!require(qualtRics)){install.packages("qualtRics")} 
if(!require(tidyverse)){install.packages("tidyverse")}
```

```{r}
#only have to run this ONCE to draw from the same Qualtrics account...but will need to get diff
#library(qualtRics)
#qualtrics_api_credentials(api_key = "Q65NIelIWsnSBw0uUIJtKIm3oYmxBbWxgP6apCT9",
#base_url = "spupsych.az1.qualtrics.com", overwrite = TRUE, install = TRUE)
#readRenviron("~/.Renviron")
```

```{r}
#QTRX_csv <- qualtRics::read_survey("KCSARC_VPS220323.csv", strip_html = TRUE, import_id = FALSE, time_zone = FALSE)
```

```{r}
#surveys <- all_surveys()
#surveys
```

There initial attempts (look at examples in text to say I used AIA approach
to analyze and manage missing data)

```{r}
#df <-qualtRics::fetch_survey(surveyID = "SV_6zEqY4i6p8rGJz7", time_zone = NULL, 
#verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
``` 

```{r}
#saveRDS(df, "df896.rds")
#getwd()
df<-readRDS("df896.rds")
```

```{r}
library(tidyverse)
#the identification key was three parts; the second used letters from their name
#the students were using a mix of upper and lowercase; this makes it all upper case (otherwise R would read them as different people).
#this code makes the second part of the identification key all upper case
df$Key_2 <- toupper(df$Key_2) 

#this combines the three parts of the key
df$StdID <- paste(df$Key_1, "-", df$Key_2, "-", df$Key_3)

#this assigns an index number (time1, time2, etc.) by the ID
df <- df%>%
  group_by(StdID)%>%
  mutate(index = order(order(EndDate, decreasing = FALSE)))
#this puts those variables we care about all at the front so we can check our work
#for your project I want to get rid of all those with a number 2,
#unfortunately, the students who took this survey all before we had the key/identification system all have NAs,
#so first I have to recode those kids with NA as NA before I can delete the "2s"
df <-(select (df, StdID, index, EndDate, everything()))
#this code recodes all the students with an ID of NA - NA - NA as NA
df$index <- ifelse(df$StdID == "NA - NA - NA", NA, df$index)
#this less us properly delete the students who took it a second time (it saved us one student)
df <- df[!(df$index =="2"),]
#I would have liked to keep the ID variable, but for some reason R was reading it as "very important" and insisted that it remain in all the remaining dataframes. This means it was messing up scoring and alpha coefficients
#I deleted it and things seem to work fine.  Weird. Really. Weird.
df <- subset(df, select = -(StdID))
```


```{r}
df$gender <- factor(df$Gender,
levels = c("1","2", "3"),
labels = c("Male", "Female", "Other"))

str(df$gender)
```

I figured out that neither lavaan nor Hayes' process macro for R can handle a multi-categorical predictor.

SO!  (more hours), I decided that we should eliminate the 7 students who identified as "other" and dummy-code Gender (0 = male, 1 = female). Once dummy-coded (and in numeric format, rather than factor), it's ok to enter the dichotomous variable in its numerical format.
```{r}
df <- subset(df, gender != "Other") #subset data

df$Gender <- plyr::mapvalues(df$gender, from = c("Male", "Female"), to = c(0, 1))

df$Gender <- droplevels(df$Gender)

df$Gender <- as.numeric(df$Gender)
df$Gender <- df$Gender-1
str(df$Gender)
```

```{r}
#dev.set(dev.next())
```

```{r}

df %>%
    count(Q31)
```







I scored my variables, if there were at least 80% nonmissing (part of AIA approach look for citation)
```{r}
library(sjstats)
Emp_vars <- c('emp1_1','emp1_2','emp1_3','emp1_4','emp2_1','emp2_2','emp2_3','emp2_4','emp2_5')

df$Empathy <- sjstats::mean_n(df[,Emp_vars], .80)

```

```{r}
Con_vars <- c('consent_1','consent_2','consent_3','consent_4','consent_5','consent_6')

df$Consent <- sjstats::mean_n(df[,Con_vars], .80)
```

```{r}
Mgrs_vars<- c('mgrs_1','mgrs_2', 'mgrs_3', 'mgrs_4', 'mgrs_5', 'mgrs_6', 'mgrs_7')
df$MGRS <- sjstats::mean_n(df[,Mgrs_vars], .80)

```

```{r}
EMPdf <- df%>%dplyr::select(emp1_1:emp2_5)
psych::alpha(EMPdf)
str(EMPdf)
```

```{r}
CONdf <- df%>%dplyr::select(consent_1:consent_6)
psych::alpha(CONdf)
```

```{r}
MGRSdf<- df%>%dplyr::select(mgrs_1:mgrs_7)
psych::alpha(MGRSdf)
```

```{r}
MODELdf<- df%>%dplyr::select(Age, Ethnicity, Gender, gender, Empathy, Consent, MGRS)
#MODELdf <- rename(MODELdf, Gender = gender)
MODELdf<- dplyr::filter(MODELdf, rowSums(is.na(MODELdf)) != ncol(MODELdf))
```
Considering the variables in my study there were 466 cases with nonmissingness. 
I will conduct the missing analysis on the variables that I use in the study
```{r}
mice_out <- mice::md.pattern(MODELdf, plot = TRUE, rotate.names = TRUE)
mice_out
```



```{r}
MODELdf<-MODELdf[complete.cases(MODELdf), ]
```
Mean age is 15.5 with a standard deviation of 1.6.  The youngest participant age was 13 and the oldest was 19.  
```{r}
psych::describe(MODELdf)
```
```{r}
MODELdf$Mahal <- psych::outlier(MODELdf[c("Empathy", "Consent", "MGRS")]) 
```
```{r}
psych::describe(MODELdf$Mahal)
```
```{r}
MODELdf$MOutlier <- if_else(MODELdf$Mahal > (median(MODELdf$Mahal) + (3*sd(MODELdf$Mahal))), TRUE, FALSE)
library(dplyr)
OutlierCount <- MODELdf%>%  
  count(MOutlier)
OutlierCount
```
```{r}
MODELdf<- dplyr::filter (MODELdf, MOutlier != "TRUE")
```


```{r}
ALLvars <- c('Gender','MGRS','Empathy','Consent')
apaTables::apa.cor.table(MODELdf[, c('Gender','MGRS','Empathy','Consent')],filename="mytable.doc", table.number=1, show.sig.stars=TRUE)
```
# Demographics

```{r}
#0 = male; 1 = female
MODELdf %>%
  count(Gender)
```

```{r}
str(MODELdf$Ethnicity)
```
```{r}
MODELdf$Ethn <- factor(MODELdf$Ethnicity,
levels = c("1","2", "3", "4", "5", "6", "7"),
labels = c("Asian", "Black", "Hispanic", "White", "NativeAm", "Multiracial", "Other"))

MODELdf %>%
  count(Ethn)

```

Do these totals add to our sample size?  
```{r}
120+21+55+160+3+58+11
154+23+66+190+3+70+11
```

Can divide each ethnicity by total sample to get % of that ethnicity
```{r}
154/517
```




Model has a simple mediation and two simple moderations. Let's do them:

## Simple 

The processR package has been removed fromt the CRAN. Because you are likely still using the same base R, R Studio, and packages -- it would probably run on your computer. However, in my computer nightmares (motherboard broke and I have a "spare" and had to install all that stuff from scratch), p, I had to reinstall R and all my packages and no longer have access to ProcessR. That's ok for me, I wasn't really trusting it. And this has given me more practice in getting lavaan and its related packages to do more of the work.

We're down to straight up lavaan.

```{r}
set.seed(230207) #using same seed
med <- '
          Consent ~ b*MGRS + c_p*Gender 
          MGRS ~ a*Gender
          
          indirect :=  a*b
          direct  := c_p
          total_c  := c_p + (a*b)
          '
med_fit <- lavaan::sem(med, data = MODELdf, se="bootstrap", missing= 'fiml')
lavaan::summary(med_fit, standardized=TRUE, rsq=T, ci=TRUE)

```
```{r}
MedOUT <- lavaan::parameterEstimates(med_fit, boot.ci.type = "bca.simple", standardized=TRUE, rsq=T, ci=TRUE)
MedOUT

```
```{r}
write.csv(MedOUT, file = "MedOUT.csv")
```

https://cran.r-project.org/web/packages/tidySEM/vignettes/Plotting_graphs.html 
```{r}
#only worked when I used the library to turn on all these pkgs
library(lavaan)
library(dplyr)
library(ggplot2)
library(tidySEM)
tidySEM::graph_sem(model=med_fit)
```
This code lets us understand the label names and how they are mapped
```{r}
tidySEM::get_layout(med_fit)
```
We can write code to remap them
```{r}
med_map <- tidySEM::get_layout("", "MGRS", "",
                               "Gender", "", "Consent", rows=2)
med_map
```
We run again with our map and BOOM!  Still needs tinkering for gorgeous, but hey!
```{r}
tidySEM::graph_sem(med_fit, layout=med_map)
```


## Moderation #1:  Empathy*Gender moderation on Consent


```{r}
set.seed(230207)
mod1<- '
    Consent ~ b1*Gender + b2*Empathy + b3*Gender:Empathy
    #intercept (constant) of DV
    Consent ~ Consent.mean*1
    #mean of W (Empathy, in this case) for use in simple slopes
    Empathy ~ Empathy.mean*1
    #variance of W (Empathy, in this case) for use in simple slopes
    Empathy ~~Empathy.var*Empathy

    #simple slopes
    SD.below := b1 + b3*(Empathy.mean - sqrt(Empathy.var))
    mean := b1 + b3*(Empathy.mean)
    SD.above := b1 + b3*(Empathy.mean + sqrt(Empathy.var))
'
mod1_fit <- lavaan::sem(mod1, data = MODELdf, missing = 'fiml', se = "bootstrap", bootstrap = 1000)
lavaan::summary(mod1_fit, standardized = TRUE, rsq=T, ci=TRUE)    
```
```{r}
Mod1OUT <- lavaan::parameterEstimates(mod1_fit, boot.ci.type = "bca.simple", standardized=TRUE, rsq=T, ci=TRUE)
Mod1OUT
```
```{r}
write.csv(Mod1OUT, file = "Mod1OUT.csv")
```


```{r}
tidySEM::graph_sem(model=mod1_fit)
```
```{r}
tidySEM::get_layout(mod1_fit)
```
```{r}
mod1_map <- tidySEM::get_layout("Gender", "",
         "Empathy", "Consent",
         "Gender:Empathy", "", rows=3)
mod1_map
```

```{r}
tidySEM::graph_sem(mod1_fit, layout=mod1_map)
```


Let's graph the simple interaction. Let's run it in OLS (the graph will work)

This checks out with the same results we just got!
```{r}
OLSmod1 <- lm(Consent ~ Gender*Empathy, data=MODELdf)
summary(OLSmod1)
```
```{r}
library(interactions)
library(ggplot2)
interactions::interact_plot(OLSmod1, pred=Gender, modx=Empathy, pred.labels=c("Male", "Female")) + ylim(0, 100)
```



## Moderation #2:  Empathy*MGRS moderation on Consent

```{r}
set.seed(230207)
mod2<- '
    Consent ~ b1*MGRS + b2*Empathy + b3*MGRS:Empathy
    #intercept (constant) of DV
    Consent ~ Consent.mean*1
    #mean of W (Empathy, in this case) for use in simple slopes
    Empathy ~ Empathy.mean*1
    #variance of W (Empathy, in this case) for use in simple slopes
    Empathy ~~Empathy.var*Empathy

    #simple slopes
    SD.below := b1 + b3*(Empathy.mean - sqrt(Empathy.var))
    mean := b1 + b3*(Empathy.mean)
    SD.above := b1 + b3*(Empathy.mean + sqrt(Empathy.var))
'
mod2_fit <- lavaan::sem(mod2, data = MODELdf, missing = 'fiml', se = "bootstrap", bootstrap = 1000)
lavaan::summary(mod2_fit, standardized = TRUE, rsq=T, ci=TRUE)    
```


```{r}
Mod2OUT<-lavaan::parameterEstimates(mod2_fit)
Mod2OUT
```

```{r}
write.csv(Mod2OUT, file = "Mod2OUT.csv")
```

```{r}
tidySEM::graph_sem(model=mod2_fit)
```
```{r}
tidySEM::get_layout(mod2_fit)
```
```{r}
mod2_map <- tidySEM::get_layout("MGRS", "",
         "Empathy", "Consent",
         "MGRS:Empathy", "", rows=3)
mod2_map
```
```{r}
tidySEM::graph_sem(mod2_fit, layout=mod2_map)
```


And now to get to an interaction plot of this second regression (the potential moderation of the b path).

```{r}
OLSmod2 <- lm(Consent ~ MGRS*Empathy, data=MODELdf)
summary(OLSmod2)
```
```{r}
interactions::interact_plot(OLSmod2, pred=MGRS, modx=Empathy) + ylim(0, 100)
```


## The final assembly

```{r}
set.seed(230207)

Combined <- '
    #equations
    MGRS ~ a*Gender    
    Consent ~ c_p1*Gender + c_p2*Gender:Empathy + b1*MGRS + b2*Empathy + b3*MGRS:Empathy

    #intercepts
    MGRS ~ MGRS.mean*1
    Consent ~ Consent.mean*1

    #means, variances of W for simple slopes
    Empathy ~ Empathy.mean*1
    Empathy ~~ Empathy.var*Empathy
    
    #index of moderated mediation, there will be an a and b path in the product
    #if the a and/or b path is moderated, select the label that represents the moderation
    imm := a*b3

    #Note that we first create the indirect product, then add to it the product of the imm and the W level
    indirect.SDbelow := a*b1 + imm*(Empathy.mean - sqrt(Empathy.var))
    indirect.mean := a*b1 + imm*(Empathy.mean)
    indirect.SDabove := a*b1 + imm*(Empathy.mean + sqrt(Empathy.var))

    #direct effect is also moderated so calculate with c_p1 + c_p3
    direct.SDbelow := c_p1 + c_p2*(Empathy.mean - sqrt(Empathy.var)) 
    direct.Smean := c_p1 + c_p2*(Empathy.mean)
    direct.SDabove := c_p1 + c_p2*(Empathy.mean + sqrt(Empathy.var))

    #total effect
    total.SDbelow := direct.SDbelow + indirect.SDbelow
    total.mean := direct.Smean + indirect.mean
    total.SDabove := direct.SDabove + indirect.SDabove
 '
Combined_fit <- lavaan::sem(Combined, data = MODELdf, se = "bootstrap", missing = 'fiml', bootstrap = 1000)
lavaan::summary(Combined_fit, standardized = TRUE, rsq=T, ci=TRUE)    

```
```{r}
ModMedOUT<- lavaan::parameterEstimates(Combined_fit, boot.ci.type = "bca.simple", standardized=TRUE, rsq=T, ci=TRUE)
ModMedOUT
```


```{r}
write.csv(ModMedOUT, file = "ModMedOUT.csv")
#semTable::semTable(Combined_fit)
```


```{r}
tidySEM::graph_sem(model=Combined_fit)
```
```{r}
tidySEM::get_layout(Combined_fit)
```
```{r}
Combo_map <- tidySEM::get_layout(
        "", "", "MGRS", "", "Empathy", "",
        "", "", "", "", "", "MGRS:Empathy", 
        "Gender", "", "", "", "Consent", "", 
        "", "", "", "Gender:Empathy", "", "", rows=4)
Combo_map
```

     MGRS   Empathy
            MGRS:Empathy
Gender            Consent
      Gender:Empathy

```{r}
tidySEM::graph_sem(Combined_fit, layout=Combo_map, rect_width = 2.5, rect_height = 1.5, spacing_x = 3, spacing_y = 3, text_size = 2.5)
```




