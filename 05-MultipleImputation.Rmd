---
output:
  word_document: default
  html_document: default
---
# Multiple Imputation (A Brief Demo) {#multimp}

[Screencasted Lecture Link](https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=94d59efe-3f02-4c65-b068-ad01003e09a9)

Multiple imputation is a tool for managing missing data that works with the whole raw data file to impute values for missing data for *multiple sets* (e.g., 5-20) of the raw data. Those multiple sets are considered together in analyses (such as regression) and interpretation is made on the pooled results.  Much has been written about multiple imputation and, if used, should be done with many considerations.  This chapter is intended as a brief introduction.  In this chapter, I demonstrate the use of multiple imputation with the data from the [Rate-a-Recent-Course:  A ReCentering Psych Stats Exercise](https://spupsych.az1.qualtrics.com/jfe/form/SV_b2cClqAlLGQ6nLU) that has served as the research vignette for the first few chapters of this OER.

## Navigating this Lesson

There is about one hour of lecture.  If you work through the materials with me it would be good to add another hour (to an hour-and-a-half).

While the majority of R objects and data you will need are created within the R script that sources the chapter, there are a few that cannot be created from within the R framework. Additionally, sometimes links fail.  All original materials are provided at the [Github site](https://github.com/lhbikos/ReC_MultivariateModeling) that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER's [introduction](#ReCintro)

### Learning Objectives

Learning objectives from this lecture include the following:

* Describe circumstances under which multiple imputation would be appropriate 
* List and define the stages in multiple imputation.
* Apply multiple imputation to a dataset that has missingness
* Interpret results from a simple regression that uses multiple imputation
* Articulate how multiple imputation fits into the workflow for scrubbing and scoring data.
* Write up the results of an the process of imputation from raw data through analyzing a simple regression (or similar) analysis.

### Planning for Practice

The suggestions for practice are a continuation from the three prior chapters. If you have completed one or more of those assignments, you should have worked through the steps in preparing a data set and evaluating its appropriateness for the planned, statistical, analysis. This chapter takes a deviation from the AIA [@parent_handling_2013] approach that was the focus of the first few chapters in that we used multiple imputation as the approach for managing missingness.  Options, of graded complexity, for practice include:

* Repeating the steps in the chapter with the most recent data from the Rate-A-Recent-Course survey; differences will be in the number of people who have completed the survey since the chapter was written.
* Use the dataset that is the source of the chapter, but score a different set of items that you choose.
* Begin with raw data to which you have access. 

### Readings & Resources

In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.

Enders, C. K. (2017). Multiple imputation as a flexible tool for missing data handling in clinical research. *Behaviour Research and Therapy*, 98, 4â€“18.

Katitas, A. (2019). Getting Started with Multiple Imputation in R. University of Virginia Library:  Research Data Services + Sciences. https://uvastatlab.github.io/2019/05/01/getting-started-with-multiple-imputation-in-r/

Kline Ch4, Data Preparation & Psychometrics Review (pp. 72/Outliers - 88/Modern Methods)

Little, T. D., Howard, W. J., McConnell, E. K., & Stump, K. N. (2008). Missing data in large data projects: Two methods of missing data imputation when working with large data projects. KUant Guides, 011.3, 10.

### Packages

The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.

<!-- TODO: Build out this section. -->
```{r initial packages for multiple imputation, eval=FALSE}
#will install the package if not already installed
if(!require(qualtRics)){install.packages("qualtRics")}
if(!require(psych)){install.packages("psych")}
if(!require(dplyr)){install.packages("dplyr")}
if(!require(mice)){install.packages("mice")}
#if(!require(foreign)){install.packages("foreign")}
#if(!require(car)){install.packages("car")}
```


## Workflow for Multiple Imputation

The following is a proposed workflow for preparing data for analysis. 

![An image of a workflow for scrubbing and scoring data.](images/Ch05/scrubscore_mimp_itemlvl.jpg) 

In this lecture we are working on the right side of the flowchart in the multiple imputation (blue) section.  Within it, there are two options, each with a slightly different set of options.

* imputing at the item level
  * in this case, scales/subscales are scored after the item-level imputation
* imputating at the scale level
  * in this case, scales/subscales are scored prior to the imputation; likely using some of the same criteria as identified in the scoring chapter (i.e., scoring if 75-80% of data are non-missing). Multiple imputation, then, is used to estimate the remaining, missing values.
 
Whichever approach is used, the imputed variables (multiple sets) are used in a *pooled analysis* and results are interpreted from that analysis.

## Research Vignette

The research vignette comes from the survey titled, [Rate-a-Recent-Course:  A ReCentering Psych Stats Exercise](https://spupsych.az1.qualtrics.com/jfe/form/SV_b2cClqAlLGQ6nLU) and is explained in the [scrubbing chapter](#scrub). In the [scoring chapter](#score) we prepared four variables for analysis. In the [data diagnostics chapter](#DataDx) we assessed the quality of the variables and conducted the multiple regression described below. Details for these are in our [codebook](./Rate-a-Course_Codebook.pdf).

Let's quickly review the variables in our model:

* Perceived Campus Climate for Black Students includes 6 items, one of which was reverse scored. This scale was adapted from Szymanski et al.'s [-@szymanski_perceptions_2020] Campus Climate for LGBTQ students. It has not been evaluated for use with other groups.  The Szymanski et al. analysis suggested that it could be used as a total scale score, or divided into three items each that assess
  * College response to LGBTQ students (items 6, 4, 1)
  * LGBTQ stigma (items 3, 2, 5)
* Sense of Belonging includes 3 items. This is a subscale from Bollen and Hoyle's [-@bollen_perceived_1990] Perceived Cohesion Scale. There are no items on this scale that require reversing.
* Percent of Black classmates is a single item that asked respondents to estimate the proportion of students in various racial categories
* Percent of BIPOC instructional staff, similarly, asked respondents to identify the racial category of each member of their instructional staff

As we noted in the [scrubbing chapter](#scrub), our design has notable limitations. Briefly, (a) owing to the open source aspect of the data we do not ask about the demographic characteristics of the respondent; (b) the items that ask respondents to *guess* the identities of the instructional staff and to place them in broad categories, (c) we do not provide a "write-in" a response. We made these decisions after extensive conversation with stakeholders. The primary reason for these decisions was to prevent potential harm (a) to respondents who could be identified if/when the revealed private information in this open-source survey, and (b) trolls who would write inappropriate or harmful comments. 
  
As I think about "how these variables go together" (which is often where I start in planning a study), I suspect parallel mediation.  That is the perception of campus climate for Black students would be predicted by the respondent's sense of belonging, mediated in separate paths through the proportion of classmates who are Black and the proportion of BIPOC instructional staff.  

*I would like to assess the model by having the instructional staff variable to be the %Black instructional staff.  At the time that this lecture is being prepared, there is not sufficient Black representation in the instructional staff to model this.* 

![An image of the statistical model for which we are preparing data.](images/Ch04/BlStuMed.jpg)

As in the [data diagnostic chapter](#DataDx), I will conclude this chapter by conducting a statistical analysis with the multiply imputed data. Because parallel mediation can be complicated (I teach it in a later chapter), I will demonstrate use of our prepared variables with a simple multiple regression.

![An image of the statistical model for which we are preparing data.](images/Ch04/BlStuRegression.jpg)

## Multiple Imputation -- a Super Brief Review

Multiple imputation is complex. Numerous quantitative psychologists had critiqued it and provided numerous cautions and guidelines for its use [@enders_applied_2010; @enders_multiple_2017; @little_missing_2008; @little_statistical_2002]. In brief, 

### Steps in Multiple Imputation

* Multiple imputation starts with a raw data file. 
  * Multiple imputation assumes that data are MAR (remember, MCAR is the more prestigious one).  This means that researchers assume that missing values can be replaced by predictions derived from the observable portion of the dataset.  
* Multiple datasets (often 5 to 20) are created where missing values are replaced via a randomized process (so the same missing value [item 4 for person A] will likely have different values for each dataset). 
* The desired analysis is conducted simultaneously/separately for each of the imputed sets (so if you imputed 5 sets and wanted a linear regression, you get 5 linear regressions).  
* A *pooled analysis* uses the point estimates and the standard errors to provide a single result that represents the analysis.

In a web-hosted guide from the University of Virginia Library, Katitas [-@katitas_getting_2019] provided a user-friendly review and example of using tools in R in a multiple imputation. Katitas' figure is a useful conceptual tool in understanding how multiple imputation works. *This figure is my recreation of Katitas' original.*

![An image adapted from the Katitas multiple imputation guide showing the four stages of multiple imputation.](images/Ch05/KatitasMimpFig.jpg)

* the dataframe with missing data is the single place we start
* we intervene with a package like *mice()* to 
* impute multiple sets of data (filling in the missing variables with different values that are a product of their conditional distribution and an element of "random"); 
  * "mids" ("multiply imputed dataset") is an object class where the completed datasets are stored.
* the "with_mids" command allows OLS regression to be run, as many times as we have imputed datasets (in this figure, 3X).  It produces different regression coefficients for each datset
* the "pool" command pools together the multiple coefficients taking into consideration the value of the coefficients,the standard errors, and the variance of the missing value parameter across the samples.

### Statistical Approaches to Multiple Imputation

**Joint multivariate normal distribution multiple imputation** assumes that the observed data follow a multivariate normal distribution.  The algorithm used draws from this assumed distribution.  A drawback is that if the data do not follow a multivariate normal distribution, the imputed values are incorrect.  *Amelia* and *norm* packages use this approach.

**Conditional multiple imputation** is an iterative procedure, modeling the conditional distribution of a certain variable given the other variables.  In this way the distribution is assumed for each variable, rather than or the entire dataset.  *mice* uses this approach.

*mice*:  multivariate imputation by chained equations

## Working the Problem

Katitas [-@katitas_getting_2019] claims that it is best to impute the data in its rawest form possible because any change would be taking it away from its original distribution.  There are debates about how many variables to include in an imputation.  Some authors would suggest that researchers include everything that was collected. Others (like me) will trim the dataset to include (a) the variables included in the model, plus (b) auxiliary variables (i.e., variables not in the model, but that are sufficiently non-missing and will provide additional information to the data).

In our case we will want:

Item for the variables represented in our model

* the item level responses to the scales/subscales
  * respondents' sense of belonging to campus (3 items)
  * respondents' rating of campus climate for Black students (6 items)
* proportion of BIPOC instructional staff
* proportion of classmates who are Black

Auxiliary variables -- let's choose four. One will be the format of the course.  Three items will be from the course evaluation.

* format, whether the course was taught in-person, a blend, or virtual
* cEval_1, "Course material was presented clearly"
* cEval_13, "Where applicable, issues were considered from multiple perspectives"
* cEval_19, "My understanding of the subject matter increased over the span of the course"


### Selecting and Formatting Variables

There are some guidelines for selecting and formatting variables for imputation.  

* Variables should be in their *most natural* state
* Redundant or too highly correlated variables should not be included
  * If you reverse coded a variable (we haven't yet), that's ok, but if you have already reverse-coded, then exclude the original variable
  * Redundant variables (or multicollinear variables) may cause the multiple imputation process to cease
  * Violation of this also provides clues for troubleshooting 
* Exclude variables with more than 25% missing

To make this as realistic as possible. Let's start with our very raw data.  The [Scrubbing chapter](#scrub) provides greater detail on importing data directly from Qualtrics.  Therefore, I will repeat our protocol that imports the data and then scrubs it for our purposes. As described in the prior chapter, I named variables in Qualtrics to facilitate a more intuitive use in R.

```{r intRavenous qualtRics, warning=FALSE, message=FALSE}
library(qualtRics)
QTRX_df2 <- qualtRics::fetch_survey(surveyID = "SV_b2cClqAlLGQ6nLU",useLocalTime = TRUE,
                         verbose = FALSE, label=FALSE, convert=FALSE, force_request = TRUE, import_id = FALSE)
```

Next, I apply inclusion/exclusion criteria.  As described in the [Scrubbing chapter](#scrub) this includes:

* excluding all *previews*
* including only those who consented
* including only those whose rated course was offered by a U.S. institution

```{r Apply inclusion and exclusion critera}
library(tidyverse)
QTRX_df2 <- filter (QTRX_df2, DistributionChannel != "preview")
QTRX_df2 <-filter (QTRX_df2, Consent == 1)
QTRX_df2 <-filter (QTRX_df2, USinst == 0)
```

Preparing the data also meant renaming some variables that started with numbers (a hassle in R). I also renamed variables on the Campus Climate scale so that we know to which subscale they belong.
```{r rename variables that start with a number}
library(tidyverse)
#renaming variables that started with numbers
QTRX_df2 <- rename(QTRX_df2, iRace1 = '1_iRace', iRace2 = '2_iRace', iRace3 = '3_iRace', iRace4 = '4_iRace', iRace5 = '5_iRace', iRace6 = '6_iRace', iRace7 = '7_iRace', iRace8 = '8_iRace', iRace9 = '9_iRace', iRace10 = '10_iRace')
#renaming variables from the identification of classmates
QTRX_df2 <- rename(QTRX_df2, cmBiMulti = Race_10, cmBlack = Race_1, cmNBPoC = Race_7, cmWhite = Race_8, cmUnsure = Race_2)
```

The Qualtrics download does not include an ID number.  Because new variables are always appended to the end of the df, we also include code to make this the first column. 
```{r applying an ID number for each case}
QTRX_df2 <- QTRX_df2 %>% mutate(ID = row_number())
#moving the ID number to the first column; requires 
QTRX_df2 <- QTRX_df2%>%select(ID, everything())
```

Because this huge df is cumbersome to work with, let's downsize it to be closer to the size we will work with in the imputation
```{r downsizing the df}
mimp_df <-  select (QTRX_df2, ID, iRace1, iRace2, iRace3, iRace4, iRace5, iRace6, iRace7, iRace8, iRace9, iRace10, cmBiMulti, cmBlack, cmNBPoC, cmWhite, cmUnsure, Belong_1:Belong_3, Blst_1:Blst_6, cEval_1, cEval_13, cEval_19, format)
#glimpse(mimp_df)
head(mimp_df)
```

### Creating Composite Variables

Qualtrics imports many of the categorical variables as numbers.  R often reads them numerically (integers or numbers). If they are directly converted to factors, R will sometimes collapse.  In this example, if there is a race that is not represented (e.g., 2 for BiMulti), when the numbers are changed to factors, R will assume it's ordered and will change up the numbers.  Therefore, it is ESSENTIAL to check (again and again ad nauseum) to ensure that your variables are recoding in a manner you understand.
```{r creating an ordered factor}
mimp_df$iRace1 = factor(mimp_df$iRace1,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace2 = factor(mimp_df$iRace2,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace3 = factor(mimp_df$iRace3,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace4 = factor(mimp_df$iRace4,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace5 = factor(mimp_df$iRace5,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace6 = factor(mimp_df$iRace6,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace7 = factor(mimp_df$iRace7,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace8 = factor(mimp_df$iRace8,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace9 = factor(mimp_df$iRace9,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
mimp_df$iRace10 = factor(mimp_df$iRace10,
                        levels = c(0,1,2,3,4),
                        labels = c("Black", "nBpoc", "BiMulti", "White", "NotNotice"))
```

```{r another peek, results='hide'}
head(mimp_df)
```

This is a quick recap of how we calculated the proportion of instructional staff who are BIPOC.
```{r calculating the proportion of BIPOC instructional staff}
#creating a count of BIPOC faculty identified by each respondent
mimp_df$count.BIPOC <- apply(mimp_df[c("iRace1", "iRace2", "iRace3", "iRace4", "iRace5", "iRace6", "iRace7", "iRace8", "iRace9", "iRace10")], 1, function(x) sum(x %in% c("Black", "nBpoc", "BiMulti")))

#creating a count of all instructional  faculty identified by each respondent
mimp_df$count.nMiss <- apply(mimp_df[c("iRace1", "iRace2", "iRace3", "iRace4", "iRace5", "iRace6", "iRace7", "iRace8", "iRace9", "iRace10")], 1, function(x) sum(!is.na(x)))

#calculating the proportion of BIPOC faculty with the counts above
mimp_df$iBIPOC_pr = mimp_df$count.BIPOC/mimp_df$count.nMiss
```

I have included another variable, *format* that we will use as auxiliary variable. As written, these are the following meanings:

1. In-person (all persons are attending in person)
2. In person (some students are attending remotely)
3. Blended:  some sessions in person and some sessions online/virtual
4. Online or virtual
5. Other

Let's recoded it to have three categories:

0. 100% in-person (1)
1. Some sort of blend/mix (2, 3)
2. 100% online/virtual (4)
NA. Other (5)

```{r creating an ordered factor for course format}
#we can assign more than one value to the same factor by repeating the label
mimp_df$format = factor(mimp_df$format,
                        levels = c(1,2,3,4,5),
                        labels = c("InPerson", "Blend", "Blend", "Online", is.na(5)))
```


Let's trim the df again to just include the variables we need in the imputation.
```{r trim the df to variables of interest}
mimp_df <-  select (mimp_df, ID, iBIPOC_pr, cmBlack, Belong_1:Belong_3, Blst_1:Blst_6, cEval_1, cEval_13, cEval_19, format)
```

Recall one of the guidelines was to remove variables with more than 25% missing. This code calculates the proportion missing from our variables and places them in rank order.
```{r Proportion of missingness of each variable for raw data}
p_missing <- unlist(lapply(mimp_df, function(x) sum(is.na(x))))/nrow(mimp_df)
sort(p_missing[p_missing > 0], decreasing = TRUE)
```
Luckily, none of our variables have more than 25% missing (*or at least they didn't when I wrote this; the open nature of the survey and how it sources this chapter could change this*). If we did have a variable with more than 25% missing, we would have to consider what to do about it.

Later we learn that we should eliminate case with greater than 50% missingness.  Let's write code for that, now.
```{r Remove cases with too much missingness}
#Calculating number and proportion of item-level missingness
mimp_df$nmiss <- mimp_df%>%
    select(iBIPOC_pr:format) %>% #the colon allows us to include all variables between the two listed (the variables need to be in order)
    is.na %>% 
    rowSums

mimp_df<- mimp_df%>%
  mutate(prop_miss = (nmiss/15)*100) #11 is the number of variables included in calculating the proportion

mimp_df <- filter(mimp_df, prop_miss <= 50)  #update df to have only those with at least 50% of complete data
```

Once again, trim the df to include only the data to be included in the imputation
```{r another trimming of the df}
mimp_df <-  select (mimp_df, ID, iBIPOC_pr, cmBlack, Belong_1:Belong_3, Blst_1:Blst_6, cEval_1, cEval_13, cEval_19, format)
```

### The Multiple Imputation

Because multiple imputation is a *random* process, if we all want the same answers we need to set a *random seed.* 

```{r Set random seed}
set.seed(210404) #you can pick any number you want, today I'm using today's datestamp
```

The program we will use is *mice*. *mice* assumes that each variable has a distribution and it imputes missing variables according to that distribution.  

This means we need to correctly specify each variable's format/role.  *mice* will automatically choose a distribution (think "format") for each variable; we can override this by changing the methods' characteristics.

The following code sets up the structure for the imputation. I'm not an expert at this -- just following the Katitas example.

```{r Setting up the structure for the imputation}
library(mice)
# runs the mice code with 0 iterations
imp <- mice(mimp_df, maxit = 0)
# Extract predictor Matrix and methods of imputation 
predM = imp$predictorMatrix
meth = imp$method
```

Here we code what format/role each variable should be.
```{r Specifying variable role in imputation}
#These variables are left in the dataset, but setting them = 0 means they are not used as predictors.  
#We want our ID to be retained in the df.  There's nothing missing from it, and we don't want it used as a predictor, so it will just hang out.
predM[, c("ID")]=0

#If you like, view the first few rows of the predictor matrix
#head(predM)

#We don't have any ordered categorical variables, but if we did we would follow this format
#poly <- c("Var1", "Var2")

#We don't have any dichotomous variables, but if we did we would follow this format
#log <- c("Var3", "Var4")

#Unordered categorical variables (nominal variables), but if we did we would follow this format
poly2 <- c("format")

#Turn their methods matrix into the specified imputation models
#Remove the hashtag if you have any of these variables
#meth[poly] = "polr" 
#meth[log] = "logreg"
meth[poly2] = "polyreg"

meth
```

This list (meth) contains all our variables; "pmm" is the default and is the "predictive mean matching" process used. We see that format (an unordered categorical variable) is noted as "polyreg."  If we had used other categorical variables (ordered/poly, dichotomous/log), we would have seen those designations, instead.  If there is "" underneath it means the data is complete.

Our variables of interest are now configured to be imputed with the imputation method we specified.  Empty cells in the method matrix mean that those variables aren't going to be imputed.

If a variable has no missing values, it is automatically set to be empty.  We can also manually set variables to not be imputed with the *meth[variable]=""* command.

The code below begins the imputation process. We are asking for 5 datasets. If you have many cases and many variables, this can take awhile. How many imputations?  Recommendations have ranged as low as five to several hundred.


```{r imputing five sets}
# With this command, we tell mice to impute the anesimpor2 data, create 5vvdatasets, use predM as the predictor matrix and don't print the imputation process. 
#If you would like to see the process (or if the process is failing to execute) set print as TRUE; seeing where the execution halts can point to problematic variables (more notes at end of lecture)

imp2 <- mice(mimp_df, maxit = 5, 
             predictorMatrix = predM, 
             method = meth, print =  FALSE)
```

We need to create a "long file" that stacks all the imputed data.  Looking at the df in R Studio shows us that when imp = 0 (the pe-imputed data), there is still missingness.  As we scroll through the remaining imputations, there are no NA cells.

```{r Restructuring df to long}
# First, turn the datasets into long format
# This procedure is, best I can tell, unique to mice and wouldn't work for repeated measures designs
mimp_long <- mice::complete(imp2, action="long", include = TRUE)
```

If we look at it, we can see 6 sets of data.  Playing with it...

* .imp = 0 is the unimputed set; there are still missing values
* .imp = 1, 2, 3, or 5 has no missing values for the variables we included in the imputation

Sort on the ID number to see how this works...6 sets of data.

With this fully imputed file, let's recode the data as we had done for the OLS regression with the raw, unimputed, data.

```{r Proportion of missingness for each imputed item, eval = FALSE}
p_missing_mimp_long <- unlist(lapply(mimp_long, function(x) sum(is.na(x))))/nrow(mimp_long)
sort(p_missing_mimp_long[p_missing_mimp_long > 0], decreasing = TRUE)#check to see if this works
```

### Creating Scale Scores

Because our imputation was item-level, we need to score the variables with scales/subscales.  As demonstrated more completely in the [Scoring chapter](#score), this required reversing one item in the campus climate scale:

```{r reverse scoring the Blst_1 item}
mimp_long<- mimp_long %>%
  mutate(rBlst_1 = 8 - Blst_1) #if you had multiple items, you could add a pipe (%>%) at the end of the line and add more until the last one
```


Below is the scoring protocol we used in the AIA protocol for scoring.  Although the protocol below functionally says, "Create a mean score if (65-80)% is non-missing, for the imputed version, it doesn't harm anything to leave this because there is no missing data.
```{r Scoring scales and subscales}
library(sjstats)
#Making the list of variables
Belonging_vars <- c('Belong_1','Belong_2','Belong_3')
ResponseBL_vars <- c('rBlst_1', 'Blst_4','Blst_6')
StigmaBL_vars <- c('Blst_2', 'Blst_3','Blst_5')
ClimateBL_vars <- c('rBlst_1', 'Blst_4','Blst_6','Blst_2', 'Blst_3','Blst_5' )

#Creating the new variables
mimp_long$Belonging <- mean_n(mimp_long[,Belonging_vars], .65)
mimp_long$ResponseBL <- mean_n(mimp_long[,ResponseBL_vars], .80)
mimp_long$StigmaBL <- mean_n(mimp_long[,StigmaBL_vars], .80)
mimp_long$ClimateBL <- mean_n(mimp_long[,ClimateBL_vars], .80)
```


## Multiple Regression with Multiply Imputed Data

For a refresher, here was the script when we used the AIA approach for managing missingness:

~~~
Climate_fit <- lm(ClimateBL ~ Belonging + cmBlack + iBIPOC_pr, data = item_scores_df)
summary(Climate_fit)
~~~

In order for the regression to use multiply imputed data, it must be a "mids" (multiply imputed data sets) type
```{r Convertion to mids_A}
# Convert to mids type - mice can work with this type
mimp_mids<-as.mids(mimp_long)
```

Here's what we do with imputed data:

```{r OLS regression w imputed data}
fitimp <- with(mimp_mids,
               lm(ClimateBL ~ Belonging + cmBlack + iBIPOC_pr))
```

In this process, 5 individual, OLS, regressions are being conducted and the results being pooled into this single set.

```{r Summary of each OLS regression}
# to get the 5, individual imputations
summary(fitimp)
```

```{r The pooled result}
# the pooled result
pooledests <- pool(fitimp)
pooledests
#str(pooledests)
```

```{r Another view of the pooled result}
sumpooled <- summary(pool(fitimp))
sumpooled
#str(sumpooled)
```

```{r creating the inline text objects, echo=FALSE, results='hide'}
library(formattable)
mimpBel_B <- digits(sumpooled$estimate[2],3)
mimpBel_B
mimpBel_p <- digits(sumpooled$p.value[2],3)
mimpBel_p
mimp_cmBl_B <- digits(sumpooled$estimate[3],3)
mimp_cmBl_B
mimp_cmBl_p <- digits(sumpooled$p.value[3],3)
mimp_cmBl_p
mimp_i_B <- digits(sumpooled$estimate[4],3)
mimp_i_B
mimp_i_p <- digits(sumpooled$p.value[4],3)
mimp_i_p
```
Results of a multiple regression predicting the respondents' perceptions of campus climate for Black students indicated that neither contributions of the respondents' personal belonging ($B$ = `r mimpBel_B`, $p$ = `r mimpBel_p`) nor the proportion of BIPOC instructional staff ($B$ = `r mimp_i_B`, $p$ = `r mimp_i_p`) led to statistically significant changes in perceptions of campus climate for Black students. Results did suggest a statistically significant negative effect of the proportion of Black classmates on the campus climate for Black students. Specifically, as the proportion of Black students increases, there is less stigmatization and hostility on the campus ($B$ = `r mimp_cmBl_B`, $p$ = `r mimp_cmBl_p`). Results are presented in Table X.


## Toward the APA Style Write-up

### Method/Data Diagnostics

Data screening suggested that `r attempts` individuals opened the survey link. Of those, `r consented_attempts` granted consent and proceeded to the survey items. A further inclusion criteria was that the course was taught in the U.S; `r US_inclusion` met this criteria.  Across cases that were deemed eligible on the basis of the inclusion/exclusion criteria, missingness ranged from `r missMin`% to `r missMax`%.  Across the dataset, `r CellsMiss` of cells had missing data and `r CaseComplete` of cases had nonmissing data. At this stage in the analysis, we allowed all cases with fewer than 50% missing to be included the multiple imputation [@katitas_getting_2019].

Regarding the distributional characteristics of the data, skew and kurtosis values of the variables fell below the values of 3 (skew) and 8 to 20 (kurtosis) that Kline suggests are concerning [-@kline_principles_2016]. Results of the Shapiro-Wilk test of normality indicate that our variables assessing the proportion of classmates who are Black ($W$ = `r cmSW`, $p$ = `r cmSWp`) and the proportion of BIPOC instructional staff($W$ = `r iSW`, $p$ = `r iSWp`)  are statistically significantly different than a normal distribution. The scales assessing the respondent's belonging ($W$ = `r belSW`, $p$ = `r belSWp`) and the respondent's perception of campus climate for Black students ($W$ = `r clSW`, $p$ = `r clSWp`) did not differ differently from a normal distribution.

We evaluated multivariate normality with the Mahalanobis distance test. Specifically, we used the *outlier()* function in the *psych* package and included all continuous variables in the calculation. Our visual inspection of the Q-Q plot suggested that the plotted line strayed from the straight line as the quantiles increased.  Additionally, we appended the Mahalanobis distance scores as a variable to the data. Analyzing this variable, we found that `r NumOutliers$n` exceed three standard deviations beyond the median. *Thus, with no outliers, we assumed multivariate normality and proceeded with the data analysis* AS DATA IS ADDED THIS NUMBER OF OUTLIERS COULD UPDATE FROM ZERO AND THIS TEXT COULD CHANGE.*

We managed missing data with multiple imputation [@enders_multiple_2017; @katitas_getting_2019]. We imputed five sets of data with the R package, *mice* (v. 3.13) -- a program that utilizes conditional multiple imputation. The imputation included the item-level variables that comprised our scales, the variables that represented proportion of BIPOC instructional staff and proportion of Black classmates, as well as four auxiliary variables (three variables from the course evaluation and the format [in-person/blended/virtual] of the class).

### Results

Results of a multiple regression predicting the respondents' perceptions of campus climate for Black students indicated that neither contributions of the respondents' personal belonging ($B$ = `r Bel_B`, $p$ = `r Bel_p`) nor the proportion of BIPOC instructional staff ($B$ = `r i_B`, $p$ = `r i_p`) led to statistically significant changes in perceptions of campus climate for Black students. Results did suggest a statistically significant negative effect of the proportion of Black classmates on the campus climate for Black students. Specifically, as the proportion of Black students increases, there is less stigmatization and hostility on the campus ($B$ = `r cm_B`, $p$ = `r cm_p`). Although it accounted for `r modR2` of the variance, the overall model was not statistically significant. Results are presented in Table 2.

**Some notes about this write-up**

* I went ahead and used the data diagnostics that we did in the AIA method.  It feels to me like these should be calculated with the multiply imputed data (i.e., 5 sets, with pooled estimates and standard errors), but I do not see that modeled -- anywhere in R.
* Note the similarities with the AIA write-up. 


## Multiple imputation considerations

* Character vectors (i.e., values that are represented with words) can be problematic.  If they are causing trouble, consider
  * recode into factors,
  * keep it in the df, but exclude it from the imputation protocol,
  * our "format" variable was an ordered factor (i.e., each term was associated with a value), so I think that helped us avoid problems
* Variables with really high (like 50% or more) proportions of missingness should be excluded.
* Variables that are highly correlated or redundant (even if inverse) will halt the execution. If you set print=TRUE you will see where the algorithm is having difficulty because it will halt at that variable.
* Variables with non-missing values can be problematic.  If they are problematic, just exclude them from the process.
*Width (columns/variables) versus length (rows/cases).  You must have more rows/cases than columns/variables.  It is difficult to say how many.  If this is a problem:
  * Consider scoring scales first with AIA, then impute with whole scales.
  * Divide the df in halves or thirds, impute separately, then join with the ID numbers. 
  * There should be auxiliary variables in each.
*Item-level imputation is its "whole big thing" with multiple, complex considerations.  There are tremendous resources
  *  Enders [BLIMP](http://www.appliedmissingdata.com/multilevel-imputation.html) app is free and works with R
  *  Little's [-@little_statistical_2002] article
* How many imputations? Controversial and has changed over the years. 
  *  Practical concern: the more you request, the longer it will take in R, this demo was 5
  *  For a number of years there was a push for 20, but I've also seen recommendations for 100s.
  *  Check examples of imputed studies in your disciplinary specialty/journals.
* There are lots of discussions and debates about
  * allowing for fractional/decimal responses (a 3.5 on 1 to 4 scaling; or a 0.75 on a dichotomous variable such as male/female)
  * out-of-bounds estimates (what if you get a 7 on 1 to 4 scaling?)


## Practice Problems

The three problems described below are designed to be continuations from the previous chapters. You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.

### Problem #1: Reworking the Chapter Problem

If you chose this option in the prior chapters, you imported the data from Qualtrics, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.

Continue working with this data to:

|Assignment Component                                                          | Points Possible| Points Earned|
|:---------------------------------------------------------------------------- |:-------------: |:------------:|
|1. Import the raw data from Qualtrics                                         |      5         |    _____     |           
|2. Apply inclusionary/exclusionary criteria                                   |      5         |    _____     |
|3. Format any variables that shouldn't be imputed in their raw form           |      5         |    _____     |  
|4. Multiply impute a minimum of 5 sets of data                                |      5         |    _____     |               
|5. Run a regression with at least three variables                             |      5         |    _____     |   
|6. APA style write-up of the multiple imputation section of data diagnostics  |      5         |    _____     |       
|7. APA style write-up regression results                                      |      5         |    _____     |
|8. Explanation to grader                                                      |      5         |    _____     |
|**Totals**                                                                    |      40        |    _____     |             


### Problem #2:  Use the *Rate-a-Recent-Course* Survey, Choosing Different Variables

If you chose this option in the prior chapter, you chose a minimum of three variables from the *Rate-a-Recent-Course* survey to include in a simple statistical model. You imported the data from Qualtrics, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.

Continue working with this data to:

|Assignment Component                                                          | Points Possible| Points Earned|
|:---------------------------------------------------------------------------- |:-------------: |:------------:|
|1. Import the raw data from Qualtrics                                         |      5         |    _____     |           
|2. Apply inclusionary/exclusionary criteria                                   |      5         |    _____     |
|3. Format any variables that shouldn't be imputed in their raw form           |      5         |    _____     |  
|4. Multiply impute a minimum of 5 sets of data                                |      5         |    _____     |               
|5. Run a regression with at least three variables                             |      5         |    _____     |   
|6. APA style write-up of the multiple imputation section of data diagnostics  |      5         |    _____     |       
|7. APA style write-up regression results                                      |      5         |    _____     |
|8. Explanation to grader                                                      |      5         |    _____     |
|**Totals**                                                                    |      40        |    _____     |   
      

### Problem #3:  Other data

If you chose this option in the prior chapter, you used raw data that was available to you. You imported it into R, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.

Continue working with this data to:

|Assignment Component                                                          | Points Possible| Points Earned|
|:---------------------------------------------------------------------------- |:-------------: |:------------:|
|1. Import the raw data from Qualtrics (or elsewhere)                          |      5         |    _____     |           
|2. Apply inclusionary/exclusionary criteria                                   |      5         |    _____     |
|3. Format any variables that shouldn't be imputed in their raw form           |      5         |    _____     |  
|4. Multiply impute a minimum of 5 sets of data                                |      5         |    _____     |               
|5. Run a regression with at least three variables                             |      5         |    _____     |   
|6. APA style write-up of the multiple imputation section of data diagnostics  |      5         |    _____     |       
|7. APA style write-up regression results                                      |      5         |    _____     |
|8. Explanation to grader                                                      |      5         |    _____     |
|**Totals**                                                                    |      40        |    _____     |   
                     

```{r sessionInfo 05}
sessionInfo()
```


