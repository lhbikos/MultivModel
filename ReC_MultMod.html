<!DOCTYPE html>
<html lang="en" xml:lang="en">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>ReCentering Psych Stats: Multivariate Modeling</title>
  <meta name="description" content="This is an open-access, book-in-progress. My goal in offering it is to re-center the materials used in training statistics and research methods in graduate and post-graduate psychology programs." />
  <meta name="generator" content="bookdown #bookdown:version# and GitBook 2.6.7" />

  <meta property="og:title" content="ReCentering Psych Stats: Multivariate Modeling" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is an open-access, book-in-progress. My goal in offering it is to re-center the materials used in training statistics and research methods in graduate and post-graduate psychology programs." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="ReCentering Psych Stats: Multivariate Modeling" />
  
  <meta name="twitter:description" content="This is an open-access, book-in-progress. My goal in offering it is to re-center the materials used in training statistics and research methods in graduate and post-graduate psychology programs." />
  

<meta name="author" content="Lynette H Bikos, PhD, ABPP" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



<!--bookdown:title:start-->
<div id="header">
<h1 class="title">ReCentering Psych Stats: Multivariate Modeling</h1>
<p class="author"><em>Lynette H Bikos, PhD, ABPP</em></p>
</div>
<!--bookdown:title:end-->

<!--bookdown:toc:start-->
  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">
<!--bookdown:toc2:start-->
<ul>
<li><a href="#book-cover">BOOK COVER</a></li>
<li><a href="#preface">PREFACE</a>
<ul>
<li><a href="#copyright-with-open-access">Copyright with Open Access</a></li>
</ul></li>
<li><a href="#acknowledgements">ACKNOWLEDGEMENTS</a></li>
<li><a href="#ReCintro"><span class="toc-section-number">1</span> Introduction</a>
<ul>
<li><a href="#what-to-expect-in-each-chapter"><span class="toc-section-number">1.1</span> What to expect in each chapter</a></li>
<li><a href="#strategies-for-accessing-and-using-this-oer"><span class="toc-section-number">1.2</span> Strategies for Accessing and Using this OER</a></li>
<li><a href="#if-you-are-new-to-r"><span class="toc-section-number">1.3</span> If You are New to R</a>
<ul>
<li><a href="#base-r"><span class="toc-section-number">1.3.1</span> Base R</a></li>
<li><a href="#r-studio"><span class="toc-section-number">1.3.2</span> R Studio</a></li>
<li><a href="#r-hygiene"><span class="toc-section-number">1.3.3</span> R Hygiene</a>
<ul>
<li><a href="#everything-is-documented-in-the-.rmd-file"><span class="toc-section-number">1.3.3.1</span> Everything is documented in the .rmd file</a></li>
<li><a href="#file-organization"><span class="toc-section-number">1.3.3.2</span> File organization</a></li>
<li><a href="#chunks"><span class="toc-section-number">1.3.3.3</span> Chunks</a></li>
<li><a href="#packages"><span class="toc-section-number">1.3.3.4</span> Packages</a></li>
<li><a href="#knitting"><span class="toc-section-number">1.3.3.5</span> Knitting</a></li>
</ul></li>
<li><a href="#troubleshooting-in-r-markdown"><span class="toc-section-number">1.3.4</span> tRoubleshooting in R maRkdown</a></li>
<li><a href="#strategies-for-success"><span class="toc-section-number">1.3.5</span> stRategies for success</a></li>
<li><a href="#resources-for-getting-started"><span class="toc-section-number">1.3.6</span> Resources for getting staRted</a></li>
</ul></li>
</ul></li>
<li><a href="#dataprep">DATA PREP</a></li>
<li><a href="#scrub"><span class="toc-section-number">2</span> Scrubbing</a>
<ul>
<li><a href="#navigating-this-lesson"><span class="toc-section-number">2.1</span> Navigating this Lesson</a>
<ul>
<li><a href="#learning-objectives"><span class="toc-section-number">2.1.1</span> Learning Objectives</a></li>
<li><a href="#planning-for-practice"><span class="toc-section-number">2.1.2</span> Planning for Practice</a></li>
<li><a href="#readings-resources"><span class="toc-section-number">2.1.3</span> Readings &amp; Resources</a></li>
<li><a href="#packages-1"><span class="toc-section-number">2.1.4</span> Packages</a></li>
</ul></li>
<li><a href="#workflow-for-scrubbing-and-scoring"><span class="toc-section-number">2.2</span> Workflow for Scrubbing and Scoring</a></li>
<li><a href="#research-vignette"><span class="toc-section-number">2.3</span> Research Vignette</a></li>
<li><a href="#working-the-problem"><span class="toc-section-number">2.4</span> Working the Problem</a>
<ul>
<li><a href="#intravenous-qualtrics"><span class="toc-section-number">2.4.1</span> intRavenous Qualtrics</a></li>
<li><a href="#about-the-rate-a-recent-course-survey"><span class="toc-section-number">2.4.2</span> About the <em>Rate-a-Recent-Course</em> Survey</a></li>
<li><a href="#the-codebook"><span class="toc-section-number">2.4.3</span> The Codebook</a></li>
</ul></li>
<li><a href="#scrubbing"><span class="toc-section-number">2.5</span> Scrubbing</a>
<ul>
<li><a href="#tools-for-data-manipulations"><span class="toc-section-number">2.5.1</span> Tools for Data Manipulations</a></li>
<li><a href="#inclusion-and-exclusion-criteria"><span class="toc-section-number">2.5.2</span> Inclusion and Exclusion Criteria</a></li>
<li><a href="#renaming-variables"><span class="toc-section-number">2.5.3</span> Renaming Variables</a></li>
<li><a href="#downsizing-the-dataframe"><span class="toc-section-number">2.5.4</span> Downsizing the Dataframe</a></li>
</ul></li>
<li><a href="#toward-the-apa-style-write-up"><span class="toc-section-number">2.6</span> Toward the APA Style Write-up</a>
<ul>
<li><a href="#methodprocedure"><span class="toc-section-number">2.6.1</span> Method/Procedure</a></li>
</ul></li>
<li><a href="#practice-problems"><span class="toc-section-number">2.7</span> Practice Problems</a>
<ul>
<li><a href="#problem-1-rework-the-chapter-problem"><span class="toc-section-number">2.7.1</span> Problem #1: Rework the Chapter Problem</a></li>
<li><a href="#problem-2-use-the-rate-a-recent-course-survey-choosing-different-variables"><span class="toc-section-number">2.7.2</span> Problem #2: Use the <em>Rate-a-Recent-Course</em> Survey, Choosing Different Variables</a></li>
<li><a href="#problem-3-other-data"><span class="toc-section-number">2.7.3</span> Problem #3: Other data</a></li>
</ul></li>
<li><a href="#bonus-track"><span class="toc-section-number">2.8</span> Bonus Track:</a>
<ul>
<li><a href="#importing-data-from-an-exported-qualtrics-.csv-file"><span class="toc-section-number">2.8.1</span> Importing data from an exported Qualtrics .csv file</a></li>
</ul></li>
</ul></li>
<li><a href="#score"><span class="toc-section-number">3</span> Scoring</a>
<ul>
<li><a href="#navigating-this-lesson-1"><span class="toc-section-number">3.1</span> Navigating this Lesson</a>
<ul>
<li><a href="#learning-objectives-1"><span class="toc-section-number">3.1.1</span> Learning Objectives</a></li>
<li><a href="#planning-for-practice-1"><span class="toc-section-number">3.1.2</span> Planning for Practice</a></li>
<li><a href="#readings-resources-1"><span class="toc-section-number">3.1.3</span> Readings &amp; Resources</a></li>
<li><a href="#packages-2"><span class="toc-section-number">3.1.4</span> Packages</a></li>
</ul></li>
<li><a href="#workflow-for-scrubbing-and-scoring-1"><span class="toc-section-number">3.2</span> Workflow for Scrubbing and Scoring</a></li>
<li><a href="#research-vignette-1"><span class="toc-section-number">3.3</span> Research Vignette</a></li>
<li><a href="#on-missing-data"><span class="toc-section-number">3.4</span> On Missing Data</a>
<ul>
<li><a href="#data-loss-mechanisms"><span class="toc-section-number">3.4.1</span> Data Loss Mechanisms</a></li>
<li><a href="#diagnosing-missing-data-mechanisms"><span class="toc-section-number">3.4.2</span> Diagnosing Missing Data Mechanisms</a></li>
<li><a href="#managing-missing-data"><span class="toc-section-number">3.4.3</span> Managing Missing Data</a></li>
<li><a href="#available-information-analysis-aia"><span class="toc-section-number">3.4.4</span> Available Information Analysis (AIA)</a></li>
</ul></li>
<li><a href="#working-the-problem-1"><span class="toc-section-number">3.5</span> Working the Problem</a>
<ul>
<li><a href="#missing-data-analysis-whole-df-and-item-level"><span class="toc-section-number">3.5.1</span> Missing Data Analysis: Whole df and Item level</a></li>
<li><a href="#analyzing-missing-data-patterns"><span class="toc-section-number">3.5.2</span> Analyzing Missing Data Patterns</a></li>
<li><a href="#missing-mechanisms"><span class="toc-section-number">3.5.3</span> Missing Mechanisms</a></li>
</ul></li>
<li><a href="#scoring"><span class="toc-section-number">3.6</span> Scoring</a>
<ul>
<li><a href="#reverse-scoring"><span class="toc-section-number">3.6.1</span> Reverse scoring</a></li>
</ul></li>
<li><a href="#missing-analysis-scale-level"><span class="toc-section-number">3.7</span> Missing Analysis: Scale level</a></li>
<li><a href="#revisiting-missing-analysis-at-the-scale-level"><span class="toc-section-number">3.8</span> Revisiting Missing Analysis at the Scale Level</a>
<ul>
<li><a href="#scale-level-patterns-of-missing-data"><span class="toc-section-number">3.8.1</span> Scale Level: Patterns of Missing Data</a></li>
<li><a href="#is-it-mcar"><span class="toc-section-number">3.8.2</span> Is it MCAR?</a></li>
<li><a href="#r-eady-for-analysis"><span class="toc-section-number">3.8.3</span> R-eady for Analysis</a></li>
</ul></li>
<li><a href="#the-apa-style-write-up"><span class="toc-section-number">3.9</span> The APA Style Write-Up</a></li>
<li><a href="#results"><span class="toc-section-number">3.10</span> Results</a></li>
<li><a href="#practice-problems-1"><span class="toc-section-number">3.11</span> Practice Problems</a>
<ul>
<li><a href="#problem-1-reworking-the-chapter-problem"><span class="toc-section-number">3.11.1</span> Problem #1: Reworking the Chapter Problem</a></li>
<li><a href="#problem-2-use-the-rate-a-recent-course-survey-choosing-different-variables-1"><span class="toc-section-number">3.11.2</span> Problem #2: Use the <em>Rate-a-Recent-Course</em> Survey, Choosing Different Variables</a></li>
<li><a href="#problem-3-other-data-1"><span class="toc-section-number">3.11.3</span> Problem #3: Other data</a></li>
</ul></li>
</ul></li>
<li><a href="#DataDx"><span class="toc-section-number">4</span> Data Dx</a>
<ul>
<li><a href="#navigating-this-lesson-2"><span class="toc-section-number">4.1</span> Navigating this Lesson</a>
<ul>
<li><a href="#learning-objectives-2"><span class="toc-section-number">4.1.1</span> Learning Objectives</a></li>
<li><a href="#planning-for-practice-2"><span class="toc-section-number">4.1.2</span> Planning for Practice</a></li>
<li><a href="#readings-resources-2"><span class="toc-section-number">4.1.3</span> Readings &amp; Resources</a></li>
<li><a href="#packages-3"><span class="toc-section-number">4.1.4</span> Packages</a></li>
</ul></li>
<li><a href="#workflow-for-scrubbing-and-scoring-2"><span class="toc-section-number">4.2</span> Workflow for Scrubbing and Scoring</a></li>
<li><a href="#research-vignette-2"><span class="toc-section-number">4.3</span> Research Vignette</a></li>
<li><a href="#internal-consistency-of-scalessubscales"><span class="toc-section-number">4.4</span> Internal Consistency of Scales/Subscales</a></li>
<li><a href="#distributional-characteristics-of-the-variables"><span class="toc-section-number">4.5</span> Distributional Characteristics of the Variables</a>
<ul>
<li><a href="#evaluating-univariate-normality"><span class="toc-section-number">4.5.1</span> Evaluating Univariate Normality</a></li>
<li><a href="#pairs-panels"><span class="toc-section-number">4.5.2</span> Pairs Panels</a></li>
</ul></li>
<li><a href="#evaluating-multivariate-normality"><span class="toc-section-number">4.6</span> Evaluating Multivariate Normality</a></li>
<li><a href="#a-few-words-on-transformations"><span class="toc-section-number">4.7</span> A Few Words on Transformations</a></li>
<li><a href="#the-apa-style-write-up-1"><span class="toc-section-number">4.8</span> The APA Style Write-Up</a>
<ul>
<li><a href="#data-diagnostics"><span class="toc-section-number">4.8.1</span> Data Diagnostics</a></li>
</ul></li>
<li><a href="#a-quick-regression-of-our-research-vignette"><span class="toc-section-number">4.9</span> A Quick Regression of our Research Vignette</a></li>
<li><a href="#practice-problems-2"><span class="toc-section-number">4.10</span> Practice Problems</a>
<ul>
<li><a href="#problem-1-reworking-the-chapter-problem-1"><span class="toc-section-number">4.10.1</span> Problem #1: Reworking the Chapter Problem</a></li>
<li><a href="#problem-2-use-the-rate-a-recent-course-survey-choosing-different-variables-2"><span class="toc-section-number">4.10.2</span> Problem #2: Use the <em>Rate-a-Recent-Course</em> Survey, Choosing Different Variables</a></li>
<li><a href="#problem-3-other-data-2"><span class="toc-section-number">4.10.3</span> Problem #3: Other data</a></li>
</ul></li>
</ul></li>
<li><a href="#multimp"><span class="toc-section-number">5</span> Multiple Imputation (A Brief Demo)</a>
<ul>
<li><a href="#navigating-this-lesson-3"><span class="toc-section-number">5.1</span> Navigating this Lesson</a>
<ul>
<li><a href="#learning-objectives-3"><span class="toc-section-number">5.1.1</span> Learning Objectives</a></li>
<li><a href="#planning-for-practice-3"><span class="toc-section-number">5.1.2</span> Planning for Practice</a></li>
<li><a href="#readings-resources-3"><span class="toc-section-number">5.1.3</span> Readings &amp; Resources</a></li>
<li><a href="#packages-4"><span class="toc-section-number">5.1.4</span> Packages</a></li>
</ul></li>
<li><a href="#workflow-for-multiple-imputation"><span class="toc-section-number">5.2</span> Workflow for Multiple Imputation</a></li>
<li><a href="#research-vignette-3"><span class="toc-section-number">5.3</span> Research Vignette</a></li>
<li><a href="#multiple-imputation-a-super-brief-review"><span class="toc-section-number">5.4</span> Multiple Imputation – a Super Brief Review</a>
<ul>
<li><a href="#steps-in-multiple-imputation"><span class="toc-section-number">5.4.1</span> Steps in Multiple Imputation</a></li>
<li><a href="#statistical-approaches-to-multiple-imputation"><span class="toc-section-number">5.4.2</span> Statistical Approaches to Multiple Imputation</a></li>
</ul></li>
<li><a href="#working-the-problem-2"><span class="toc-section-number">5.5</span> Working the Problem</a>
<ul>
<li><a href="#selecting-and-formatting-variables"><span class="toc-section-number">5.5.1</span> Selecting and Formatting Variables</a></li>
<li><a href="#creating-composite-variables"><span class="toc-section-number">5.5.2</span> Creating Composite Variables</a></li>
<li><a href="#the-multiple-imputation"><span class="toc-section-number">5.5.3</span> The Multiple Imputation</a></li>
<li><a href="#creating-scale-scores"><span class="toc-section-number">5.5.4</span> Creating Scale Scores</a></li>
</ul></li>
<li><a href="#multiple-regression-with-multiply-imputed-data"><span class="toc-section-number">5.6</span> Multiple Regression with Multiply Imputed Data</a></li>
<li><a href="#toward-the-apa-style-write-up-1"><span class="toc-section-number">5.7</span> Toward the APA Style Write-up</a>
<ul>
<li><a href="#methoddata-diagnostics"><span class="toc-section-number">5.7.1</span> Method/Data Diagnostics</a></li>
<li><a href="#results-1"><span class="toc-section-number">5.7.2</span> Results</a></li>
</ul></li>
<li><a href="#multiple-imputation-considerations"><span class="toc-section-number">5.8</span> Multiple imputation considerations</a></li>
<li><a href="#practice-problems-3"><span class="toc-section-number">5.9</span> Practice Problems</a>
<ul>
<li><a href="#problem-1-reworking-the-chapter-problem-2"><span class="toc-section-number">5.9.1</span> Problem #1: Reworking the Chapter Problem</a></li>
<li><a href="#problem-2-use-the-rate-a-recent-course-survey-choosing-different-variables-3"><span class="toc-section-number">5.9.2</span> Problem #2: Use the <em>Rate-a-Recent-Course</em> Survey, Choosing Different Variables</a></li>
<li><a href="#problem-3-other-data-3"><span class="toc-section-number">5.9.3</span> Problem #3: Other data</a></li>
</ul></li>
</ul></li>
<li><a href="#CPA">CONDITIONAL PROCESS ANALYSIS</a></li>
<li><a href="#SimpleMed"><span class="toc-section-number">6</span> Simple Mediation</a>
<ul>
<li><a href="#navigating-this-lesson-4"><span class="toc-section-number">6.1</span> Navigating this Lesson</a>
<ul>
<li><a href="#learning-objectives-4"><span class="toc-section-number">6.1.1</span> Learning Objectives</a></li>
<li><a href="#planning-for-practice-4"><span class="toc-section-number">6.1.2</span> Planning for Practice</a></li>
<li><a href="#readings-resources-4"><span class="toc-section-number">6.1.3</span> Readings &amp; Resources</a></li>
<li><a href="#packages-5"><span class="toc-section-number">6.1.4</span> Packages</a></li>
</ul></li>
<li><a href="#estimating-indirect-effects-the-analytic-approach-often-termed-mediation"><span class="toc-section-number">6.2</span> Estimating Indirect Effects (the analytic approach often termed <em>mediation</em>)</a>
<ul>
<li><a href="#the-definitional-and-conceptual"><span class="toc-section-number">6.2.1</span> The definitional and conceptual</a></li>
</ul></li>
<li><a href="#workflow-for-simple-mediation"><span class="toc-section-number">6.3</span> Workflow for Simple Mediation</a></li>
<li><a href="#simple-mediation-in-lavaan-a-focus-on-the-mechanics"><span class="toc-section-number">6.4</span> Simple Mediation in <em>lavaan</em>: A focus on the mechanics</a>
<ul>
<li><a href="#simulate-fake-data"><span class="toc-section-number">6.4.1</span> Simulate Fake Data</a></li>
<li><a href="#specify-mediation-model"><span class="toc-section-number">6.4.2</span> Specify Mediation Model</a></li>
<li><a href="#interpret-the-output"><span class="toc-section-number">6.4.3</span> Interpret the Output</a></li>
<li><a href="#a-table-and-a-figure"><span class="toc-section-number">6.4.4</span> A Table and a Figure</a></li>
<li><a href="#results-2"><span class="toc-section-number">6.4.5</span> Results</a></li>
</ul></li>
<li><a href="#research-vignette-4"><span class="toc-section-number">6.5</span> Research Vignette</a>
<ul>
<li><a href="#simulate-data-from-the-journal-article"><span class="toc-section-number">6.5.1</span> Simulate Data from the Journal Article</a></li>
<li><a href="#specify-the-model-in-lavaan"><span class="toc-section-number">6.5.2</span> Specify the Model in <em>lavaan</em></a></li>
<li><a href="#interpret-the-output-1"><span class="toc-section-number">6.5.3</span> Interpret the Output</a></li>
<li><a href="#a-figure-and-a-table"><span class="toc-section-number">6.5.4</span> A Figure and a Table</a></li>
<li><a href="#results-3"><span class="toc-section-number">6.5.5</span> Results</a></li>
</ul></li>
<li><a href="#considering-covariates"><span class="toc-section-number">6.6</span> Considering Covariates</a>
<ul>
<li><a href="#a-figure-and-a-table-1"><span class="toc-section-number">6.6.1</span> A Figure and a Table</a></li>
<li><a href="#apa-style-write-up"><span class="toc-section-number">6.6.2</span> APA Style Write-up</a></li>
</ul></li>
<li><a href="#residual-and-related-questions"><span class="toc-section-number">6.7</span> Residual and Related Questions…</a></li>
<li><a href="#practice-problems-4"><span class="toc-section-number">6.8</span> Practice Problems</a>
<ul>
<li><a href="#problem-1-rework-the-research-vignette-as-demonstrated-but-change-the-random-seed"><span class="toc-section-number">6.8.1</span> Problem #1: Rework the research vignette as demonstrated, but change the random seed</a></li>
<li><a href="#problem-2-rework-the-research-vignette-but-swap-one-or-more-variables"><span class="toc-section-number">6.8.2</span> Problem #2: Rework the research vignette, but swap one or more variables</a></li>
<li><a href="#problem-3-use-other-data-that-is-available-to-you"><span class="toc-section-number">6.8.3</span> Problem #3: Use other data that is available to you</a></li>
</ul></li>
</ul></li>
<li><a href="#CompMed"><span class="toc-section-number">7</span> Complex Mediation</a>
<ul>
<li><a href="#navigating-this-lesson-5"><span class="toc-section-number">7.1</span> Navigating this Lesson</a>
<ul>
<li><a href="#learning-objectives-5"><span class="toc-section-number">7.1.1</span> Learning Objectives</a></li>
<li><a href="#planning-for-practice-5"><span class="toc-section-number">7.1.2</span> Planning for Practice</a></li>
<li><a href="#readings-resources-5"><span class="toc-section-number">7.1.3</span> Readings &amp; Resources</a></li>
<li><a href="#packages-6"><span class="toc-section-number">7.1.4</span> Packages</a></li>
</ul></li>
<li><a href="#complex-mediation"><span class="toc-section-number">7.2</span> Complex Mediation</a></li>
<li><a href="#parallel-mediation"><span class="toc-section-number">7.3</span> Parallel Mediation</a>
<ul>
<li><a href="#a-mechanical-example"><span class="toc-section-number">7.3.1</span> A Mechanical Example</a>
<ul>
<li><a href="#data-simulation"><span class="toc-section-number">7.3.1.1</span> Data Simulation</a></li>
<li><a href="#specifying-lavaan-code"><span class="toc-section-number">7.3.1.2</span> Specifying <em>lavaan</em> code</a></li>
<li><a href="#a-note-on-indirect-effects-and-confidence-intervals"><span class="toc-section-number">7.3.1.3</span> A note on indirect effects and confidence intervals</a></li>
<li><a href="#figures-and-tables"><span class="toc-section-number">7.3.1.4</span> Figures and Tables</a></li>
<li><a href="#apa-style-writeup"><span class="toc-section-number">7.3.1.5</span> APA Style Writeup</a></li>
</ul></li>
<li><a href="#research-vignette-5"><span class="toc-section-number">7.3.2</span> Research Vignette</a>
<ul>
<li><a href="#data-simulation-1"><span class="toc-section-number">7.3.2.1</span> Data Simulation</a></li>
<li><a href="#quick-descriptives"><span class="toc-section-number">7.3.2.2</span> Quick Descriptives</a></li>
<li><a href="#specifying-the-lavaan-model"><span class="toc-section-number">7.3.2.3</span> Specifying the <em>lavaan</em> model</a></li>
<li><a href="#figures-and-tables-1"><span class="toc-section-number">7.3.2.4</span> Figures and Tables</a></li>
<li><a href="#apa-style-writeup-1"><span class="toc-section-number">7.3.2.5</span> APA Style Writeup</a></li>
</ul></li>
</ul></li>
<li><a href="#serial-multiple-mediator-model"><span class="toc-section-number">7.4</span> Serial Multiple Mediator Model</a>
<ul>
<li><a href="#we-stick-with-the-lewis-et-al.--lewis_applying_2017-example-but-modify-it."><span class="toc-section-number">7.4.1</span> We stick with the Lewis et al. <span class="citation">(<span>2017</span>)</span> example, but modify it.</a></li>
<li><a href="#specify-the-lavaan-model"><span class="toc-section-number">7.4.2</span> Specify the <em>lavaan</em> model</a></li>
<li><a href="#figures-and-tables-2"><span class="toc-section-number">7.4.3</span> Figures and Tables</a></li>
<li><a href="#apa-style-writeup-2"><span class="toc-section-number">7.4.4</span> APA Style Writeup</a></li>
</ul></li>
<li><a href="#troubleshooting-and-faqs"><span class="toc-section-number">7.5</span> Troubleshooting and FAQs</a></li>
<li><a href="#practice-problems-5"><span class="toc-section-number">7.6</span> Practice Problems</a>
<ul>
<li><a href="#problem-1-rework-the-research-vignette-as-demonstrated-but-change-the-random-seed-1"><span class="toc-section-number">7.6.1</span> Problem #1: Rework the research vignette as demonstrated, but change the random seed</a></li>
<li><a href="#problem-2-rework-the-research-vignette-but-swap-one-or-more-variables-1"><span class="toc-section-number">7.6.2</span> Problem #2: Rework the research vignette, but swap one or more variables</a></li>
<li><a href="#problem-3-use-other-data-that-is-available-to-you-1"><span class="toc-section-number">7.6.3</span> Problem #3: Use other data that is available to you</a></li>
</ul></li>
</ul></li>
<li><a href="#CPA">CONDITIONAL PROCESS ANLAYSIS</a></li>
<li><a href="#ModMed"><span class="toc-section-number">8</span> Moderated Mediation</a>
<ul>
<li><a href="#navigating-this-lesson-6"><span class="toc-section-number">8.1</span> Navigating this Lesson</a>
<ul>
<li><a href="#learning-objectives-6"><span class="toc-section-number">8.1.1</span> Learning Objectives</a></li>
<li><a href="#planning-for-practice-6"><span class="toc-section-number">8.1.2</span> Planning for Practice</a></li>
<li><a href="#readings-resources-6"><span class="toc-section-number">8.1.3</span> Readings &amp; Resources</a></li>
<li><a href="#packages-7"><span class="toc-section-number">8.1.4</span> Packages</a></li>
</ul></li>
<li><a href="#conditional-process-analysis"><span class="toc-section-number">8.2</span> Conditional Process Analysis</a>
<ul>
<li><a href="#the-definitional-and-conceptual-1"><span class="toc-section-number">8.2.1</span> The definitional and conceptual</a></li>
<li><a href="#hayes--hayes_introduction_2018-piecewise-approach-to-building-models"><span class="toc-section-number">8.2.2</span> Hayes’ <span class="citation">(<span>2018</span>)</span> Piecewise Approach to Building Models</a></li>
</ul></li>
<li><a href="#workflow-for-moderated-mediation"><span class="toc-section-number">8.3</span> Workflow for Moderated Mediation</a></li>
<li><a href="#research-vignette-6"><span class="toc-section-number">8.4</span> Research Vignette</a>
<ul>
<li><a href="#simulating-the-data-from-the-journal-article"><span class="toc-section-number">8.4.1</span> Simulating the data from the journal article</a></li>
<li><a href="#quick-peek-at-the-data"><span class="toc-section-number">8.4.2</span> Quick peek at the data</a></li>
</ul></li>
<li><a href="#working-the-moderated-mediation"><span class="toc-section-number">8.5</span> Working the Moderated Mediation</a>
<ul>
<li><a href="#piecewise-assembly-of-the-moderated-mediation"><span class="toc-section-number">8.5.1</span> Piecewise Assembly of the Moderated Mediation</a>
<ul>
<li><a href="#analysis-1-a-simple-moderation"><span class="toc-section-number">8.5.1.1</span> Analysis #1: A simple moderation</a></li>
<li><a href="#analysis-2-another-simple-moderation"><span class="toc-section-number">8.5.1.2</span> Analysis #2: Another simple moderation</a></li>
<li><a href="#analysis-3-a-simple-mediation"><span class="toc-section-number">8.5.1.3</span> Analysis #3: A simple mediation</a></li>
</ul></li>
</ul></li>
<li><a href="#the-moderated-mediation-a-combined-analysis"><span class="toc-section-number">8.6</span> The Moderated Mediation: A Combined analysis</a>
<ul>
<li><a href="#specification-in-lavaan"><span class="toc-section-number">8.6.1</span> Specification in <em>lavaan</em></a></li>
<li><a href="#a-quick-plot"><span class="toc-section-number">8.6.2</span> A quick plot</a></li>
<li><a href="#beginning-the-interpretation"><span class="toc-section-number">8.6.3</span> Beginning the interpretation</a></li>
<li><a href="#tabling-the-data"><span class="toc-section-number">8.6.4</span> Tabling the data</a>
<ul>
<li><a href="#conditional-indirect-effects"><span class="toc-section-number">8.6.4.1</span> Conditional Indirect effects</a></li>
<li><a href="#conditional-direct-effect"><span class="toc-section-number">8.6.4.2</span> Conditional Direct effect</a></li>
</ul></li>
<li><a href="#model-trimming"><span class="toc-section-number">8.6.5</span> Model trimming</a></li>
<li><a href="#apa-style-write-up-1"><span class="toc-section-number">8.6.6</span> APA Style Write-up</a></li>
</ul></li>
<li><a href="#residual-and-related-questions-1"><span class="toc-section-number">8.7</span> Residual and Related Questions…</a></li>
<li><a href="#practice-problems-6"><span class="toc-section-number">8.8</span> Practice Problems</a>
<ul>
<li><a href="#problem-1-rework-the-research-vignette-as-demonstrated-but-change-the-random-seed-2"><span class="toc-section-number">8.8.1</span> Problem #1: Rework the research vignette as demonstrated, but change the random seed</a></li>
<li><a href="#problem-2-rework-the-research-vignette-but-swap-one-or-more-variables-2"><span class="toc-section-number">8.8.2</span> Problem #2: Rework the research vignette, but swap one or more variables</a></li>
<li><a href="#problem-3-use-other-data-that-is-available-to-you-2"><span class="toc-section-number">8.8.3</span> Problem #3: Use other data that is available to you</a></li>
</ul></li>
<li><a href="#bonus-track-1"><span class="toc-section-number">8.9</span> Bonus Track:</a></li>
</ul></li>
<li><a href="#MOD">MODERATION</a></li>
<li><a href="#SimpMod"><span class="toc-section-number">9</span> Simple Moderation in OLS and MLE</a>
<ul>
<li><a href="#navigating-this-lesson-7"><span class="toc-section-number">9.1</span> Navigating this Lesson</a>
<ul>
<li><a href="#learning-objectives-7"><span class="toc-section-number">9.1.1</span> Learning Objectives</a></li>
<li><a href="#planning-for-practice-7"><span class="toc-section-number">9.1.2</span> Planning for Practice</a></li>
<li><a href="#readings-resources-7"><span class="toc-section-number">9.1.3</span> Readings &amp; Resources</a></li>
<li><a href="#packages-8"><span class="toc-section-number">9.1.4</span> Packages</a></li>
</ul></li>
<li><a href="#on-modeling-introductory-comments-on-the-simultaneously-invisible-and-paradigm-shifting-transition-we-are-making"><span class="toc-section-number">9.2</span> On <em>Modeling</em>: Introductory Comments on the simultaneously invisible and paradigm-shifting transition we are making</a>
<ul>
<li><a href="#nhst-versus-modeling"><span class="toc-section-number">9.2.1</span> NHST versus modeling</a></li>
<li><a href="#introducing-the-model"><span class="toc-section-number">9.2.2</span> Introducing: <em>The Model</em></a></li>
</ul></li>
<li><a href="#ols-to-ml-for-estimation"><span class="toc-section-number">9.3</span> OLS to ML for Estimation</a>
<ul>
<li><a href="#ordinary-least-squares-ols"><span class="toc-section-number">9.3.1</span> Ordinary least squares (OLS)</a></li>
<li><a href="#maximum-likelihood-estimation-mle-a-brief-orientation"><span class="toc-section-number">9.3.2</span> Maximum likelihood estimation (MLE): A brief orientation</a></li>
<li><a href="#ols-and-mle-comparison"><span class="toc-section-number">9.3.3</span> OLS and MLE Comparison</a></li>
<li><a href="#hayes-and-process-aka-conditional-process-analysis"><span class="toc-section-number">9.3.4</span> Hayes and PROCESS (aka conditional process analysis)</a></li>
</ul></li>
<li><a href="#introducing-the-lavaan-package"><span class="toc-section-number">9.4</span> Introducing the <em>lavaan</em> package</a>
<ul>
<li><a href="#the-fiml-magic-for-which-we-have-been-waiting"><span class="toc-section-number">9.4.1</span> The FIML magic for which we have been waiting</a></li>
</ul></li>
<li><a href="#picking-up-with-moderation"><span class="toc-section-number">9.5</span> Picking up with Moderation</a></li>
<li><a href="#workflow-for-name-of-statistic"><span class="toc-section-number">9.6</span> Workflow for NAME OF STATISTIC</a></li>
<li><a href="#research-vignette-7"><span class="toc-section-number">9.7</span> Research Vignette</a>
<ul>
<li><a href="#simulate-data-from-the-journal-article-1"><span class="toc-section-number">9.7.1</span> Simulate Data from the Journal Article</a></li>
</ul></li>
<li><a href="#working-the-simple-moderation-with-ols-and-mle"><span class="toc-section-number">9.8</span> Working the Simple Moderation with OLS and MLE</a>
<ul>
<li><a href="#ols-with-lm"><span class="toc-section-number">9.8.1</span> OLS with <em>lm()</em></a>
<ul>
<li><a href="#an-apa-style-write-up-of-ols-results"><span class="toc-section-number">9.8.1.1</span> An APA Style Write-up of OLS results</a></li>
</ul></li>
<li><a href="#mle-with-lavaansem"><span class="toc-section-number">9.8.2</span> MLE with <em>lavaan::sem()</em></a></li>
<li><a href="#tabling-the-data-1"><span class="toc-section-number">9.8.3</span> Tabling the data</a></li>
<li><a href="#apa-style-writeup-3"><span class="toc-section-number">9.8.4</span> APA Style Writeup</a></li>
</ul></li>
<li><a href="#residual-and-related-questions-2"><span class="toc-section-number">9.9</span> Residual and Related Questions…</a></li>
<li><a href="#practice-problems-7"><span class="toc-section-number">9.10</span> Practice Problems</a>
<ul>
<li><a href="#problem-1-rework-the-research-vignette-as-demonstrated-but-change-the-random-seed-3"><span class="toc-section-number">9.10.1</span> Problem #1: Rework the research vignette as demonstrated, but change the random seed</a></li>
<li><a href="#problem-2-rework-the-research-vignette-but-swap-one-or-more-variables-3"><span class="toc-section-number">9.10.2</span> Problem #2: Rework the research vignette, but swap one or more variables</a></li>
<li><a href="#problem-3-use-other-data-that-is-available-to-you-3"><span class="toc-section-number">9.10.3</span> Problem #3: Use other data that is available to you</a></li>
</ul></li>
<li><a href="#bonus-track-2"><span class="toc-section-number">9.11</span> Bonus Track:</a></li>
</ul></li>
<li><a href="#refs">References</a></li>
</ul>
<!--bookdown:toc2:end-->
      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">ReCentering Psych Stats: Multivariate Modeling</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<!--bookdown:toc:end-->
<!--bookdown:body:start-->
<div id="book-cover" class="section level1 unnumbered">
<h1 class="unnumbered">BOOK COVER</h1>
<div class="figure">
<img src="images/ReC_multivariate_bkcvr.png" alt="" />
<p class="caption">An image of the book cover. It includes four quadrants of non-normal distributions representing gender, race/ethnicty, sustainability/global concerns, and journal articles</p>
</div>
</div>
<div id="preface" class="section level1 unnumbered">
<h1 class="unnumbered">PREFACE</h1>
<p><strong>If you are viewing this document, you should know that this is a book-in-progress. Early drafts are released for the purpose teaching my classes and gaining formative feedback from a host of stakeholders. The document was last updated on 02 May 2021</strong></p>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=c932455e-ef06-444a-bdca-acf7012d759a">Screencasted Lecture Link</a></p>
<p>To <em>center</em> a variable in regression means to set its value at zero and interpret all other values in relation to this reference point. Regarding race and gender, researchers often center male and White at zero. Further, it is typical that research vignettes in statistics textbooks are similarly seated in a White, Western (frequently U.S.), heteronormative, framework. The purpose of this project is to create a set of open educational resources (OER) appropriate for doctoral and post-doctoral training that contribute to a socially responsive pedagogy – that is, it contributes to justice, equity, diversity, and inclusion.</p>
<p>Statistics training in doctoral programs are frequently taught with fee-for-use programs (e.g., SPSS/AMOS, SAS, MPlus) that may not be readily available to the post-doctoral professional. In recent years, there has been an increase and improvement in R packages (e.g., <em>psych</em>, <em>lavaan</em>) used for in analyses common to psychological research. Correspondingly, many graduate programs are transitioning to statistics training in R (free and open source). This is a challenge for post-doctoral psychologists who were trained with other software. This OER will offer statistics training with R and be freely available (specifically in a GitHub respository and posted through GitHub Pages) under a Creative Commons Attribution - Non Commercial - Share Alike license [CC BY-NC-SA 4.0].</p>
<p>Training models for doctoral programs in HSP are commonly scholar-practitioner, scientist-practitioner, or clinical-scientist. An emerging model, the <em>scientist-practitioner-advocacy</em> training model incorporates social justice advocacy so that graduates are equipped to recognize and address the sociocultural context of oppression and unjust distribution of resources and opportunities <span class="citation">(<a href="#ref-mallinckrodt_scientist-practitioner-advocate_2014" role="doc-biblioref">Mallinckrodt et al., 2014</a>)</span>. In statistics textbooks, the use of research vignettes engages the learner around a tangible scenario for identifying independent variables, dependent variables, covariates, and potential mechanisms of change. Many students recall examples in Field’s <span class="citation">(<a href="#ref-field_discovering_2012" role="doc-biblioref">2012</a>)</span> popular statistics text: Viagra to teach one-way ANOVA, beer goggles for two-way ANOVA, and bushtucker for repeated measures. What if the research vignettes were more socially responsive?</p>
<p>In this OER, research vignettes will be from recently published articles where:</p>
<ul>
<li>the author’s identity is from a group where scholarship is historically marginalized (e.g., BIPOC, LGBTQ+, LMIC[low-middle income countries]),</li>
<li>the research is responsive to issues of justice, equity, inclusion, diversity,</li>
<li>the lesson’s statistic is used in the article, and</li>
<li>there is sufficient information in the article to simulate the data for the chapter example(s) and practice problem(s); or it is publicly available.</li>
</ul>
<p>In training for multicultural competence, the saying, “A fish doesn’t know that it’s wet” is often used to convey the notion that we are often unaware of our own cultural characteristics. In recent months and years, there has been an increased awakening to the institutional and systemic racism that our systems are perpetuating. Queuing from the water metaphor, I am hopeful that a text that is recentered in the ways I have described can contribute to <em>changing the water</em> in higher education and in the profession of psychology.</p>
<div id="copyright-with-open-access" class="section level2 unnumbered">
<h2 class="unnumbered">Copyright with Open Access</h2>
<p><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a></p>
<p>This book is published under a a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. This means that this book can be reused, remixed, retained, revised and redistributed (including commercially) as long as appropriate credit is given to the authors. If you remix, or modify the original version of this open textbook, you must redistribute all versions of this open textbook under the same license - CC BY-SA.</p>
<p>A <a href="https://github.com/lhbikos/ReC_MultivariateModeling">GitHub open-source repository</a> contains all of the text and source code for the book, including data and images.</p>
</div>
</div>
<div id="acknowledgements" class="section level1 unnumbered">
<h1 class="unnumbered">ACKNOWLEDGEMENTS</h1>
<p>As a doctoral student at the University of Kansas (1992-2005), I learned that “a foreign language” was required for graduation. <em>Please note that as one who studies the intersections of global, vocational, and sustainable psychology, I regret that I do not have language skills beyond English.</em> This could have been met with credit from high school my rural, mid-Missouri high school did not offer such classes. This requirement would have typically been met with courses taken during an undergraduate program – but my non-teaching degree in the University of Missouri’s School of Education was exempt from this. The requirement could have also been met with a computer language (fortran, C++) – I did not have any of those either. There was a tiny footnote on my doctoral degree plan that indicated that a 2-credit course, “SPSS for Windows” would substitute for the language requirement. Given that it was taught by my one of my favorite professors, I readily signed up. As it turns out, Samuel B. Green, PhD, was using the course to draft chapters in the textbook <span class="citation">(<a href="#ref-green_using_2014" role="doc-biblioref">Green &amp; Salkind, 2014</a>)</span> that has been so helpful for so many. Unfortunately, Drs. Green (1947 - 2018) and Salkind (2947 - 2017) are no longer with us. I have worn out numerous versions of their text. Another favorite text of mine was Dr. Barbara Byrne’s <span class="citation">(<a href="#ref-byrne_structural_2016" role="doc-biblioref">2016</a>)</span>, “Structural Equation Modeling with AMOS.” I loved the way she worked through each problem and paired it with a published journal article, so that the user could see how the statistical evaluation fit within the larger project/article. I took my tea-stained text with me to a workshop she taught at APA and was proud of the signature she added to it (a little catfur might have fallen out). Dr. Byrne created SEM texts for a number of statistical programs (e.g., LISREL, EQS, MPlus). As I was learning R, I wrote Dr. Byrne, asking if she had an edition teaching SEM/CFA with R. She promptly wrote back, saying that she did not have the bandwidth to learn a new statistics package. We lost Dr. Byrne in December 2020. I am so grateful to these role models for their contributions to my statistical training. I am also grateful for the doctoral students who have taken my courses and are continuing to provide input for how to improve the materials.</p>
<p>The inspiration for training materials that re*center statistics and research methods came from the <a href="https://www.academics4blacklives.com/">Academics for Black Survival and Wellness Initiative</a>. This project, co-founded by Della V. Mosley, Ph.D., and Pearis L. Bellamy, M.S., made clear the necessity and urgency for change in higher education and the profession of psychology.</p>
<p>At very practical levels, I am indebted to SPU’s Library, and more specifically, SPU’s Education, Technology, and Media Department. Assistant Dean for Instructional Design and Emerging Technologies, R. John Robertson, MSc, MCS, has offered unlimited consultation, support, and connection. Senior Instructional Designer in Graphics &amp; Illustrations, Dominic Wilkinson, designed the logo and bookcover. Psychology and Scholarly Communications Librarian, Kristin Hoffman, MLIS, has provided consultation on topics ranging from OERS to citations. I am alo indebted to Associate Vice President, Teaching and Learning at Kwantlen Polytechnic University, Rajiv Jhangiani, PhD. Dr. Jhangiani’s text <span class="citation">(<a href="#ref-jhangiani_research_2019" role="doc-biblioref">2019</a>)</span> was the first OER I ever used and I was grateful for his encouraging conversation.</p>
<p>Financial support for this text has been provided from the <em>Call to Action on Equity, Inclusion, Diversity, Justice, and Social Responsivity
Request for Proposals</em> grant from the Association of Psychology Postdoctoral and Internship Centers (2021-2022).</p>
<!--chapter:end:index.Rmd-->
</div>
<div id="ReCintro" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Introduction</h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=cc9b7c0d-e5c3-4e4e-a469-acf7013ee761">Screencasted Lecture Link</a></p>
<div id="what-to-expect-in-each-chapter" class="section level2" number="1.1">
<h2 number="1.1"><span class="header-section-number">1.1</span> What to expect in each chapter</h2>
<p>This textbook is intended as <em>applied,</em> in that a primary goal is to help the scientist-practitioner-advocate use a variety of statistics in research problems and <em>writing them up</em> for a program evaluation, dissertation, or journal article. In support of that goal, I try to provide just enough conceptual information so that the researcher can select the appropriate statistic (i.e., distinguishing between when ANOVA is appropriate and when regression is appropriate) and assign variables to their proper role (e.g., covariate, moderator, mediator).</p>
<p>This conceptual approach does include occasional, step-by-step, <em>hand-calculations</em> (only we calculate them arithmetically in R) to provide a <em>visceral feeling</em> of what is happening within the statistical algorithm that may be invisible to the researcher. Additionally, the conceptual review includes a review of the assumptions about the characteristics of the data and research design that are required for the statistic. Statistics can be daunting, so I have worked hard to establish a <em>workflow</em> through each analysis. When possible, I include a flowchart that is referenced frequently in each chapter and assists the the researcher keep track of their place in the many steps and choices that accompany even the simplest of analyses.</p>
<p>As with many statistics texts, each chapter includes a <em>research vignette.</em> Somewhat unique to this resource is that the vignettes are selected from recently published articles. Each vignette is chosen with the intent to meet as many of the following criteria as possible:</p>
<ul>
<li>the statistic that is the focus of the chapter was properly used in the article,</li>
<li>the author’s identity is from a group where scholarship is historically marginalized (e.g., BIPOC, LGBTQ+, LMIC [low middle income countries]),</li>
<li>the research has a justice, equity, inclusion, diversity, and social responsivity focus and will contribute positively to a social justice pedagogy, and</li>
<li>the data is available in a repository or there is sufficient information in the article to simulate the data for the chapter example(s) and practice problem(s).</li>
</ul>
<p>In each chapter we employ <em>R</em> packages that will efficiently calculate the statistic and the dashboard of metrics (e.g., effect sizes, confidence intervals) that are typically reported in psychological science.</p>
</div>
<div id="strategies-for-accessing-and-using-this-oer" class="section level2" number="1.2">
<h2 number="1.2"><span class="header-section-number">1.2</span> Strategies for Accessing and Using this OER</h2>
<p>There are a number of ways you can access this resource. You may wish to try several strategies and then select which works best for you. I demonstrate these in the screencast that accompanies this chapter.</p>
<ol style="list-style-type: decimal">
<li>Simply follow along in the .html formatted document that is available on via GitHub Pages, and then
<ul>
<li>open a fresh .rmd file of your own, copying (or retyping) the script and running it</li>
</ul></li>
<li>Locate the original documents at the <a href="https://github.com/lhbikos/ReC_MultivariateModeling">GitHub repository</a> . You can
<ul>
<li>open them to simply take note of the “behind the scenes” script</li>
<li>copy/download individual documents that are of interest to you</li>
<li>fork a copy of the entire project to your own GitHub site and further download it (in its entirety) to your personal workspace. The <a href="https://desktop.github.com/">GitHub Desktop app</a> makes this easy!</li>
</ul></li>
<li>Listen to the accompanying lectures (I think sound best when the speed is 1.75). The lectures are being recorded in Panopto and should include the closed captioning.</li>
<li>Provide feedback to me! If you fork a copy to your own GitHub repository, you can
<ul>
<li>open up an editing tool and mark up the document with your edits,</li>
<li>start a discussion by leaving comments/questions, and then</li>
<li>sending them back to me by committing and saving. I get an e-mail notiying me of this action. I can then review (accepting or rejecting) them and, if a discussion is appropriate, reply back to you.</li>
</ul></li>
</ol>
</div>
<div id="if-you-are-new-to-r" class="section level2" number="1.3">
<h2 number="1.3"><span class="header-section-number">1.3</span> If You are New to R</h2>
<p>R can be oveRwhelming. Jumping right into advanced statistics might not be the easiest way to start. However, in these chapters, I provide complete code for every step of the process, starting with uploading the data. To help explain what R script is doing, I sometimes write it in the chapter text; sometimes leave hastagged-comments in the chunks; and, particularly in the accompanying screencasted lectures, try to take time to narrate what the R script is doing.</p>
<p>I’ve found that, somewhere on the internet, there’s almost always a solution to what I’m trying to do. I am frequently stuck and stumped and have spent hours searching the internet for even the tiniest of things. When you watch my videos, you may notice that in my R studio, there is a “scRiptuRe” file. I takes notes on the solutions and scripts here – using keywords that are meaningful to me so that when I need to repeat the task, I can hopefully search my own prior solutions and find a fix or a hint.</p>
<div id="base-r" class="section level3" number="1.3.1">
<h3 number="1.3.1"><span class="header-section-number">1.3.1</span> Base R</h3>
<p>The base program is free and is available here: <a href="https://www.r-project.org/" class="uri">https://www.r-project.org/</a></p>
<p>Because R is already on my machine (and because the instructions are sufficient), I will not walk through the instllation, but I will point out a few things.</p>
<ul>
<li>Follow the instructions for your operating system (Mac, Windows, Linux)</li>
<li>The “cran” (I think “cranium”) is the <em>Comprehensive R Archive Network.</em> In order for R to run on your computer, you have to choose a location. Because proximity is somewhat related to processing speed, select one that is geographically “close to you.”</li>
<li>You will see the results of this download on your desktop (or elsewhere if you chose to not have it appear there) but you won’t ever use R through this platform.</li>
</ul>
</div>
<div id="r-studio" class="section level3" number="1.3.2">
<h3 number="1.3.2"><span class="header-section-number">1.3.2</span> R Studio</h3>
<p><em>R Studio</em> is the desktop application I work in R. It’s a separate download. Choose the free, desktop, option that is appropriate for your operating system: <a href="https://www.rstudio.com/products/RStudio/" class="uri">https://www.rstudio.com/products/RStudio/</a></p>
<ul>
<li>Upper right window: Includes several tabs; we frequently monitor the
<ul>
<li>Environment: it lists the <em>objects</em> that are available to you (e.g., dataframes)</li>
</ul></li>
<li>Lower right window: has a number of helpful tabs.
<ul>
<li>Files: Displays the file structure in your computer’s environment. Make it a practice to (a) organize your work in small folders and (b) navigating to that small folder that is holding your project when you are working on it.</li>
<li>Packages: Lists the packages that have been installed. If you navigate to it, you can see if it is “on.” You can also access information about the package (e.g., available functions, examples of script used with the package) in this menu. This information opens in the Help window.</li>
<li>Viewer and Plots are helpful, later, when we can simultaneously look at our output and still work on our script.</li>
</ul></li>
<li>Primary window
<ul>
<li>R Studio runs in the background(in the console). Very occasionally, I can find useful troubleshooting information here.</li>
<li>More commonly, I open my R Markdown document so that it takes the whole screen and I work directly, right here.</li>
</ul></li>
<li><em>R Markdown</em> is the way that many analysts write <em>script</em>, conduct analyses, and even write up results. These are saved as .rmd files.
<ul>
<li>In R Studio, open an R Markdown document through File/New File/R Markdown</li>
<li>Specify the details of your document (title, author, desired ouput)</li>
<li>In a separate step, SAVE this document (File/Save] into a NEW FILE FOLDER that will contain anything else you need for your project (e.g., the data).</li>
<li><em>Packages</em> are at the heart of working in R. Installing and activating packages require writing script.</li>
</ul></li>
</ul>
</div>
<div id="r-hygiene" class="section level3" number="1.3.3">
<h3 number="1.3.3"><span class="header-section-number">1.3.3</span> R Hygiene</h3>
<p>Many initial problems in R can be solved with good R hygiene. Here are some suggestions for basic practices. It can be tempting to “skip this.” However, in the first few weeks of class, these are the solutions I am presenting to my students.</p>
<div id="everything-is-documented-in-the-.rmd-file" class="section level4" number="1.3.3.1">
<h4 number="1.3.3.1"><span class="header-section-number">1.3.3.1</span> Everything is documented in the .rmd file</h4>
<p>Although others do it differently, everything is in my .rmd file. That is, for uploading data and opening packages I write the code in my .rmd file. Why? Because when I read about what I did hours or years later, I have a permanent record of very critical things like (a) where my data is located, (b) what version I was using, and (c) what package was associated with the functions.</p>
</div>
<div id="file-organization" class="section level4" number="1.3.3.2">
<h4 number="1.3.3.2"><span class="header-section-number">1.3.3.2</span> File organization</h4>
<p>File organization is a critical key to this:</p>
<ul>
<li>Create a project file folder.</li>
<li>Put the data file in it.</li>
<li>Open an R Markdown file.</li>
<li>Save it in the same file folder.</li>
<li>When your data and .rmd files are in the same folder (not your desktop, but a shared folder), they can be connected.</li>
</ul>
</div>
<div id="chunks" class="section level4" number="1.3.3.3">
<h4 number="1.3.3.3"><span class="header-section-number">1.3.3.3</span> Chunks</h4>
<p>The R Markdown document is an incredible tool for integrating text, tables, and analyses. This entire OER is written in R Markdown. A central feature of this is “chunks.”</p>
<p>The easiest way to insert a chunk is to use the INSERT/R command at the top of this editor box. You can also insert a chunk with the keyboard shortcut: CTRL/ALT/i</p>
<p>“Chunks” start and end with with those three tic marks and will show up in a shaded box, like this:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">#hashtags let me write comments to remind myself what I did</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#here I am simply demonstrating arithmetic (but I would normally be running code)</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="dv">2021</span> <span class="sc">-</span> <span class="dv">1966</span></span></code></pre></div>
<pre><code>## [1] 55</code></pre>
<p>Each chunk must open and close. If one or more of your tic marks get deleted, your chunk won’t be read as such and your script will not run. The only thing in the chunks should be script for running R; you can hashtag-out script so it won’t run.</p>
<p>Although unnecessary, you can add a brief title for the chunk in the opening row, after the “r.” These create something of a table of contents of all the chunks – making it easier to find what you did. You can access them in the “Chunks” tab at the bottom left of R Studio. If you wish to knit a document, you cannot have identical chunk titles.</p>
<p>You can put almost anything you want in the space outside of tics. Syntax for simple formatting in the text areas (e.g,. using italics, making headings, bold, etc.) is found here: <a href="https://rmarkdown.rstudio.com/authoring_basics.html" class="uri">https://rmarkdown.rstudio.com/authoring_basics.html</a></p>
</div>
<div id="packages" class="section level4" number="1.3.3.4">
<h4 number="1.3.3.4"><span class="header-section-number">1.3.3.4</span> Packages</h4>
<p>As scientist-practitioners (and not coders), we will rely on <em>packages</em> to do our work for us. At first you may feel overwhelmed about the large number of packages that are available. Soon, though, you will become accustomed to the ones most applicable to our work (e.g., psych, tidyverse, lavaan, apaTables).</p>
<p>Researchers treat packages differently. In these lectures, I list all the packages we will use in an opening chunk that asks R to check to see if the package is installed, and if not, installs it.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(psych)){<span class="fu">install.packages</span>(<span class="st">&quot;psych&quot;</span>)}</span></code></pre></div>
<pre><code>## Loading required package: psych</code></pre>
<pre><code>## Warning: package &#39;psych&#39; was built under R version 4.0.5</code></pre>
<p>To make a package operable, you need to open it through the library. This process must be repeated each time you restart R. I don’t open the package (through the “library(package_name)”) command until it is time to use it. Especially for new users, I think it’s important to connect the functions with the specific packages.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages (&quot;psych&quot;)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (psych)</span></code></pre></div>
<p>If you type in your own “install.packages” code, hashtag it out once it’s been installed. It is problematic to continue to re-run this code .</p>
</div>
<div id="knitting" class="section level4" number="1.3.3.5">
<h4 number="1.3.3.5"><span class="header-section-number">1.3.3.5</span> Knitting</h4>
<p>An incredible feature of R Markdown is its capacity to <em>knit</em> to HTML, powerpoint, or word. If you access the .rmd files for this OER, you can use annotate or revise them to suit your purposes. If you redistribute them, though, please honor the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License with a citation.</p>
</div>
</div>
<div id="troubleshooting-in-r-markdown" class="section level3" number="1.3.4">
<h3 number="1.3.4"><span class="header-section-number">1.3.4</span> tRoubleshooting in R maRkdown</h3>
<p>Hiccups are normal. Here are some ideas that I have found useful in getting unstuck.</p>
<ul>
<li>In an R script, you must have everything in order – Every. Single. Time.
<ul>
<li>All the packages have to be in your library and activated; if you restart R, you need to reload each package.</li>
<li>If you open an .rmd file and want a boxplot, you cannot just scroll down to that script. You need to run any <em>prerequisite</em> script (like loading the package, importing data, putting the data in the global environment, etc.)</li>
<li>Do you feel lost? clear your global environment (broom) and start at the top of the R script. Frequent, fresh starts are good.</li>
</ul></li>
<li>Your .rmd file and your data need to be stored in the same file folder. These should be separate for separate projects, no matter how small.</li>
<li>Type any warnings you get into a search engine. Odds are, you’ll get some decent hints in a manner of seconds. Especially at first, these are common errors:
<ul>
<li>The package isn’t loaded (if you restarted R, you need to reload your packages)</li>
<li>The .rmd file has been saved yet, or isn’t saved in the same folder as the data</li>
<li>Errors of punctuation or spelling</li>
</ul></li>
<li>Restart R (it’s quick – not like restarting your computer)</li>
<li>If you receive an error indicating that a function isn’t working or recognized, and you have loaded the package, type the name of the package in front of the function with two colons (e.g., psych::describe(df). If multiple packages are loaded with functions that have the same name, R can get confused.</li>
</ul>
</div>
<div id="strategies-for-success" class="section level3" number="1.3.5">
<h3 number="1.3.5"><span class="header-section-number">1.3.5</span> stRategies for success</h3>
<ul>
<li>Engage with R, but don’t let it overwhelm you.
<ul>
<li>The <em>mechanical is also the conceptual</em>. Especially when it is <em>simpler</em>, do try to retype the script into your own .rmd file and run it. Track down the errors you are making and fix them.</li>
<li>If this stresses you out, move to simply copying the code into the .rmd file and running it. If you continue to have errors, you may have violated one of the best practices above (Is the package loaded? Are the data and .rmd files in the same place? Is all the prerequisite script run?).</li>
<li>Still overwhelmed? Keep moving forward by downloading a copy of the .rmd file that accompanies any given chapter and just “run it along” with the lecture. Spend your mental power trying to understand what each piece does. Then select a practice problem that is appropriate for your next level of growth.</li>
</ul></li>
<li>Copy script that works elsewhere and replace it with your datafile, variables, etc.<br />
</li>
<li>The leaRning curve is steep, but not impossible. Gladwell<span class="citation">(<a href="#ref-gladwell_outliers_2008" role="doc-biblioref">2008</a>)</span> reminds us that it takes about 10,000 hours to get GREAT at something (2,000 to get reasonably competent). Practice. Practice. Practice.</li>
<li>Updates to R, R Studio, and the packages are NECESSARY, but can also be problematic. It could very well be that updates cause programs/script to fail (e.g., “X has been deprecated for version X.XX”). Moreover, this very well could have happened between my distribution of these resources and your attempt to use it. My personal practice is to update R, R Studio, and the packages a week or two before each academic term.</li>
<li>Embrace your downward dog. Also, walk away, then come back.</li>
</ul>
</div>
<div id="resources-for-getting-started" class="section level3" number="1.3.6">
<h3 number="1.3.6"><span class="header-section-number">1.3.6</span> Resources for getting staRted</h3>
<p>R for Data Science: <a href="https://r4ds.had.co.nz/" class="uri">https://r4ds.had.co.nz/</a></p>
<p>R Cookbook: <a href="http://shop.oreilly.com/product/9780596809164.do" class="uri">http://shop.oreilly.com/product/9780596809164.do</a></p>
<p>R Markdown homepage with tutorials: <a href="https://rmarkdown.rstudio.com/index.html" class="uri">https://rmarkdown.rstudio.com/index.html</a></p>
<p>R has cheatsheets for everything, here’s one for R Markdown: <a href="https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf" class="uri">https://www.rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf</a></p>
<p>R Markdown Reference guide: <a href="https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf" class="uri">https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf</a></p>
<p>Using R Markdown for writing reproducible scientific papers: <a href="https://libscie.github.io/rmarkdown-workshop/handout.html" class="uri">https://libscie.github.io/rmarkdown-workshop/handout.html</a></p>
<p>LaTeX equation editor: <a href="https://www.codecogs.com/latex/eqneditor.php" class="uri">https://www.codecogs.com/latex/eqneditor.php</a></p>
<!--chapter:end:01-Introduction.Rmd-->
</div>
</div>
</div>
<div id="dataprep" class="section level1 unnumbered">
<h1 class="unnumbered">DATA PREP</h1>
</div>
<div id="scrub" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> Scrubbing</h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=7c87f991-276b-448f-aed9-acf6015b9638">Screencasted Lecture Link</a></p>
<p>The focus of this chapter is the process of starting with raw data and preparing it for multivariate analysis. To that end, we will address the conceptual considerations and practical steps in “scrubbing and scoring.”</p>
<p>A twist in this lesson is that I am asking you to contribute to the dataset that serves as the basis for the chapter and the practice problems. In the spirit of <em>open science</em>, this dataset is available to you and others for your own learning. Before continuing, please take 15-20 minutes to complete the survey titled, <a href="https://spupsych.az1.qualtrics.com/jfe/form/SV_b2cClqAlLGQ6nLU">Rate-a-Recent-Course: A ReCentering Psych Stats Exercise</a>. The study is approved by the Institutional Review Board at Seattle Pacific University (SPUIRB# 202102011, no expiration). Details about the study, including an informed consent, are included at the link.</p>
<div id="navigating-this-lesson" class="section level2" number="2.1">
<h2 number="2.1"><span class="header-section-number">2.1</span> Navigating this Lesson</h2>
<p>There is about 90 minutes of lecture. If you work through the materials with me it would be good to add another hour.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, there are a few that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_MultivariateModeling">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="#ReCintro">introduction</a></p>
<div id="learning-objectives" class="section level3" number="2.1.1">
<h3 number="2.1.1"><span class="header-section-number">2.1.1</span> Learning Objectives</h3>
<p>Learning objectives from this lecture include the following:</p>
<ul>
<li>Import data from Qualtrics into R.</li>
<li>Begin the scrubbing process by applying exclusion and inclusion criteria.</li>
<li>Rename variables.</li>
<li>Create a smaller dataframe with variables appropriate for testing a specific statistical model.</li>
<li>Use critical data manipulation functions from the <em>tidyverse</em> (and <em>dplyr</em>) in particular such as <em>filter()</em>, <em>select()</em>, and <em>mutate()</em> to prepare variables.</li>
<li>Articulate the initial steps in a workflow for scrubbing and scoring data.</li>
</ul>
</div>
<div id="planning-for-practice" class="section level3" number="2.1.2">
<h3 number="2.1.2"><span class="header-section-number">2.1.2</span> Planning for Practice</h3>
<!-- TODO: Specify set of items to score for homework. -->
<p>The suggestions for practice will start with this chapter and continue in the next two chapters (Scoring, Data Dx). Using Parent’s <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> AIA approach to managing missing data, you will scrub-and-score a raw dataset. Options of graded complexity could incude:</p>
<ul>
<li>Repeating the steps in the chapter with the most recent data from the Rate-A-Recent-Course survey; differences will be in the number of people who have completed the survey since the chapter was written.</li>
<li>Use the dataset that is the source of the chapter, but score a different set of items that you choose. Hey :)</li>
<li>Begin with raw data to which you have access.</li>
</ul>
</div>
<div id="readings-resources" class="section level3" number="2.1.3">
<h3 number="2.1.3"><span class="header-section-number">2.1.3</span> Readings &amp; Resources</h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<ul>
<li><p>Parent, M. C. (2013). Handling item-level missing data: Simpler is just as good. The Counseling Psychologist, 41(4), 568–600. <a href="https://doi.org/10.1177/0011000012445176" class="uri">https://doi.org/10.1177/0011000012445176</a></p></li>
<li><p>Kline, R. B. (2015). Data preparation and psychometrics review. In Principles and Practice of Structural Equation Modeling, Fourth Edition. Guilford Publications. <a href="http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4000663" class="uri">http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4000663</a></p></li>
<li><p>Grolemund, G., &amp; Wickham, H. (n.d.). 5 Data transformation | R for Data Science. Retrieved March 12, 2020, from <a href="https://r4ds.had.co.nz/" class="uri">https://r4ds.had.co.nz/</a></p></li>
</ul>
</div>
<div id="packages-1" class="section level3" number="2.1.4">
<h3 number="2.1.4"><span class="header-section-number">2.1.4</span> Packages</h3>
<p>The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<!-- TODO: Build out this section. -->
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#will install the package if not already installed</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(qualtRics)){<span class="fu">install.packages</span>(<span class="st">&quot;qualtRics&quot;</span>)}</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(tidyverse)){<span class="fu">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>)}</span></code></pre></div>
</div>
</div>
<div id="workflow-for-scrubbing-and-scoring" class="section level2" number="2.2">
<h2 number="2.2"><span class="header-section-number">2.2</span> Workflow for Scrubbing and Scoring</h2>
<p>The following is a proposed workflow for preparing data for analysis.</p>
<!-- TODO: When finalized, save as PDF so it can open in its own window) -->
<div class="figure">
<img src="images/Ch02/scrubscore_wrkflow.jpg" alt="" />
<p class="caption">An image of a workflow for scrubbing and scoring data.</p>
</div>
<p>Here is a narration of the figure:</p>
<ol style="list-style-type: decimal">
<li>The workflow begins by importing data into R. Most lessons in this series involve simulated data that are created directly in R. Alternatively, data could be:
<ul>
<li>imported “intRavenously” through programs such as Qualtrics,</li>
<li>exported from programs such as Qualtrics to another program (e.g., .xlxs, .csv),</li>
<li>imported in other forms (e.g., .csv,.sps, .sav).</li>
</ul></li>
<li>Scrubbing data by
<ul>
<li>variable naming,</li>
<li>specifying variable characteristics such as factoring,</li>
<li>ensuring that included particpiants consented to participation,</li>
<li>determining and executing the inclusion and exclusion criteria.</li>
</ul></li>
<li>Conduct preliminary data diagnostics such as
<ul>
<li>outlier anlaysis</li>
<li>assessing for univariate and multivariate analysis</li>
<li>making transformations and/or corrections</li>
</ul></li>
<li>Managing missingness by one of two routes
<ul>
<li>Available information analysis <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">Parent, 2013</a>)</span> at either the item-level or scale level. The result is a single set of data for analysis. If missingness remains, options include pairwise deletion, listwise deletion, or specifying FIML (when available). Another option is to use multiple imputation.</li>
<li>Multiple imputation at either scale level or item-level</li>
</ul></li>
</ol>
</div>
<div id="research-vignette" class="section level2" number="2.3">
<h2 number="2.3"><span class="header-section-number">2.3</span> Research Vignette</h2>
<p>To provide first-hand experience as both the respondent and analyst for the same set of data, you were asked to complete a survey titled, <a href="https://spupsych.az1.qualtrics.com/jfe/form/SV_b2cClqAlLGQ6nLU">Rate-a-Recent-Course: A ReCentering Psych Stats Exercise</a>. If you haven’t yet completed it, please consider doing so, now. In order to reduce the potential threats to validity by providing background information about the survey, I will wait to describe it until later in the chapter.</p>
<p>The survey is administered in Qualtrics. In the chapter I teach two ways to import Qualtrics data into R. We will then use the data to work through the steps identified in the workflow.</p>
</div>
<div id="working-the-problem" class="section level2" number="2.4">
<h2 number="2.4"><span class="header-section-number">2.4</span> Working the Problem</h2>
<div id="intravenous-qualtrics" class="section level3" number="2.4.1">
<h3 number="2.4.1"><span class="header-section-number">2.4.1</span> intRavenous Qualtrics</h3>
<p>I will demonstrate using a Qualtrics account at my institution, Seattle Pacific University. The only surveys in this account are for the <em>Recentering Psych Stats</em> chapters and lessons. All surveys are designed to not capture personally identifying information.</p>
<p>Access credentials for the institutional account, individual user’s account, and survey are essential for getting the survey items and/or results to export into R. The Qualtrics website provides a tutorial for <a href="https://www.qualtrics.com/support/integrations/api-integration/overview/#GeneratingAnAPIToken">generating an API token</a>.</p>
<p>We need two pieces of information: the <strong>root_url</strong> and an <strong>API token</strong>.</p>
<ul>
<li>Log into your respective qualtrics.com account.</li>
<li>Select Account Settings</li>
<li>Choose “Qualtrics IDs” from the user name dropdown</li>
</ul>
<p>We need the <strong>root_url</strong>. This is the first part of the web address for the Qualtrics account. For our institution it is: spupsych.az1.qualtrics.com</p>
<p>The API token is in the box labeled, “API.” If it is empty, select, “Generate Token.” If you do not have this option, locate the <em>brand administrator</em> for your Qualtrics account. They will need to set up your account so that you have API privileges.</p>
<p><em>BE CAREFUL WITH THE API TOKEN</em> This is the key to your Qualtrics accounts. If you leave it in an .rmd file that you forward to someone else, this key and the base URL gives access to every survey in your account. If you share it, you could be releasing survey data to others that would violate confidentiality promises in an IRB application.</p>
<p>If you mistakenly give out your API token you can generate a new one within your Qualtrics account and re-protect all its contents.</p>
<p>You do need to change the API key/token if you want to download data from a different Qualtrics account. If your list of surveys generates the wrong set of surveys, restart R, make sure you have the correct API token and try again.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#only have to run this ONCE to draw from the same Qualtrics account...but will need to get different token if you are changing between accounts </span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(qualtRics)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#qualtrics_api_credentials(api_key = &quot;mUgPMySYkiWpMFkwHale1QE5HNmh5LRUaA8d9PDg&quot;,</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>              <span class="co">#base_url = &quot;spupsych.az1.qualtrics.com&quot;, overwrite = TRUE, install = TRUE)</span></span></code></pre></div>
<p><em>all_surveys()</em> generates a dataframe containing information about all the surveys stored on your Qualtrics account.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>surveys <span class="ot">&lt;-</span> <span class="fu">all_surveys</span>() </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#View this as an object (found in the right: Environment).  </span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#Get survey id # for the next command</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">#If this is showing you the WRONG list of surveys, you are pulling from the wrong Qualtrics account (i.e., maybe this one instead of your own). Go back and change your API token (it saves your old one). Changing the API likely requires a restart of R.</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>surveys</span></code></pre></div>
<p>To retrieve the survey, use the <em>fetch_survey()</em> function.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#obtained with the survey ID </span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&quot;surveyID&quot; should be the ID from above</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&quot;verbose&quot; prints messages to the R console</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&quot;label&quot;, when TRUE, imports data as text responses; if FALSE prints the data as numerical responses</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&quot;convert&quot;, when TRUE, attempts to convert certain question types to the &quot;proper&quot; data type in R; because I don&#39;t like guessing, I want to set up my own factors.</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&quot;force_request&quot;, when TRUE, always downloads the survey from the API instead of from a temporary directory (i.e., it always goes to the primary source)</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co"># &quot;import_id&quot;, when TRUE includes the unique Qualtrics-assigned ID; since I have provided labels, I want false</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Out of the blue, I started getting an error, that R couldn&#39;t find function &quot;fetch_survey.&quot;  After trying a million things, adding qualtRics:: to the front of it solved the problem</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>QTRX_df <span class="ot">&lt;-</span>qualtRics<span class="sc">::</span><span class="fu">fetch_survey</span>(<span class="at">surveyID =</span> <span class="st">&quot;SV_b2cClqAlLGQ6nLU&quot;</span>, <span class="at">time_zone =</span> <span class="cn">NULL</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>, <span class="at">label=</span><span class="cn">FALSE</span>, <span class="at">convert=</span><span class="cn">FALSE</span>, <span class="at">force_request =</span> <span class="cn">TRUE</span>, <span class="at">import_id =</span> <span class="cn">FALSE</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co">#useLocalTime = TRUE,</span></span></code></pre></div>
<!-- TODO: Link to the Bonus Reel -->
<p><em>It is possible (and helpful, even) to import Qualtrics data that has been downloaded from Qualtrics as a .csv. I demo this in the Bonus Reel.</em></p>
</div>
<div id="about-the-rate-a-recent-course-survey" class="section level3" number="2.4.2">
<h3 number="2.4.2"><span class="header-section-number">2.4.2</span> About the <em>Rate-a-Recent-Course</em> Survey</h3>
<!-- TODO: Add link to chapter when it is available. -->
<p>As a teaching activity for the ReCentering Psych Stats OER, the topic of the survey was selected to be consistent with the overall theme of OER. Specifically, the purpose of this study is to understand the campus climate for students whose identities make them vulnerable to bias and discrimination. These include students who are Black, non-Black students of color, LGBTQ+ students, international students, and students with disabilities.</p>
<p>Although the dataset should provide the opportunity to test a number of statistical models, one working hypothesis that framed the study is that the there will be a greater sense of belonging and less bias and discrimination when there is similar representation (of identities that are often marginalized) in the instructional faculty and student body. Termed, “structural diversity” <span class="citation">(<a href="#ref-lewis_black_2019" role="doc-biblioref">K. R. Lewis &amp; Shah, 2019</a>)</span> this is likely an oversimplification. In fact, an increase in diverse representation without attention to interacting factors can increase hostility on campus <span class="citation">(<a href="#ref-hurtado_linking_2007" role="doc-biblioref">Hurtado, 2007</a>)</span>. Thus, we included the task of rating of a single course relates to the larger campus along the dimensions of belonging and bias/discrimination. For example, if a single class has higher ratings on issues of inclusivity, diversity, and respect, we would expect that sentiment to be echoed in the broader institution.</p>
<p>Our design has notable limitations You will likely notice that we ask about demographic characteristics of the instructional staff and classmates in the course rated, but we do not ask about the demographic characteristics of the respondent. In making this decision, we likely lose important information; Iacovino and James <span class="citation">(<a href="#ref-iacovino_retaining_2016" role="doc-biblioref">2016</a>)</span> have noted that White students perceive campus more favorably than Black student counterparts. We made this decision to protect the identity of the respondent. As you will see when we download the data, if a faculty member asked an entire class to take the survey, the datestamp and a handful of demographic identifiers could very likely identify a student. In certain circumstances, this might be risky in that private information (i.e., gender nonconformity, disclosure of a disability) or course evaluation data could be related back to the student.</p>
<p>Further, the items that ask respondents to <em>guess</em> the identities of the instructional staff and classmates are limited, and contrary to best practices in survey construction that recommend providing the option of a “write-in” a response. After consulting with a diverse group of stakeholders and subject matter experts (and revising the response options numerous times) I have attempted to center anti-Black racism in the U.S. <span class="citation">(<a href="#ref-mosley_radical_2020" role="doc-biblioref">Mosley et al., 2020</a>, <a href="#ref-mosley_critical_2021" role="doc-biblioref">2021</a>; <a href="#ref-singh_building_2020" role="doc-biblioref">Singh, 2020</a>)</span>. In fact, the display logic does not present the race items when the course is offered outside the U.S. There are only five options for race: <em>biracial/multiracial</em>, <em>Black</em>, <em>non-Black person(s) of color</em>, <em>White</em>, and <em>I did not notice</em> (intended to capture a color-blind response). One unintended negative consequence of this design is that the response options could contribute to <em>colorism</em> <span class="citation">(<a href="#ref-adames_fallacy_2021" role="doc-biblioref">Adames et al., 2021</a>; <a href="#ref-capielo_rosario_acculturation_2019" role="doc-biblioref">Capielo Rosario et al., 2019</a>)</span>. Another possibility is that the limited options may erase, or make invisible, other identities. At the time that I am writing the first draft of this chapter, the murder of six Asian American women in Atlanta has just occurred. The Center for the Study of Hate and Extremeism has documented that while overall hate drimes dropped by 7% in 2020, anti-Asian hate crimes reported to the police in America’s largest cities increasedby 149% <span class="citation">(<a href="#ref-noauthor_fact_nodate" role="doc-biblioref"><em><span>FACT</span> <span>SHEET</span></em>, n.d.</a>)</span>. These incidents have occurred not only in cities, but in our neighborhoods and on our campusus <span class="citation">(<a href="#ref-kim_yes_2021" role="doc-biblioref">P. Kim, 2021</a>; <a href="#ref-kim_guest_2021" role="doc-biblioref">Paul Y. Kim, 2021</a>; <a href="#ref-noauthor_stop_nodate" role="doc-biblioref"><em><span>STOP</span> <span>AAPI</span> <span>HATE</span></em>, n.d.</a>)</span>. While this survey is intended to assess campus climate as a function of race, it unfortunately does not distinguish between many identities that experience marginalization.</p>
<p>In parallel, the items asking respondents to identity characteristics of the instructional staff along dimensions of gender, international status, and disability are “large buckets” and do not include “write-in” options. Similarly, there was no intent to cause harm by erasing or making invisible individuals whose identities are better defined by different descriptors. Further, no write-in items were allowed. This was also intentional to prevent potential harm caused by people who could leave inappropriate or harmful comments.</p>
</div>
<div id="the-codebook" class="section level3" number="2.4.3">
<h3 number="2.4.3"><span class="header-section-number">2.4.3</span> The Codebook</h3>
<p>In order to scrub-and-score a survey, it is critical to know about its content, scoring directions for scales/subscales, and its design. A more complete description of the survey design elements is (or will be) available in the <em>Recentering Psych Stats: Psychometric</em> OER. The review in this chapter provides just-enough information to allow us to make decisions about which items to retain and how to score them. When they are well-written, information in the <a href="./Bikos_ReCenteringPsychStats_ReCupload.pdf">IRB application</a> and <a href="https://osf.io/a8e5u">pre-registration</a> can be helpful in the scrubbing and scoring process.</p>
<p>Let’s look “live” at the survey. In Qualtrics it is possible to <em>print</em> a PDF that looks very similar to its presentation when someone is taking it. You can access that static version <a href="./Rate_a_CoursePDF.pdf">here</a>.</p>
<p>We can export a <a href="./Rate-a-Course_Codebook.pdf">codebook</a>, that is, a Word (or PDF) version of the survey with all the coding. In Qualtrics the protocol is: Survey/Tools/ImportExport/Export Survey to Word. Then select all the options you want (especially “Show Coded Values”). A tutorial provided by Qualtrics can be found <a href="https://www.qualtrics.com/support/survey-platform/survey-module/survey-tools/import-and-export-surveys/">here</a>. This same process can be used to print the PDF example I used above.</p>
<p>It is almost impossible to give this lecture without some reference to Qualtrics and the features used in Qualtrics. An import of raw data from Qualtrics into R can be nightmare in that the Qualtrics-assigned variable names are numbers (e.g., QID1, QID2) – but often out of order because the number is assigned when the question is first created. If the survey is reordered, the numbers get out of sequence.</p>
<p>Similarly, values for Likert-type scales can also get out of order if the scale anchors are revised (which is common to do).</p>
<p>I recommend providing custom variable names and recode values directly in Qualtrics before exporting them into R. A Qualtrics tutorial for this is provided <a href="https://www.qualtrics.com/support/survey-platform/survey-module/question-options/recode-values/">here</a>. In general, consider these qualities when creating variable names:</p>
<ul>
<li>Brevity: historically, SPSS variable names could be a maximum of 8 characters.</li>
<li>Intuitive: although variables can be renamed in R (e.g., for use in charts and tables), it is helpful when the name imported from Qualtrics provides some indication of what the variable is.</li>
<li>Systematic: start items in a scale with the same stem, followed by the item number – ITEM1, ITEM2, ITEM3.</li>
</ul>
<p>The Rate-a-Recent-Course survey was written using some special features in Qualtrics. These include</p>
<ul>
<li>Display logic
<ul>
<li>Items that are U.S.-centric are only shown if the respondent is taking a course from an institution in the U.S. is a student in the U.S.</li>
</ul></li>
<li>Loop and merge
<ul>
<li>Because course may have multiple instructional staff, the information asking about demographic characteristics of the instructors is repeated according to the number input by the respondent</li>
</ul></li>
<li>Random presentation of the 30 items asking about campus climate for the five groups of students
<ul>
<li>Although this might increase the cognitive load of the survey, this helps “spread out” missingness for respondents who might tire of the survey and stop early</li>
</ul></li>
<li>Rank ordering of the institutional level (department, school/faculty, campus/university) to which the respondent feels most connected</li>
</ul>
<p>Looking at the QTRX_df, <em>StartDate</em> thru <em>UserLanguage</em> are metadata created by Qualtrics. The remaining variables and associated value labels are in the <a href="./Rate-a-Course_Codebook.pdf">codebook</a>.</p>
</div>
</div>
<div id="scrubbing" class="section level2" number="2.5">
<h2 number="2.5"><span class="header-section-number">2.5</span> Scrubbing</h2>
<p>With a look at our survey, codebook, and imported data, we now get to the business of scRubbing (deleting those who did not give consent, deleting previews, etc.). This level of “scrubbing” precedes the more formal detection of outliers.</p>
<div id="tools-for-data-manipulations" class="section level3" number="2.5.1">
<h3 number="2.5.1"><span class="header-section-number">2.5.1</span> Tools for Data Manipulations</h3>
<p>The next stages will provide some experience manipulating data with <strong>dplyr</strong> from the <strong>tidyverse</strong>.</p>
<p>The <strong>tidyverse</strong> is a system of packages (i.e,. when you download the tidyverse, you download all its packages/members) for data manipulation, exploration and visualization. The packages in the tidyverse share a common design philosophy. These were mostly developed by Hadley Wickham, but more recently, more designers are contributing to them. Tidyverse packages are intended to make statisticians and data scientists more productive by guiding them through workflows that facilitate communication and result in reproducible work products. Fundamentally, the tidyverse is about the connections between the tools that make the workflow possible. Critical packages in the tidyverse include:</p>
<ul>
<li><strong>dplyr</strong>: data manipulation: mutate, select, filter, summarize, arrange</li>
<li><strong>ggplot2</strong>: extravagant graphing</li>
<li><strong>tibble</strong>: a <em>tibble</em> is a dataframe that provides the user with more (and less) control over the data.</li>
<li><strong>readr</strong>: gives access to “rectangular data” like .csv and tables</li>
<li><strong>tidyr</strong>: tidy data is where each variable is a column, each observation is a row, each value is a cell (duh). <strong>tidyr</strong>’s contributions are gather(wide to long) and spread(long to wide) as well as separate, extract, unite.</li>
<li><strong>purrr</strong>: facilitates working with functions and vectors. For example, if you write a function, using purrr may help you replace loops with code that is more efficient and intuitive.</li>
</ul>
<p>The tidyverse is ever-evolving – so check frequently for updates and troubleshooting.</p>
<p>A handy cheatsheet for data transformation is found <a href="https://www.rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf">here</a>.</p>
</div>
<div id="inclusion-and-exclusion-criteria" class="section level3" number="2.5.2">
<h3 number="2.5.2"><span class="header-section-number">2.5.2</span> Inclusion and Exclusion Criteria</h3>
<p>For me, the first pass at scrubbing is to eliminate the obvious. In our case this is includes <em>previews</em> and respondents who did not consent to continue. Previews are the researcher-initiated responses usually designed to proofread or troubleshoot survey problems. There could be other first-pass-deletions, such as selecting response between certain dates.</p>
<p>I think these first-pass deletions, especially the ones around consent, are important to do as soon as possible. Otherwise, we might delete some of the variables (e.g., timestamps, consent documentation, preview status) and neglect to delete these cases later in the process.</p>
<p>We are here in the workflow:</p>
<div class="figure">
<img src="images/Ch02/wrkflow_prelim.jpg" alt="" />
<p class="caption">An image of a workflow for scrubbing and scoring data.</p>
</div>
<p>We can either update the existing df (by using the same object), or creating a new df from the old. Either works. In my early years, I tended to create lots of new objects. As I have gained confidence in myself and in R, I’m inclined to update the existing df. Why? Because unless you write the object as an outfile (using the same name for the object as for the filename – which I do not recommend), the object used in R does not change the source of the dat. Therefore, it is easy to correct early code and it keeps the global environment less cluttered.</p>
<p>In this particular survey, the majority of respondents will take the survey because they clicked an <em>anonymous</em> link provided by Qualtrics. Another Qualtrics distribution method is e-mail. At the time of this writing, we have not recruited by e-mail, but it is is possible we could do so in the future. What we should not include, though, are <em>previews</em>. These are the times when the researcher is self-piloting the survey to look for errors and to troubleshoot.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the filter command is used when we are making inclusion/exclusion decisions about rows</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># != means do not include cases with &quot;preview&quot;</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<pre><code>## Warning: package &#39;tidyverse&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;forcats&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>QTRX_df <span class="ot">&lt;-</span> <span class="fu">filter</span> (QTRX_df, DistributionChannel <span class="sc">!=</span> <span class="st">&quot;preview&quot;</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">#FYI, another way that doesn&#39;t use tidyverse, but gets the same result</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">#QTRX_df &lt;- QTRX_df[!QTRX_df$DistributionChannel == &quot;preview&quot;,]</span></span></code></pre></div>
<p>APA Style, and in particular the Journal Article Reporting Standards (JARS) for quantitative research specify that we should report the frequency or percentages of missing data. We would start our counting <em>after</em> eliminating the previews.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># I created an object that lists how many rows/cases remain.</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># I used inline text below to update the text with the new number</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>attempts <span class="ot">&lt;-</span> <span class="fu">nrow</span>(QTRX_df)</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>attempts</span></code></pre></div>
<pre><code>## [1] 52</code></pre>
<p>CAPTURING RESULTS FOR WRITING IT UP: Data screening suggested that 52 individuals opened the survey link.</p>
<p>Next let’s filter in only those who consented to take the survey. Because Qualtrics discontinued the survey for everyone who did not consent, we do not have to worry that their data is unintentionally included, but it can be useful to mention the number of non-consenters in the summary of missing data.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># == are used </span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>QTRX_df <span class="ot">&lt;-</span>(<span class="fu">filter</span> (QTRX_df, Consent <span class="sc">==</span> <span class="dv">1</span>))</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>consented_attempts <span class="ot">&lt;-</span> <span class="fu">nrow</span>(QTRX_df)</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>consented_attempts</span></code></pre></div>
<pre><code>## [1] 44</code></pre>
<p>CAPTURING RESULTS FOR WRITING IT UP: Data screening suggested that 52 individuals opened the survey link. Of those, 44, granted consent and proceeded into the survey items.</p>
<p>In this particular study, the categories used to collect race were U.S.-centric. Thus, they were only shown if the respondent indicated that the course being rated was taught by an institution in the U.S. Therefore, an an additional inclusion criteria for this specific research model should be that the course was taught in the U.S.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>QTRX_df <span class="ot">&lt;-</span>(<span class="fu">filter</span> (QTRX_df, USinst <span class="sc">==</span> <span class="dv">0</span>))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>US_inclusion <span class="ot">&lt;-</span> <span class="fu">nrow</span>(QTRX_df)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>US_inclusion</span></code></pre></div>
<pre><code>## [1] 38</code></pre>
<p>CAPTURING RESULTS FOR WRITING IT UP: Data screening suggested that 52 individuals opened the survey link. Of those, 44, granted consent and proceeded into the survey items. A further inclusion criteria was that the course was taught in the U.S; 38 met this criteria.</p>
</div>
<div id="renaming-variables" class="section level3" number="2.5.3">
<h3 number="2.5.3"><span class="header-section-number">2.5.3</span> Renaming Variables</h3>
<p>Even though we renamed the variables in Qualtrics, the loop-and-merge variables were auto-renamed such that they each started with a number. I cannot see how to rename these from inside Qualtrics. A potential problem is that, in R, when variable names start with numbers, they need to be surrounded with single quotation marks. I find it easier to rename them now. I used “i” to start the variable name to represent “instructor.”</p>
<p>The form of the <em>rename()</em> function is this:
df_named &lt;- rename(df_raw, NewName1 = OldName1)</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>QTRX_df <span class="ot">&lt;-</span> <span class="fu">rename</span>(QTRX_df, <span class="at">iRace1 =</span> <span class="st">&#39;1_iRace&#39;</span>, <span class="at">iRace2 =</span> <span class="st">&#39;2_iRace&#39;</span>, <span class="at">iRace3 =</span> <span class="st">&#39;3_iRace&#39;</span>, <span class="at">iRace4 =</span> <span class="st">&#39;4_iRace&#39;</span>, <span class="at">iRace5 =</span> <span class="st">&#39;5_iRace&#39;</span>, <span class="at">iRace6 =</span> <span class="st">&#39;6_iRace&#39;</span>, <span class="at">iRace7 =</span> <span class="st">&#39;7_iRace&#39;</span>, <span class="at">iRace8 =</span> <span class="st">&#39;8_iRace&#39;</span>, <span class="at">iRace9 =</span> <span class="st">&#39;9_iRace&#39;</span>, <span class="at">iRace10 =</span> <span class="st">&#39;10_iRace&#39;</span>)</span></code></pre></div>
<p>Also in Qualtrics, it was not possible to rename the variable (formatted with sliders) that asked respondents to estimate the proportion of classmates in each race-based category. Using the codebook, we can do this now. I will use “cm” to precede each variable name to represent “classmates.”</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>QTRX_df <span class="ot">&lt;-</span> <span class="fu">rename</span>(QTRX_df, <span class="at">cmBiMulti =</span> Race_10, <span class="at">cmBlack =</span> Race_1, <span class="at">cmNBPoC =</span> Race_7, <span class="at">cmWhite =</span> Race_8, <span class="at">cmUnsure =</span> Race_2)</span></code></pre></div>
<p>Let’s also create an ID variable (different from the lengthy Qualtrics-issued ID) and then move it to the front of the distribution.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>QTRX_df <span class="ot">&lt;-</span> QTRX_df <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="fu">row_number</span>())</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co">#moving the ID number to the first column; requires </span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>QTRX_df <span class="ot">&lt;-</span> QTRX_df<span class="sc">%&gt;%</span><span class="fu">select</span>(ID, <span class="fu">everything</span>())</span></code></pre></div>
</div>
<div id="downsizing-the-dataframe" class="section level3" number="2.5.4">
<h3 number="2.5.4"><span class="header-section-number">2.5.4</span> Downsizing the Dataframe</h3>
<p>Although researchers may differ in their approach, my tendency is to downsize the df to the variables I will be using in my study. These could include variables in the model, demographic variables, and potentially auxiliary variables (i.e,. variables not in the model, but that might be used in the case of multiple imputation).</p>
<p>This particular survey did not collect demographic information, so that will not be used. The model that I will demonstrate in this research vignette examines the the respondent’s perceived campus climate for students who are Black, predicted by the the respondent’s own campus belonging, and also the <em>structural diversity</em> <span class="citation">(<a href="#ref-lewis_black_2019" role="doc-biblioref">K. R. Lewis &amp; Shah, 2019</a>)</span> proportions of Black students in the classroom and BIPOC (Black, Indigenous, and people of color) instructional staff.</p>
<p><em>I would like to assess the model by having the instructional staff variable to be the %Black instructional staff. At the time that this lecture is being prepared, there is not sufficient Black representation in the staff to model this.</em></p>
<p>The <em>select()</em> function can let us list the variables we want to retain.</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co">#You can use the &quot;:&quot; to include all variables from the first to last variable in any sequence; I could have written this more efficiently.  I just like to &quot;see&quot; my scales and clusters of variables.</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>Model_df <span class="ot">&lt;-</span>(<span class="fu">select</span> (QTRX_df, ID, iRace1, iRace2, iRace3, iRace4, iRace5, iRace6, iRace7, iRace8, iRace9, iRace10, cmBiMulti, cmBlack, cmNBPoC, cmWhite, cmUnsure, Belong_1<span class="sc">:</span>Belong_3, Blst_1<span class="sc">:</span>Blst_6))</span></code></pre></div>
<p>It can be helpful to save outfile of progress as we go along. Here I save this raw file.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">write.table</span>(Model_df, <span class="at">file=</span><span class="st">&quot;BlackStntsModel210318.csv&quot;</span>, <span class="at">sep=</span><span class="st">&quot;,&quot;</span>, <span class="at">col.names=</span><span class="cn">TRUE</span>, <span class="at">row.names=</span><span class="cn">FALSE</span>)</span></code></pre></div>
</div>
</div>
<div id="toward-the-apa-style-write-up" class="section level2" number="2.6">
<h2 number="2.6"><span class="header-section-number">2.6</span> Toward the APA Style Write-up</h2>
<div id="methodprocedure" class="section level3" number="2.6.1">
<h3 number="2.6.1"><span class="header-section-number">2.6.1</span> Method/Procedure</h3>
<p>Data screening suggested that 52 individuals opened the survey link. Of those, 44 granted consent and proceeded to the survey items. A further inclusion criteria was that the course was taught in the U.S; 38 met this criteria.</p>
</div>
</div>
<div id="practice-problems" class="section level2" number="2.7">
<h2 number="2.7"><span class="header-section-number">2.7</span> Practice Problems</h2>
<p>Starting with this chapter, the practice problems for this and the next two chapters (i.e., Scoring, Data Dx) are connected. Whatever practice option(s) you choose, please (a) use raw data that (b) has some data missing. This second criteria will be important in the subsequent chapters.</p>
<p>The three problems below are listed in the order of graded complexity. If you are just getting started, you may wish to start with the first problem. If you are more confident, choose the second or third option. You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.</p>
<div id="problem-1-rework-the-chapter-problem" class="section level3" number="2.7.1">
<h3 number="2.7.1"><span class="header-section-number">2.7.1</span> Problem #1: Rework the Chapter Problem</h3>
<p>Because the <em>Rate-a-Recent-Course</em> survey remains open, it is quite likely that there will be more participants who have taken the survey since this chapter was last updated. If not – please encourage a peer to take it. Even one additional response will change the results. This practice problem encourages you to rework the chapter, as written, with the updated data from the survey.</p>
<table>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Import the data from Qualtrics</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Exclude all previews</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Include only those who consented</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Exclude those whose institutions are outside the U.S.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Rename variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Downsize the dataframe to the variables of interest</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Write up of preliminary results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-2-use-the-rate-a-recent-course-survey-choosing-different-variables" class="section level3" number="2.7.2">
<h3 number="2.7.2"><span class="header-section-number">2.7.2</span> Problem #2: Use the <em>Rate-a-Recent-Course</em> Survey, Choosing Different Variables</h3>
<p>Before starting this option, choose a minimum of three variables from the <em>Rate-a-Recent-Course</em> survey to include in a simple statistical model. Work through the chapter making decisions that are consistent with the research model you have proposed. There will likely be differences at several points in the process. For example, you may wish to include (not exclude) data where the rated-course was offered by an institution outside the U.S. Different decisions may involve an internet search for the R script you will need as you decide on inclusion and exclusion criteria.</p>
<table>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Import the data from Qualtrics</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Exclude all previews</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Include only those who consented</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Other exclusionary/inclusionary criteria?</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Rename variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Downsize the dataframe to the variables of interest</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Write up of preliminary results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-3-other-data" class="section level3" number="2.7.3">
<h3 number="2.7.3"><span class="header-section-number">2.7.3</span> Problem #3: Other data</h3>
<p>Using raw data for which you have access, use the chapter as a rough guide. Your data will likely have unique characteristics that may involved searching for solutions beyond this chapter/OER.</p>
<table>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Import the data</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Include only those who consented</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Apply other exclusionary/inclusionary critera</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Addressing unique concerns</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Rename variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Downsize the dataframe to the variables of interest</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Write up of preliminary results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="bonus-track" class="section level2" number="2.8">
<h2 number="2.8"><span class="header-section-number">2.8</span> Bonus Track:</h2>
<div class="figure">
<img src="images/film-strip-1.jpg" id="id" class="class" width="620" height="211" alt="" />
<p class="caption">Image of a filmstrip</p>
</div>
<div id="importing-data-from-an-exported-qualtrics-.csv-file" class="section level3" number="2.8.1">
<h3 number="2.8.1"><span class="header-section-number">2.8.1</span> Importing data from an exported Qualtrics .csv file</h3>
<p>The lecture focused on the “intRavenous” import. It is is also possible to download the Qualtrics data in a variety of formats (e.g., CSV, Excel, SPSS). Since I got started using files with the CSV extension (think “Excel” lite), that is my preference.</p>
<p>In Qualtrics, these are the steps to download the data: Projects/YOURsurvey/Data &amp; Analysis/Export &amp; Import/Export data/CSV/Use numeric values</p>
<p>I think that it is critical that to save this file in the same folder as the .rmd file that you will use with the data.</p>
<p>R is sensitive to characters used filenames As downloaded, my Qualtrics .csv file had a long name with spaces and symbols that are not allowed. Therore, I gave it a simple, sensible, filename, “ReC_Download210319.csv.” An idiosyncracy of mine is to datestamp filenames. I use two-digit representations of the year, month, and date so that if the letters preceding the date are the same, the files would alphabetize automatically.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(qualtRics)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>QTRX_csv <span class="ot">&lt;-</span> <span class="fu">read_survey</span>(<span class="st">&quot;ReC_Download210319.csv&quot;</span>, <span class="at">strip_html =</span> <span class="cn">TRUE</span>, <span class="at">import_id =</span> <span class="cn">FALSE</span>, <span class="at">time_zone=</span><span class="cn">NULL</span>, <span class="at">legacy =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
## -- Column specification --------------------------------------------------------
## cols(
##   .default = col_double(),
##   StartDate = col_datetime(format = &quot;&quot;),
##   EndDate = col_datetime(format = &quot;&quot;),
##   RecordedDate = col_datetime(format = &quot;&quot;),
##   ResponseId = col_character(),
##   DistributionChannel = col_character(),
##   UserLanguage = col_character(),
##   Virtual = col_number(),
##   `5_iPronouns` = col_logical(),
##   `5_iGenderConf` = col_logical(),
##   `5_iRace` = col_logical(),
##   `5_iUS` = col_logical(),
##   `5_iDis` = col_logical(),
##   `6_iPronouns` = col_logical(),
##   `6_iGenderConf` = col_logical(),
##   `6_iRace` = col_logical(),
##   `6_iUS` = col_logical(),
##   `6_iDis` = col_logical(),
##   `7_iPronouns` = col_logical(),
##   `7_iGenderConf` = col_logical(),
##   `7_iRace` = col_logical()
##   # ... with 17 more columns
## )
## i Use `spec()` for the full column specifications.</code></pre>
<p>Although minor tweaking may be required, the same script above should be applicable to this version of the data.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] qualtRics_3.1.4 forcats_0.5.1   stringr_1.4.0   dplyr_1.0.5    
##  [5] purrr_0.3.4     readr_1.4.0     tidyr_1.1.3     tibble_3.1.1   
##  [9] ggplot2_3.3.3   tidyverse_1.3.1 psych_2.1.3    
## 
## loaded via a namespace (and not attached):
##  [1] Rcpp_1.0.6        lubridate_1.7.10  lattice_0.20-41   assertthat_0.2.1 
##  [5] digest_0.6.27     utf8_1.2.1        R6_2.5.0          cellranger_1.1.0 
##  [9] backports_1.2.1   reprex_2.0.0      evaluate_0.14     httr_1.4.2       
## [13] pillar_1.6.0      rlang_0.4.11      curl_4.3.1        readxl_1.3.1     
## [17] rstudioapi_0.13   jquerylib_0.1.4   rmarkdown_2.7     munsell_0.5.0    
## [21] broom_0.7.6       compiler_4.0.4    modelr_0.1.8      xfun_0.22        
## [25] pkgconfig_2.0.3   mnormt_2.0.2      tmvnsim_1.0-2     htmltools_0.5.1.1
## [29] insight_0.13.2    tidyselect_1.1.1  bookdown_0.22     fansi_0.4.2      
## [33] withr_2.4.2       crayon_1.4.1      dbplyr_2.1.1      grid_4.0.4       
## [37] nlme_3.1-151      jsonlite_1.7.2    gtable_0.3.0      lifecycle_1.0.0  
## [41] DBI_1.1.1         magrittr_2.0.1    scales_1.1.1      cli_2.5.0        
## [45] stringi_1.5.3     fs_1.5.0          xml2_1.3.2        bslib_0.2.4      
## [49] ellipsis_0.3.1    generics_0.1.0    vctrs_0.3.7       sjlabelled_1.1.7 
## [53] tools_4.0.4       glue_1.4.2        hms_1.0.0         parallel_4.0.4   
## [57] yaml_2.2.1        colorspace_2.0-0  rvest_1.0.0       knitr_1.33       
## [61] haven_2.4.1       sass_0.3.1</code></pre>
<!--chapter:end:02-Scrubbing.Rmd-->
</div>
</div>
</div>
<div id="score" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Scoring</h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=18a6be07-5bdc-404d-bc95-acf601830887">Screencasted Lecture Link</a></p>
<p>The focus of this chapter is to continue the process of scrubbing-and-scoring. We continue with the raw data we downloaded and prepared in the prior chapter. In this chapter we analyze and manage missingness, score scales/subscales, and represent our work with an APA-style write-up. To that end, we will address the conceptual considerations and practical steps in this process.</p>
<div id="navigating-this-lesson-1" class="section level2" number="3.1">
<h2 number="3.1"><span class="header-section-number">3.1</span> Navigating this Lesson</h2>
<p>There is about 1 hour and 20 minutes of lecture. If you work through the materials with me it would be good to add another hour.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, there are a few that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_MultivariateModeling">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="#ReCintro">introduction</a></p>
<div id="learning-objectives-1" class="section level3" number="3.1.1">
<h3 number="3.1.1"><span class="header-section-number">3.1.1</span> Learning Objectives</h3>
<p>Learning objectives from this lecture include the following:</p>
<ul>
<li>Recognize the key components of data loss mechanisms (MCAR, MAR, MNAR), including how to diagnose MCAR.</li>
<li>Interpret missingness figures produced by packages such as <em>mice</em>.</li>
<li>Articulate a workflow for scrubbing and scoring data.</li>
<li>Use critical data manipulation functions from <em>dplyr</em> including <em>filter()</em>, <em>select()</em>, and <em>mutate()</em> to prepare variables.</li>
<li>Interpret code related to missingness (i.e., “is.na,” “!is.na”) and the pipe (%&gt;%)</li>
</ul>
</div>
<div id="planning-for-practice-1" class="section level3" number="3.1.2">
<h3 number="3.1.2"><span class="header-section-number">3.1.2</span> Planning for Practice</h3>
<!-- TODO: Specify set of items to score for homework. -->
<p>The suggestions for practice continue from the prior chapter. The assignment in the prior chapter involved downloading a dataset from Qualtrics and the “scrubbing” it on the basis of inclusion and exclusion criteria. Using that same data, the practice suggestions in this chapter will continue to use Parent’s <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> AIA approach to managing missing data, to score the variables of interest. Options of graded complexity could incude:</p>
<ul>
<li>Repeating the steps in the chapter with the most recent data from the Rate-A-Recent-Course survey; differences will be in the number of people who have completed the survey since the chapter was written.</li>
<li>Use the dataset that is the source of the chapter, but score a different set of items that you choose.</li>
<li>Begin with raw data to which you have access.</li>
</ul>
</div>
<div id="readings-resources-1" class="section level3" number="3.1.3">
<h3 number="3.1.3"><span class="header-section-number">3.1.3</span> Readings &amp; Resources</h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<ul>
<li><p>Parent, M. C. (2013). Handling item-level missing data: Simpler is just as good. The Counseling Psychologist, 41(4), 568–600. <a href="https://doi.org/10.1177/0011000012445176" class="uri">https://doi.org/10.1177/0011000012445176</a></p></li>
<li><p>Kline, R. B. (2015). Data preparation and psychometrics review. In Principles and Practice of Structural Equation Modeling, Fourth Edition. Guilford Publications. <a href="http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4000663" class="uri">http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4000663</a></p></li>
<li><p>Grolemund, G., &amp; Wickham, H. (n.d.). 5 Data transformation | R for Data Science. Retrieved March 12, 2020, from <a href="https://r4ds.had.co.nz/" class="uri">https://r4ds.had.co.nz/</a></p></li>
</ul>
</div>
<div id="packages-2" class="section level3" number="3.1.4">
<h3 number="3.1.4"><span class="header-section-number">3.1.4</span> Packages</h3>
<p>The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<!-- TODO: Build out this section. -->
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(tidyverse)){<span class="fu">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>)}</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(psych)){<span class="fu">install.packages</span>(<span class="st">&quot;psych&quot;</span>)}</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(formattable)){<span class="fu">install.packages</span>(<span class="st">&quot;formattable&quot;</span>)}</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(mice)){<span class="fu">install.packages</span>(<span class="st">&quot;mice&quot;</span>)}</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(sjstats)){<span class="fu">install.packages</span>(<span class="st">&quot;sjstats&quot;</span>)}</span></code></pre></div>
</div>
</div>
<div id="workflow-for-scrubbing-and-scoring-1" class="section level2" number="3.2">
<h2 number="3.2"><span class="header-section-number">3.2</span> Workflow for Scrubbing and Scoring</h2>
<p>The following is a proposed workflow for preparing data for analysis.</p>
<!-- TODO: When finalized, save as PDF so it can open in its own window) -->
<p>The same workflow guides us through the Scrubbing, Scoring, and Data dx chapters. At this stage in the chapter we are still scrubbing as we work through the item-level and whole-level portions of the AIA (left side) of the chart.</p>
<div class="figure">
<img src="images/Ch02/wrkflow_prelim.jpg" alt="" />
<p class="caption">An image of our stage in the workflow for scrubbing and scoring data.</p>
</div>
</div>
<div id="research-vignette-1" class="section level2" number="3.3">
<h2 number="3.3"><span class="header-section-number">3.3</span> Research Vignette</h2>
<p>The research vignette comes from the survey titled, <a href="https://spupsych.az1.qualtrics.com/jfe/form/SV_b2cClqAlLGQ6nLU">Rate-a-Recent-Course: A ReCentering Psych Stats Exercise</a> and is explained in the prior chapter. In the prior chapter we conducted super-preliminary scrubbing of variables that will allow us to examine the respondent’s perceived campus climate for students who are Black, predicted by the the respondent’s own campus belonging, and also the <em>structural diversity</em> proportions of Black students in the classroom and the BIPOC instructional staff. At present, I see this as a parallel mediation. That is, the perceived campus climate for Black students will be predicted by the respondent’s sense of belonging, through the proportion of Black classmates and BIPOC (Black, Indigenous, and people of color)instructional staff.</p>
<p><em>I would like to assess the model by having the instructional staff variable to be the %Black instructional staff. At the time that this lecture is being prepared, there is not sufficient Black representation in the staff to model this.</em></p>
<div class="figure">
<img src="images/Ch03/BlStuMed.jpg" alt="" />
<p class="caption">An image of the statistical model for which we are preparing data.</p>
</div>
<p>First, though, let’s take a more conceptual look at issues regarding missing data. We’ll come back to details of the survey as we work with it.</p>
</div>
<div id="on-missing-data" class="section level2" number="3.4">
<h2 number="3.4"><span class="header-section-number">3.4</span> On Missing Data</h2>
<p>On the topic of missing data, we follow the traditions in most textbooks. We start by considering <em>data loss mechanisms</em> and options for <em>managing missingness.</em></p>
<p>Although the workflow I recommend is fairly straightforward, the topic is not. Quantitative psychologist have produced volumes of research that supports and refutes all of these issues in detail. An in-deth review of this is found in Enders’ <span class="citation">(<a href="#ref-enders_applied_2010" role="doc-biblioref">2010</a>)</span> text.</p>
<div id="data-loss-mechanisms" class="section level3" number="3.4.1">
<h3 number="3.4.1"><span class="header-section-number">3.4.1</span> Data Loss Mechanisms</h3>
<p>We generally classify missingess in data in three different ways <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">Kline, 2016</a>; <a href="#ref-parent_handling_2013" role="doc-biblioref">Parent, 2013</a>)</span>:</p>
<p><strong>Missing completely at random (MCAR)</strong> is the ideal case (and often unrealistic in actual data). For variable <em>Y</em> this mean that</p>
<ul>
<li>Missingness is due to a factor(s) completely unrelated to the missing data. Stated another way:
<ul>
<li>Missing observations differ from the observed scores only by chance; that is, whether scores on Y are missing or not missing is unrelated to <em>Y</em> itself</li>
</ul></li>
<li>The presence versus absence of data on <em>Y</em> is unrelated to all other variables in the dataset. That is, the nonmissing data are just a random sample of scores that the researcher would have analyzed had the data been complete. We might think of it as <em>haphazard</em> missing.
<ul>
<li>A respondent is interrupted, looks up, looks down, and skips an item.</li>
<li>A computer glitch causes spotty missingness – unrelated to any particular variable.</li>
</ul></li>
</ul>
<p>MCAR is the ideal state because results from it should not be biased as a function of the missingness.</p>
<p><strong>Missing at random (MAR)</strong> missing data arise from a process that is both measured and predictable in a particular sample. <em>Admittedly the use of “random” in this term is odd, because, by definition, the missingness is not random.</em></p>
<p>Restated:</p>
<ol style="list-style-type: decimal">
<li>Missingness on Y is unrelated to Y itself, but</li>
<li>Missingness is on Y is correlated with other variables in the data set.</li>
</ol>
<p>Example: Men are less likely to respond to questions about mental health than women, but among men, the probability of responding is unrelated to their true mental health status.</p>
<p>Kline <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span> indicated that information loss due to MAR is potentially recoverable through imputation where missing scores are replaced by predicted scores. The predicted scores are generated from other variables in the data set that predict missingness on Y. If the strength of that prediction is reasonably strong, then results on Y after imputation may be relatively unbiased. In this sense, the MAR pattern is described as <em>ignorable</em> with regard to potential bias. Two types of variables can be used to predict the missing data</p>
<ol style="list-style-type: decimal">
<li>variables that are in the prediction equation, and</li>
<li><em>auxiliary</em> variables (i.e., variables in the dataset that are not in the prediction equation).</li>
</ol>
<p>Parent <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> noted that multiple imputation and expectation maximization have frequently been used to manage missingness in MAR circumstances.</p>
<p><strong>Missing not at random (MNAR)</strong> is when the presence versus absence of scores on <em>Y</em> depend on <em>Y</em> itself. This is <em>non-ignorable</em>.</p>
<p>For example, if a patient drops out of a medical RCT because there are unpleasant side effects from the treatment, this discomfort is not measured, but the data is missing due to a process that is unknown in a particular data set. Results based on <em>complete cases only</em> can be severely biased when the data loss pattern is MNAR. That is, a treatment may look more beneficial than it really is if data from patients who were unable to tolerate the treatment are lost.</p>
<p>Parent <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> described MNAR a little differently – but emphasized that the systematic missingness would be related to a variable outside the datset. Parent provided the example of items written in a manner that may be inappropriate for some participants (e.g., asking women about a relationship with their boyfriend/husband, when the woman might be in same gender relationship). If there were not demographic items that could identify the bias, this would be MNAR. Parent strongly advises researchers to carefully proofread and pilot surveys to avoid MNAR circumstances.</p>
<p>Kline <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span> noted that the choice of the method to deal with the incomplete records can make a difference in the results, and should be made carefully.</p>
</div>
<div id="diagnosing-missing-data-mechanisms" class="section level3" number="3.4.2">
<h3 number="3.4.2"><span class="header-section-number">3.4.2</span> Diagnosing Missing Data Mechanisms</h3>
<p>The bad news is that we never really know (with certainty) the type of missing data mechanism in our data. The following tools can help understand the mechanisms that contribute to missingness.</p>
<ul>
<li>Missing data analyses often includes correlations that could predict missingness.</li>
<li>Little and Rubin <span class="citation">(<a href="#ref-little_statistical_2002" role="doc-biblioref">2002</a>)</span> proposed a multivariate statistical test of the MCAR assumption that simultaneously compares complete versus incomplete cases on <em>Y</em> across all other variables. If this comparison is significant, then the MCAR hypothesis is rejected.
<ul>
<li>To restate: we want a non-significant result; and we use the sometimes-backwards-sounding NHST (null hypothesis significance testing) language, “MCAR cannot be rejected.”</li>
</ul></li>
<li>MCAR can also be examined through a series of <em>t</em> tests of the cases that have missing scores on Y with cases that have complete records on other variables. Unfortunately, sample sizes contribute to problems with interpretation. With low samples, they are underpowered; in large samples they can flag trivial differences.</li>
</ul>
<p>If MCAR is rejected, we are never sure whether the data loss mechanism is MAR or MNAR. There is no magical statistical “fix.” Kline <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span> wrote, “About the best that can be done is to understand the nature of the underlying data loss pattern and accordingly modify your interpretation of the results” (p. 85).</p>
</div>
<div id="managing-missing-data" class="section level3" number="3.4.3">
<h3 number="3.4.3"><span class="header-section-number">3.4.3</span> Managing Missing Data</h3>
<p>There are a number of approaches to managing missing data. Here is a summary of the ones most commonly used.</p>
<ul>
<li><p><strong>Listwise deletion</strong> (aka, Complete Case Analysis) If there is a missing score on any variable, that case is excluded from <strong>all</strong>
analyses.</p></li>
<li><p><strong>Pairwise deletion</strong> Cases are excluded only if they have missing data on variables involved in a particular analysis. AIA is a variant of pair-wise deletion, but it preserves as much data as possible with person-mean imputation at the scale level.</p></li>
<li><p><strong>Mean/median substitution</strong> Mean/median substitution replaces missing values with the mean/median of that particular variable. While this preserves the mean of the dataset, it can cause bias by decreasing variance. For example, if you have a column that has substantial of missingness and you replace each value with the same, fixed, mean, the variability of that variable has just been reduced. A variation on this is a <strong>group-mean substitution</strong> where the missing score in a particular group (e.g., women) is replaced by the group mean.</p></li>
<li><p><strong>Full information maximum likelihood (FIML)</strong> A <em>model-based method</em> that takes the researcher’s model as the starting point. The procedure partitions the cases in a raw data file into subsets, each with the same pattern of missing observations, including none (complete cases). Statistical information (e.g., means, variances) is extracted from each subset so all case are retained in the analysis. Parameters for the researcher’s model are estimated after combining all available information over the subsets of cases.</p></li>
<li><p><strong>Multiple imputation</strong> A <em>data based method</em> that works with the whole raw data file (not just with the observed variables that comprise the researcher’s model). Multiple imputation assumes that data are MAR (remember, MCAR is the more prestigious one). This means that researchers assume that missing values can be replaced by predictions derived from the observable portion fo the dataset.</p>
<ul>
<li>Multiple datasets (often 5 to 20) are created where missing values are replaced via a randomized process (so the same missing value [item 4 for person A] will likely have different values for each dataset).</li>
<li>The desired anlayis(es) is conducted simultaneously/separately for each of the imputed sets (so if you imputed 5 sets and wanted a linear regression, you get 5 linear regressions).</li>
<li>A <em>pooled analysis</em> uses the point estimates and the standard errors to provide a single result that represents the analysis.</li>
</ul></li>
</ul>
</div>
<div id="available-information-analysis-aia" class="section level3" number="3.4.4">
<h3 number="3.4.4"><span class="header-section-number">3.4.4</span> Available Information Analysis (AIA)</h3>
<p>Parent <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> has created a set of recommendations that help us create a streamlined workflow for managing missing data. After evaluating three approaches to managing missingness (AIA, mean substitution, and multiple imputation) Parent concluded that in datasets with (a) low levels of missingness, (b) a reasonable sample size, and (c) adequate internal reliability of measures, these approaches had similar results.</p>
<p>Further, in simulation studies where there was (a) low sample size (<em>n</em> = 50), (b) weak associations among items, and (c) a small number of missing items, AIA was equivalent to multiple imputation. Even in cases where the data conditions were the “best” (i.e., <em>N</em> = 200, moderate correlations, at least 10 items), even 10% missingness (overall) did not produce notable difference among the methods. That is, means, standard errors, and alphas were similar across the methods (AIA, mean substitution, multiple imputation).</p>
<p>AIA is an older method of handling missing data that, as its name suggests, uses the <em>available data</em> for analysis and excludes missing data points only for analyses in which the missing data point would be directly involved. This means</p>
<ul>
<li>In the case of research that uses multiple item scales, and analysis takes place at the scale level
<ul>
<li>AIA is used to generate <strong>mean</strong> scores for the scale using the available data without substituting or imputing values;</li>
<li>This method generally produces a fairly complete set of scale-level data where
<ul>
<li>pairwise deletion (the whole row/case/person is skipped) can be used where there will be multiple analyses using statistics (e.g., correlations, t-tests, ANOVA) were missingness is not permitted</li>
<li>FIML can be specified in path analysisand CFA/SEM (where item-level data is required), and</li>
<li>some statistics, such as principal components analysis and principal axis factoring (item-level analyses) permit missing data,</li>
</ul></li>
<li>Of course, the researcher could still impute data, but why…</li>
</ul></li>
</ul>
<p>Parent’s <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> recommendations:</p>
<ul>
<li>Scale scores should be first calculated as a <em>mean</em> (average) not a sum. Why?
<ul>
<li>Calculating a “sum” from available data will result in automatically lower scores in cases where there is missingness.</li>
<li>If a sum is required (i.e., because you want to interpret some clinical level of something), calculate the mean first, do the analyses, then transform the results back into the whole-scale equivalent (multiply the mean by the number of items) for any interpretation.</li>
<li>For R script, do not write the script ([item1 + item2 + item3]/3) because this will return an empty entry for participants missing data (same problem as if you were to use sum). There are several functions for properly computing a mean; I will demo the <em>mean_n()</em> function from <em>sjstats</em> package because it allows us to simultaneously specify the tolerance level (next item).</li>
</ul></li>
<li>Determine your <em>tolerance</em> for missingness (20% seems to be common, although you could also look for guidance in the test manual/article). Then
<ul>
<li>Run a “percent missingness” check on the level of analysis (i.e., total score, scale, or subscale) you are using. If you are using a total scale score, then check to see what percent is missing across all the items in the whole scale. In contrast, if you are looking at subscales, run the percent missing at that level.</li>
<li>Parent <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> advised that the tolerance levels should be made mindfully. A four-item scale with one item missing, won’t meet the 80% threshold, so it may make sense to set a 75% threshold for this scale.</li>
</ul></li>
<li>“Clearly and concisely detail the level of missingness” in papers <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">Parent, 2013, p. 595</a>)</span>. This includes
<ul>
<li>tolerance level for missing data by scale or subscale (e.g., 80% or 75%)</li>
<li>the number of missing values out of all data points on that scale for all participants and the maximum by participant (e.g., “For Scale X, a total of # missing data points out of ### were observed with no participant missing more than a single point.”)</li>
<li>verify a manual inspection of missing data for obvious patterns (e.g., abnormally high missing rates for only one or two items). This can be accomplished by requesting frequency output for the items and checking the nonmissing data points for each scale, ensuring there are no abnormal spikes in missingness (looking for MNAR).</li>
</ul></li>
<li>Curiously, Parent <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> does not recommend that we run all the diagnostic tests. However, because recent reviewers have required them of me, I will demonstrate a series of them.</li>
<li>Reducing missingness starts at the survey design – make sure that all people can answer all items (i.e,. relationship-related items may contain heterosexist assumptions…which would result in an MNAR circumstance)</li>
</ul>
<p>Very practically speaking, Parent’s <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> recommendations follow us through the entire data analysis process.</p>
</div>
</div>
<div id="working-the-problem-1" class="section level2" number="3.5">
<h2 number="3.5"><span class="header-section-number">3.5</span> Working the Problem</h2>
<p>In the prior chapter we imported the data from Qualtrics and applied the broadest levels of inclusion (e.g., the course rated was offered from an institution in the U.S., the respondent consented to participation) and exclusion (e.g., the survey was not a preview). We then downsized the survey to include the variables we will use in our statistical model. We then saved the data in a .csv file.</p>
<p>Presuming that you are working along with me in an .rmd file, if you have placed that file in the same folder as this .rmd file, the following code should read the data into your environment.</p>
<p>I use <em>different</em> names for the object/df in my R environment than I use for the filename that holds the data on my computer. Why? I don’t want to accidentally overwrite this precious “source” of data.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>scrub_df <span class="ot">&lt;-</span> <span class="fu">read.csv</span> (<span class="st">&quot;BlackStntsModel210318.csv&quot;</span>, <span class="at">head =</span> <span class="cn">TRUE</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(scrub_df)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    38 obs. of  25 variables:
##  $ ID       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ iRace1   : int  3 3 3 3 1 3 3 3 1 0 ...
##  $ iRace2   : int  1 NA 1 1 NA NA 3 NA NA 0 ...
##  $ iRace3   : int  3 NA NA 3 NA NA NA NA NA 3 ...
##  $ iRace4   : int  NA NA NA NA NA NA NA NA NA 3 ...
##  $ iRace5   : logi  NA NA NA NA NA NA ...
##  $ iRace6   : logi  NA NA NA NA NA NA ...
##  $ iRace7   : logi  NA NA NA NA NA NA ...
##  $ iRace8   : logi  NA NA NA NA NA NA ...
##  $ iRace9   : logi  NA NA NA NA NA NA ...
##  $ iRace10  : logi  NA NA NA NA NA NA ...
##  $ cmBiMulti: int  0 0 0 2 5 15 0 0 0 7 ...
##  $ cmBlack  : int  0 5 10 6 5 20 0 0 0 4 ...
##  $ cmNBPoC  : int  39 10 30 19 10 30 40 5 30 13 ...
##  $ cmWhite  : int  61 85 60 73 80 35 60 90 70 73 ...
##  $ cmUnsure : int  0 0 0 0 0 0 0 5 0 3 ...
##  $ Belong_1 : int  6 4 NA 5 4 5 6 7 6 3 ...
##  $ Belong_2 : int  6 4 3 3 4 6 6 7 6 3 ...
##  $ Belong_3 : int  7 6 NA 2 4 5 5 7 6 3 ...
##  $ Blst_1   : int  5 6 NA 2 6 5 5 5 5 3 ...
##  $ Blst_2   : int  3 6 5 2 1 1 4 4 3 5 ...
##  $ Blst_3   : int  5 2 2 2 1 1 4 3 1 2 ...
##  $ Blst_4   : int  2 2 2 2 1 2 4 3 2 3 ...
##  $ Blst_5   : int  2 4 NA 2 1 1 4 4 1 3 ...
##  $ Blst_6   : int  2 1 2 2 1 2 4 3 2 3 ...</code></pre>
<p>Let’s think about how the variables in our model should be measured:</p>
<ul>
<li>DV: Campus Climate for Black Students (as perceived by the respondent)
<ul>
<li>mean score of the 6 items on that scale (higher scores indicate a climate characterized by hostility, nonresponsiveness, and stigma)</li>
<li>1 item needs to be reverse-coded</li>
<li>this scale was adapted from the LGBT Campus Climate Scale <span class="citation">(<a href="#ref-szymanski_perceptions_2020" role="doc-biblioref">Szymanski &amp; Bissonette, 2020</a>)</span></li>
</ul></li>
<li>IV: Belonging
<ul>
<li>mean score for the 3 items on that scale (higher scores indicate a greater sense of belonging)</li>
<li>this scale is taken from the Sense of Belonging subscale from the Perceived Cohesion Scale <span class="citation">(<a href="#ref-bollen_perceived_1990" role="doc-biblioref">Bollen &amp; Hoyle, 1990</a>)</span></li>
</ul></li>
<li>Proportion of classmates who are Black
<ul>
<li>a single item</li>
</ul></li>
<li>Proportion of instructional staff who are BIPOC
<ul>
<li>must be calculated from each of the single items for each instructor</li>
</ul></li>
</ul>
<p>Our next step is to conduct a preliminary missing data analysis at the item level, across the dataset we are using. The Campus Climate and Belonging scales are traditional in the sense that they have items that we sum. The variable representing proportion of classmates who are Black is a single item. The variable representing the proportion of instructional staff who are BIPOC must be calculated in a manner that takes into consideration the there may be multiple instructors. The survey allowed a respondent to name up to 10 instructors.</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(scrub_df<span class="sc">$</span>iRace1)</span></code></pre></div>
<pre><code>##  int [1:38] 3 3 3 3 1 3 3 3 1 0 ...</code></pre>
<p>Looking at the structure of our data, the iRace(1 thru 10) variables are in “int” or integer format. This means that they are represented as whole numbers. We need them to be represented as factors. R handles factors represented as words well. Therefore, let’s use our codebook to reformat this variable as a an ordered factor, with words instead of numbers.</p>
<p>Qualtrics imports many of the categorical variables as numbers. R often reads them numerically (integers or numbers). If they are directly converted to factors, R will sometimes collapse across missing numbers. In this example, if there is a race that is not represented (e.g., 2 for BiMulti), when the numbers are changed to factors, R will assume they are ordered and there is a consecutive series of numbers (0,1,2,3,4). If a number in the sequence is missing (0,1,3,4) and labels are applied, it will collapse across the numbers and the labels you think are attached to each number are not. Therefore, it is ESSENTIAL to check (again and again ad nauseum) to ensure that your variables are recoding in a manner you understand.</p>
<p>One way to avoid this is to use the code below to identify the levels and the labels. When they are in order, they align and don’t “skip” numbers. To quadruple check our work, we will recode into a new variable “tRace#” for “teacher” Race.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace1 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace1,</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace2 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace2,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace3 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace3,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace4 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace4,</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace5 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace5,</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace6 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace6,</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace7 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace7,</span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace8 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace8,</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace9 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace9,</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>tRace10 <span class="ot">=</span> <span class="fu">factor</span>(scrub_df<span class="sc">$</span>iRace10,</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span></code></pre></div>
<p>Let’s check the structure to see if they are factors.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(scrub_df)</span></code></pre></div>
<pre><code>## Rows: 38
## Columns: 35
## $ ID        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1~
## $ iRace1    &lt;int&gt; 3, 3, 3, 3, 1, 3, 3, 3, 1, 0, 2, 1, 1, 1, 3, 3, 3, 1, 3, 3, ~
## $ iRace2    &lt;int&gt; 1, NA, 1, 1, NA, NA, 3, NA, NA, 0, NA, NA, 3, NA, 3, 3, NA, ~
## $ iRace3    &lt;int&gt; 3, NA, NA, 3, NA, NA, NA, NA, NA, 3, NA, NA, NA, NA, 3, 1, N~
## $ iRace4    &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, 3, NA, NA, NA, NA, NA, 3~
## $ iRace5    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ iRace6    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ iRace7    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ iRace8    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ iRace9    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ iRace10   &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ cmBiMulti &lt;int&gt; 0, 0, 0, 2, 5, 15, 0, 0, 0, 7, 0, 0, 20, 0, 9, 12, 0, 6, 6, ~
## $ cmBlack   &lt;int&gt; 0, 5, 10, 6, 5, 20, 0, 0, 0, 4, 0, 7, 0, 6, 9, 1, 21, 5, 6, ~
## $ cmNBPoC   &lt;int&gt; 39, 10, 30, 19, 10, 30, 40, 5, 30, 13, 80, 19, 0, 19, 15, 22~
## $ cmWhite   &lt;int&gt; 61, 85, 60, 73, 80, 35, 60, 90, 70, 73, 10, 74, 80, 0, 67, 5~
## $ cmUnsure  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 5, 0, 3, 10, 0, 0, 75, 0, 14, 0, 5, 0, ~
## $ Belong_1  &lt;int&gt; 6, 4, NA, 5, 4, 5, 6, 7, 6, 3, 6, 6, 3, 4, 3, 3, 4, 5, 1, 2,~
## $ Belong_2  &lt;int&gt; 6, 4, 3, 3, 4, 6, 6, 7, 6, 3, 6, 6, 5, 4, 3, 3, 4, 6, 1, 2, ~
## $ Belong_3  &lt;int&gt; 7, 6, NA, 2, 4, 5, 5, 7, 6, 3, 5, 6, 4, 4, 3, 2, 4, 5, 1, 1,~
## $ Blst_1    &lt;int&gt; 5, 6, NA, 2, 6, 5, 5, 5, 5, 3, NA, 4, 5, 6, 3, 4, 6, 4, 4, 4~
## $ Blst_2    &lt;int&gt; 3, 6, 5, 2, 1, 1, 4, 4, 3, 5, NA, 5, 1, 1, 3, 2, 1, 2, 5, 3,~
## $ Blst_3    &lt;int&gt; 5, 2, 2, 2, 1, 1, 4, 3, 1, 2, 2, 1, 1, 1, 3, 2, 6, 2, 2, 2, ~
## $ Blst_4    &lt;int&gt; 2, 2, 2, 2, 1, 2, 4, 3, 2, 3, NA, 4, 3, 1, 3, 2, 1, 3, 2, 1,~
## $ Blst_5    &lt;int&gt; 2, 4, NA, 2, 1, 1, 4, 4, 1, 3, 2, 2, 1, 1, 3, 2, 1, 2, 2, 1,~
## $ Blst_6    &lt;int&gt; 2, 1, 2, 2, 1, 2, 4, 3, 2, 3, NA, 2, 1, 1, 3, 2, 2, 3, 2, 1,~
## $ tRace1    &lt;fct&gt; White, White, White, White, nBpoc, White, White, White, nBpo~
## $ tRace2    &lt;fct&gt; nBpoc, NA, nBpoc, nBpoc, NA, NA, White, NA, NA, Black, NA, N~
## $ tRace3    &lt;fct&gt; White, NA, NA, White, NA, NA, NA, NA, NA, White, NA, NA, NA,~
## $ tRace4    &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, White, NA, NA, NA, NA, N~
## $ tRace5    &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ tRace6    &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ tRace7    &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ tRace8    &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ tRace9    &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~
## $ tRace10   &lt;fct&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ~</code></pre>
<p>Calculating the proportion of the BIPOC instructional staff could likely be accomplished a number of ways. My searching for solutions resulted in this. Hopefully it’s a fair balance between intuitive and elegant coding. First, I created code that</p>
<ul>
<li>created a new variable (count.BIPOC) by
<ul>
<li>summing across the tRace1 through tRace10 variables,</li>
<li>assigning a count of “1” each time the factor value was Black, nBpoc, or BiMulti</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>count.BIPOC <span class="ot">&lt;-</span> <span class="fu">apply</span>(scrub_df[<span class="fu">c</span>(<span class="st">&quot;tRace1&quot;</span>, <span class="st">&quot;tRace2&quot;</span>, <span class="st">&quot;tRace3&quot;</span>, <span class="st">&quot;tRace4&quot;</span>, <span class="st">&quot;tRace5&quot;</span>, <span class="st">&quot;tRace6&quot;</span>, <span class="st">&quot;tRace7&quot;</span>, <span class="st">&quot;tRace8&quot;</span>, <span class="st">&quot;tRace9&quot;</span>, <span class="st">&quot;tRace10&quot;</span>)], <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="fu">sum</span>(x <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>)))</span></code></pre></div>
<p>Next, I created a variable that counted the number of non-missing values across the tRace1 through tRace10 variables.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>count.nMiss <span class="ot">&lt;-</span> <span class="fu">apply</span>(scrub_df[<span class="fu">c</span>(<span class="st">&quot;tRace1&quot;</span>, <span class="st">&quot;tRace2&quot;</span>, <span class="st">&quot;tRace3&quot;</span>, <span class="st">&quot;tRace4&quot;</span>, <span class="st">&quot;tRace5&quot;</span>, <span class="st">&quot;tRace6&quot;</span>, <span class="st">&quot;tRace7&quot;</span>, <span class="st">&quot;tRace8&quot;</span>, <span class="st">&quot;tRace9&quot;</span>, <span class="st">&quot;tRace10&quot;</span>)], <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="fu">sum</span>(<span class="sc">!</span><span class="fu">is.na</span>(x)))</span></code></pre></div>
<p>Now to calculate the proportion of BIPOC instructional faculty for each case.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>iBIPOC_pr <span class="ot">=</span> scrub_df<span class="sc">$</span>count.BIPOC<span class="sc">/</span>scrub_df<span class="sc">$</span>count.nMiss</span></code></pre></div>
<div id="missing-data-analysis-whole-df-and-item-level" class="section level3" number="3.5.1">
<h3 number="3.5.1"><span class="header-section-number">3.5.1</span> Missing Data Analysis: Whole df and Item level</h3>
<p>In understanding missingness across the dataset, I think it is important to analyze and manage it, iteratively. We will start with a view of the whole df-level missingness. Subsequently, and consistent with the available information analysis [AIA; <span class="citation"><a href="#ref-parent_handling_2013" role="doc-biblioref">Parent</a> (<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span>] approach, we will score the scales and then look again at missingness, using the new information to update our decisions about how to manage it.</p>
<div class="figure">
<img src="images/Ch02/wrkflow_item_lvl.jpg" alt="" />
<p class="caption">An image of our stage in the workflow for scrubbing and scoring data.</p>
</div>
<p>Because we just created a host of new variables in creating the <em>prop_BIPOC</em> variable, let’s downsize the df so that the calculations are sensible.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>scrub_df <span class="ot">&lt;-</span>(<span class="fu">select</span> (scrub_df, ID, iBIPOC_pr, cmBlack, Belong_1<span class="sc">:</span>Belong_3, Blst_1<span class="sc">:</span>Blst_6))</span></code></pre></div>
<p>With a couple of calculations, we create a proportion of item-level missingness.</p>
<p>In this chunk I first calculate the number of missing (nmiss)</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Calculating number and proportion of item-level missingness</span></span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>nmiss <span class="ot">&lt;-</span> scrub_df<span class="sc">%&gt;%</span></span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(iBIPOC_pr<span class="sc">:</span>Blst_6) <span class="sc">%&gt;%</span> <span class="co">#the colon allows us to include all variables between the two listed (the variables need to be in order)</span></span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    is.na <span class="sc">%&gt;%</span> </span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>    rowSums</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="ot">&lt;-</span> scrub_df<span class="sc">%&gt;%</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prop_miss =</span> (nmiss<span class="sc">/</span><span class="dv">11</span>)<span class="sc">*</span><span class="dv">100</span>) <span class="co">#11 is the number of variables included in calculating the proportion</span></span></code></pre></div>
<p>We can grab the descriptives for the <em>prop_miss</em> variable to begin to understand our data. I will create an object from it so I can use it with inline</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(formattable)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>CaseMiss<span class="ot">&lt;-</span>psych<span class="sc">::</span><span class="fu">describe</span>(scrub_df<span class="sc">$</span>prop_miss)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>CaseMiss</span></code></pre></div>
<pre><code>##    vars  n mean   sd median trimmed mad min   max range skew kurtosis   se
## X1    1 38 3.35 9.31      0    0.85   0   0 36.36 36.36 2.77     6.48 1.51</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>missMin <span class="ot">&lt;-</span> <span class="fu">digits</span>(CaseMiss<span class="sc">$</span>min, <span class="dv">0</span>)</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>missMax <span class="ot">&lt;-</span> <span class="fu">digits</span>(CaseMiss<span class="sc">$</span>max, <span class="dv">0</span>)</span></code></pre></div>
<p>CUMULATIVE CAPTURE FOR WRITING IT UP: Across cases that were deemed eligible on the basis of the inclusion/exclusion criteria, missingness ranged from 0% to 36%.</p>
<p>At the time that I am lecturing this, the the amount of missing is not so egregious that I want to eliminate any cases. That is, I’m willing to wait until after I score the items to make further decisions, then.</p>
<p>Because (a) I want to teach it and (b) it is quite likely that we will receive responses with high levels of missingness, I will write code to eliminate cases with <span class="math inline">\(\geq\)</span> 90%.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>scrub_df <span class="ot">&lt;-</span> <span class="fu">filter</span>(scrub_df, prop_miss <span class="sc">&lt;=</span> <span class="dv">90</span>)  <span class="co">#update df to have only those with at least 90% of complete data</span></span></code></pre></div>
<p>To analyze missingness at this level, we need a df that has only the variables of interest. That is, variables like <em>ID</em> and the <em>prop_miss</em> and <em>nmiss</em> variables we created will interfere with an accurate assessment of missingness. I will update our df to eliminate these.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>scrub_df <span class="ot">&lt;-</span> scrub_df <span class="sc">%&gt;%</span></span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span> (<span class="sc">-</span><span class="fu">c</span>(ID, nmiss, prop_miss))<span class="co">#further update to exclude the n_miss and prop_miss variables</span></span></code></pre></div>
<p>Missing data analysis commonly looks at proportions by:</p>
<ul>
<li>the entire df</li>
<li>rows/cases/people</li>
</ul>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co">#install.packages(&quot;formattable&quot;)</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>CellsMiss <span class="ot">&lt;-</span> <span class="fu">percent</span>(<span class="fu">mean</span>(<span class="fu">is.na</span>(scrub_df)))<span class="co">#what proportion of cells missing across entire dataset</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>CaseComplete <span class="ot">&lt;-</span> <span class="fu">percent</span>(<span class="fu">mean</span>(<span class="fu">complete.cases</span>(scrub_df)))<span class="co">#what proportion of cases (rows) are complete (nonmissing)</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>CellsMiss</span></code></pre></div>
<pre><code>## [1] 3.35%</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>CaseComplete</span></code></pre></div>
<pre><code>## [1] 84.21%</code></pre>
<p>CUMULATIVE CAPTURE FOR WRITING IT UP: Across cases that were deemed eligible on the basis of the inclusion/exclusion criteria, missingness ranged from 0% to 36%. Across the dataset, 3.35% of cells had missing data and 84.21% of cases had nonmissing data.</p>
</div>
<div id="analyzing-missing-data-patterns" class="section level3" number="3.5.2">
<h3 number="3.5.2"><span class="header-section-number">3.5.2</span> Analyzing Missing Data Patterns</h3>
<p>One approach to analyzing missing data is to assess patterns of missingness.</p>
<p>Several R packages are popularly used for conducting such analyses. In the <em>mice</em> package, <em>md.pattern()</em> function provides a matrix with the number of columns + 1, in which each row corresponds to a missing data pattern (1 = observed, 0 = missing).</p>
<p>Rows and columns are sorted in increasing amounts of missing information.</p>
<p>The last column and row contain row and column counts, respectively.</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Using the package: mice</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mice)</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>mice_out <span class="ot">&lt;-</span> <span class="fu">md.pattern</span>(scrub_df, <span class="at">plot =</span> <span class="cn">TRUE</span>, <span class="at">rotate.names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>mice_out</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span> (mice_out, <span class="at">file=</span><span class="st">&quot;mice_out.csv&quot;</span>) <span class="co">#optional to write it to a .csv file</span></span></code></pre></div>
<p>The table lets you look at each missing pattern and see which variable(s) is/are missing. The output is in the form of a table that indicates the frequency of each pattern of missingness. Because I haven’t (yet) figured out how to pipe objects from this table into the chapter, this text may dier from the patterns in the current data frame.</p>
<p>Each row in the table represents a different pattern of missingness. At the time of writing, there are <em>6</em> patterns of missing data. The patterns are listed in descending order of the least amount of missingness. The most common pattern (<em>23</em> cases, top row) is one with no missing data. One cases (is missing three cells – three of the items assessing the campus climate for Black students, and so forth. <em>These numbers are not piped and subject to change.</em></p>
<p>In general, the data patterns represented a haphazard patterns of responding <span class="citation">(<a href="#ref-enders_applied_2010" role="doc-biblioref">Enders, 2010</a>)</span>.</p>
</div>
<div id="missing-mechanisms" class="section level3" number="3.5.3">
<h3 number="3.5.3"><span class="header-section-number">3.5.3</span> Missing Mechanisms</h3>
<p>Remember Little’s MCAR test. Recently it has a history of appearing, working with glitches, disappearing, and so forth. At the present time I cannot find a package that is working well. When I do, I will add this section.</p>
</div>
</div>
<div id="scoring" class="section level2" number="3.6">
<h2 number="3.6"><span class="header-section-number">3.6</span> Scoring</h2>
<p>So let’s get to work to score up the measures for our analysis. Each step of this should involve careful cross-checking with the <a href="./Rate-a-Course_Codebook.pdf">codebook</a>.</p>
<div id="reverse-scoring" class="section level3" number="3.6.1">
<h3 number="3.6.1"><span class="header-section-number">3.6.1</span> Reverse scoring</h3>
<p>As we discovered previously, in the scale that assesses campus climate (higher scores reflect a more negative climate) one of our items (Blst_1, “My <em>institution</em> provides a supportive environment for Black students.”) requires reverse-coding.</p>
<p>To rescore:</p>
<ul>
<li>Create a <em>new</em> variable (this is essential) that is designated as the reversed item. We might put a the letter “r” (for reverse scoring) at the beginning or end: rBlst_1 or Blst_1r. It does not matter; just be consistent.
<ul>
<li>We don’t reverse score into the same variable because when you rerun the script, it just re-reverses the reversed score…into infinity. It’s very easy to lose your place.</li>
</ul></li>
<li>The reversal is an <em>equation</em> where you subtract the value in the item from the range/scaling + 1. For the our three items we subtract each item’s value from 8.</li>
</ul>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="ot">&lt;-</span> scrub_df <span class="sc">%&gt;%</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rBlst_1 =</span> <span class="dv">8</span> <span class="sc">-</span> Blst_1) <span class="co">#if you had multiple items, you could add a pipe (%&gt;%) at the end of the line and add more until the last one</span></span></code></pre></div>
<p>Per Parent <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> we will analyze missingness for each scale, separately.</p>
<ul>
<li>We will calculate scale scores on each scale separately when 80% (roughly) of the data is present.
<ul>
<li>this is somewhat arbitrary, on 4 item scales, I would choose 75% (to allow one to be missing)</li>
<li>on the 3 item scale, I will allow one item to be missing (65%)</li>
</ul></li>
<li>After calculating the scale scores, we will return to analyzing the missingness, looking at the whole df</li>
</ul>
<p>The <em>mean_n()</em> function of <em>sjstats</em> package has allows you to specify how many items (whole number) or what percentage of items should be present in order to get the mean. First, though, we should identify the variables (properly formatted, if rescoring was needed) that should be included in the calculation of each scale and subscale.</p>
<p>In our case, the scale assessing belonging <span class="citation">(<a href="#ref-bollen_perceived_1990" role="doc-biblioref">Bollen &amp; Hoyle, 1990</a>; <a href="#ref-hurtado_effects_1997" role="doc-biblioref">Hurtado &amp; Carter, 1997</a>)</span> involves three items with no reversals. Our campus climate scale was adapted from Szymanski et al.’s LGBTQ College Campus Climate Scale <span class="citation">(<a href="#ref-szymanski_perceptions_2020" role="doc-biblioref">Szymanski &amp; Bissonette, 2020</a>)</span>. While it has not been psychometrically evaluated for the purpose for which I am using it, I will follow the scoring structure in the journal article that introduces the measure. Specifically, the factor structure permits a total scale score and two subscales representing the college response and stigma.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjstats)</span></code></pre></div>
<pre><code>## Warning: package &#39;sjstats&#39; was built under R version 4.0.5</code></pre>
<pre><code>## 
## Attaching package: &#39;sjstats&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:psych&#39;:
## 
##     phi</code></pre>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Making the list of variables</span></span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>Belonging_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;Belong_1&#39;</span>,<span class="st">&#39;Belong_2&#39;</span>,<span class="st">&#39;Belong_3&#39;</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>ResponseBL_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;rBlst_1&#39;</span>, <span class="st">&#39;Blst_4&#39;</span>,<span class="st">&#39;Blst_6&#39;</span>)</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>StigmaBL_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;Blst_2&#39;</span>, <span class="st">&#39;Blst_3&#39;</span>,<span class="st">&#39;Blst_5&#39;</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>ClimateBL_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;rBlst_1&#39;</span>, <span class="st">&#39;Blst_4&#39;</span>,<span class="st">&#39;Blst_6&#39;</span>,<span class="st">&#39;Blst_2&#39;</span>, <span class="st">&#39;Blst_3&#39;</span>,<span class="st">&#39;Blst_5&#39;</span> )</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating the new variables</span></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>Belonging <span class="ot">&lt;-</span> <span class="fu">mean_n</span>(scrub_df[,Belonging_vars], .<span class="dv">65</span>)</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>ResponseBL <span class="ot">&lt;-</span> <span class="fu">mean_n</span>(scrub_df[,ResponseBL_vars], .<span class="dv">80</span>)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>StigmaBL <span class="ot">&lt;-</span> <span class="fu">mean_n</span>(scrub_df[,StigmaBL_vars], .<span class="dv">80</span>)</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>scrub_df<span class="sc">$</span>ClimateBL <span class="ot">&lt;-</span> <span class="fu">mean_n</span>(scrub_df[,ClimateBL_vars], .<span class="dv">80</span>)</span></code></pre></div>
<p>Later it will be helpful to have a df with the item and scale-level variables. It will also be helpful if there is an ID for each case.</p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>scrub_df <span class="ot">&lt;-</span> scrub_df <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="fu">row_number</span>())</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a><span class="co">#moving the ID number to the first column; requires </span></span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>scrub_df <span class="ot">&lt;-</span> scrub_df<span class="sc">%&gt;%</span><span class="fu">select</span>(ID, <span class="fu">everything</span>())</span></code></pre></div>
<p>Let’s save our <em>scrub_df</em> data for this and write it as an outfile.</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">write.table</span>(scrub_df, <span class="at">file=</span><span class="st">&quot;BlStItmsScrs210320.csv&quot;</span>, <span class="at">sep=</span><span class="st">&quot;,&quot;</span>, <span class="at">col.names=</span><span class="cn">TRUE</span>, <span class="at">row.names=</span><span class="cn">FALSE</span>)</span></code></pre></div>
</div>
</div>
<div id="missing-analysis-scale-level" class="section level2" number="3.7">
<h2 number="3.7"><span class="header-section-number">3.7</span> Missing Analysis: Scale level</h2>
<p>Let’s return to analyzing the missingness, this time including the <em>scale level</em> variables (without the individual items) that will be in our statistical model(s).</p>
<div class="figure">
<img src="images/Ch02/wrkflow_scale_lvl.jpg" alt="" />
<p class="caption">An image of our stage in the workflow for scrubbing and scoring data.</p>
</div>
<p>First let’s get the df down to the variables we want to retain:</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>scored <span class="ot">&lt;-</span>(<span class="fu">select</span> (scrub_df, iBIPOC_pr, cmBlack, Belonging, ResponseBL, StigmaBL, ClimateBL))</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>ScoredCaseMiss <span class="ot">&lt;-</span> <span class="fu">nrow</span>(scored) <span class="co">#I produced this object for the sole purpose of feeding the number of cases into the inline text, below</span></span></code></pre></div>
<p>Before we start our formal analysis of missingness at the scale level, let’s continue to scrub by eliminating cases that clearly won’t remain. In the script below we create a variable that counts the number of missing variables and then creates a proportion by dividing it by the number of total variables.</p>
<p>Using the <em>describe()</em> function from the <em>psych</em> package, we can investigate this variable.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Create a variable (n_miss) that counts the number missing</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>scored<span class="sc">$</span>n_miss <span class="ot">&lt;-</span> scored<span class="sc">%&gt;%</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a><span class="fu">select</span>(iBIPOC_pr<span class="sc">:</span>ClimateBL) <span class="sc">%&gt;%</span> </span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>is.na <span class="sc">%&gt;%</span> </span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>rowSums</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Create a proportion missing by dividing n_miss by the total number of variables (6)</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Pipe to sort in order of descending frequency to get a sense of the missingness</span></span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>scored<span class="ot">&lt;-</span> scored<span class="sc">%&gt;%</span></span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a><span class="fu">mutate</span>(<span class="at">prop_miss =</span> (n_miss<span class="sc">/</span><span class="dv">6</span>)<span class="sc">*</span><span class="dv">100</span>)<span class="sc">%&gt;%</span></span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(<span class="fu">desc</span>(n_miss))</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>ScoredPrMiss <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">describe</span>(scored<span class="sc">$</span>prop_miss)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>ScoredPrMiss</span></code></pre></div>
<pre><code>##    vars  n mean   sd median trimmed mad min   max range skew kurtosis   se
## X1    1 38 3.51 9.62      0    1.04   0   0 33.33 33.33 2.45     4.51 1.56</code></pre>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>ScrdMissMin <span class="ot">&lt;-</span> <span class="fu">digits</span>(ScoredPrMiss<span class="sc">$</span>min, <span class="dv">0</span>)<span class="co">#this object is displayed below and I use input from  it for the inline text used in the write-up</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>ScrdMissMax <span class="ot">&lt;-</span> <span class="fu">digits</span>(ScoredPrMiss<span class="sc">$</span>max, <span class="dv">0</span>)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>ScrdMissMin</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>ScrdMissMax</span></code></pre></div>
<pre><code>## [1] 33</code></pre>
<p>CUMULATIVE CAPTURE FOR WRITING IT UP: Across the 38 cases for which the scoring protocol was applied, missingness ranged from 0% to 33%.</p>
<p>We need to decide what is our retention threshhold. Twenty percent seems to be a general rule of thumb. Let’s delete all cases with missingness at 20% or greater.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>scored <span class="ot">&lt;-</span> <span class="fu">filter</span>(scored, prop_miss <span class="sc">&lt;=</span> <span class="dv">20</span>)  <span class="co">#update df to have only those with at least 20% of complete data (this is an arbitrary decision)</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>scored <span class="ot">&lt;-</span>(<span class="fu">select</span> (scored, iBIPOC_pr<span class="sc">:</span>ClimateBL)) <span class="co">#the variable selection just lops off the proportion missing</span></span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>ScoredCasesIncluded <span class="ot">&lt;-</span> <span class="fu">nrow</span>(scored)</span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>ScoredCasesIncluded <span class="co">#this object is displayed below and I use input from  it for the inline text used in the write-up</span></span></code></pre></div>
<pre><code>## [1] 35</code></pre>
<p>CUMULATIVE CAPTURE FOR WRITING IT UP: Across the 38 cases for which the scoring protocol was applied, missingness ranged from 0% to 33%. After eliminating cases with greater than 20% missing, the dataset analyzed included 35 cases.</p>
<p>With a decision about the number of cases we are going to include, we can continue to analyze missingness.</p>
</div>
<div id="revisiting-missing-analysis-at-the-scale-level" class="section level2" number="3.8">
<h2 number="3.8"><span class="header-section-number">3.8</span> Revisiting Missing Analysis at the Scale Level</h2>
<p>We work with a df that includes only the variables in our model. In our case this is easy. In other cases (i.e., maybe there is an ID number) it might be good to create a subset just for this analysis.</p>
<p>Again, we look at missingness as the proportion of</p>
<ul>
<li>individual cells across the dataset, and</li>
<li>rows/cases with nonmissing data</li>
</ul>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>PrScoredCellsMissing <span class="ot">&lt;-</span><span class="fu">percent</span>(<span class="fu">mean</span>(<span class="fu">is.na</span>(scored))) <span class="co">#percent missing across df</span></span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>PrScoredRowsMissing <span class="ot">&lt;-</span> <span class="fu">percent</span>(<span class="fu">mean</span>(<span class="fu">complete.cases</span>(scored))) <span class="co">#percent of rows with nonmissing data</span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>PrScoredCellsMissing</span></code></pre></div>
<pre><code>## [1] 0.95%</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a>PrScoredRowsMissing</span></code></pre></div>
<pre><code>## [1] 94.29%</code></pre>
<p>CUMULATIVE CAPTURE FOR WRITING IT UP: Across the 38 cases for which the scoring protocol was applied, missingness ranged from 0% to 33%. After eliminating cases with greater than 20% missing, the dataset analyzed included 35 cases. In this dataset we had 0.95% missing across the df; 94.29% of the rows had nonmissing data.</p>
<p>Let’s look again at missing patterns and mechanisms.</p>
<div id="scale-level-patterns-of-missing-data" class="section level3" number="3.8.1">
<h3 number="3.8.1"><span class="header-section-number">3.8.1</span> Scale Level: Patterns of Missing Data</h3>
<p>Returning to the <em>mice</em> package, we can use the <em>md.pattern()</em> function to examine a matrix with the number of columns + 1 in which each row corresponds to a missing data pattern (1 = observed, 0 = missing). The rows and columns are sorted in increasing amounts of missing information. The last column and row contain row and column counts, respectively.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Using the package: mice</span></span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mice)</span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>mice_ScaleLvl <span class="ot">&lt;-</span> <span class="fu">md.pattern</span>(scored, <span class="at">plot =</span> <span class="cn">TRUE</span>, <span class="at">rotate.names=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/scale%20level%20missingness%20w%20mice-1.svg" width="672" /></p>
<p>At the scale-level, this is much easier to interpret. As I am lecturing the results today (the numbers will change) there are <em>2</em> rows of data because there are only <em>2</em> patterns of missingness. The most common pattern is non-missing data (<em>n</em> = 26).</p>
</div>
<div id="is-it-mcar" class="section level3" number="3.8.2">
<h3 number="3.8.2"><span class="header-section-number">3.8.2</span> Is it MCAR?</h3>
<p>As noted earlier, I cannot find an MCAR package. This is a placeholder for updating this portion of the lecture when one becomes readily available (and I learn about it)</p>
</div>
<div id="r-eady-for-analysis" class="section level3" number="3.8.3">
<h3 number="3.8.3"><span class="header-section-number">3.8.3</span> R-eady for Analysis</h3>
<p>At this stage the data is ready for analysis (data diagnostics). With the AIA approach <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">Parent, 2013</a>)</span> the following preliminary analyses would involve pairwise deletion (i.e., the row/case is dropped for that analysis, but included for all others):</p>
<div class="figure">
<img src="images/Ch02/wrkflow_AIAready.jpg" alt="" />
<p class="caption">An image of our stage in the workflow for scrubbing and scoring data.</p>
</div>
<ul>
<li>data diagnostics
<ul>
<li>psychometric properties of scales, such as alpha coefficients</li>
<li>assessing assumptions such as univariate and multivariate normality, outliers, etc.</li>
</ul></li>
<li>preliminary analyses
<ul>
<li>descriptives (means/standard deviations, frequencies)</li>
<li>correlation matrices</li>
</ul></li>
</ul>
<p>AIA can also be used with primary analyses. Examples of how to manage missingness include:</p>
<ul>
<li>ANOVA/regression models
<ul>
<li>if completed with ordinary least squares, pairwise deletion would be utilized</li>
</ul></li>
<li>SEM/CFA models with observed, latent, or hybrid models
<ul>
<li>if FIML (we’ll discuss later) is specified, all cases are used, even when there is missingness</li>
</ul></li>
<li>EFA models
<ul>
<li>these can handle item-level missingness</li>
</ul></li>
<li>Hierarchical linear modeling/multilevel modeling/mixed effects modeling
<ul>
<li>While all data needs to be present for a given cluster/wave, it is permissible to have varying numbers of clusters/waves per case</li>
</ul></li>
</ul>
</div>
</div>
<div id="the-apa-style-write-up" class="section level2" number="3.9">
<h2 number="3.9"><span class="header-section-number">3.9</span> The APA Style Write-Up</h2>
</div>
<div id="results" class="section level2" number="3.10">
<h2 number="3.10"><span class="header-section-number">3.10</span> Results</h2>
<p>All analyses were completed in R Studio (v. 1.4.1106) with R (v. 4.0.4).</p>
<p><strong>Missing Data Analysis and Treatment of Missing Data</strong></p>
<p>Available item analysis (AIA; <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">Parent, 2013</a>)</span>) is a strategy for managing missing data that uses available data for analysis and excludes cases with missing data points only for analyses in which the data points would be directly involved. Parent (2013) suggested that AIA is equivalent to more complex methods (e.g., multiple imputation) across a number of variations of sample size, magnitude of associations among items, and degree of missingness. Thus, we utilized Parent’s recommendations to guide our approach to managing missing data. Missing data analyses were conducted with tools in base R as well as the R packages, <em>psych</em> (v. 1.0.12) and <em>mice</em> (v. 3.13.0).</p>
<p>Across cases that were deemed eligible on the basis of the inclusion/exclusion criteria, missingness ranged from 0% to 36%. Across the dataset, 3.35% of cells had missing data and 84.21% of cases had nonmissing data. At this stage in the analysis, we allowed all cases with less than 90% missing to continue to the scoring stage. Guided by Parent’s <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> AIA approach, scales with three items were scored if at least two items were non-missing; the scale with four items was scored if it at least three non-missing items; and the scale with six items was scored if it had at least five non-missing items.</p>
<p>Across the 38 cases for which the scoring protocol was applied, missingness ranged from 0% to 33%. After eliminating cases with greater than 20% missing, the dataset analyzed included 35 cases. In this dataset we had 0.95% missing across the df; 94.29% of the rows had nonmissing data.</p>
</div>
<div id="practice-problems-1" class="section level2" number="3.11">
<h2 number="3.11"><span class="header-section-number">3.11</span> Practice Problems</h2>
<p>The three problems described below are designed to be continuations from the previous chapter (Scrubbing). You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.</p>
<div id="problem-1-reworking-the-chapter-problem" class="section level3" number="3.11.1">
<h3 number="3.11.1"><span class="header-section-number">3.11.1</span> Problem #1: Reworking the Chapter Problem</h3>
<p>If you chose this option in the prior chapter, you imported the data from Qualtrics, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, and wrote up the preliminary results.</p>
<p>Continue working with this data to:</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Proper formatting of your the variable representing the proportion of BIPOC instructor</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Proper formatting of your the variable representing the proportion of Black students in the classroom</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Proper formatting of variables that will be used in the scales/subscales</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Evaluate and interpret item-level missingness</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Score any scales/subscales</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Evaluate and interpret scale-level missingness</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Represent your work in an APA-style write-up (added to the writeup in the previous chapter)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-2-use-the-rate-a-recent-course-survey-choosing-different-variables-1" class="section level3" number="3.11.2">
<h3 number="3.11.2"><span class="header-section-number">3.11.2</span> Problem #2: Use the <em>Rate-a-Recent-Course</em> Survey, Choosing Different Variables</h3>
<p>If you chose this option in the prior chapter, you chose a minimum of three variables from the <em>Rate-a-Recent-Course</em> survey to include in a simple statistical model. You imported the dat from Qualtrics, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest and wrote up the preliminary results.</p>
<p>Continue working with this data to:</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Proper formatting of your first variable</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Proper formatting of your second variable</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Proper formatting of your third variable</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Evaluate and interpret item-level missingness</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Score any scales/subscales</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Evaluate and interpret scale-level missingness</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Represent your work in an APA-style write-up (added to the writeup in the previous chapter)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-3-other-data-1" class="section level3" number="3.11.3">
<h3 number="3.11.3"><span class="header-section-number">3.11.3</span> Problem #3: Other data</h3>
<p>If you chose this option in the prior chapter, you used raw data that was available to you. You imported it into R, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, and wrote up the preliminary results.</p>
<p>Continue working with this data to:</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Proper formatting of variables of interest (at least three)</td>
<td align="center">15</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Evaluate and interpret item-level missingness</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Score any scales/subscales</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Evaluate and interpret scale-level missingness</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up (added to the writeup in the previous chapter)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] mice_3.13.0       sjstats_0.18.1    formattable_0.2.1 qualtRics_3.1.4  
##  [5] forcats_0.5.1     stringr_1.4.0     dplyr_1.0.5       purrr_0.3.4      
##  [9] readr_1.4.0       tidyr_1.1.3       tibble_3.1.1      ggplot2_3.3.3    
## [13] tidyverse_1.3.1   psych_2.1.3      
## 
## loaded via a namespace (and not attached):
##  [1] nlme_3.1-151       fs_1.5.0           lubridate_1.7.10   insight_0.13.2    
##  [5] httr_1.4.2         tools_4.0.4        backports_1.2.1    bslib_0.2.4       
##  [9] utf8_1.2.1         R6_2.5.0           sjlabelled_1.1.7   DBI_1.1.1         
## [13] colorspace_2.0-0   withr_2.4.2        tidyselect_1.1.1   mnormt_2.0.2      
## [17] emmeans_1.6.0      curl_4.3.1         compiler_4.0.4     performance_0.7.1 
## [21] cli_2.5.0          rvest_1.0.0        xml2_1.3.2         sandwich_3.0-0    
## [25] bookdown_0.22      bayestestR_0.9.0   sass_0.3.1         scales_1.1.1      
## [29] mvtnorm_1.1-1      systemfonts_1.0.1  digest_0.6.27      minqa_1.2.4       
## [33] svglite_2.0.0      rmarkdown_2.7      pkgconfig_2.0.3    htmltools_0.5.1.1 
## [37] lme4_1.1-26        highr_0.9          dbplyr_2.1.1       htmlwidgets_1.5.3 
## [41] rlang_0.4.11       readxl_1.3.1       rstudioapi_0.13    jquerylib_0.1.4   
## [45] generics_0.1.0     zoo_1.8-9          jsonlite_1.7.2     magrittr_2.0.1    
## [49] parameters_0.13.0  Matrix_1.2-18      Rcpp_1.0.6         munsell_0.5.0     
## [53] fansi_0.4.2        lifecycle_1.0.0    stringi_1.5.3      multcomp_1.4-17   
## [57] yaml_2.2.1         MASS_7.3-53.1      grid_4.0.4         parallel_4.0.4    
## [61] sjmisc_2.8.6       crayon_1.4.1       lattice_0.20-41    haven_2.4.1       
## [65] splines_4.0.4      hms_1.0.0          tmvnsim_1.0-2      knitr_1.33        
## [69] pillar_1.6.0       boot_1.3-27        estimability_1.3   effectsize_0.4.4-1
## [73] codetools_0.2-18   reprex_2.0.0       glue_1.4.2         evaluate_0.14     
## [77] modelr_0.1.8       nloptr_1.2.2.2     vctrs_0.3.7        cellranger_1.1.0  
## [81] gtable_0.3.0       assertthat_0.2.1   xfun_0.22          xtable_1.8-4      
## [85] broom_0.7.6        coda_0.19-4        survival_3.2-11    statmod_1.4.35    
## [89] TH.data_1.0-10     ellipsis_0.3.1</code></pre>
<!--chapter:end:03-Scoring.Rmd-->
</div>
</div>
</div>
<div id="DataDx" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> Data Dx</h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=43dbe818-8186-498d-8e84-acf7000acb5b">Screencasted Lecture Link</a></p>
<p>The focus of this chapter engage in <em>data diagnostics</em>, that is, to evaluate the appropriateness of the data for the <em>specific research model we are going to evaluate</em>. We are asking the question, “Does the data have the appropriate characteristics for the analysis we want to perform?” Some statistics are more robust than others to violations of the assumptions about the characteristics of the data. None-the-less, we must report these characteristics when we disseminate the results.</p>
<div id="navigating-this-lesson-2" class="section level2" number="4.1">
<h2 number="4.1"><span class="header-section-number">4.1</span> Navigating this Lesson</h2>
<p>There is about 45 minutes of lecture. If you work through the materials with me it would be plan for an additional hour.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, there are a few that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_MultivariateModeling">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="#ReCintro">introduction</a></p>
<div id="learning-objectives-2" class="section level3" number="4.1.1">
<h3 number="4.1.1"><span class="header-section-number">4.1.1</span> Learning Objectives</h3>
<p>Learning objectives from this lecture include the following:</p>
<ul>
<li>Conduct and interpret critical data diagnostics, including
<ul>
<li>alpha coefficients</li>
<li>skew</li>
<li>kurtosis</li>
</ul></li>
<li>Assess univariate and multivariate normality</li>
<li>Identify options for managing outliers and skewed data</li>
<li>Articulate a workflow for data preparation, including scrubbing, scoring, and data diagnostics</li>
</ul>
</div>
<div id="planning-for-practice-2" class="section level3" number="4.1.2">
<h3 number="4.1.2"><span class="header-section-number">4.1.2</span> Planning for Practice</h3>
<p>The suggestions from practice are a continuation from the two prior chapters. If you have completed one or more of those assignments, you should have started with a raw dataset and then scrubbed and scored it. This chapter will involve running basic data diagnostics. Options of graded complexity could incude:</p>
<ul>
<li>Repeating the steps in the chapter with the most recent data from the Rate-A-Recent-Course survey; differences will be in the number of people who have completed the survey since the chapter was written.</li>
<li>Use the dataset that is the source of the chapter, but score a different set of items that you choose.</li>
<li>Begin with raw data to which you have access.</li>
</ul>
</div>
<div id="readings-resources-2" class="section level3" number="4.1.3">
<h3 number="4.1.3"><span class="header-section-number">4.1.3</span> Readings &amp; Resources</h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<ul>
<li><p>Parent, M. C. (2013). Handling item-level missing data: Simpler is just as good. The Counseling Psychologist, 41(4), 568–600. <a href="https://doi.org/10.1177/0011000012445176" class="uri">https://doi.org/10.1177/0011000012445176</a></p></li>
<li><p>Kline, R. B. (2015). Data preparation and psychometrics review. In Principles and Practice of Structural Equation Modeling, Fourth Edition. Guilford Publications. <a href="http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4000663" class="uri">http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4000663</a></p></li>
</ul>
</div>
<div id="packages-3" class="section level3" number="4.1.4">
<h3 number="4.1.4"><span class="header-section-number">4.1.4</span> Packages</h3>
<p>The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<!-- TODO: Build out this section. -->
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(tidyverse)){<span class="fu">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>)} <span class="co">#this includes dplyr</span></span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(psych)){<span class="fu">install.packages</span>(<span class="st">&quot;psych&quot;</span>)}</span>
<span id="cb80-3"><a href="#cb80-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(apaTables)){<span class="fu">install.packages</span>(<span class="st">&quot;apaTables&quot;</span>)}</span>
<span id="cb80-4"><a href="#cb80-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(formattable)){<span class="fu">install.packages</span>(<span class="st">&quot;formattable&quot;</span>)}</span></code></pre></div>
</div>
</div>
<div id="workflow-for-scrubbing-and-scoring-2" class="section level2" number="4.2">
<h2 number="4.2"><span class="header-section-number">4.2</span> Workflow for Scrubbing and Scoring</h2>
<!-- TODO: When finalized, save as PDF so it can open in its own window) -->
<p>The same workflow guides us through the Scrubbing, Scoring, and Data Dx chapters. At this stage we have</p>
<ul>
<li>imported our raw data from Qualtrics,</li>
<li>scrubbed the data by applying our inclusion and exclusion criteria, and</li>
<li>used Parent’s available information approach [AIA; <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span>] for determining the acceptable amount of missingness for each scale, and</li>
<li>prepared variables and scored them.</li>
</ul>
<p>We are now ready to engage in data diagnostics for the statistical model we will test.</p>
<div class="figure">
<img src="images/Ch04/wrkflow_dx.jpg" alt="" />
<p class="caption">An image of our stage in the workflow for scrubbing and scoring data.</p>
</div>
</div>
<div id="research-vignette-2" class="section level2" number="4.3">
<h2 number="4.3"><span class="header-section-number">4.3</span> Research Vignette</h2>
<p>The research vignette comes from the survey titled, <a href="https://spupsych.az1.qualtrics.com/jfe/form/SV_b2cClqAlLGQ6nLU">Rate-a-Recent-Course: A ReCentering Psych Stats Exercise</a> and is explained in the <a href="#scrub">scrubbing chapter</a>. In the <a href="#score">scoring chapter</a> we prepared four variables for analysis. Details for these are in our <a href="./Rate-a-Course_Codebook.pdf">codebook</a>.</p>
<p>Variable recap:</p>
<ul>
<li>Perceived Campus Climate for Black Students includes 6 items, one of which was reverse scored. This scale was adapted from Szymanski et al.’s <span class="citation">(<a href="#ref-szymanski_perceptions_2020" role="doc-biblioref">2020</a>)</span> Campus Climate for LGBTQ students. It has not been evaluated for use with other groups. The Szymanski et al. analysis suggested that it could be used as a total scale score, or divided into three items each that assess
<ul>
<li>College response to LGBTQ students (items 6, 4, 1)</li>
<li>LGBTQ stigma (items 3, 2, 5)</li>
</ul></li>
<li>Sense of Belonging includes 3 items. This is a subscale from Bollen and Hoyle’s <span class="citation">(<a href="#ref-bollen_perceived_1990" role="doc-biblioref">1990</a>)</span> Perceived Cohesion Scale. There are no items on this scale that require reversing.</li>
<li>Percent of Black classmates is a single item that asked respondents to estimate the proportion of students in various racial categories</li>
<li>Percent of BIPOC instructional staff, similarly, asked respondents to identify the racial category of each member of their instructional staff</li>
</ul>
<p>As we noted in the <a href="#scrub">scrubbing chapter</a>, our design has notable limitations. Briefly, (a) owing to the open source aspect of the data we do not ask about the demographic characteristics of the respondent; (b) the items that ask respondents to <em>guess</em> the identities of the instructional staff and to place them in broad categories, (c) we do not provide a “write-in” a response. We made these decisions after extensive conversation with stakeholders. The primary reason for these decisions was to prevent potential harm (a) to respondents who could be identified if/when the revealed private information in this open-source survey, and (b) trolls who would write inappropriate or harmful comments.</p>
<p>As I think about “how these variables go together” (which is often where I start in planning a study), imagine a parallel mediation. That is the perception of campus climate for Black students would be predicted by the respondent’s sense of belonging, mediated in separate paths through the proportion of classmates who are Black and the proportion of BIPOC instructional staff.</p>
<p><em>I would like to assess the model by having the instructional staff variable to be the %Black instructional staff. At the time that this lecture is being prepared, there is not sufficient Black representation in the staff to model this.</em></p>
<div class="figure">
<img src="images/Ch04/BlStuMed.jpg" alt="" />
<p class="caption">An image of the statistical model for which we are preparing data.</p>
</div>
<p>I will finish up this chapter by conducting a regression. Because parallel mediation can be complicated (I teach it in a later chapter), I will demonstrate use of our prepared variables with a simple multiple regression.</p>
<div class="figure">
<img src="images/Ch04/BlStuRegression.jpg" alt="" />
<p class="caption">An image of the statistical model for which we are preparing data.</p>
</div>
<p>First, though, let’s take a more conceptual look at issues regarding missing data. We’ll come back to details of the survey as we work with it.</p>
</div>
<div id="internal-consistency-of-scalessubscales" class="section level2" number="4.4">
<h2 number="4.4"><span class="header-section-number">4.4</span> Internal Consistency of Scales/Subscales</h2>
<p>Alpha coefficients are <em>reliability coefficients</em> that assess the <em>internal consistency</em> of an instrument. It asks, “For each person, are responses <em>consistently</em> high, or medium, or low?” To the degree that they are (meaning there are high inter-item correlations), the internal consistency coefficient will be high. We want values &gt;.80. There are numerous problems with alpha coefficients. The biggest one is that they are influenced by sample size – longer scales have higher alpha coefficients <span class="citation">(<a href="#ref-cortina_what_1993" role="doc-biblioref">Cortina, 1993</a>)</span>. Fourteen seems to be a magic number where we begin to not trust the high alpha coefficient. I address this more thoroughly – offering an alternative – in psychometrics. While there is much criticism about the usefulness of the alpha coefficient <span class="citation">(<a href="#ref-sijtsma_use_2009" role="doc-biblioref">Sijtsma, 2009</a>)</span>, researchers continue to use the alpha coefficient as an indicator of the internal consistency of scales that consist of multiple items and contain several variables.</p>
<p>We need item level data to compute an alpha coefficient. The easiest way to get an alpha coefficient is to feed the <em>alpha()</em> function (<em>psych</em> package) a contatonated list of items (with any items already reverse-scored). There should be no extra items. In the <a href="#score">scoring chapter</a> we already reverse-coded the single item in the campus climate scale, so we are ready to calculate alphas.</p>
<p>The df from which I am pulling data was created and written as an outfile in the <a href="#score">scoring chapter</a>. This particular df has item-level data.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>item_scores_df <span class="ot">&lt;-</span> <span class="fu">read.csv</span> (<span class="st">&quot;BlStItmsScrs210320.csv&quot;</span>, <span class="at">head =</span> <span class="cn">TRUE</span>, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>)</span></code></pre></div>
<p>From this, we create tiny dfs, one for each of the alpha coefficients we need to create. A priori, we are planning to use all six items of the campus climate scale. We’ll go ahead and also calculate the subscales because (a) it’s good practice and (b) if the alpha is low, a <em>reason</em> might show up in one of the subscales.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(formattable)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>Bel_alpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(item_scores_df[<span class="fu">c</span>(<span class="st">&quot;Belong_1&quot;</span>, <span class="st">&quot;Belong_2&quot;</span>, <span class="st">&quot;Belong_3&quot;</span>)])</span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a>Bel_alpha</span></code></pre></div>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = item_scores_df[c(&quot;Belong_1&quot;, &quot;Belong_2&quot;, &quot;Belong_3&quot;)])
## 
##   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r
##       0.96      0.96    0.95      0.89  23 0.012  4.2 1.5     0.89
## 
##  lower alpha upper     95% confidence boundaries
## 0.93 0.96 0.98 
## 
##  Reliability if an item is dropped:
##          raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r
## Belong_1      0.94      0.94    0.89      0.89  16    0.020    NA  0.89
## Belong_2      0.91      0.91    0.84      0.84  10    0.029    NA  0.84
## Belong_3      0.97      0.97    0.93      0.93  29    0.011    NA  0.93
## 
##  Item statistics 
##           n raw.r std.r r.cor r.drop mean  sd
## Belong_1 37  0.96  0.96  0.94   0.91  4.2 1.5
## Belong_2 38  0.98  0.98  0.97   0.95  4.3 1.5
## Belong_3 37  0.94  0.94  0.89   0.88  4.0 1.6
## 
## Non missing response frequency for each item
##             1    2    3    4    5    6    7 miss
## Belong_1 0.03 0.11 0.22 0.19 0.22 0.19 0.05 0.03
## Belong_2 0.03 0.08 0.24 0.21 0.16 0.24 0.05 0.00
## Belong_3 0.05 0.16 0.14 0.24 0.24 0.11 0.05 0.03</code></pre>
<p>CAPTURE FOR THE APA STYLE WRITE-UP(since these are generally placed in the description of each measure in the Method section, I am not doing a cumulative capture): Cronbach’s alpha for the belonging scale was 0.958.</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>CClim_alpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(item_scores_df[<span class="fu">c</span>(<span class="st">&quot;rBlst_1&quot;</span>, <span class="st">&quot;Blst_2&quot;</span>, <span class="st">&quot;Blst_3&quot;</span>, <span class="st">&quot;Blst_4&quot;</span>, <span class="st">&quot;Blst_5&quot;</span>, <span class="st">&quot;Blst_6&quot;</span>)])</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>CClim_alpha</span></code></pre></div>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = item_scores_df[c(&quot;rBlst_1&quot;, &quot;Blst_2&quot;, &quot;Blst_3&quot;, 
##     &quot;Blst_4&quot;, &quot;Blst_5&quot;, &quot;Blst_6&quot;)])
## 
##   raw_alpha std.alpha G6(smc) average_r S/N   ase mean sd median_r
##       0.86      0.88     0.9      0.55 7.3 0.035  2.3  1     0.57
## 
##  lower alpha upper     95% confidence boundaries
## 0.79 0.86 0.93 
## 
##  Reliability if an item is dropped:
##         raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r
## rBlst_1      0.85      0.88    0.90      0.58 7.0    0.039 0.027  0.61
## Blst_2       0.87      0.88    0.88      0.59 7.1    0.036 0.023  0.63
## Blst_3       0.87      0.88    0.90      0.61 7.7    0.035 0.019  0.63
## Blst_4       0.82      0.84    0.86      0.52 5.3    0.047 0.027  0.50
## Blst_5       0.82      0.84    0.85      0.52 5.3    0.048 0.029  0.52
## Blst_6       0.82      0.83    0.83      0.49 4.9    0.047 0.021  0.50
## 
##  Item statistics 
##          n raw.r std.r r.cor r.drop mean   sd
## rBlst_1 34  0.72  0.72  0.63   0.58  3.1 1.30
## Blst_2  37  0.76  0.71  0.65   0.58  2.7 1.67
## Blst_3  37  0.67  0.67  0.59   0.51  2.1 1.29
## Blst_4  36  0.86  0.86  0.85   0.78  2.2 1.18
## Blst_5  37  0.88  0.86  0.85   0.80  1.9 1.18
## Blst_6  37  0.87  0.91  0.92   0.85  2.0 0.96
## 
## Non missing response frequency for each item
##            1    2    3    4    5    6 miss
## rBlst_1 0.09 0.29 0.26 0.24 0.06 0.06 0.11
## Blst_2  0.38 0.16 0.11 0.14 0.19 0.03 0.03
## Blst_3  0.43 0.32 0.08 0.11 0.03 0.03 0.03
## Blst_4  0.31 0.36 0.17 0.11 0.06 0.00 0.05
## Blst_5  0.49 0.27 0.08 0.14 0.03 0.00 0.03
## Blst_6  0.32 0.43 0.14 0.11 0.00 0.00 0.03</code></pre>
<p>CAPTURE FOR THE APA STYLE WRITE-UP (since these are generally placed in the description of each measure in the Method section, I am not doing a cumulative capture): Cronbach’s alpha for the campus climate scale was 0.863. Since this value is <span class="math inline">\(\geq\)</span> .80, it is within the realm of acceptability. Let’s go ahead, though, and look at its subscales.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a>Stigma_alpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(item_scores_df[<span class="fu">c</span>(<span class="st">&quot;Blst_3&quot;</span>, <span class="st">&quot;Blst_2&quot;</span>, <span class="st">&quot;Blst_5&quot;</span>)])</span>
<span id="cb86-2"><a href="#cb86-2" aria-hidden="true" tabindex="-1"></a>Stigma_alpha</span></code></pre></div>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = item_scores_df[c(&quot;Blst_3&quot;, &quot;Blst_2&quot;, &quot;Blst_5&quot;)])
## 
##   raw_alpha std.alpha G6(smc) average_r S/N   ase mean  sd median_r
##       0.73      0.75    0.73       0.5   3 0.078  2.3 1.2     0.53
## 
##  lower alpha upper     95% confidence boundaries
## 0.58 0.73 0.88 
## 
##  Reliability if an item is dropped:
##        raw_alpha std.alpha G6(smc) average_r  S/N alpha se var.r med.r
## Blst_3      0.79      0.81    0.69      0.69 4.40    0.062    NA  0.69
## Blst_2      0.69      0.69    0.53      0.53 2.27    0.099    NA  0.53
## Blst_5      0.42      0.43    0.28      0.28 0.76    0.181    NA  0.28
## 
##  Item statistics 
##         n raw.r std.r r.cor r.drop mean  sd
## Blst_3 37  0.72  0.74  0.53   0.41  2.1 1.3
## Blst_2 37  0.84  0.80  0.69   0.54  2.7 1.7
## Blst_5 37  0.91  0.91  0.87   0.77  1.9 1.2
## 
## Non missing response frequency for each item
##           1    2    3    4    5    6 miss
## Blst_3 0.43 0.32 0.08 0.11 0.03 0.03 0.03
## Blst_2 0.38 0.16 0.11 0.14 0.19 0.03 0.03
## Blst_5 0.49 0.27 0.08 0.14 0.03 0.00 0.03</code></pre>
<p>Cronbach’s alpha for the campus climate stigma subscale was 0.728.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a>Resp_alpha <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">alpha</span>(item_scores_df[<span class="fu">c</span>(<span class="st">&quot;rBlst_1&quot;</span>, <span class="st">&quot;Blst_4&quot;</span>, <span class="st">&quot;Blst_6&quot;</span>)])</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>Resp_alpha</span></code></pre></div>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = item_scores_df[c(&quot;rBlst_1&quot;, &quot;Blst_4&quot;, &quot;Blst_6&quot;)])
## 
##   raw_alpha std.alpha G6(smc) average_r S/N   ase mean sd median_r
##       0.85      0.87    0.83      0.69 6.6 0.041  2.4  1     0.63
## 
##  lower alpha upper     95% confidence boundaries
## 0.77 0.85 0.94 
## 
##  Reliability if an item is dropped:
##         raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r
## rBlst_1      0.88      0.89    0.81      0.81 8.5    0.035    NA  0.81
## Blst_4       0.75      0.77    0.63      0.63 3.4    0.075    NA  0.63
## Blst_6       0.76      0.77    0.62      0.62 3.3    0.076    NA  0.62
## 
##  Item statistics 
##          n raw.r std.r r.cor r.drop mean   sd
## rBlst_1 34  0.86  0.84  0.69   0.66  3.1 1.30
## Blst_4  36  0.91  0.91  0.87   0.77  2.2 1.18
## Blst_6  37  0.89  0.91  0.87   0.80  2.0 0.96
## 
## Non missing response frequency for each item
##            1    2    3    4    5    6 miss
## rBlst_1 0.09 0.29 0.26 0.24 0.06 0.06 0.11
## Blst_4  0.31 0.36 0.17 0.11 0.06 0.00 0.05
## Blst_6  0.32 0.43 0.14 0.11 0.00 0.00 0.03</code></pre>
<p>Cronbach’s alpha for the campus climate responsiveness subscale was 0.855. Between the two subscales, it looks as if the responsivenes subscale is more internally consistent.</p>
</div>
<div id="distributional-characteristics-of-the-variables" class="section level2" number="4.5">
<h2 number="4.5"><span class="header-section-number">4.5</span> Distributional Characteristics of the Variables</h2>
<div id="evaluating-univariate-normality" class="section level3" number="4.5.1">
<h3 number="4.5.1"><span class="header-section-number">4.5.1</span> Evaluating Univariate Normality</h3>
<p>Statistics like ANOVA and regression each have a set of assumptions about the distributional characteristics of the data. In most of the chapters in this OER we review those assumptions and how to evaluate them. Common across many statistics is the requirement of univariate and multivariate normality. Let’s take a look at the variables we will use in our analysis and assess those.</p>
<p>We can continue to work from the df we uploaded at the beginning of the chapter to do this work. Let’s take a quick peek. This df has the item-level data (we used it for the alpha coefficients); the scale and subscale scores; and the two items that assess proportion of instructional staff that are BIPOC and proportion of classmates that are BIPOC.</p>
<p>The <em>str()</em> function let’s us look at the variable format/measurement level of each variable.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(item_scores_df)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    38 obs. of  17 variables:
##  $ ID        : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ iBIPOC_pr : num  0.333 0 0.5 0.333 1 ...
##  $ cmBlack   : int  0 5 10 6 5 20 0 0 0 4 ...
##  $ Belong_1  : int  6 4 NA 5 4 5 6 7 6 3 ...
##  $ Belong_2  : int  6 4 3 3 4 6 6 7 6 3 ...
##  $ Belong_3  : int  7 6 NA 2 4 5 5 7 6 3 ...
##  $ Blst_1    : int  5 6 NA 2 6 5 5 5 5 3 ...
##  $ Blst_2    : int  3 6 5 2 1 1 4 4 3 5 ...
##  $ Blst_3    : int  5 2 2 2 1 1 4 3 1 2 ...
##  $ Blst_4    : int  2 2 2 2 1 2 4 3 2 3 ...
##  $ Blst_5    : int  2 4 NA 2 1 1 4 4 1 3 ...
##  $ Blst_6    : int  2 1 2 2 1 2 4 3 2 3 ...
##  $ rBlst_1   : int  3 2 NA 6 2 3 3 3 3 5 ...
##  $ Belonging : num  6.33 4.67 NA 3.33 4 5.33 5.67 7 6 3 ...
##  $ ResponseBL: num  2.33 1.67 2 3.33 1.33 2.33 3.67 3 2.33 3.67 ...
##  $ StigmaBL  : num  3.33 4 3.5 2 1 1 4 3.67 1.67 3.33 ...
##  $ ClimateBL : num  2.83 2.83 NA 2.67 1.17 1.67 3.83 3.33 2 3.5 ...</code></pre>
<p>The difference between “int” (integer) and “num” (numerical) is that integers are limited to whole numbers. In the functions used in this chapter, both are acceptable formats for the variables.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the script may look a little complicated; I could have simply written</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a><span class="co"># describe(item_scores_df) #it would have given me descriptives for all the items in the df</span></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a><span class="co"># because I only wanted a few variables, I provided them in a concatenated: list [c(&quot;iBIPOC_pr&quot;, &quot;cmBlack&quot;, &quot;Belonging&quot;, &quot;ClimateBL&quot;)]</span></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="co"># I also added &quot;psych::&quot; in front of the command to make sure that R is using the describe function from the psych package</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="co"># I popped the output into an object; objects are not required, but can be helpful to write as outfiles, to pipe elements of inline text, and to use with packages like apaTables</span></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a><span class="co"># When we use an object, we need to write it below so the results will display</span></span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a>descriptives <span class="ot">&lt;-</span> (psych<span class="sc">::</span><span class="fu">describe</span>(item_scores_df[<span class="fu">c</span>(<span class="st">&quot;iBIPOC_pr&quot;</span>, <span class="st">&quot;cmBlack&quot;</span>, <span class="st">&quot;Belonging&quot;</span>, <span class="st">&quot;ClimateBL&quot;</span>)]))</span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a>descriptives</span></code></pre></div>
<pre><code>##           vars  n mean   sd median trimmed  mad min   max range  skew kurtosis
## iBIPOC_pr    1 36 0.44 0.40   0.33    0.42 0.49   0  1.00  1.00  0.37    -1.42
## cmBlack      2 38 7.00 8.12   5.00    5.84 7.41   0 29.00 29.00  1.25     0.46
## Belonging    3 37 4.20 1.49   4.00    4.23 1.48   1  7.00  6.00 -0.15    -0.91
## ClimateBL    4 35 2.29 0.99   2.33    2.23 0.99   1  4.17  3.17  0.32    -1.07
##             se
## iBIPOC_pr 0.07
## cmBlack   1.32
## Belonging 0.24
## ClimateBL 0.17</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span> (descriptives, <span class="at">file=</span><span class="st">&quot;DataDx_descripts.csv&quot;</span>) <span class="co">#this can be useful if you wish to manually format the data for an APA style table</span></span></code></pre></div>
<p>To understand whether our data are normally distributed, we can look at skew and kurtosis. The skew and kurtosis indices in the psych package are reported as <em>z</em> scores. Regarding skew, values &gt; 3.0 are generally considered “severely skewed.” Regarding kurtosis, “severely kurtotic” is argued anywhere &gt; 8 to 20 <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">Kline, 2016</a>)</span>. At the time I am writing this chapter, our skew and kurtosis values fall below the thresholds that Kline identified as concerning.</p>
<p>We can also apply the Shapiro-Wilk test of normality to each of our variables. When the <span class="math inline">\(p\)</span> value is &lt; .05, the variable’s distribution is deviates from a normal distribution to a degree that is statistically significant. Below, the plotting of the histogram with a normal curve superimposed shows how the distribution approximates one that is normal.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="co">#The shapiro-test is in base R; it&#39;s specification is simple:  shapiro.test(df$variable)</span></span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a><span class="co">#I added the object (and had to list it below) so I can use the inline text function</span></span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>SWt_i <span class="ot">&lt;-</span> <span class="fu">shapiro.test</span>(item_scores_df<span class="sc">$</span>iBIPOC_pr)</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>SWt_cm <span class="ot">&lt;-</span> <span class="fu">shapiro.test</span>(item_scores_df<span class="sc">$</span>cmBlack)</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>SWt_Bel <span class="ot">&lt;-</span><span class="fu">shapiro.test</span>(item_scores_df<span class="sc">$</span>Belonging)</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a>SWt_Cl <span class="ot">&lt;-</span><span class="fu">shapiro.test</span>(item_scores_df<span class="sc">$</span>ClimateBL)</span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>SWt_i</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  item_scores_df$iBIPOC_pr
## W = 0.82348, p-value = 4.939e-05</code></pre>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a>SWt_cm</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  item_scores_df$cmBlack
## W = 0.80586, p-value = 1.379e-05</code></pre>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a>SWt_Bel</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  item_scores_df$Belonging
## W = 0.97551, p-value = 0.5767</code></pre>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a>SWt_Cl</span></code></pre></div>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  item_scores_df$ClimateBL
## W = 0.93431, p-value = 0.03763</code></pre>
<p>CUMULATIVE CAPTURE FOR THE APA STYLE WRITE-UP: Regarding the distributional characteristics of the data, skew and kurtosis values of the variables fell below the values of 3 (skew) and 8 to 20 (kurtosis) that Kline suggests are concerning <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span>. Results of the Shapiro-Wilk test of normality indicate that our variables assessing the proportion of classmates who are Black (<span class="math inline">\(W\)</span> = 0.806, <span class="math inline">\(p\)</span> = 0.0000) and the proportion of BIPOC instructional staff(<span class="math inline">\(W\)</span> = 0.823, <span class="math inline">\(p\)</span> = 0.0000) are statistically significantly different than a normal distribution. The scales assessing the respondent’s belonging (<span class="math inline">\(W\)</span> = 0.976, <span class="math inline">\(p\)</span> = 0.5767) and the respondent’s perception of campus climate for Black students (<span class="math inline">\(W\)</span> = 0.934, <span class="math inline">\(p\)</span> = 0.0376) did not differ differently from a normal distribution.</p>
<p><em>Note. Owing to the open nature of the dataset, these values will change. While I have used inline text to update the values of the Shapiro Wilks’ and associated significance test, the text narration is not automatically updated and may be inconsistent with the results.</em></p>
<p>What would we do in the case of a univariate outlier? I find Kline’s <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span> chapter on data preparation and management to be extremely useful. He provides ideas for more complex analysis of both univariate and multivariate normality and provides suggestions that range from recoding an extreme value to the next most extreme that is within three standard deviations of the mean to more complicated transformations. First, though we need to further examine the relationships between variables. We do that, next.</p>
</div>
<div id="pairs-panels" class="section level3" number="4.5.2">
<h3 number="4.5.2"><span class="header-section-number">4.5.2</span> Pairs Panels</h3>
<p>As we work our way from univariate to multivariate inspection of our data, let’s take a look at the bivariate relations.</p>
<p>The <em>pairs.panels()</em> function from the <em>psych</em> package is useful for showing the relationship between variables (probably no more than 10) in a model.</p>
<ul>
<li>The lower half is a scatterplot between the two variables with a regression line (red) and mean (dot).<br />
</li>
<li>The diagonal is a histogram of each variable.<br />
</li>
<li>The upper half of is the correlation coefficient between the two variables.</li>
</ul>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">pairs.panels</span>(item_scores_df[<span class="fu">c</span>(<span class="st">&quot;iBIPOC_pr&quot;</span>, <span class="st">&quot;cmBlack&quot;</span>, <span class="st">&quot;Belonging&quot;</span>, <span class="st">&quot;ClimateBL&quot;</span>)], <span class="at">stars =</span> <span class="cn">TRUE</span>, <span class="at">lm =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/pairs%20panels-1.svg" width="672" /></p>
<p>The histograms displayed in the diagonal graph for us what we learned from the Shapiro Wilk’s test of normality. We can clearly see the non-normal distribution in the iBIPOC_pr and cmBlack variables.</p>
</div>
</div>
<div id="evaluating-multivariate-normality" class="section level2" number="4.6">
<h2 number="4.6"><span class="header-section-number">4.6</span> Evaluating Multivariate Normality</h2>
<p><strong>Multivariate outliers</strong> have extreme scores on two or more variables, or a pattern of scores that is atypical. For example, a case may have scores between two and three standard deviations above the mean on all variables, even though no case would be extreme. A common method of multivariate outlier detection is the <strong>Mahalanobis distance</strong> (<span class="math inline">\(D_{M}^{2}\)</span>). This indicates the distance in variance units between the profile of scores for that case and the vector of sample means, or <strong>centroid</strong>, correcting for intercorrelations.</p>
<p>The <em>outlier()</em> function from the <em>psych</em> package tells us how far each datapoint is from the multivariate centroid of the data. That is, find the squared Mahalanobis distance for each data point and compare it to the expected values of <span class="math inline">\(\chi^2\)</span>. The <em>outlier()</em> protocol also produces a Q-Q (quantile-quantile) plot with the <em>n</em> most extreme data points labeled.</p>
<p>The code below appends the Mahalanobis values to the dataframe. It is easy, then, to identify, sort, and examine the most extreme values (relative to the rest of the data in their case/row) to make decisions about their retention or adjustment.</p>
<p>Numeric variables are required in the for the calculation of the Mahalanobis.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>item_scores_df<span class="sc">$</span>Mahal <span class="ot">&lt;-</span> psych<span class="sc">::</span><span class="fu">outlier</span>(item_scores_df[<span class="fu">c</span>(<span class="st">&quot;iBIPOC_pr&quot;</span>, <span class="st">&quot;cmBlack&quot;</span>, <span class="st">&quot;Belonging&quot;</span>, <span class="st">&quot;ClimateBL&quot;</span>)]) </span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/Detect%20multivariate%20outliers-1.svg" width="672" /></p>
<p>Q-Q plots take your sample data, sort it in ascending order, and then plot them versus quantiles (the number varies; you can see it on the X axis) calculated from a theoretical distribution. The number of quantiles is selected to match the size of your sample data. While Normal Q-Q Plots are the ones most often used in practice due to so many statistical methods assuming normality, Q-Q Plots can actually be created for any distribution. To the degree that the plotted line stays on the straight line (representing the theoretical normal distribution), the data is multivariate normally distributed.</p>
<p>It is possible, then to analyze the Mahalanobis distance values.</p>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">describe</span>(item_scores_df<span class="sc">$</span>Mahal)</span></code></pre></div>
<pre><code>##    vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
## X1    1 38 3.75 2.21   3.15    3.62 2.25 0.19 9.27  9.08 0.61     -0.4 0.36</code></pre>
<p>Using this information we can determine cases that have a Mahalanobis distance values that exceeds three standard deviations around the median. In fact, we can have these noted in a column in the dataframe.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="co">#str(item_scores_df$Mahal)</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>item_scores_df<span class="sc">$</span>MOutlier <span class="ot">&lt;-</span> <span class="fu">if_else</span>(item_scores_df<span class="sc">$</span>Mahal <span class="sc">&gt;</span> (<span class="fu">median</span>(item_scores_df<span class="sc">$</span>Mahal) <span class="sc">+</span> (<span class="dv">3</span><span class="sc">*</span><span class="fu">sd</span>(item_scores_df<span class="sc">$</span>Mahal))), <span class="cn">TRUE</span>, <span class="cn">FALSE</span>)</span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a>OutlierCount <span class="ot">&lt;-</span> item_scores_df<span class="sc">%&gt;%</span></span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(MOutlier)</span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>OutlierCount</span></code></pre></div>
<pre><code>##   MOutlier  n
## 1    FALSE 38</code></pre>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>NumOutliers <span class="ot">&lt;-</span> <span class="fu">nrow</span>(item_scores_df) <span class="sc">-</span> OutlierCount <span class="co">#calculating how many outliers</span></span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>NumOutliers <span class="co">#this object is used for the inline text for the reesults</span></span></code></pre></div>
<pre><code>##   MOutlier n
## 1       38 0</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>NumOutliers</span></code></pre></div>
<pre><code>##   MOutlier n
## 1       38 0</code></pre>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(item_scores_df) <span class="co">#shows us the first 6 rows of the data so we can see the new variables (Mahal, MOutlier)</span></span></code></pre></div>
<pre><code>##   ID iBIPOC_pr cmBlack Belong_1 Belong_2 Belong_3 Blst_1 Blst_2 Blst_3 Blst_4
## 1  1 0.3333333       0        6        6        7      5      3      5      2
## 2  2 0.0000000       5        4        4        6      6      6      2      2
## 3  3 0.5000000      10       NA        3       NA     NA      5      2      2
## 4  4 0.3333333       6        5        3        2      2      2      2      2
## 5  5 1.0000000       5        4        4        4      6      1      1      1
## 6  6 0.0000000      20        5        6        5      5      1      1      2
##   Blst_5 Blst_6 rBlst_1 Belonging ResponseBL StigmaBL ClimateBL     Mahal
## 1      2      2       3      6.33       2.33     3.33      2.83 3.0887370
## 2      4      1       2      4.67       1.67     4.00      2.83 1.7791058
## 3     NA      2      NA        NA       2.00     3.50        NA 0.1863186
## 4      2      2       6      3.33       3.33     2.00      2.67 0.5130016
## 5      1      1       2      4.00       1.33     1.00      1.17 3.1774793
## 6      1      2       3      5.33       2.33     1.00      1.67 5.3309540
##   MOutlier
## 1    FALSE
## 2    FALSE
## 3    FALSE
## 4    FALSE
## 5    FALSE
## 6    FALSE</code></pre>
<p>CUMULATIVE CAPTURE FOR THE APA STYLE WRITE-UP: We evaluated multivariate normality with the Mahalanobis distance test. Specifically, we used the <em>outlier()</em> function in the <em>psych</em> package and included all continuous variables in the calculation. Our visual inspection of the Q-Q plot suggested that the plotted line strayed from the straight line as the quantiles increased. Additionally, we appended the Mahalanobis distance scores as a variable to the data. Analyzing this variable, we found that 0 exceed three standard deviations beyond the median. <em>Thus, with no outliers, we assumed multivariate normality and proceeded with the data analysis</em> AS DATA IS ADDED THIS NUMBER OF OUTLIERS COULD UPDATE FROM ZERO AND THIS TEXT COULD CHANGE.</p>
</div>
<div id="a-few-words-on-transformations" class="section level2" number="4.7">
<h2 number="4.7"><span class="header-section-number">4.7</span> A Few Words on Transformations</h2>
<p>To quote from Kline <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span>, “Before applying a normalizing transformation, you should think about the variables of interest and whether the expectation of normality is reasonable.” (p. 77)</p>
<p>At this point in history, the non-normal distribution of the proportions of classmates who are Black and instructional staff who are BIPOC are accurate representations in higher education. Kline <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span> has noted that transforming an inherently non-normal variable to force a normal distribution may fundamentally alter it such that the variable of interest is not actually studied. Kline’s chapter reviews some options for applying corrections to outliers. Additionally, the chapter describes a variety of normalizing transformations.</p>
<p>On a personal note, while I will use stadardized scores (a linear transformation) if it improves interpretation and center variables around a meaningful intercept, I tend to resist the transformation of data without a really compelling reason. Why? It’s complicated and can make interpretation difficult.</p>
</div>
<div id="the-apa-style-write-up-1" class="section level2" number="4.8">
<h2 number="4.8"><span class="header-section-number">4.8</span> The APA Style Write-Up</h2>
<p>Since the focus of this chapter was on data diagnostics, the APA style writeup will focus on on this element of the Method section:</p>
<div id="data-diagnostics" class="section level3" number="4.8.1">
<h3 number="4.8.1"><span class="header-section-number">4.8.1</span> Data Diagnostics</h3>
<p>Data screening suggested that 52 individuals opened the survey link. Of those, 44 granted consent and proceeded to the survey items. A further inclusion criteria was that the course was taught in the U.S; 38 met this criteria.</p>
<p>Available item analysis (AIA; <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">Parent, 2013</a>)</span>) is a strategy for managing missing data that uses available data for analysis and excludes cases with missing data points only for analyses in which the data points would be directly involved. Parent (2013) suggested that AIA is equivalent to more complex methods (e.g., multiple imputation) across a number of variations of sample size, magnitude of associations among items, and degree of missingness. Thus, we utilized Parent’s recommendations to guide our approach to managing missing data. Missing data analyses were conducted with tools in base R as well as the R packages, <em>psych</em> (v. 1.0.12) and <em>mice</em> (v. 3.13.0).</p>
<p>Across cases that were deemed eligible on the basis of the inclusion/exclusion criteria, missingness ranged from 0% to 36%. Across the dataset, 3.35% of cells had missing data and 84.21% of cases had nonmissing data. At this stage in the analysis, we allowed all cases with less than 90% missing to continue to the scoring stage. Guided by Parent’s <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">2013</a>)</span> AIA approach, scales with three items were scored if at least two items were non-missing; the scale with four items was scored if it at least three non-missing items; and the scale with six items was scored if it had at least five non-missing items.</p>
<p>Across the 38 cases for which the scoring protocol was applied, missingness ranged from 0% to 33%. After eliminating cases with greater than 20% missing, the dataset analyzed included 35 cases. In this dataset we had 0.95% missing across the df; 94.29% of the rows had nonmissing data.</p>
<p>Regarding the distributional characteristics of the data, skew and kurtosis values of the variables fell below the values of 3 (skew) and 8 to 20 (kurtosis) that Kline suggests are concerning <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span>. Results of the Shapiro-Wilk test of normality indicate that our variables assessing the proportion of classmates who are Black (<span class="math inline">\(W\)</span> = 0.806, <span class="math inline">\(p\)</span> = 0.0000) and the proportion of BIPOC instructional staff(<span class="math inline">\(W\)</span> = 0.823, <span class="math inline">\(p\)</span> = 0.0000) are statistically significantly different than a normal distribution. The scales assessing the respondent’s belonging (<span class="math inline">\(W\)</span> = 0.976, <span class="math inline">\(p\)</span> = 0.5767) and the respondent’s perception of campus climate for Black students (<span class="math inline">\(W\)</span> = 0.934, <span class="math inline">\(p\)</span> = 0.0376) did not differ differently from a normal distribution.</p>
<p>We evaluated multivariate normality with the Mahalanobis distance test. Specifically, we used the <em>outlier()</em> function in the <em>psych</em> package and included all continuous variables in the calculation. Our visual inspection of the Q-Q plot suggested that the plotted line strayed from the straight line as the quantiles increased. Additionally, we appended the Mahalanobis distance scores as a variable to the data. Analyzing this variable, we found that 0 exceed three standard deviations beyond the median. <em>Thus, with no outliers, we assumed multivariate normality and proceeded with the data analysis</em> AS DATA IS ADDED THIS NUMBER OF OUTLIERS COULD UPDATE FROM ZERO AND THIS TEXT COULD CHANGE.</p>
<p>Given that our sample sizes were reasonable for the planned analyses and the degree of missingness was low, we used pairwise deletion in our multiple regression analysis.</p>
</div>
</div>
<div id="a-quick-regression-of-our-research-vignette" class="section level2" number="4.9">
<h2 number="4.9"><span class="header-section-number">4.9</span> A Quick Regression of our Research Vignette</h2>
<p>With some confidence that our scrubbed-and-scored variables are appropriate for analysis, let me conduct the super quick regression that is our research vignette.</p>
<div class="figure">
<img src="images/Ch04/BlStuRegression.jpg" alt="" />
<p class="caption">An image of the statistical model for which we are preparing data.</p>
</div>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a>Climate_fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(ClimateBL <span class="sc">~</span> Belonging <span class="sc">+</span> cmBlack <span class="sc">+</span> iBIPOC_pr, <span class="at">data =</span> item_scores_df)</span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Climate_fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = ClimateBL ~ Belonging + cmBlack + iBIPOC_pr, data = item_scores_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.52062 -0.73534 -0.01292  0.61904  1.90366 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.31588    0.57674   4.015 0.000384 ***
## Belonging    0.05035    0.12260   0.411 0.684342    
## cmBlack     -0.01550    0.02056  -0.754 0.456936    
## iBIPOC_pr   -0.45576    0.44324  -1.028 0.312328    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9806 on 29 degrees of freedom
##   (5 observations deleted due to missingness)
## Multiple R-squared:  0.05276,    Adjusted R-squared:  -0.04523 
## F-statistic: 0.5384 on 3 and 29 DF,  p-value: 0.6597</code></pre>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Climate_fit)</span></code></pre></div>
<pre><code>##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;         
##  [5] &quot;fitted.values&quot; &quot;assign&quot;        &quot;qr&quot;            &quot;df.residual&quot;  
##  [9] &quot;na.action&quot;     &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;        
## [13] &quot;model&quot;</code></pre>
<p>Results of a multiple regression predicting the respondents’ perceptions of campus climate for Black students indicated that neither contributions of the respondents’ personal belonging (<span class="math inline">\(B\)</span> = 0.050, <span class="math inline">\(p\)</span> = 0.684) nor the proportion of BIPOC instructional staff (<span class="math inline">\(B\)</span> = -0.456, <span class="math inline">\(p\)</span> = 0.312), nor the proportion of Black classmates (<span class="math inline">\(B\)</span> = -0.015, <span class="math inline">\(p\)</span> = 0.457) led to statistically significant changes in perceptions of campus climate for Black students. Although it accounted for 5.28% of the variance, the overall model was not statistically significant. Results are presented in Table 2.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(apaTables)</span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="fu">apa.cor.table</span>(item_scores_df[<span class="fu">c</span>(<span class="st">&quot;iBIPOC_pr&quot;</span>, <span class="st">&quot;cmBlack&quot;</span>, <span class="st">&quot;Belonging&quot;</span>, <span class="st">&quot;ClimateBL&quot;</span>)], <span class="at">table.number =</span> <span class="dv">1</span>, <span class="at">show.sig.stars =</span> <span class="cn">TRUE</span>, <span class="at">filename =</span> <span class="st">&quot;Table1_M_SDs_r_DataDx.doc&quot;</span>)</span></code></pre></div>
<pre><code>## 
## 
## Table 1 
## 
## Means, standard deviations, and correlations with confidence intervals
##  
## 
##   Variable     M    SD   1           2           3          
##   1. iBIPOC_pr 0.44 0.40                                    
##                                                             
##   2. cmBlack   7.00 8.12 -.12                               
##                          [-.43, .22]                        
##                                                             
##   3. Belonging 4.20 1.49 .24         -.16                   
##                          [-.10, .53] [-.46, .17]            
##                                                             
##   4. ClimateBL 2.29 0.99 -.16        -.13        -.04       
##                          [-.48, .19] [-.45, .21] [-.37, .30]
##                                                             
## 
## Note. M and SD are used to represent mean and standard deviation, respectively.
## Values in square brackets indicate the 95% confidence interval.
## The confidence interval is a plausible range of population correlations 
## that could have caused the sample correlation (Cumming, 2014).
##  * indicates p &lt; .05. ** indicates p &lt; .01.
## </code></pre>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(apaTables)</span>
<span id="cb121-2"><a href="#cb121-2" aria-hidden="true" tabindex="-1"></a>apaTables<span class="sc">::</span><span class="fu">apa.reg.table</span>(Climate_fit, <span class="at">table.number =</span> <span class="dv">2</span>, <span class="at">filename =</span> <span class="st">&quot;Climate_table.doc&quot;</span>)</span></code></pre></div>
<pre><code>## 
## 
## Table 2 
## 
## Regression results using ClimateBL as the criterion
##  
## 
##    Predictor      b      b_95%_CI  beta   beta_95%_CI sr2  sr2_95%_CI    r
##  (Intercept) 2.32**  [1.14, 3.50]                                         
##    Belonging   0.05 [-0.20, 0.30]  0.08 [-0.30, 0.46] .01 [-.04, .05]  .05
##      cmBlack  -0.02 [-0.06, 0.03] -0.14 [-0.51, 0.24] .02 [-.07, .11] -.13
##    iBIPOC_pr  -0.46 [-1.36, 0.45] -0.19 [-0.57, 0.19] .03 [-.09, .16] -.16
##                                                                           
##                                                                           
##                                                                           
##              Fit
##                 
##                 
##                 
##                 
##        R2 = .053
##  95% CI[.00,.18]
##                 
## 
## Note. A significant b-weight indicates the beta-weight and semi-partial correlation are also significant.
## b represents unstandardized regression weights. beta indicates the standardized regression weights. 
## sr2 represents the semi-partial correlation squared. r represents the zero-order correlation.
## Square brackets are used to enclose the lower and upper limits of a confidence interval.
## * indicates p &lt; .05. ** indicates p &lt; .01.
## </code></pre>
</div>
<div id="practice-problems-2" class="section level2" number="4.10">
<h2 number="4.10"><span class="header-section-number">4.10</span> Practice Problems</h2>
<p>The three problems described below are designed to be continuations from the previous chapter (Scrubbing). You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.</p>
<div id="problem-1-reworking-the-chapter-problem-1" class="section level3" number="4.10.1">
<h3 number="4.10.1"><span class="header-section-number">4.10.1</span> Problem #1: Reworking the Chapter Problem</h3>
<p>If you chose this option in the prior chapters, you imported the data from Qualtrics, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.</p>
<p>If you continue with this option, please continue working with the data to:</p>
<p>Continue working with this data to:</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Calculate alpha coefficients for scales/subscales.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Evaluate univariate normality (skew, kurtosis, Shapiro-Wilks).</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Evaluate multivarite normality (Mahalanobis test)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Represent your work in an APA-style write-up (added to the writeup in the previous chapter)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. For fun, run a quick analysis (e.g., regression, ANOVA) including at least three variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">30</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-2-use-the-rate-a-recent-course-survey-choosing-different-variables-2" class="section level3" number="4.10.2">
<h3 number="4.10.2"><span class="header-section-number">4.10.2</span> Problem #2: Use the <em>Rate-a-Recent-Course</em> Survey, Choosing Different Variables</h3>
<p>If you chose this option in the prior chapter, you chose a minimum of three variables from the <em>Rate-a-Recent-Course</em> survey to include in a simple statistical model. You imported the data from Qualtrics, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.</p>
<p>Continue working with this data to:</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Calculate alpha coefficients for scales/subscales.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Evaluate univariate normality (skew, kurtosis, Shapiro-Wilks).</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Evaluate multivarite normality (Mahalanobis test)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Represent your work in an APA-style write-up (added to the writeup in the previous chapter)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. For fun, run a quick analysis (e.g., regression, ANOVA) including at least three variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">30</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-3-other-data-2" class="section level3" number="4.10.3">
<h3 number="4.10.3"><span class="header-section-number">4.10.3</span> Problem #3: Other data</h3>
<p>If you chose this option in the prior chapter, you used raw data that was available to you. You imported it into R, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.</p>
<p>Continue working with this data to:</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Calculate alpha coefficients for scales/subscales.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Evaluate univariate normality (skew, kurtosis, Shapiro-Wilks).</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Evaluate multivarite normality (Mahalanobis test)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Represent your work in an APA-style write-up (added to the writeup in the previous chapter)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. For fun, run a quick analysis (e.g., regression, ANOVA) including at least three variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">30</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] apaTables_2.0.8   mice_3.13.0       sjstats_0.18.1    formattable_0.2.1
##  [5] qualtRics_3.1.4   forcats_0.5.1     stringr_1.4.0     dplyr_1.0.5      
##  [9] purrr_0.3.4       readr_1.4.0       tidyr_1.1.3       tibble_3.1.1     
## [13] ggplot2_3.3.3     tidyverse_1.3.1   psych_2.1.3      
## 
## loaded via a namespace (and not attached):
##  [1] nlme_3.1-151       fs_1.5.0           lubridate_1.7.10   MBESS_4.8.0       
##  [5] insight_0.13.2     httr_1.4.2         tools_4.0.4        backports_1.2.1   
##  [9] bslib_0.2.4        utf8_1.2.1         R6_2.5.0           sjlabelled_1.1.7  
## [13] DBI_1.1.1          colorspace_2.0-0   withr_2.4.2        tidyselect_1.1.1  
## [17] mnormt_2.0.2       emmeans_1.6.0      curl_4.3.1         compiler_4.0.4    
## [21] performance_0.7.1  cli_2.5.0          rvest_1.0.0        xml2_1.3.2        
## [25] sandwich_3.0-0     bookdown_0.22      bayestestR_0.9.0   sass_0.3.1        
## [29] scales_1.1.1       mvtnorm_1.1-1      systemfonts_1.0.1  digest_0.6.27     
## [33] minqa_1.2.4        svglite_2.0.0      rmarkdown_2.7      pkgconfig_2.0.3   
## [37] htmltools_0.5.1.1  lme4_1.1-26        highr_0.9          dbplyr_2.1.1      
## [41] htmlwidgets_1.5.3  rlang_0.4.11       readxl_1.3.1       rstudioapi_0.13   
## [45] jquerylib_0.1.4    generics_0.1.0     zoo_1.8-9          jsonlite_1.7.2    
## [49] magrittr_2.0.1     parameters_0.13.0  Matrix_1.2-18      Rcpp_1.0.6        
## [53] munsell_0.5.0      fansi_0.4.2        lifecycle_1.0.0    stringi_1.5.3     
## [57] multcomp_1.4-17    yaml_2.2.1         MASS_7.3-53.1      grid_4.0.4        
## [61] parallel_4.0.4     sjmisc_2.8.6       crayon_1.4.1       lattice_0.20-41   
## [65] haven_2.4.1        splines_4.0.4      hms_1.0.0          tmvnsim_1.0-2     
## [69] knitr_1.33         pillar_1.6.0       boot_1.3-27        estimability_1.3  
## [73] effectsize_0.4.4-1 codetools_0.2-18   reprex_2.0.0       glue_1.4.2        
## [77] evaluate_0.14      modelr_0.1.8       nloptr_1.2.2.2     vctrs_0.3.7       
## [81] cellranger_1.1.0   gtable_0.3.0       assertthat_0.2.1   xfun_0.22         
## [85] xtable_1.8-4       broom_0.7.6        coda_0.19-4        survival_3.2-11   
## [89] statmod_1.4.35     TH.data_1.0-10     ellipsis_0.3.1</code></pre>
<!--chapter:end:04-DataDx.Rmd-->
</div>
</div>
</div>
<div id="multimp" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> Multiple Imputation (A Brief Demo)</h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=94d59efe-3f02-4c65-b068-ad01003e09a9">Screencasted Lecture Link</a></p>
<p>Multiple imputation is a tool for managing missing data that works with the whole raw data file to impute values for missing data for <em>multiple sets</em> (e.g., 5-20) of the raw data. Those multiple sets are considered together in analyses (such as regression) and interpretation is made on the pooled results. Much has been written about multiple imputation and, if used, should be done with many considerations. This chapter is intended as a brief introduction. In this chapter, I demonstrate the use of multiple imputation with the data from the <a href="https://spupsych.az1.qualtrics.com/jfe/form/SV_b2cClqAlLGQ6nLU">Rate-a-Recent-Course: A ReCentering Psych Stats Exercise</a> that has served as the research vignette for the first few chapters of this OER.</p>
<div id="navigating-this-lesson-3" class="section level2" number="5.1">
<h2 number="5.1"><span class="header-section-number">5.1</span> Navigating this Lesson</h2>
<p>There is about one hour of lecture. If you work through the materials with me it would be good to add another hour (to an hour-and-a-half).</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, there are a few that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_MultivariateModeling">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="#ReCintro">introduction</a></p>
<div id="learning-objectives-3" class="section level3" number="5.1.1">
<h3 number="5.1.1"><span class="header-section-number">5.1.1</span> Learning Objectives</h3>
<p>Learning objectives from this lecture include the following:</p>
<ul>
<li>Describe circumstances under which multiple imputation would be appropriate</li>
<li>List and define the stages in multiple imputation.</li>
<li>Apply multiple imputation to a dataset that has missingness</li>
<li>Interpret results from a simple regression that uses multiple imputation</li>
<li>Articulate how multiple imputation fits into the workflow for scrubbing and scoring data.</li>
<li>Write up the results of an the process of imputation from raw data through analyzing a simple regression (or similar) analysis.</li>
</ul>
</div>
<div id="planning-for-practice-3" class="section level3" number="5.1.2">
<h3 number="5.1.2"><span class="header-section-number">5.1.2</span> Planning for Practice</h3>
<p>The suggestions for practice are a continuation from the three prior chapters. If you have completed one or more of those assignments, you should have worked through the steps in preparing a data set and evaluating its appropriateness for the planned, statistical, analysis. This chapter takes a deviation from the AIA <span class="citation">(<a href="#ref-parent_handling_2013" role="doc-biblioref">Parent, 2013</a>)</span> approach that was the focus of the first few chapters in that we used multiple imputation as the approach for managing missingness. Options, of graded complexity, for practice include:</p>
<ul>
<li>Repeating the steps in the chapter with the most recent data from the Rate-A-Recent-Course survey; differences will be in the number of people who have completed the survey since the chapter was written.</li>
<li>Use the dataset that is the source of the chapter, but score a different set of items that you choose.</li>
<li>Begin with raw data to which you have access.</li>
</ul>
</div>
<div id="readings-resources-3" class="section level3" number="5.1.3">
<h3 number="5.1.3"><span class="header-section-number">5.1.3</span> Readings &amp; Resources</h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<p>Enders, C. K. (2017). Multiple imputation as a flexible tool for missing data handling in clinical research. <em>Behaviour Research and Therapy</em>, 98, 4–18.</p>
<p>Katitas, A. (2019). Getting Started with Multiple Imputation in R. University of Virginia Library: Research Data Services + Sciences. <a href="https://uvastatlab.github.io/2019/05/01/getting-started-with-multiple-imputation-in-r/" class="uri">https://uvastatlab.github.io/2019/05/01/getting-started-with-multiple-imputation-in-r/</a></p>
<p>Kline Ch4, Data Preparation &amp; Psychometrics Review (pp. 72/Outliers - 88/Modern Methods)</p>
<p>Little, T. D., Howard, W. J., McConnell, E. K., &amp; Stump, K. N. (2008). Missing data in large data projects: Two methods of missing data imputation when working with large data projects. KUant Guides, 011.3, 10.</p>
</div>
<div id="packages-4" class="section level3" number="5.1.4">
<h3 number="5.1.4"><span class="header-section-number">5.1.4</span> Packages</h3>
<p>The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<!-- TODO: Build out this section. -->
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co">#will install the package if not already installed</span></span>
<span id="cb125-2"><a href="#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(qualtRics)){<span class="fu">install.packages</span>(<span class="st">&quot;qualtRics&quot;</span>)}</span>
<span id="cb125-3"><a href="#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(psych)){<span class="fu">install.packages</span>(<span class="st">&quot;psych&quot;</span>)}</span>
<span id="cb125-4"><a href="#cb125-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(dplyr)){<span class="fu">install.packages</span>(<span class="st">&quot;dplyr&quot;</span>)}</span>
<span id="cb125-5"><a href="#cb125-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(mice)){<span class="fu">install.packages</span>(<span class="st">&quot;mice&quot;</span>)}</span>
<span id="cb125-6"><a href="#cb125-6" aria-hidden="true" tabindex="-1"></a><span class="co">#if(!require(foreign)){install.packages(&quot;foreign&quot;)}</span></span>
<span id="cb125-7"><a href="#cb125-7" aria-hidden="true" tabindex="-1"></a><span class="co">#if(!require(car)){install.packages(&quot;car&quot;)}</span></span></code></pre></div>
</div>
</div>
<div id="workflow-for-multiple-imputation" class="section level2" number="5.2">
<h2 number="5.2"><span class="header-section-number">5.2</span> Workflow for Multiple Imputation</h2>
<p>The following is a proposed workflow for preparing data for analysis.</p>
<div class="figure">
<img src="images/Ch05/scrubscore_mimp_itemlvl.jpg" alt="" />
<p class="caption">An image of a workflow for scrubbing and scoring data.</p>
</div>
<p>In this lecture we are working on the right side of the flowchart in the multiple imputation (blue) section. Within it, there are two options, each with a slightly different set of options.</p>
<ul>
<li>imputing at the item level
<ul>
<li>in this case, scales/subscales are scored after the item-level imputation</li>
</ul></li>
<li>imputating at the scale level
<ul>
<li>in this case, scales/subscales are scored prior to the imputation; likely using some of the same criteria as identified in the scoring chapter (i.e., scoring if 75-80% of data are non-missing). Multiple imputation, then, is used to estimate the remaining, missing values.</li>
</ul></li>
</ul>
<p>Whichever approach is used, the imputed variables (multiple sets) are used in a <em>pooled analysis</em> and results are interpreted from that analysis.</p>
</div>
<div id="research-vignette-3" class="section level2" number="5.3">
<h2 number="5.3"><span class="header-section-number">5.3</span> Research Vignette</h2>
<p>The research vignette comes from the survey titled, <a href="https://spupsych.az1.qualtrics.com/jfe/form/SV_b2cClqAlLGQ6nLU">Rate-a-Recent-Course: A ReCentering Psych Stats Exercise</a> and is explained in the <a href="#scrub">scrubbing chapter</a>. In the <a href="#score">scoring chapter</a> we prepared four variables for analysis. In the <a href="#DataDx">data diagnostics chapter</a> we assessed the quality of the variables and conducted the multiple regression described below. Details for these are in our <a href="./Rate-a-Course_Codebook.pdf">codebook</a>.</p>
<p>Let’s quickly review the variables in our model:</p>
<ul>
<li>Perceived Campus Climate for Black Students includes 6 items, one of which was reverse scored. This scale was adapted from Szymanski et al.’s <span class="citation">(<a href="#ref-szymanski_perceptions_2020" role="doc-biblioref">2020</a>)</span> Campus Climate for LGBTQ students. It has not been evaluated for use with other groups. The Szymanski et al. analysis suggested that it could be used as a total scale score, or divided into three items each that assess
<ul>
<li>College response to LGBTQ students (items 6, 4, 1)</li>
<li>LGBTQ stigma (items 3, 2, 5)</li>
</ul></li>
<li>Sense of Belonging includes 3 items. This is a subscale from Bollen and Hoyle’s <span class="citation">(<a href="#ref-bollen_perceived_1990" role="doc-biblioref">1990</a>)</span> Perceived Cohesion Scale. There are no items on this scale that require reversing.</li>
<li>Percent of Black classmates is a single item that asked respondents to estimate the proportion of students in various racial categories</li>
<li>Percent of BIPOC instructional staff, similarly, asked respondents to identify the racial category of each member of their instructional staff</li>
</ul>
<p>As we noted in the <a href="#scrub">scrubbing chapter</a>, our design has notable limitations. Briefly, (a) owing to the open source aspect of the data we do not ask about the demographic characteristics of the respondent; (b) the items that ask respondents to <em>guess</em> the identities of the instructional staff and to place them in broad categories, (c) we do not provide a “write-in” a response. We made these decisions after extensive conversation with stakeholders. The primary reason for these decisions was to prevent potential harm (a) to respondents who could be identified if/when the revealed private information in this open-source survey, and (b) trolls who would write inappropriate or harmful comments.</p>
<p>As I think about “how these variables go together” (which is often where I start in planning a study), I suspect parallel mediation. That is the perception of campus climate for Black students would be predicted by the respondent’s sense of belonging, mediated in separate paths through the proportion of classmates who are Black and the proportion of BIPOC instructional staff.</p>
<p><em>I would like to assess the model by having the instructional staff variable to be the %Black instructional staff. At the time that this lecture is being prepared, there is not sufficient Black representation in the instructional staff to model this.</em></p>
<div class="figure">
<img src="images/Ch04/BlStuMed.jpg" alt="" />
<p class="caption">An image of the statistical model for which we are preparing data.</p>
</div>
<p>As in the <a href="#DataDx">data diagnostic chapter</a>, I will conclude this chapter by conducting a statistical analysis with the multiply imputed data. Because parallel mediation can be complicated (I teach it in a later chapter), I will demonstrate use of our prepared variables with a simple multiple regression.</p>
<div class="figure">
<img src="images/Ch04/BlStuRegression.jpg" alt="" />
<p class="caption">An image of the statistical model for which we are preparing data.</p>
</div>
</div>
<div id="multiple-imputation-a-super-brief-review" class="section level2" number="5.4">
<h2 number="5.4"><span class="header-section-number">5.4</span> Multiple Imputation – a Super Brief Review</h2>
<p>Multiple imputation is complex. Numerous quantitative psychologists had critiqued it and provided numerous cautions and guidelines for its use <span class="citation">(<a href="#ref-enders_multiple_2017" role="doc-biblioref">Enders, 2017</a>, <a href="#ref-enders_applied_2010" role="doc-biblioref">2010</a>; <a href="#ref-little_statistical_2002" role="doc-biblioref">R. J. A. Little &amp; Rubin, 2002</a>; <a href="#ref-little_missing_2008" role="doc-biblioref">T. D. Little et al., 2008</a>)</span>. In brief,</p>
<div id="steps-in-multiple-imputation" class="section level3" number="5.4.1">
<h3 number="5.4.1"><span class="header-section-number">5.4.1</span> Steps in Multiple Imputation</h3>
<ul>
<li>Multiple imputation starts with a raw data file.
<ul>
<li>Multiple imputation assumes that data are MAR (remember, MCAR is the more prestigious one). This means that researchers assume that missing values can be replaced by predictions derived from the observable portion of the dataset.<br />
</li>
</ul></li>
<li>Multiple datasets (often 5 to 20) are created where missing values are replaced via a randomized process (so the same missing value [item 4 for person A] will likely have different values for each dataset).</li>
<li>The desired analysis is conducted simultaneously/separately for each of the imputed sets (so if you imputed 5 sets and wanted a linear regression, you get 5 linear regressions).<br />
</li>
<li>A <em>pooled analysis</em> uses the point estimates and the standard errors to provide a single result that represents the analysis.</li>
</ul>
<p>In a web-hosted guide from the University of Virginia Library, Katitas <span class="citation">(<a href="#ref-katitas_getting_2019" role="doc-biblioref">2019</a>)</span> provided a user-friendly review and example of using tools in R in a multiple imputation. Katitas’ figure is a useful conceptual tool in understanding how multiple imputation works. <em>This figure is my recreation of Katitas’ original.</em></p>
<div class="figure">
<img src="images/Ch05/KatitasMimpFig.jpg" alt="" />
<p class="caption">An image adapted from the Katitas multiple imputation guide showing the four stages of multiple imputation.</p>
</div>
<ul>
<li>the dataframe with missing data is the single place we start</li>
<li>we intervene with a package like <em>mice()</em> to</li>
<li>impute multiple sets of data (filling in the missing variables with different values that are a product of their conditional distribution and an element of “random”);
<ul>
<li>“mids” (“multiply imputed dataset”) is an object class where the completed datasets are stored.</li>
</ul></li>
<li>the “with_mids” command allows OLS regression to be run, as many times as we have imputed datasets (in this figure, 3X). It produces different regression coefficients for each datset</li>
<li>the “pool” command pools together the multiple coefficients taking into consideration the value of the coefficients,the standard errors, and the variance of the missing value parameter across the samples.</li>
</ul>
</div>
<div id="statistical-approaches-to-multiple-imputation" class="section level3" number="5.4.2">
<h3 number="5.4.2"><span class="header-section-number">5.4.2</span> Statistical Approaches to Multiple Imputation</h3>
<p><strong>Joint multivariate normal distribution multiple imputation</strong> assumes that the observed data follow a multivariate normal distribution. The algorithm used draws from this assumed distribution. A drawback is that if the data do not follow a multivariate normal distribution, the imputed values are incorrect. <em>Amelia</em> and <em>norm</em> packages use this approach.</p>
<p><strong>Conditional multiple imputation</strong> is an iterative procedure, modeling the conditional distribution of a certain variable given the other variables. In this way the distribution is assumed for each variable, rather than or the entire dataset. <em>mice</em> uses this approach.</p>
<p><em>mice</em>: multivariate imputation by chained equations</p>
</div>
</div>
<div id="working-the-problem-2" class="section level2" number="5.5">
<h2 number="5.5"><span class="header-section-number">5.5</span> Working the Problem</h2>
<p>Katitas <span class="citation">(<a href="#ref-katitas_getting_2019" role="doc-biblioref">2019</a>)</span> claims that it is best to impute the data in its rawest form possible because any change would be taking it away from its original distribution. There are debates about how many variables to include in an imputation. Some authors would suggest that researchers include everything that was collected. Others (like me) will trim the dataset to include (a) the variables included in the model, plus (b) auxiliary variables (i.e., variables not in the model, but that are sufficiently non-missing and will provide additional information to the data).</p>
<p>In our case we will want:</p>
<p>Item for the variables represented in our model</p>
<ul>
<li>the item level responses to the scales/subscales
<ul>
<li>respondents’ sense of belonging to campus (3 items)</li>
<li>respondents’ rating of campus climate for Black students (6 items)</li>
</ul></li>
<li>proportion of BIPOC instructional staff</li>
<li>proportion of classmates who are Black</li>
</ul>
<p>Auxiliary variables – let’s choose four. One will be the format of the course. Three items will be from the course evaluation.</p>
<ul>
<li>format, whether the course was taught in-person, a blend, or virtual</li>
<li>cEval_1, “Course material was presented clearly”</li>
<li>cEval_13, “Where applicable, issues were considered from multiple perspectives”</li>
<li>cEval_19, “My understanding of the subject matter increased over the span of the course”</li>
</ul>
<div id="selecting-and-formatting-variables" class="section level3" number="5.5.1">
<h3 number="5.5.1"><span class="header-section-number">5.5.1</span> Selecting and Formatting Variables</h3>
<p>There are some guidelines for selecting and formatting variables for imputation.</p>
<ul>
<li>Variables should be in their <em>most natural</em> state</li>
<li>Redundant or too highly correlated variables should not be included
<ul>
<li>If you reverse coded a variable (we haven’t yet), that’s ok, but if you have already reverse-coded, then exclude the original variable</li>
<li>Redundant variables (or multicollinear variables) may cause the multiple imputation process to cease</li>
<li>Violation of this also provides clues for troubleshooting</li>
</ul></li>
<li>Exclude variables with more than 25% missing</li>
</ul>
<p>To make this as realistic as possible. Let’s start with our very raw data. The <a href="#scrub">Scrubbing chapter</a> provides greater detail on importing data directly from Qualtrics. Therefore, I will repeat our protocol that imports the data and then scrubs it for our purposes. As described in the prior chapter, I named variables in Qualtrics to facilitate a more intuitive use in R.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(qualtRics)</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a>QTRX_df2 <span class="ot">&lt;-</span> qualtRics<span class="sc">::</span><span class="fu">fetch_survey</span>(<span class="at">surveyID =</span> <span class="st">&quot;SV_b2cClqAlLGQ6nLU&quot;</span>,<span class="at">useLocalTime =</span> <span class="cn">TRUE</span>,</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a>                         <span class="at">verbose =</span> <span class="cn">FALSE</span>, <span class="at">label=</span><span class="cn">FALSE</span>, <span class="at">convert=</span><span class="cn">FALSE</span>, <span class="at">force_request =</span> <span class="cn">TRUE</span>, <span class="at">import_id =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p>Next, I apply inclusion/exclusion criteria. As described in the <a href="#scrub">Scrubbing chapter</a> this includes:</p>
<ul>
<li>excluding all <em>previews</em></li>
<li>including only those who consented</li>
<li>including only those whose rated course was offered by a U.S. institution</li>
</ul>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>QTRX_df2 <span class="ot">&lt;-</span> <span class="fu">filter</span> (QTRX_df2, DistributionChannel <span class="sc">!=</span> <span class="st">&quot;preview&quot;</span>)</span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>QTRX_df2 <span class="ot">&lt;-</span><span class="fu">filter</span> (QTRX_df2, Consent <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>QTRX_df2 <span class="ot">&lt;-</span><span class="fu">filter</span> (QTRX_df2, USinst <span class="sc">==</span> <span class="dv">0</span>)</span></code></pre></div>
<p>Preparing the data also meant renaming some variables that started with numbers (a hassle in R). I also renamed variables on the Campus Climate scale so that we know to which subscale they belong.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="co">#renaming variables that started with numbers</span></span>
<span id="cb128-3"><a href="#cb128-3" aria-hidden="true" tabindex="-1"></a>QTRX_df2 <span class="ot">&lt;-</span> <span class="fu">rename</span>(QTRX_df2, <span class="at">iRace1 =</span> <span class="st">&#39;1_iRace&#39;</span>, <span class="at">iRace2 =</span> <span class="st">&#39;2_iRace&#39;</span>, <span class="at">iRace3 =</span> <span class="st">&#39;3_iRace&#39;</span>, <span class="at">iRace4 =</span> <span class="st">&#39;4_iRace&#39;</span>, <span class="at">iRace5 =</span> <span class="st">&#39;5_iRace&#39;</span>, <span class="at">iRace6 =</span> <span class="st">&#39;6_iRace&#39;</span>, <span class="at">iRace7 =</span> <span class="st">&#39;7_iRace&#39;</span>, <span class="at">iRace8 =</span> <span class="st">&#39;8_iRace&#39;</span>, <span class="at">iRace9 =</span> <span class="st">&#39;9_iRace&#39;</span>, <span class="at">iRace10 =</span> <span class="st">&#39;10_iRace&#39;</span>)</span>
<span id="cb128-4"><a href="#cb128-4" aria-hidden="true" tabindex="-1"></a><span class="co">#renaming variables from the identification of classmates</span></span>
<span id="cb128-5"><a href="#cb128-5" aria-hidden="true" tabindex="-1"></a>QTRX_df2 <span class="ot">&lt;-</span> <span class="fu">rename</span>(QTRX_df2, <span class="at">cmBiMulti =</span> Race_10, <span class="at">cmBlack =</span> Race_1, <span class="at">cmNBPoC =</span> Race_7, <span class="at">cmWhite =</span> Race_8, <span class="at">cmUnsure =</span> Race_2)</span></code></pre></div>
<p>The Qualtrics download does not include an ID number. Because new variables are always appended to the end of the df, we also include code to make this the first column.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a>QTRX_df2 <span class="ot">&lt;-</span> QTRX_df2 <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">ID =</span> <span class="fu">row_number</span>())</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="co">#moving the ID number to the first column; requires </span></span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>QTRX_df2 <span class="ot">&lt;-</span> QTRX_df2<span class="sc">%&gt;%</span><span class="fu">select</span>(ID, <span class="fu">everything</span>())</span></code></pre></div>
<p>Because this huge df is cumbersome to work with, let’s downsize it to be closer to the size we will work with in the imputation</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>mimp_df <span class="ot">&lt;-</span>  <span class="fu">select</span> (QTRX_df2, ID, iRace1, iRace2, iRace3, iRace4, iRace5, iRace6, iRace7, iRace8, iRace9, iRace10, cmBiMulti, cmBlack, cmNBPoC, cmWhite, cmUnsure, Belong_1<span class="sc">:</span>Belong_3, Blst_1<span class="sc">:</span>Blst_6, cEval_1, cEval_13, cEval_19, format)</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="co">#glimpse(mimp_df)</span></span>
<span id="cb130-3"><a href="#cb130-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mimp_df)</span></code></pre></div>
<pre><code>## # A tibble: 6 x 29
##      ID iRace1 iRace2 iRace3 iRace4 iRace5 iRace6 iRace7 iRace8 iRace9 iRace10
##   &lt;int&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt;  &lt;lgl&gt;  
## 1     1      3      1      3     NA NA     NA     NA     NA     NA     NA     
## 2     2      3     NA     NA     NA NA     NA     NA     NA     NA     NA     
## 3     3      3      1     NA     NA NA     NA     NA     NA     NA     NA     
## 4     4      3      1      3     NA NA     NA     NA     NA     NA     NA     
## 5     5      1     NA     NA     NA NA     NA     NA     NA     NA     NA     
## 6     6      3     NA     NA     NA NA     NA     NA     NA     NA     NA     
## # ... with 18 more variables: cmBiMulti &lt;dbl&gt;, cmBlack &lt;dbl&gt;, cmNBPoC &lt;dbl&gt;,
## #   cmWhite &lt;dbl&gt;, cmUnsure &lt;dbl&gt;, Belong_1 &lt;dbl&gt;, Belong_2 &lt;dbl&gt;,
## #   Belong_3 &lt;dbl&gt;, Blst_1 &lt;dbl&gt;, Blst_2 &lt;dbl&gt;, Blst_3 &lt;dbl&gt;, Blst_4 &lt;dbl&gt;,
## #   Blst_5 &lt;dbl&gt;, Blst_6 &lt;dbl&gt;, cEval_1 &lt;dbl&gt;, cEval_13 &lt;dbl&gt;, cEval_19 &lt;dbl&gt;,
## #   format &lt;dbl&gt;</code></pre>
</div>
<div id="creating-composite-variables" class="section level3" number="5.5.2">
<h3 number="5.5.2"><span class="header-section-number">5.5.2</span> Creating Composite Variables</h3>
<p>Qualtrics imports many of the categorical variables as numbers. R often reads them numerically (integers or numbers). If they are directly converted to factors, R will sometimes collapse. In this example, if there is a race that is not represented (e.g., 2 for BiMulti), when the numbers are changed to factors, R will assume it’s ordered and will change up the numbers. Therefore, it is ESSENTIAL to check (again and again ad nauseum) to ensure that your variables are recoding in a manner you understand.</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace1 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace1,</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-3"><a href="#cb132-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-4"><a href="#cb132-4" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace2 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace2,</span>
<span id="cb132-5"><a href="#cb132-5" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-6"><a href="#cb132-6" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-7"><a href="#cb132-7" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace3 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace3,</span>
<span id="cb132-8"><a href="#cb132-8" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-9"><a href="#cb132-9" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-10"><a href="#cb132-10" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace4 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace4,</span>
<span id="cb132-11"><a href="#cb132-11" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-12"><a href="#cb132-12" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-13"><a href="#cb132-13" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace5 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace5,</span>
<span id="cb132-14"><a href="#cb132-14" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-15"><a href="#cb132-15" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-16"><a href="#cb132-16" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace6 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace6,</span>
<span id="cb132-17"><a href="#cb132-17" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-18"><a href="#cb132-18" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-19"><a href="#cb132-19" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace7 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace7,</span>
<span id="cb132-20"><a href="#cb132-20" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-21"><a href="#cb132-21" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-22"><a href="#cb132-22" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace8 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace8,</span>
<span id="cb132-23"><a href="#cb132-23" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-24"><a href="#cb132-24" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-25"><a href="#cb132-25" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace9 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace9,</span>
<span id="cb132-26"><a href="#cb132-26" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-27"><a href="#cb132-27" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span>
<span id="cb132-28"><a href="#cb132-28" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iRace10 <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>iRace10,</span>
<span id="cb132-29"><a href="#cb132-29" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>),</span>
<span id="cb132-30"><a href="#cb132-30" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>, <span class="st">&quot;White&quot;</span>, <span class="st">&quot;NotNotice&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(mimp_df)</span></code></pre></div>
<p>This is a quick recap of how we calculated the proportion of instructional staff who are BIPOC.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co">#creating a count of BIPOC faculty identified by each respondent</span></span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>count.BIPOC <span class="ot">&lt;-</span> <span class="fu">apply</span>(mimp_df[<span class="fu">c</span>(<span class="st">&quot;iRace1&quot;</span>, <span class="st">&quot;iRace2&quot;</span>, <span class="st">&quot;iRace3&quot;</span>, <span class="st">&quot;iRace4&quot;</span>, <span class="st">&quot;iRace5&quot;</span>, <span class="st">&quot;iRace6&quot;</span>, <span class="st">&quot;iRace7&quot;</span>, <span class="st">&quot;iRace8&quot;</span>, <span class="st">&quot;iRace9&quot;</span>, <span class="st">&quot;iRace10&quot;</span>)], <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="fu">sum</span>(x <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Black&quot;</span>, <span class="st">&quot;nBpoc&quot;</span>, <span class="st">&quot;BiMulti&quot;</span>)))</span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a><span class="co">#creating a count of all instructional  faculty identified by each respondent</span></span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>count.nMiss <span class="ot">&lt;-</span> <span class="fu">apply</span>(mimp_df[<span class="fu">c</span>(<span class="st">&quot;iRace1&quot;</span>, <span class="st">&quot;iRace2&quot;</span>, <span class="st">&quot;iRace3&quot;</span>, <span class="st">&quot;iRace4&quot;</span>, <span class="st">&quot;iRace5&quot;</span>, <span class="st">&quot;iRace6&quot;</span>, <span class="st">&quot;iRace7&quot;</span>, <span class="st">&quot;iRace8&quot;</span>, <span class="st">&quot;iRace9&quot;</span>, <span class="st">&quot;iRace10&quot;</span>)], <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="fu">sum</span>(<span class="sc">!</span><span class="fu">is.na</span>(x)))</span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a><span class="co">#calculating the proportion of BIPOC faculty with the counts above</span></span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>iBIPOC_pr <span class="ot">=</span> mimp_df<span class="sc">$</span>count.BIPOC<span class="sc">/</span>mimp_df<span class="sc">$</span>count.nMiss</span></code></pre></div>
<p>I have included another variable, <em>format</em> that we will use as auxiliary variable. As written, these are the following meanings:</p>
<ol style="list-style-type: decimal">
<li>In-person (all persons are attending in person)</li>
<li>In person (some students are attending remotely)</li>
<li>Blended: some sessions in person and some sessions online/virtual</li>
<li>Online or virtual</li>
<li>Other</li>
</ol>
<p>Let’s recoded it to have three categories:</p>
<ol start="0" style="list-style-type: decimal">
<li>100% in-person (1)</li>
<li>Some sort of blend/mix (2, 3)</li>
<li>100% online/virtual (4)
NA. Other (5)</li>
</ol>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co">#we can assign more than one value to the same factor by repeating the label</span></span>
<span id="cb135-2"><a href="#cb135-2" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>format <span class="ot">=</span> <span class="fu">factor</span>(mimp_df<span class="sc">$</span>format,</span>
<span id="cb135-3"><a href="#cb135-3" aria-hidden="true" tabindex="-1"></a>                        <span class="at">levels =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>),</span>
<span id="cb135-4"><a href="#cb135-4" aria-hidden="true" tabindex="-1"></a>                        <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;InPerson&quot;</span>, <span class="st">&quot;Blend&quot;</span>, <span class="st">&quot;Blend&quot;</span>, <span class="st">&quot;Online&quot;</span>, <span class="fu">is.na</span>(<span class="dv">5</span>)))</span></code></pre></div>
<p>Let’s trim the df again to just include the variables we need in the imputation.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="#cb136-1" aria-hidden="true" tabindex="-1"></a>mimp_df <span class="ot">&lt;-</span>  <span class="fu">select</span> (mimp_df, ID, iBIPOC_pr, cmBlack, Belong_1<span class="sc">:</span>Belong_3, Blst_1<span class="sc">:</span>Blst_6, cEval_1, cEval_13, cEval_19, format)</span></code></pre></div>
<p>Recall one of the guidelines was to remove variables with more than 25% missing. This code calculates the proportion missing from our variables and places them in rank order.</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>p_missing <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(mimp_df, <span class="cf">function</span>(x) <span class="fu">sum</span>(<span class="fu">is.na</span>(x))))<span class="sc">/</span><span class="fu">nrow</span>(mimp_df)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span>(p_missing[p_missing <span class="sc">&gt;</span> <span class="dv">0</span>], <span class="at">decreasing =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>##     Blst_1  iBIPOC_pr     Blst_4   Belong_1   Belong_3     Blst_2     Blst_3 
## 0.10526316 0.05263158 0.05263158 0.02631579 0.02631579 0.02631579 0.02631579 
##     Blst_5     Blst_6    cEval_1   cEval_19 
## 0.02631579 0.02631579 0.02631579 0.02631579</code></pre>
<p>Luckily, none of our variables have more than 25% missing (<em>or at least they didn’t when I wrote this; the open nature of the survey and how it sources this chapter could change this</em>). If we did have a variable with more than 25% missing, we would have to consider what to do about it.</p>
<p>Later we learn that we should eliminate case with greater than 50% missingness. Let’s write code for that, now.</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Calculating number and proportion of item-level missingness</span></span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="sc">$</span>nmiss <span class="ot">&lt;-</span> mimp_df<span class="sc">%&gt;%</span></span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(iBIPOC_pr<span class="sc">:</span>format) <span class="sc">%&gt;%</span> <span class="co">#the colon allows us to include all variables between the two listed (the variables need to be in order)</span></span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>    is.na <span class="sc">%&gt;%</span> </span>
<span id="cb139-5"><a href="#cb139-5" aria-hidden="true" tabindex="-1"></a>    rowSums</span>
<span id="cb139-6"><a href="#cb139-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-7"><a href="#cb139-7" aria-hidden="true" tabindex="-1"></a>mimp_df<span class="ot">&lt;-</span> mimp_df<span class="sc">%&gt;%</span></span>
<span id="cb139-8"><a href="#cb139-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prop_miss =</span> (nmiss<span class="sc">/</span><span class="dv">15</span>)<span class="sc">*</span><span class="dv">100</span>) <span class="co">#11 is the number of variables included in calculating the proportion</span></span>
<span id="cb139-9"><a href="#cb139-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb139-10"><a href="#cb139-10" aria-hidden="true" tabindex="-1"></a>mimp_df <span class="ot">&lt;-</span> <span class="fu">filter</span>(mimp_df, prop_miss <span class="sc">&lt;=</span> <span class="dv">50</span>)  <span class="co">#update df to have only those with at least 50% of complete data</span></span></code></pre></div>
<p>Once again, trim the df to include only the data to be included in the imputation</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>mimp_df <span class="ot">&lt;-</span>  <span class="fu">select</span> (mimp_df, ID, iBIPOC_pr, cmBlack, Belong_1<span class="sc">:</span>Belong_3, Blst_1<span class="sc">:</span>Blst_6, cEval_1, cEval_13, cEval_19, format)</span></code></pre></div>
</div>
<div id="the-multiple-imputation" class="section level3" number="5.5.3">
<h3 number="5.5.3"><span class="header-section-number">5.5.3</span> The Multiple Imputation</h3>
<p>Because multiple imputation is a <em>random</em> process, if we all want the same answers we need to set a <em>random seed.</em></p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210404</span>) <span class="co">#you can pick any number you want, today I&#39;m using today&#39;s datestamp</span></span></code></pre></div>
<p>The program we will use is <em>mice</em>. <em>mice</em> assumes that each variable has a distribution and it imputes missing variables according to that distribution.</p>
<p>This means we need to correctly specify each variable’s format/role. <em>mice</em> will automatically choose a distribution (think “format”) for each variable; we can override this by changing the methods’ characteristics.</p>
<p>The following code sets up the structure for the imputation. I’m not an expert at this – just following the Katitas example.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mice)</span>
<span id="cb142-2"><a href="#cb142-2" aria-hidden="true" tabindex="-1"></a><span class="co"># runs the mice code with 0 iterations</span></span>
<span id="cb142-3"><a href="#cb142-3" aria-hidden="true" tabindex="-1"></a>imp <span class="ot">&lt;-</span> <span class="fu">mice</span>(mimp_df, <span class="at">maxit =</span> <span class="dv">0</span>)</span>
<span id="cb142-4"><a href="#cb142-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract predictor Matrix and methods of imputation </span></span>
<span id="cb142-5"><a href="#cb142-5" aria-hidden="true" tabindex="-1"></a>predM <span class="ot">=</span> imp<span class="sc">$</span>predictorMatrix</span>
<span id="cb142-6"><a href="#cb142-6" aria-hidden="true" tabindex="-1"></a>meth <span class="ot">=</span> imp<span class="sc">$</span>method</span></code></pre></div>
<p>Here we code what format/role each variable should be.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="co">#These variables are left in the dataset, but setting them = 0 means they are not used as predictors.  </span></span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a><span class="co">#We want our ID to be retained in the df.  There&#39;s nothing missing from it, and we don&#39;t want it used as a predictor, so it will just hang out.</span></span>
<span id="cb143-3"><a href="#cb143-3" aria-hidden="true" tabindex="-1"></a>predM[, <span class="fu">c</span>(<span class="st">&quot;ID&quot;</span>)]<span class="ot">=</span><span class="dv">0</span></span>
<span id="cb143-4"><a href="#cb143-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-5"><a href="#cb143-5" aria-hidden="true" tabindex="-1"></a><span class="co">#If you like, view the first few rows of the predictor matrix</span></span>
<span id="cb143-6"><a href="#cb143-6" aria-hidden="true" tabindex="-1"></a><span class="co">#head(predM)</span></span>
<span id="cb143-7"><a href="#cb143-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-8"><a href="#cb143-8" aria-hidden="true" tabindex="-1"></a><span class="co">#We don&#39;t have any ordered categorical variables, but if we did we would follow this format</span></span>
<span id="cb143-9"><a href="#cb143-9" aria-hidden="true" tabindex="-1"></a><span class="co">#poly &lt;- c(&quot;Var1&quot;, &quot;Var2&quot;)</span></span>
<span id="cb143-10"><a href="#cb143-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-11"><a href="#cb143-11" aria-hidden="true" tabindex="-1"></a><span class="co">#We don&#39;t have any dichotomous variables, but if we did we would follow this format</span></span>
<span id="cb143-12"><a href="#cb143-12" aria-hidden="true" tabindex="-1"></a><span class="co">#log &lt;- c(&quot;Var3&quot;, &quot;Var4&quot;)</span></span>
<span id="cb143-13"><a href="#cb143-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-14"><a href="#cb143-14" aria-hidden="true" tabindex="-1"></a><span class="co">#Unordered categorical variables (nominal variables), but if we did we would follow this format</span></span>
<span id="cb143-15"><a href="#cb143-15" aria-hidden="true" tabindex="-1"></a>poly2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;format&quot;</span>)</span>
<span id="cb143-16"><a href="#cb143-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-17"><a href="#cb143-17" aria-hidden="true" tabindex="-1"></a><span class="co">#Turn their methods matrix into the specified imputation models</span></span>
<span id="cb143-18"><a href="#cb143-18" aria-hidden="true" tabindex="-1"></a><span class="co">#Remove the hashtag if you have any of these variables</span></span>
<span id="cb143-19"><a href="#cb143-19" aria-hidden="true" tabindex="-1"></a><span class="co">#meth[poly] = &quot;polr&quot; </span></span>
<span id="cb143-20"><a href="#cb143-20" aria-hidden="true" tabindex="-1"></a><span class="co">#meth[log] = &quot;logreg&quot;</span></span>
<span id="cb143-21"><a href="#cb143-21" aria-hidden="true" tabindex="-1"></a>meth[poly2] <span class="ot">=</span> <span class="st">&quot;polyreg&quot;</span></span>
<span id="cb143-22"><a href="#cb143-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb143-23"><a href="#cb143-23" aria-hidden="true" tabindex="-1"></a>meth</span></code></pre></div>
<pre><code>##        ID iBIPOC_pr   cmBlack  Belong_1  Belong_2  Belong_3    Blst_1    Blst_2 
##        &quot;&quot;     &quot;pmm&quot;        &quot;&quot;     &quot;pmm&quot;        &quot;&quot;     &quot;pmm&quot;     &quot;pmm&quot;     &quot;pmm&quot; 
##    Blst_3    Blst_4    Blst_5    Blst_6   cEval_1  cEval_13  cEval_19    format 
##     &quot;pmm&quot;     &quot;pmm&quot;     &quot;pmm&quot;     &quot;pmm&quot;     &quot;pmm&quot;        &quot;&quot;     &quot;pmm&quot; &quot;polyreg&quot;</code></pre>
<p>This list (meth) contains all our variables; “pmm” is the default and is the “predictive mean matching” process used. We see that format (an unordered categorical variable) is noted as “polyreg.” If we had used other categorical variables (ordered/poly, dichotomous/log), we would have seen those designations, instead. If there is "" underneath it means the data is complete.</p>
<p>Our variables of interest are now configured to be imputed with the imputation method we specified. Empty cells in the method matrix mean that those variables aren’t going to be imputed.</p>
<p>If a variable has no missing values, it is automatically set to be empty. We can also manually set variables to not be imputed with the <em>meth[variable]=""</em> command.</p>
<p>The code below begins the imputation process. We are asking for 5 datasets. If you have many cases and many variables, this can take awhile. How many imputations? Recommendations have ranged as low as five to several hundred.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="co"># With this command, we tell mice to impute the anesimpor2 data, create 5vvdatasets, use predM as the predictor matrix and don&#39;t print the imputation process. </span></span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a><span class="co">#If you would like to see the process (or if the process is failing to execute) set print as TRUE; seeing where the execution halts can point to problematic variables (more notes at end of lecture)</span></span>
<span id="cb145-3"><a href="#cb145-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb145-4"><a href="#cb145-4" aria-hidden="true" tabindex="-1"></a>imp2 <span class="ot">&lt;-</span> <span class="fu">mice</span>(mimp_df, <span class="at">maxit =</span> <span class="dv">5</span>, </span>
<span id="cb145-5"><a href="#cb145-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">predictorMatrix =</span> predM, </span>
<span id="cb145-6"><a href="#cb145-6" aria-hidden="true" tabindex="-1"></a>             <span class="at">method =</span> meth, <span class="at">print =</span>  <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## Warning: Number of logged events: 275</code></pre>
<p>We need to create a “long file” that stacks all the imputed data. Looking at the df in R Studio shows us that when imp = 0 (the pe-imputed data), there is still missingness. As we scroll through the remaining imputations, there are no NA cells.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="co"># First, turn the datasets into long format</span></span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a><span class="co"># This procedure is, best I can tell, unique to mice and wouldn&#39;t work for repeated measures designs</span></span>
<span id="cb147-3"><a href="#cb147-3" aria-hidden="true" tabindex="-1"></a>mimp_long <span class="ot">&lt;-</span> mice<span class="sc">::</span><span class="fu">complete</span>(imp2, <span class="at">action=</span><span class="st">&quot;long&quot;</span>, <span class="at">include =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>If we look at it, we can see 6 sets of data. Playing with it…</p>
<ul>
<li>.imp = 0 is the unimputed set; there are still missing values</li>
<li>.imp = 1, 2, 3, or 5 has no missing values for the variables we included in the imputation</li>
</ul>
<p>Sort on the ID number to see how this works…6 sets of data.</p>
<p>With this fully imputed file, let’s recode the data as we had done for the OLS regression with the raw, unimputed, data.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a>p_missing_mimp_long <span class="ot">&lt;-</span> <span class="fu">unlist</span>(<span class="fu">lapply</span>(mimp_long, <span class="cf">function</span>(x) <span class="fu">sum</span>(<span class="fu">is.na</span>(x))))<span class="sc">/</span><span class="fu">nrow</span>(mimp_long)</span>
<span id="cb148-2"><a href="#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span>(p_missing_mimp_long[p_missing_mimp_long <span class="sc">&gt;</span> <span class="dv">0</span>], <span class="at">decreasing =</span> <span class="cn">TRUE</span>)<span class="co">#check to see if this works</span></span></code></pre></div>
</div>
<div id="creating-scale-scores" class="section level3" number="5.5.4">
<h3 number="5.5.4"><span class="header-section-number">5.5.4</span> Creating Scale Scores</h3>
<p>Because our imputation was item-level, we need to score the variables with scales/subscales. As demonstrated more completely in the <a href="#score">Scoring chapter</a>, this required reversing one item in the campus climate scale:</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>mimp_long<span class="ot">&lt;-</span> mimp_long <span class="sc">%&gt;%</span></span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rBlst_1 =</span> <span class="dv">8</span> <span class="sc">-</span> Blst_1) <span class="co">#if you had multiple items, you could add a pipe (%&gt;%) at the end of the line and add more until the last one</span></span></code></pre></div>
<p>Below is the scoring protocol we used in the AIA protocol for scoring. Although the protocol below functionally says, "Create a mean score if (65-80)% is non-missing, for the imputed version, it doesn’t harm anything to leave this because there is no missing data.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(sjstats)</span>
<span id="cb150-2"><a href="#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Making the list of variables</span></span>
<span id="cb150-3"><a href="#cb150-3" aria-hidden="true" tabindex="-1"></a>Belonging_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;Belong_1&#39;</span>,<span class="st">&#39;Belong_2&#39;</span>,<span class="st">&#39;Belong_3&#39;</span>)</span>
<span id="cb150-4"><a href="#cb150-4" aria-hidden="true" tabindex="-1"></a>ResponseBL_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;rBlst_1&#39;</span>, <span class="st">&#39;Blst_4&#39;</span>,<span class="st">&#39;Blst_6&#39;</span>)</span>
<span id="cb150-5"><a href="#cb150-5" aria-hidden="true" tabindex="-1"></a>StigmaBL_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;Blst_2&#39;</span>, <span class="st">&#39;Blst_3&#39;</span>,<span class="st">&#39;Blst_5&#39;</span>)</span>
<span id="cb150-6"><a href="#cb150-6" aria-hidden="true" tabindex="-1"></a>ClimateBL_vars <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&#39;rBlst_1&#39;</span>, <span class="st">&#39;Blst_4&#39;</span>,<span class="st">&#39;Blst_6&#39;</span>,<span class="st">&#39;Blst_2&#39;</span>, <span class="st">&#39;Blst_3&#39;</span>,<span class="st">&#39;Blst_5&#39;</span> )</span>
<span id="cb150-7"><a href="#cb150-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-8"><a href="#cb150-8" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating the new variables</span></span>
<span id="cb150-9"><a href="#cb150-9" aria-hidden="true" tabindex="-1"></a>mimp_long<span class="sc">$</span>Belonging <span class="ot">&lt;-</span> <span class="fu">mean_n</span>(mimp_long[,Belonging_vars], .<span class="dv">65</span>)</span>
<span id="cb150-10"><a href="#cb150-10" aria-hidden="true" tabindex="-1"></a>mimp_long<span class="sc">$</span>ResponseBL <span class="ot">&lt;-</span> <span class="fu">mean_n</span>(mimp_long[,ResponseBL_vars], .<span class="dv">80</span>)</span>
<span id="cb150-11"><a href="#cb150-11" aria-hidden="true" tabindex="-1"></a>mimp_long<span class="sc">$</span>StigmaBL <span class="ot">&lt;-</span> <span class="fu">mean_n</span>(mimp_long[,StigmaBL_vars], .<span class="dv">80</span>)</span>
<span id="cb150-12"><a href="#cb150-12" aria-hidden="true" tabindex="-1"></a>mimp_long<span class="sc">$</span>ClimateBL <span class="ot">&lt;-</span> <span class="fu">mean_n</span>(mimp_long[,ClimateBL_vars], .<span class="dv">80</span>)</span></code></pre></div>
</div>
</div>
<div id="multiple-regression-with-multiply-imputed-data" class="section level2" number="5.6">
<h2 number="5.6"><span class="header-section-number">5.6</span> Multiple Regression with Multiply Imputed Data</h2>
<p>For a refresher, here was the script when we used the AIA approach for managing missingness:</p>
<pre><code>Climate_fit &lt;- lm(ClimateBL ~ Belonging + cmBlack + iBIPOC_pr, data = item_scores_df)
summary(Climate_fit)</code></pre>
<p>In order for the regression to use multiply imputed data, it must be a “mids” (multiply imputed data sets) type</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert to mids type - mice can work with this type</span></span>
<span id="cb152-2"><a href="#cb152-2" aria-hidden="true" tabindex="-1"></a>mimp_mids<span class="ot">&lt;-</span><span class="fu">as.mids</span>(mimp_long)</span></code></pre></div>
<p>Here’s what we do with imputed data:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>fitimp <span class="ot">&lt;-</span> <span class="fu">with</span>(mimp_mids,</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a>               <span class="fu">lm</span>(ClimateBL <span class="sc">~</span> Belonging <span class="sc">+</span> cmBlack <span class="sc">+</span> iBIPOC_pr))</span></code></pre></div>
<p>In this process, 5 individual, OLS, regressions are being conducted and the results being pooled into this single set.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to get the 5, individual imputations</span></span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fitimp)</span></code></pre></div>
<pre><code>## # A tibble: 20 x 6
##    term         estimate std.error statistic   p.value  nobs
##    &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;
##  1 (Intercept)  2.58        0.577    4.48    0.0000805    38
##  2 Belonging   -0.000893    0.118   -0.00757 0.994        38
##  3 cmBlack     -0.0172      0.0212  -0.808   0.425        38
##  4 iBIPOC_pr   -0.240       0.435   -0.553   0.584        38
##  5 (Intercept)  2.60        0.572    4.54    0.0000669    38
##  6 Belonging   -0.00414     0.118   -0.0349  0.972        38
##  7 cmBlack     -0.0172      0.0213  -0.808   0.425        38
##  8 iBIPOC_pr   -0.254       0.431   -0.590   0.559        38
##  9 (Intercept)  2.60        0.543    4.78    0.0000330    38
## 10 Belonging    0.0202      0.116    0.175   0.862        38
## 11 cmBlack     -0.0189      0.0204  -0.926   0.361        38
## 12 iBIPOC_pr   -0.505       0.436   -1.16    0.256        38
## 13 (Intercept)  2.60        0.544    4.77    0.0000338    38
## 14 Belonging   -0.0103      0.112   -0.0922  0.927        38
## 15 cmBlack     -0.0180      0.0207  -0.867   0.392        38
## 16 iBIPOC_pr   -0.233       0.418   -0.556   0.582        38
## 17 (Intercept)  2.52        0.578    4.36    0.000113     38
## 18 Belonging    0.0163      0.120    0.136   0.893        38
## 19 cmBlack     -0.0190      0.0214  -0.884   0.383        38
## 20 iBIPOC_pr   -0.201       0.434   -0.463   0.646        38</code></pre>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the pooled result</span></span>
<span id="cb156-2"><a href="#cb156-2" aria-hidden="true" tabindex="-1"></a>pooledests <span class="ot">&lt;-</span> <span class="fu">pool</span>(fitimp)</span>
<span id="cb156-3"><a href="#cb156-3" aria-hidden="true" tabindex="-1"></a>pooledests</span></code></pre></div>
<pre><code>## Class: mipo    m = 5 
##          term m     estimate         ubar            b            t dfcom
## 1 (Intercept) 5  2.578918801 0.3168579493 1.069500e-03 0.3181413496    34
## 2   Belonging 5  0.004230366 0.0136383176 1.774196e-04 0.0138512211    34
## 3     cmBlack 5 -0.018047803 0.0004426305 7.621488e-07 0.0004435451    34
## 4   iBIPOC_pr 5 -0.286610867 0.1857887593 1.524495e-02 0.2040827000    34
##         df         riv      lambda        fmi
## 1 32.02824 0.004050396 0.004034057 0.06090051
## 2 31.60868 0.015610688 0.015370740 0.07227145
## 3 32.09475 0.002066235 0.002061974 0.05893305
## 4 27.65271 0.098466348 0.089639841 0.14903819</code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="co">#str(pooledests)</span></span></code></pre></div>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>sumpooled <span class="ot">&lt;-</span> <span class="fu">summary</span>(<span class="fu">pool</span>(fitimp))</span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>sumpooled</span></code></pre></div>
<pre><code>##          term     estimate  std.error   statistic       df      p.value
## 1 (Intercept)  2.578918801 0.56404020  4.57222516 32.02824 6.846407e-05
## 2   Belonging  0.004230366 0.11769121  0.03594462 31.60868 9.715526e-01
## 3     cmBlack -0.018047803 0.02106051 -0.85694994 32.09475 3.978263e-01
## 4   iBIPOC_pr -0.286610867 0.45175513 -0.63443854 27.65271 5.310089e-01</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="co">#str(sumpooled)</span></span></code></pre></div>
<p>Results of a multiple regression predicting the respondents’ perceptions of campus climate for Black students indicated that neither contributions of the respondents’ personal belonging (<span class="math inline">\(B\)</span> = 0.004, <span class="math inline">\(p\)</span> = 0.972) nor the proportion of BIPOC instructional staff (<span class="math inline">\(B\)</span> = -0.287, <span class="math inline">\(p\)</span> = 0.531) led to statistically significant changes in perceptions of campus climate for Black students. Results did suggest a statistically significant negative effect of the proportion of Black classmates on the campus climate for Black students. Specifically, as the proportion of Black students increases, there is less stigmatization and hostility on the campus (<span class="math inline">\(B\)</span> = -0.018, <span class="math inline">\(p\)</span> = 0.398). Results are presented in Table X.</p>
</div>
<div id="toward-the-apa-style-write-up-1" class="section level2" number="5.7">
<h2 number="5.7"><span class="header-section-number">5.7</span> Toward the APA Style Write-up</h2>
<div id="methoddata-diagnostics" class="section level3" number="5.7.1">
<h3 number="5.7.1"><span class="header-section-number">5.7.1</span> Method/Data Diagnostics</h3>
<p>Data screening suggested that 52 individuals opened the survey link. Of those, 44 granted consent and proceeded to the survey items. A further inclusion criteria was that the course was taught in the U.S; 38 met this criteria. Across cases that were deemed eligible on the basis of the inclusion/exclusion criteria, missingness ranged from 0% to 36%. Across the dataset, 3.35% of cells had missing data and 84.21% of cases had nonmissing data. At this stage in the analysis, we allowed all cases with fewer than 50% missing to be included the multiple imputation <span class="citation">(<a href="#ref-katitas_getting_2019" role="doc-biblioref">Katitas, 2019</a>)</span>.</p>
<p>Regarding the distributional characteristics of the data, skew and kurtosis values of the variables fell below the values of 3 (skew) and 8 to 20 (kurtosis) that Kline suggests are concerning <span class="citation">(<a href="#ref-kline_principles_2016" role="doc-biblioref">2016</a>)</span>. Results of the Shapiro-Wilk test of normality indicate that our variables assessing the proportion of classmates who are Black (<span class="math inline">\(W\)</span> = 0.806, <span class="math inline">\(p\)</span> = 0.0000) and the proportion of BIPOC instructional staff(<span class="math inline">\(W\)</span> = 0.823, <span class="math inline">\(p\)</span> = 0.0000) are statistically significantly different than a normal distribution. The scales assessing the respondent’s belonging (<span class="math inline">\(W\)</span> = 0.976, <span class="math inline">\(p\)</span> = 0.5767) and the respondent’s perception of campus climate for Black students (<span class="math inline">\(W\)</span> = 0.934, <span class="math inline">\(p\)</span> = 0.0376) did not differ differently from a normal distribution.</p>
<p>We evaluated multivariate normality with the Mahalanobis distance test. Specifically, we used the <em>outlier()</em> function in the <em>psych</em> package and included all continuous variables in the calculation. Our visual inspection of the Q-Q plot suggested that the plotted line strayed from the straight line as the quantiles increased. Additionally, we appended the Mahalanobis distance scores as a variable to the data. Analyzing this variable, we found that 0 exceed three standard deviations beyond the median. <em>Thus, with no outliers, we assumed multivariate normality and proceeded with the data analysis</em> AS DATA IS ADDED THIS NUMBER OF OUTLIERS COULD UPDATE FROM ZERO AND THIS TEXT COULD CHANGE.*</p>
<p>We managed missing data with multiple imputation <span class="citation">(<a href="#ref-enders_multiple_2017" role="doc-biblioref">Enders, 2017</a>; <a href="#ref-katitas_getting_2019" role="doc-biblioref">Katitas, 2019</a>)</span>. We imputed five sets of data with the R package, <em>mice</em> (v. 3.13) – a program that utilizes conditional multiple imputation. The imputation included the item-level variables that comprised our scales, the variables that represented proportion of BIPOC instructional staff and proportion of Black classmates, as well as four auxiliary variables (three variables from the course evaluation and the format [in-person/blended/virtual] of the class).</p>
</div>
<div id="results-1" class="section level3" number="5.7.2">
<h3 number="5.7.2"><span class="header-section-number">5.7.2</span> Results</h3>
<p>Results of a multiple regression predicting the respondents’ perceptions of campus climate for Black students indicated that neither contributions of the respondents’ personal belonging (<span class="math inline">\(B\)</span> = 0.050, <span class="math inline">\(p\)</span> = 0.684) nor the proportion of BIPOC instructional staff (<span class="math inline">\(B\)</span> = -0.456, <span class="math inline">\(p\)</span> = 0.312) led to statistically significant changes in perceptions of campus climate for Black students. Results did suggest a statistically significant negative effect of the proportion of Black classmates on the campus climate for Black students. Specifically, as the proportion of Black students increases, there is less stigmatization and hostility on the campus (<span class="math inline">\(B\)</span> = -0.015, <span class="math inline">\(p\)</span> = 0.457). Although it accounted for 5.28% of the variance, the overall model was not statistically significant. Results are presented in Table 2.</p>
<p><strong>Some notes about this write-up</strong></p>
<ul>
<li>I went ahead and used the data diagnostics that we did in the AIA method. It feels to me like these should be calculated with the multiply imputed data (i.e., 5 sets, with pooled estimates and standard errors), but I do not see that modeled – anywhere in R.</li>
<li>Note the similarities with the AIA write-up.</li>
</ul>
</div>
</div>
<div id="multiple-imputation-considerations" class="section level2" number="5.8">
<h2 number="5.8"><span class="header-section-number">5.8</span> Multiple imputation considerations</h2>
<ul>
<li>Character vectors (i.e., values that are represented with words) can be problematic. If they are causing trouble, consider
<ul>
<li>recode into factors,</li>
<li>keep it in the df, but exclude it from the imputation protocol,</li>
<li>our “format” variable was an ordered factor (i.e., each term was associated with a value), so I think that helped us avoid problems</li>
</ul></li>
<li>Variables with really high (like 50% or more) proportions of missingness should be excluded.</li>
<li>Variables that are highly correlated or redundant (even if inverse) will halt the execution. If you set print=TRUE you will see where the algorithm is having difficulty because it will halt at that variable.</li>
<li>Variables with non-missing values can be problematic. If they are problematic, just exclude them from the process.
*Width (columns/variables) versus length (rows/cases). You must have more rows/cases than columns/variables. It is difficult to say how many. If this is a problem:
<ul>
<li>Consider scoring scales first with AIA, then impute with whole scales.</li>
<li>Divide the df in halves or thirds, impute separately, then join with the ID numbers.</li>
<li>There should be auxiliary variables in each.
*Item-level imputation is its “whole big thing” with multiple, complex considerations. There are tremendous resources</li>
<li>Enders <a href="http://www.appliedmissingdata.com/multilevel-imputation.html">BLIMP</a> app is free and works with R</li>
<li>Little’s <span class="citation">(<a href="#ref-little_statistical_2002" role="doc-biblioref">2002</a>)</span> article</li>
</ul></li>
<li>How many imputations? Controversial and has changed over the years.
<ul>
<li>Practical concern: the more you request, the longer it will take in R, this demo was 5</li>
<li>For a number of years there was a push for 20, but I’ve also seen recommendations for 100s.</li>
<li>Check examples of imputed studies in your disciplinary specialty/journals.</li>
</ul></li>
<li>There are lots of discussions and debates about
<ul>
<li>allowing for fractional/decimal responses (a 3.5 on 1 to 4 scaling; or a 0.75 on a dichotomous variable such as male/female)</li>
<li>out-of-bounds estimates (what if you get a 7 on 1 to 4 scaling?)</li>
</ul></li>
</ul>
</div>
<div id="practice-problems-3" class="section level2" number="5.9">
<h2 number="5.9"><span class="header-section-number">5.9</span> Practice Problems</h2>
<p>The three problems described below are designed to be continuations from the previous chapters. You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.</p>
<div id="problem-1-reworking-the-chapter-problem-2" class="section level3" number="5.9.1">
<h3 number="5.9.1"><span class="header-section-number">5.9.1</span> Problem #1: Reworking the Chapter Problem</h3>
<p>If you chose this option in the prior chapters, you imported the data from Qualtrics, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.</p>
<p>Continue working with this data to:</p>
<table style="width:100%;">
<colgroup>
<col width="72%" />
<col width="14%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Import the raw data from Qualtrics</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Apply inclusionary/exclusionary criteria</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Format any variables that shouldn’t be imputed in their raw form</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Multiply impute a minimum of 5 sets of data</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Run a regression with at least three variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. APA style write-up of the multiple imputation section of data diagnostics</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. APA style write-up regression results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-2-use-the-rate-a-recent-course-survey-choosing-different-variables-3" class="section level3" number="5.9.2">
<h3 number="5.9.2"><span class="header-section-number">5.9.2</span> Problem #2: Use the <em>Rate-a-Recent-Course</em> Survey, Choosing Different Variables</h3>
<p>If you chose this option in the prior chapter, you chose a minimum of three variables from the <em>Rate-a-Recent-Course</em> survey to include in a simple statistical model. You imported the data from Qualtrics, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.</p>
<p>Continue working with this data to:</p>
<table style="width:100%;">
<colgroup>
<col width="72%" />
<col width="14%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Import the raw data from Qualtrics</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Apply inclusionary/exclusionary criteria</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Format any variables that shouldn’t be imputed in their raw form</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Multiply impute a minimum of 5 sets of data</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Run a regression with at least three variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. APA style write-up of the multiple imputation section of data diagnostics</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. APA style write-up regression results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-3-other-data-3" class="section level3" number="5.9.3">
<h3 number="5.9.3"><span class="header-section-number">5.9.3</span> Problem #3: Other data</h3>
<p>If you chose this option in the prior chapter, you used raw data that was available to you. You imported it into R, applied inclusion/exclusion criteria, renamed variables, downsized the df to the variables of interest, properly formatted the variables, interpreted item-level missingness, scored the scales/subscales, interpreted scale-level missingness, and wrote up the results.</p>
<p>Continue working with this data to:</p>
<table style="width:100%;">
<colgroup>
<col width="72%" />
<col width="14%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center">Points Possible</th>
<th align="center">Points Earned</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Import the raw data from Qualtrics (or elsewhere)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Apply inclusionary/exclusionary criteria</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Format any variables that shouldn’t be imputed in their raw form</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Multiply impute a minimum of 5 sets of data</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Run a regression with at least three variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. APA style write-up of the multiple imputation section of data diagnostics</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. APA style write-up regression results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left"><strong>Totals</strong></td>
<td align="center">40</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] apaTables_2.0.8   mice_3.13.0       sjstats_0.18.1    formattable_0.2.1
##  [5] qualtRics_3.1.4   forcats_0.5.1     stringr_1.4.0     dplyr_1.0.5      
##  [9] purrr_0.3.4       readr_1.4.0       tidyr_1.1.3       tibble_3.1.1     
## [13] ggplot2_3.3.3     tidyverse_1.3.1   psych_2.1.3      
## 
## loaded via a namespace (and not attached):
##  [1] nlme_3.1-151       fs_1.5.0           lubridate_1.7.10   MBESS_4.8.0       
##  [5] insight_0.13.2     httr_1.4.2         tools_4.0.4        backports_1.2.1   
##  [9] bslib_0.2.4        utf8_1.2.1         R6_2.5.0           sjlabelled_1.1.7  
## [13] DBI_1.1.1          colorspace_2.0-0   withr_2.4.2        tidyselect_1.1.1  
## [17] mnormt_2.0.2       emmeans_1.6.0      curl_4.3.1         compiler_4.0.4    
## [21] performance_0.7.1  cli_2.5.0          rvest_1.0.0        xml2_1.3.2        
## [25] sandwich_3.0-0     bookdown_0.22      bayestestR_0.9.0   sass_0.3.1        
## [29] scales_1.1.1       mvtnorm_1.1-1      systemfonts_1.0.1  digest_0.6.27     
## [33] minqa_1.2.4        svglite_2.0.0      rmarkdown_2.7      pkgconfig_2.0.3   
## [37] htmltools_0.5.1.1  lme4_1.1-26        highr_0.9          dbplyr_2.1.1      
## [41] htmlwidgets_1.5.3  rlang_0.4.11       readxl_1.3.1       rstudioapi_0.13   
## [45] jquerylib_0.1.4    generics_0.1.0     zoo_1.8-9          jsonlite_1.7.2    
## [49] magrittr_2.0.1     parameters_0.13.0  Matrix_1.2-18      Rcpp_1.0.6        
## [53] munsell_0.5.0      fansi_0.4.2        lifecycle_1.0.0    stringi_1.5.3     
## [57] multcomp_1.4-17    yaml_2.2.1         MASS_7.3-53.1      grid_4.0.4        
## [61] parallel_4.0.4     sjmisc_2.8.6       crayon_1.4.1       lattice_0.20-41   
## [65] haven_2.4.1        splines_4.0.4      hms_1.0.0          tmvnsim_1.0-2     
## [69] knitr_1.33         pillar_1.6.0       boot_1.3-27        estimability_1.3  
## [73] effectsize_0.4.4-1 codetools_0.2-18   reprex_2.0.0       glue_1.4.2        
## [77] evaluate_0.14      modelr_0.1.8       nloptr_1.2.2.2     vctrs_0.3.7       
## [81] cellranger_1.1.0   gtable_0.3.0       assertthat_0.2.1   xfun_0.22         
## [85] xtable_1.8-4       broom_0.7.6        coda_0.19-4        survival_3.2-11   
## [89] statmod_1.4.35     TH.data_1.0-10     ellipsis_0.3.1</code></pre>
<!--chapter:end:05-MultipleImputation.Rmd-->
</div>
</div>
</div>
<div id="CPA" class="section level1 unnumbered">
<h1 class="unnumbered">CONDITIONAL PROCESS ANALYSIS</h1>
</div>
<div id="SimpleMed" class="section level1" number="6">
<h1 number="6"><span class="header-section-number">6</span> Simple Mediation</h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=7ffb03e6-b34b-4e0b-8f10-ad080180b069">Screencasted Lecture Link</a></p>
<p>The focus of this lecture is to estimate indirect effects (aka “mediation”). We examine the logic/design required to support the argument that <em>mediation</em> is the <em>mechanism</em> that explains the X –&gt; Y relationship. We also work three examples (one with covariates).</p>
<p>At the outset, please note that although I rely heavily on Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> text and materials, I am using the R package <em>lavaan</em> in these chapters. Very recently, Hayes has introduced a <a href="https://www.processmacro.org/index.html">PROCESS macro for R</a>. Because I am not yet up-to-speed on using this macro (it is not a typical R package) and because we will use <em>lavaan</em> for confirmatory factor analysis and structural equation modeling, I have chosen to utilize the <em>lavaan</em> package. A substantial difference is that the PROCESS macros use ordinary least squares and <em>lavaan</em> uses maximum likelihood estimators.</p>
<div id="navigating-this-lesson-4" class="section level2" number="6.1">
<h2 number="6.1"><span class="header-section-number">6.1</span> Navigating this Lesson</h2>
<p>There is about 1 hour and 10 minutes of lecture. If you work through the materials with me it would be plan for an additional 1.5 hours.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, ocasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_MultivariateModeling">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="#ReCintro">introduction</a></p>
<div id="learning-objectives-4" class="section level3" number="6.1.1">
<h3 number="6.1.1"><span class="header-section-number">6.1.1</span> Learning Objectives</h3>
<p>Learning objectives from this lecture include the following:</p>
<ul>
<li>Define mediation and indirect effect.</li>
<li>Distinguish the role of a mediating variable from independent variables, covariates, and moderators.</li>
<li>Identify the conditions upon which there can be justification to support the presence of a mediated effect.</li>
<li>Articulate the arguments for and against using the term, “mediation.”</li>
<li>Using the R package <em>lavaan</em>,
<ul>
<li>specify a model with indirect effects,</li>
<li>identify and interpret B weights, <em>p</em> values, and <em>CIs</em> for total, direct, and indirect effects,</li>
<li>calculate the total effects of X and M on Y,</li>
<li>identify the proportion of variance accounted for in predicting M and Y.</li>
</ul></li>
<li>Hand calculate the values of an indirect, direct, and total effects from statistical output or a figure (just the <span class="math inline">\(B\)</span> or <span class="math inline">\(\beta\)</span>, not the significance level)</li>
</ul>
</div>
<div id="planning-for-practice-4" class="section level3" number="6.1.2">
<h3 number="6.1.2"><span class="header-section-number">6.1.2</span> Planning for Practice</h3>
<p>The following suggestions for practice will involve specifying, testing, and interpreting a model with a single indirect effect (mediator).</p>
<ul>
<li>Rework the problem in the chapter by changing the random seed in the code that simulates the data. This should provide minor changes to the data, but the results will likely be very similar.</li>
<li>There are a number of variables in the dataset and there were a handful of simple mediations conducted in the journal article that sources the research vignette. Swap out one or more variables in the model of simple mediation and compare your solution to the one in the chapter and/or the research article.</li>
<li>Conduct a simple mediation with data to which you have access. This could include data you simulate on your own or from a published article.</li>
</ul>
</div>
<div id="readings-resources-4" class="section level3" number="6.1.3">
<h3 number="6.1.3"><span class="header-section-number">6.1.3</span> Readings &amp; Resources</h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<ul>
<li>Hayes, A. F. (2018). <em>Introduction to mediation, moderation, and conditional process anlaysis: A regression-based approach</em>. New York, NY: Guilford Press. Available as an ebook from the SPU library: <a href="https://ebookcentral-proquest-com.ezproxy.spu.edu/lib/spu/detail.action?docID=5109647" class="uri">https://ebookcentral-proquest-com.ezproxy.spu.edu/lib/spu/detail.action?docID=5109647</a>
<ul>
<li><strong>Chapter 3, Simple mediation</strong>: Hayes’ text is another great example of a teaching tool that is accessible at both procedural and conceptual levels. I especially appreciate his attention to the controversies (even those directed toward his work). We deviate from his text in that we are not using the PROCESS macro…and I’ll address those concerns in the lecture.</li>
<li><strong>Chapter 4, Causality and confounds</strong>: A great chapter that addresses “What happened to Baron &amp; Kenny”; partial v complete mediation; and conditions required for claims of causality. Procedurally, our focus in this chapter is on the role of covariates.</li>
<li><strong>Appendix A: Using Process</strong>: An essential tool for PROCESS users because, even when we are in the R environment, this is the “idea book.” That is, the place where all the path models are presented in figures.</li>
</ul></li>
<li>Kim, P. Y., Kendall, D. L., &amp; Cheon, H.-S. (2017). Racial microaggressions, cultural mistrust, and mental health outcomes among Asian American college students. <em>American Journal of Orthopsychiatry, 87</em>(6), 663–670. <a href="https://doi-org.ezproxy.spu.edu/10.1037/ort0000203" class="uri">https://doi-org.ezproxy.spu.edu/10.1037/ort0000203</a></li>
</ul>
</div>
<div id="packages-5" class="section level3" number="6.1.4">
<h3 number="6.1.4"><span class="header-section-number">6.1.4</span> Packages</h3>
<p>The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<!-- TODO: Build out this section. -->
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="co">#will install the package if not already installed</span></span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(lavaan)){<span class="fu">install.packages</span>(<span class="st">&quot;lavaan&quot;</span>)}</span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(semPlot)){<span class="fu">install.packages</span>(<span class="st">&quot;semPlot&quot;</span>)}</span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(tidyverse)){<span class="fu">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>)}</span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(psych)){<span class="fu">install.packages</span>(<span class="st">&quot;psych&quot;</span>)}</span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(formattable)){<span class="fu">install.packages</span>(<span class="st">&quot;formattable&quot;</span>)}</span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(semTable)){<span class="fu">install.packages</span>(<span class="st">&quot;semTable&quot;</span>)}</span></code></pre></div>
</div>
</div>
<div id="estimating-indirect-effects-the-analytic-approach-often-termed-mediation" class="section level2" number="6.2">
<h2 number="6.2"><span class="header-section-number">6.2</span> Estimating Indirect Effects (the analytic approach often termed <em>mediation</em>)</h2>
<div id="the-definitional-and-conceptual" class="section level3" number="6.2.1">
<h3 number="6.2.1"><span class="header-section-number">6.2.1</span> The definitional and conceptual</h3>
<p>As in Hayes text <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span>, we will differentiate between <em>moderation</em> and <em>mediation</em>. <em>Conditional process analysis</em> involves both! With each of these, we are seeking to understand the <em>mechanism</em> at work that leads to the relationship (be it correlational, predictive, or causal)</p>
<p>Even though this process has sometimes been termed <em>causal modeling</em>, Hayes argues that his <em>statistical approach</em> is not claiming to determine <em>cause</em>; that is really left to the argument of the research design.</p>
<p><strong>Moderation</strong> (a review):</p>
<ul>
<li>Answers questions of <em>when</em> or <em>for whom</em> and is often the source of the answer, <em>it depends</em>.</li>
<li>Think of our <em>interaction</em> effects in ANOVA and regression</li>
<li>The effect of X on some variable Y is moderated by W if its size, sign, or strength depends on, or can be predicted, by W. Then we can say, “W is a <em>moderator</em> of X’s effect on Y” or “W and X <em>interact</em> in their influence on Y.”</li>
<li>The image below illustrates moderation with <em>conceptual</em> and <em>statistical</em> diagrams. Note that three predictors (IV, DV, their interaction) point to the DV.</li>
</ul>
<div class="figure">
<img src="images/SimpleMed/ModConcStat.jpg" alt="" />
<p class="caption">Image of Hayes’style conceptual and statistical diagrams of a simple moderation</p>
</div>
<p>The classic plot of moderation results is often the best way to detect that an interaction was included in the analysis and helps understand the <em>conditional</em> (e.g., for whom, under what conditions) nature of the analysis.</p>
<div class="figure">
<img src="images/SimpleMed/SimpleInteraction.jpg" alt="" />
<p class="caption">Image of classic interaction graph that illustrates a moderated effect. The IV is on the X axis, DV on the Y axis, and two intersecting lines represent the differential/moderated effect of the IV on the DV by the moderator</p>
</div>
<p><strong>Mediation</strong>:</p>
<ul>
<li>Answers questions of <em>how</em> (I also think <em>through</em> and <em>via</em> to describe the proposed mediating mechanism)</li>
<li>Paths in a mediation model are <em>direct</em> (X does not pass through M on its way to Y) and <em>indirect</em> (X passes through M on its way to Y). Once we get into the statistics, we will also be focused on <em>total</em> effects.</li>
<li>Hayes thinks in terms of <em>antecedent</em> and <em>consequent</em> variables. In a 3-variable, simple mediation, X and M are the antecedent variables; X and M are the consequent variables.<br />
</li>
<li>There is substantial debate and controversy about whether we can say “the effect of X on Y is <em>mediated</em> through M” or whether we should say, “There is a statistically significant indirect effect of X on Y thru M.” Hayes comes down on the “use mediation language” side of the debate.<br />
</li>
<li>In sum, a simple mediation model is any causal system in which at least one causal antecedent X variable is proposed as influencing an outcome Y through a single intervening variable, M. In such a model there are two pathways by which X can influence Y.</li>
<li>The figure below doubles as both the conceptual and statistical diagram of evaluating a simple mediation – a simple indirect effect.</li>
</ul>
<div class="figure">
<img src="images/SimpleMed/SimpleMed.jpg" alt="" />
<p class="caption">Image of Hayes’style conceptual diagram of a simple moderation</p>
</div>
<p><strong>Conditional process analysis</strong>:</p>
<ul>
<li>Used when the research goal is to understand the boundary conditions of the mechanism(s) by which a variable transmits its effect on another.<br />
</li>
<li>Typically, simultaneously, assesses the influence of mediating (indirect effects) and moderating (interactional effects) in a model-building fashion.</li>
<li>In a conditional process model, the moderator(s) may be hypothesized to influence one or more of the paths.</li>
</ul>
<p>We will work toward building a conditional process model, a moderated mediation, over the next several chapters.</p>
<div class="figure">
<img src="images/SimpleMed/CPAmodel.jpg" id="id" class="class" width="250" height="180" alt="" />
<p class="caption">Image of conditional process analysis model where the moderator is hypothesized to change the a path; the path between the IV and mediator</p>
</div>
</div>
</div>
<div id="workflow-for-simple-mediation" class="section level2" number="6.3">
<h2 number="6.3"><span class="header-section-number">6.3</span> Workflow for Simple Mediation</h2>
<p>The workflow for a simple mediation is straightforward, however the figure below (i.e., the very traditional figure used to represent mediation) is very helpful in understanding the logic beneath mediation as the explanatory mechanism.</p>
<div class="figure">
<img src="images/SimpleMed/MedRationale.jpg" alt="" />
<p class="caption">Image of conditional process analysis model where the mediator is hypothesized to change the a path; the path between the IV and mediator</p>
</div>
<p>The top figure represents the bivariate relationship between the independent and dependent variable. The result of a simple linear regression (one predictor) represent the <em>total</em> effect of the IV on the DV. We can calculate this by simply regressing the DV onto the IV. The resulting <span class="math inline">\(B\)</span> weight is known as the <em>c</em> path. A bivariate correlation coefficient results in the same value – only it is standardized (so would be the same as the <span class="math inline">\(\beta\)</span> weight).</p>
<p>The lower figure represents that the relationship between the IV and DV is <em>mediated</em> by a third variable. We assign three labels to the paths: <em>a</em>, between the IV and mediator; <em>b</em>, between the mediator and DV; and <em>c’</em> (c prime) between the IV and DV.</p>
<p>Statistically speaking, a mediated relationship is supported when the value of <em>c’</em> is statistically significantly lower than <em>c</em>. If this occurs, then we can say that the mediator is sharing some of the variance in the prediction of the DV.</p>
<p>You might already be imagining potential challenges to this model. For example, which variable should be the IV and which one should be the mediator? Can we switch them? You can – and you will likely have very similar (if not identical) results. Good research design is what provides support for suggesting that mediation is the proper, casual, mechanism regarding the relationship between the IV and DV. An excellent review of the challenges of establishing a robust mediation model is provided by Kline <span class="citation">(<a href="#ref-kline_mediation_2015" role="doc-biblioref">2015</a>)</span>, where he suggests the following as the minimally required elements of a mediation design:</p>
<ul>
<li>the IV is an experimental variable with random assignment to conditions;</li>
<li>the mediator is an individual difference variable that is not manipulated and is measured at a later time;and</li>
<li>the DV is measured at a third occasion</li>
</ul>
<p>These criteria are in addition to the rather standard criteria for establishing causality <span class="citation">(see <a href="#ref-stone-romero_research_2010" role="doc-biblioref">Stone-Romero &amp; Rosopa, 2010</a> for a review)</span>:</p>
<ul>
<li>temporal precedence,</li>
<li>statistical covariation, and</li>
<li>ruling out plausible rival hypotheses.</li>
</ul>
<p>Some journals take this very seriously. In fact <a href="https://www.journals.elsevier.com/journal-of-vocational-behavior/news/frequently-asked-questions-about-submitting-a-manuscript">FAQs</a> in the Journal of Vocational Behavior make it clear that they will very rarely publish a “mediation manuscript” unless it has a minimum of three waves.</p>
<p>Working through a mediation will help operationalize these concepts.</p>
</div>
<div id="simple-mediation-in-lavaan-a-focus-on-the-mechanics" class="section level2" number="6.4">
<h2 number="6.4"><span class="header-section-number">6.4</span> Simple Mediation in <em>lavaan</em>: A focus on the mechanics</h2>
<p>The lavaan tutorial <span class="citation">(<a href="#ref-rosseel_lavaan_2020" role="doc-biblioref">Rosseel, 2020</a>)</span> provides a helpful model of how writing code to estimate an indirect effect. Using the lavaan tutorial as our guide, let’s start with just a set of fake data with variable names that represent X (predictor, IV, antecedent), M (mediator, atencedent, consequent), and Y (outcome, DV, consequent).</p>
<div id="simulate-fake-data" class="section level3" number="6.4.1">
<h3 number="6.4.1"><span class="header-section-number">6.4.1</span> Simulate Fake Data</h3>
<p>The code below is asking to create a dataset with a sample size of 100. The dataset has 3 variables, conveniently named X (predictor, antecedent, IV), M (mediator), and Y (outome, consequent, DV). The R code asks for random selection of numbers with a normal distribution. You can see that the M variable will be related to the X variable by + .5; and the Y variable will be related to the M variable by + .7. This rather ensures a statistically significant indirect effect.</p>
<!-- TODO: Return and replace with data from our mediation) -->
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210410</span>)</span>
<span id="cb165-2"><a href="#cb165-2" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb165-3"><a href="#cb165-3" aria-hidden="true" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="fl">0.5</span><span class="sc">*</span>X <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb165-4"><a href="#cb165-4" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fl">0.7</span><span class="sc">*</span>M <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb165-5"><a href="#cb165-5" aria-hidden="true" tabindex="-1"></a>Data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">X =</span> X, <span class="at">Y =</span> Y, <span class="at">M =</span> M)</span></code></pre></div>
</div>
<div id="specify-mediation-model" class="section level3" number="6.4.2">
<h3 number="6.4.2"><span class="header-section-number">6.4.2</span> Specify Mediation Model</h3>
<p>The package we are using is <em>lavaan</em>. Hayes’ model is <em>path analysis</em>, which can be a form of structural equation modeling. As a quick reminder, in SPSS, PROCESS is limited to ordinary least squares regression. We will use maximum likliehood estimators for the Hayes/PROCESS examples, but <em>lavaan</em> can take us further than PROCESS because</p>
<ul>
<li>We can (and, in later chapters, will) do latent variable modeling.</li>
<li>We can have more specificity and flexibility than the prescribed PROCESS models allow. I say this with all due respect to Hayes – there is also a good deal of flexibility to be able to add multiple mediators and covariates within most of the Hayes’ prescribed models.</li>
</ul>
<p>Hayes text is still a great place to start because the conceptual and procedural information is clear and transferable to the R environment.</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span></code></pre></div>
<pre><code>## Warning: package &#39;lavaan&#39; was built under R version 4.0.5</code></pre>
<pre><code>## This is lavaan 0.6-8
## lavaan is FREE software! Please report any bugs.</code></pre>
<pre><code>## 
## Attaching package: &#39;lavaan&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:psych&#39;:
## 
##     cor2cov</code></pre>
<p>Our atheoretical dataset makes it easy to identify which variable belongs in each role (X,Y,M). When specifying the paths in lavaan, here’s what to keep in mind:</p>
<ul>
<li>Name your model/object (below is X, “&lt;-” means “is defined by”)</li>
<li>The model exists between 2 single quotation marks (the odd looking ’ and ’ at the beginning and end).</li>
<li>The # of regression equations you need depends on the # of variables that have arrows pointing to them. In a simple mediation, there are 3 variables with 2 variables having arrows pointing to them – need 2 regression equations:
<ul>
<li>one for the Mediator</li>
<li>one for the DV (Y)</li>
</ul></li>
<li>Operator for a regression analysis is the (tilde, ~)</li>
<li>DV goes on left
<ul>
<li>In first equation we regress both the X and M onto Y</li>
<li>In second equation we regress M onto X</li>
</ul></li>
<li>The asterisk (*) is a handy tool to label variables (don’t confuse it as defining an interaction); this labeling as a, b, and c_p (in traditional mediation, the total effect is labeled with a and the direct effect is c’[c prime], but the script won’t allow and extra single quotation mark, hence c_p) is super helpful in interpreting the ouput</li>
<li>The indirect effect is created by multiplying the a and b paths.<br />
</li>
<li>The “:=” sign is used when creating a new variable that is a function of variables in the model, but not in the dataset (i.e., the a and b path).</li>
</ul>
<p>After specifying the model, we create an object that holds our results from the SEM. To obtain all the results from our of indirect effects, we also need to print a summary of the fit statistics, standardized estimates, r-squared, and confidence intervals.</p>
<p><em>Other authors will write the model code more sensibly, predicting the mediator first, and then the Y variable. However, I found that by doing it this way, the semPlot produces a more sensible figure.</em></p>
<p>Also, because we set a random seed, you should get the same results, but if it differs a little, don’t panic.
Also, in Hayes text the direct path from X to Y is c’ (“c prime”; where as c is reserved for the total effect of X on Y).</p>
<p>Let’s run the whole model.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210410</span>) <span class="co">#reset in case you choose to separate these sections</span></span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb171-3"><a href="#cb171-3" aria-hidden="true" tabindex="-1"></a><span class="st">          Y ~ b*M + c_p*X </span></span>
<span id="cb171-4"><a href="#cb171-4" aria-hidden="true" tabindex="-1"></a><span class="st">          M ~ a*X</span></span>
<span id="cb171-5"><a href="#cb171-5" aria-hidden="true" tabindex="-1"></a><span class="st">          </span></span>
<span id="cb171-6"><a href="#cb171-6" aria-hidden="true" tabindex="-1"></a><span class="st">          indirect :=  a*b</span></span>
<span id="cb171-7"><a href="#cb171-7" aria-hidden="true" tabindex="-1"></a><span class="st">          direct  := c_p</span></span>
<span id="cb171-8"><a href="#cb171-8" aria-hidden="true" tabindex="-1"></a><span class="st">          total_c  := c_p + (a*b)</span></span>
<span id="cb171-9"><a href="#cb171-9" aria-hidden="true" tabindex="-1"></a><span class="st">          &#39;</span></span>
<span id="cb171-10"><a href="#cb171-10" aria-hidden="true" tabindex="-1"></a>fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(model, <span class="at">data =</span> Data, <span class="at">se=</span><span class="st">&quot;bootstrap&quot;</span>, <span class="at">missing=</span> <span class="st">&#39;fiml&#39;</span>)</span>
<span id="cb171-11"><a href="#cb171-11" aria-hidden="true" tabindex="-1"></a>FDsummary <span class="ot">&lt;-</span> <span class="fu">summary</span>(fit, <span class="at">standardized=</span>T, <span class="at">rsq=</span>T, <span class="at">fit=</span><span class="cn">TRUE</span>, <span class="at">ci=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## lavaan 0.6-8 ended normally after 14 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                         7
##                                                       
##   Number of observations                           100
##   Number of missing patterns                         1
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                 0.000
##   Degrees of freedom                                 0
## 
## Model Test Baseline Model:
## 
##   Test statistic                                92.701
##   Degrees of freedom                                 3
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    1.000
##   Tucker-Lewis Index (TLI)                       1.000
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)               -287.127
##   Loglikelihood unrestricted model (H1)       -287.127
##                                                       
##   Akaike (AIC)                                 588.253
##   Bayesian (BIC)                               606.489
##   Sample-size adjusted Bayesian (BIC)          584.382
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.000
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.000
##   P-value RMSEA &lt;= 0.05                             NA
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.000
## 
## Parameter Estimates:
## 
##   Standard errors                            Bootstrap
##   Number of requested bootstrap draws             1000
##   Number of successful bootstrap draws            1000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##   Y ~                                                                   
##     M          (b)    0.764    0.097    7.918    0.000    0.577    0.955
##     X        (c_p)   -0.209    0.112   -1.867    0.062   -0.446   -0.001
##   M ~                                                                   
##     X          (a)    0.693    0.104    6.665    0.000    0.485    0.900
##    Std.lv  Std.all
##                   
##     0.764    0.719
##    -0.209   -0.163
##                   
##     0.693    0.574
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .Y                -0.044    0.107   -0.413    0.680   -0.260    0.161
##    .M                 0.106    0.105    1.010    0.313   -0.100    0.310
##    Std.lv  Std.all
##    -0.044   -0.034
##     0.106    0.086
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .Y                 1.031    0.148    6.950    0.000    0.734    1.301
##    .M                 1.037    0.144    7.220    0.000    0.754    1.327
##    Std.lv  Std.all
##     1.031    0.590
##     1.037    0.670
## 
## R-Square:
##                    Estimate
##     Y                 0.410
##     M                 0.330
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     indirect          0.529    0.089    5.954    0.000    0.355    0.708
##     direct           -0.209    0.112   -1.866    0.062   -0.446   -0.001
##     total_c           0.321    0.125    2.568    0.010    0.054    0.567
##    Std.lv  Std.all
##     0.529    0.413
##    -0.209   -0.163
##     0.321    0.250</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>FD_ParamEsts <span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>FDsummary</span></code></pre></div>
<pre><code>## $FIT
##              npar              fmin             chisq                df 
##             7.000             0.000             0.000             0.000 
##            pvalue    baseline.chisq       baseline.df   baseline.pvalue 
##                NA            92.701             3.000             0.000 
##               cfi               tli              logl unrestricted.logl 
##             1.000             1.000          -287.127          -287.127 
##               aic               bic            ntotal              bic2 
##           588.253           606.489           100.000           584.382 
##             rmsea    rmsea.ci.lower    rmsea.ci.upper      rmsea.pvalue 
##             0.000             0.000             0.000                NA 
##              srmr 
##             0.000 
## 
## $PE
##         lhs op       rhs    label exo         est         se          z
## 1         Y  ~         M        b   0  0.76435996 0.09652859  7.9184825
## 2         Y  ~         X      c_p   0 -0.20861348 0.11173871 -1.8669759
## 3         M  ~         X        a   0  0.69268167 0.10392556  6.6651713
## 4         Y ~~         Y            0  1.03100570 0.14834106  6.9502383
## 5         M ~~         M            0  1.03690713 0.14360623  7.2204883
## 6         X ~~         X            1  1.06310942 0.00000000         NA
## 7         Y ~1                      0 -0.04434521 0.10738844 -0.4129421
## 8         M ~1                      0  0.10642551 0.10539643  1.0097639
## 9         X ~1                      1 -0.19457819 0.00000000         NA
## 10 indirect :=       a*b indirect   0  0.52945814 0.08892327  5.9541009
## 11   direct :=       c_p   direct   0 -0.20861348 0.11179462 -1.8660422
## 12  total_c := c_p+(a*b)  total_c   0  0.32084465 0.12495930  2.5675932
## 13        Y r2         Y            0  0.40958958         NA         NA
## 14        M r2         M            0  0.32972838         NA         NA
##          pvalue    ci.lower      ci.upper      std.lv     std.all     std.nox
## 1  2.442491e-15  0.57657158  0.9554829338  0.76435996  0.71943062  0.71943062
## 2  6.190495e-02 -0.44637206 -0.0009074259 -0.20861348 -0.16277130 -0.15786609
## 3  2.643574e-11  0.48516770  0.8996769257  0.69268167  0.57421980  0.55691534
## 4  3.646639e-12  0.73428101  1.3014220066  1.03100570  0.59041042  0.59041042
## 5  5.180301e-13  0.75440642  1.3272578298  1.03690713  0.67027162  0.67027162
## 6            NA  1.06310942  1.0631094199  1.06310942  1.00000000  1.06310942
## 7  6.796490e-01 -0.26018823  0.1613575388 -0.04434521 -0.03355778 -0.03355778
## 8  3.126084e-01 -0.10043004  0.3095687447  0.10642551  0.08556600  0.08556600
## 9            NA -0.19457819 -0.1945781883 -0.19457819 -0.18871446 -0.19457819
## 10 2.615055e-09  0.35537200  0.7084867508  0.52945814  0.41311131  0.40066195
## 11 6.203546e-02 -0.44637206 -0.0009074259 -0.20861348 -0.16277130 -0.15786609
## 12 1.024073e-02  0.05415297  0.5670554787  0.32084465  0.25034001  0.24279586
## 13           NA          NA            NA          NA          NA          NA
## 14           NA          NA            NA          NA          NA          NA</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>FD_ParamEsts</span></code></pre></div>
<pre><code>##         lhs op       rhs    label    est    se      z pvalue ci.lower ci.upper
## 1         Y  ~         M        b  0.764 0.097  7.918  0.000    0.575    0.955
## 2         Y  ~         X      c_p -0.209 0.112 -1.867  0.062   -0.451   -0.001
## 3         M  ~         X        a  0.693 0.104  6.665  0.000    0.485    0.900
## 4         Y ~~         Y           1.031 0.148  6.950  0.000    0.803    1.372
## 5         M ~~         M           1.037 0.144  7.220  0.000    0.795    1.373
## 6         X ~~         X           1.063 0.000     NA     NA    1.063    1.063
## 7         Y ~1                    -0.044 0.107 -0.413  0.680   -0.259    0.161
## 8         M ~1                     0.106 0.105  1.010  0.313   -0.096    0.317
## 9         X ~1                    -0.195 0.000     NA     NA   -0.195   -0.195
## 10 indirect :=       a*b indirect  0.529 0.089  5.954  0.000    0.358    0.710
## 11   direct :=       c_p   direct -0.209 0.112 -1.866  0.062   -0.451   -0.001
## 12  total_c := c_p+(a*b)  total_c  0.321 0.125  2.568  0.010    0.055    0.568
##    std.lv std.all std.nox
## 1   0.764   0.719   0.719
## 2  -0.209  -0.163  -0.158
## 3   0.693   0.574   0.557
## 4   1.031   0.590   0.590
## 5   1.037   0.670   0.670
## 6   1.063   1.000   1.063
## 7  -0.044  -0.034  -0.034
## 8   0.106   0.086   0.086
## 9  -0.195  -0.189  -0.195
## 10  0.529   0.413   0.401
## 11 -0.209  -0.163  -0.158
## 12  0.321   0.250   0.243</code></pre>
</div>
<div id="interpret-the-output" class="section level3" number="6.4.3">
<h3 number="6.4.3"><span class="header-section-number">6.4.3</span> Interpret the Output</h3>
<p>Note that in the script we ask (and get) two sets of parameter estimates. The second set (in the really nice dataframe) includes bootstrapped, bias-corrected confidence intervals. Bias-corrected confidence interals have the advantage of being more powerful and bias-free. Note, though, that when the CI crosses 0, the effect is NS.</p>
<p>So let’s look at this step-by-step.</p>
<ul>
<li>Overall, our model accounted for 40.96% of the variance in the IV and 32.97% of the variance in the mediator.</li>
<li>a path = 0.693, <span class="math inline">\(p\)</span> = 0.000</li>
<li>b path = 0.764, <span class="math inline">\(p\)</span> = 0.000</li>
<li>the indirect effect is a product of the a and b paths (0.693 * 0.764 = 0.529); while we don’t hand calculate it’s significance, we see that it is <span class="math inline">\(p\)</span> = 0.000</li>
<li>the direct effect (c’, c prime, or c_p) is the isolated effect of X on Y when including M. We hope this value is LOWER than the total effect because this means that including M shared some of the variance in predicting Y: c’ = -0.209, <span class="math inline">\(p\)</span> = 0.062, and it is no longer signifcant.</li>
<li>we also see the total effect; this value is
<ul>
<li>identical to the value of simply predicting Y on X (with no M it the model)</li>
<li>the value of a(b) + c_p: 0.693(0.764) + -0.209 = 0.321 (<span class="math inline">\(p\)</span> = 0.010)</li>
</ul></li>
</ul>
<p>Here’s a demonstration that the total effect is, simply, predicting Y from X (also, the correlation between X and Y:</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>fitXY <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y <span class="sc">~</span> X, <span class="at">data =</span> Data)</span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fitXY)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Y ~ X, data = Data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.2631 -0.8288  0.0902  0.9637  3.5891 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   0.0370     0.1315   0.281    0.779  
## X             0.3208     0.1253   2.560    0.012 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.292 on 98 degrees of freedom
## Multiple R-squared:  0.06267,    Adjusted R-squared:  0.05311 
## F-statistic: 6.552 on 1 and 98 DF,  p-value: 0.012</code></pre>
<p>Which is the same as the bivariate correlation. The only trick is that the bivariate correlation produces a standardized result; so it would be the <span class="math inline">\(\beta\)</span>.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>XY_r <span class="ot">&lt;-</span> <span class="fu">corr.test</span>(Data[<span class="fu">c</span>(<span class="st">&quot;Y&quot;</span>, <span class="st">&quot;X&quot;</span>)])</span>
<span id="cb179-3"><a href="#cb179-3" aria-hidden="true" tabindex="-1"></a>XY_r</span></code></pre></div>
<pre><code>## Call:corr.test(x = Data[c(&quot;Y&quot;, &quot;X&quot;)])
## Correlation matrix 
##      Y    X
## Y 1.00 0.25
## X 0.25 1.00
## Sample Size 
## [1] 100
## Probability values (Entries above the diagonal are adjusted for multiple tests.) 
##      Y    X
## Y 0.00 0.01
## X 0.01 0.00
## 
##  To see confidence intervals of the correlations, print with the short=FALSE option</code></pre>
</div>
<div id="a-table-and-a-figure" class="section level3" number="6.4.4">
<h3 number="6.4.4"><span class="header-section-number">6.4.4</span> A Table and a Figure</h3>
<p>We can use the package <a href="https://rdrr.io/cran/semPlot/man/semPaths.html">semPlot</a> to create a figure that includes the values on the path.</p>
<p>Here’s what the base package gets us</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb181-2"><a href="#cb181-2" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(fit, <span class="co">#must identify the model you want to map</span></span>
<span id="cb181-3"><a href="#cb181-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb181-4"><a href="#cb181-4" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb181-5"><a href="#cb181-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;tree&#39;</span>, <span class="at">rotation =</span> <span class="dv">2</span>, <span class="co">#together, puts predictors on left, IVs on right </span></span>
<span id="cb181-6"><a href="#cb181-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb181-7"><a href="#cb181-7" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb181-8"><a href="#cb181-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb181-9"><a href="#cb181-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb181-10"><a href="#cb181-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb181-11"><a href="#cb181-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb181-12"><a href="#cb181-12" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb181-13"><a href="#cb181-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb181-14"><a href="#cb181-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb181-15"><a href="#cb181-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb181-16"><a href="#cb181-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb181-17"><a href="#cb181-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb181-18"><a href="#cb181-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb181-19"><a href="#cb181-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb181-20"><a href="#cb181-20" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Fake Data:  Simple Mediation&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/FakyDaty%20Simple%20Plot-1.svg" width="672" /></p>
<p>Hayes has great examples of APA style tables. I haven’t yet found a package that will turn this output into a journal-ready table, however the <em>semTable</em> package can at least write the output to a .csv file and you can further manipulate it into a table.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semTable)</span>
<span id="cb182-2"><a href="#cb182-2" aria-hidden="true" tabindex="-1"></a>fitTab1 <span class="ot">&lt;-</span> <span class="fu">semTable</span>(fit, <span class="at">columns =</span> <span class="fu">c</span>(<span class="st">&quot;est&quot;</span>, <span class="st">&quot;se&quot;</span>, <span class="st">&quot;p&quot;</span>, <span class="st">&quot;rsquare&quot;</span>),  <span class="at">columnLabels =</span> <span class="fu">c</span>(<span class="at">eststars =</span> <span class="st">&quot;Estimate&quot;</span>), <span class="at">paramSets =</span> <span class="fu">c</span>(<span class="st">&quot;composites&quot;</span>, <span class="st">&quot;loadings&quot;</span>, <span class="st">&quot;slopes&quot;</span>, <span class="st">&quot;intercepts&quot;</span>, <span class="st">&quot;residualvariances&quot;</span>), <span class="at">file =</span> <span class="st">&quot;fitTABLE&quot;</span>, <span class="at">type =</span> <span class="st">&quot;csv&quot;</span>, <span class="at">print.results =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="results-2" class="section level3" number="6.4.5">
<h3 number="6.4.5"><span class="header-section-number">6.4.5</span> Results</h3>
<p>A simple mediation model examined the degree to which M mediated the relation of X on Y. Using the <em>lavaan</em> package (v 0.6-7) in R, coefficients for each path, the indirect effect, and total effects were calculated. These values are presented in Table 1 and illustrated in Figure 1. Results suggested that 32.97% of the variance in M and 40.96% of the variance in Y were accounted for in the model. The indirect effect (<span class="math inline">\(B\)</span> = 0.529, <span class="math inline">\(p\)</span> = 0.000) was statistically significant; the direct effect (<span class="math inline">\(B\)</span> = -0.209, <span class="math inline">\(p\)</span> = 0.062) was not. Comparing the nonsignificant direct effect to the statistically significant total effect (<span class="math inline">\(B\)</span> = 0.321, <span class="math inline">\(p\)</span> = 0.010) is consistent with the notion that the effect of X on Y is explained through M.</p>
</div>
</div>
<div id="research-vignette-4" class="section level2" number="6.5">
<h2 number="6.5"><span class="header-section-number">6.5</span> Research Vignette</h2>
<p>The research vignette comes from the Kim, Kendall, and Cheon’s <span class="citation">(<a href="#ref-kim_racial_2017" role="doc-biblioref">2017</a>)</span>, “Racial Microaggressions, Cultural Mistrust, and Mental Health Outcomes Among Asian American College Students.” Participants were 156 Asian American undergraduate students in the Pacific Northwest. The researchers posited the a priori hypothesis that cultural mistrust would mediate the relationship between racial microaggressions and two sets of outcomes: mental health (e.g., depression, anxiety, well-being) and help-seeking.</p>
<p>Variables used in the study included:</p>
<ul>
<li><strong>REMS</strong>: Racial and Ethnic Microaggressions Scale (Nadal, 2011). The scale includes 45 items on a 2-point scale where 0 indicates no experience of a microaggressive event and 1 indicates it was experienced at least once within the past six months. Higher scores indicate more experience of microaggressions.</li>
<li><strong>CMI</strong>: Cultural Mistrust Inventory (Terrell &amp; Terrell, 1981). This scale was adapted to assess cultural mistrust harbored among Asian Americans toward individuals from the mainstream U.S. culture (e.g., Whites). The CMI includes 47 items on a 7-point scale where higher scores indicate a higher degree of cultural mistrust.</li>
<li><strong>ANX</strong>, <strong>DEP</strong>, <strong>PWB</strong>: Subscales of the Mental Health Inventory (Veit &amp; Ware, 1983) that assess the mental health outcomes of anxiety (9 items), depression (4 items), and psychological well-being (14 items). Higher scores (on a 6 point scale) indicate stronger endorsement of the mental health outcome being assessed.</li>
<li><strong>HlpSkg</strong>: The Attiudes Toward Seeking Professional Psychological Help – Short Form (Fischer &amp; Farina, 1995) includes 10 items on a 4-point scale (0 = disagree, 3 = agree) where higher scores indicate more favorable attitudes toward help seeking.</li>
</ul>
<div id="simulate-data-from-the-journal-article" class="section level3" number="6.5.1">
<h3 number="6.5.1"><span class="header-section-number">6.5.1</span> Simulate Data from the Journal Article</h3>
<p>First, we simulate the data from the means, standard deviations, and correlation matrix from the journal article.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Entering the intercorrelations, means, and standard deviations from the journal article</span></span>
<span id="cb183-2"><a href="#cb183-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">34</span>, <span class="fl">3.00</span>, <span class="fl">2.98</span>, <span class="fl">2.36</span>, <span class="fl">3.50</span>, <span class="fl">1.64</span>)</span>
<span id="cb183-3"><a href="#cb183-3" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">16</span>, .<span class="dv">83</span>, .<span class="dv">99</span>, .<span class="dv">90</span>, .<span class="dv">90</span>, .<span class="dv">53</span>)</span>
<span id="cb183-4"><a href="#cb183-4" aria-hidden="true" tabindex="-1"></a>r_mat <span class="ot">&lt;-</span> <span class="fu">matrix</span> (<span class="fu">c</span>(<span class="dv">1</span>,   .<span class="dv">59</span>, .<span class="dv">26</span>,   .<span class="dv">34</span>,  <span class="sc">-</span>.<span class="dv">25</span>, <span class="sc">-</span>.<span class="dv">02</span>,</span>
<span id="cb183-5"><a href="#cb183-5" aria-hidden="true" tabindex="-1"></a>                  .<span class="dv">59</span>, <span class="fl">1.00</span>, .<span class="dv">12</span>,   .<span class="dv">19</span>,  <span class="sc">-</span>.<span class="dv">28</span>, .<span class="dv">00</span>, </span>
<span id="cb183-6"><a href="#cb183-6" aria-hidden="true" tabindex="-1"></a>                  .<span class="dv">26</span>,  .<span class="dv">12</span>, <span class="fl">1.00</span>, .<span class="dv">66</span>,  <span class="sc">-</span>.<span class="dv">55</span>, .<span class="dv">07</span>,</span>
<span id="cb183-7"><a href="#cb183-7" aria-hidden="true" tabindex="-1"></a>                  .<span class="dv">34</span>,  .<span class="dv">19</span>, .<span class="dv">66</span>,  <span class="fl">1.00</span>, <span class="sc">-</span>.<span class="dv">66</span>, .<span class="dv">05</span>,</span>
<span id="cb183-8"><a href="#cb183-8" aria-hidden="true" tabindex="-1"></a>                 <span class="sc">-</span>.<span class="dv">25</span>, <span class="sc">-</span>.<span class="dv">28</span>, <span class="sc">-</span>.<span class="dv">55</span>,<span class="sc">-</span>.<span class="dv">66</span>,  <span class="fl">1.00</span>, .<span class="dv">08</span>, </span>
<span id="cb183-9"><a href="#cb183-9" aria-hidden="true" tabindex="-1"></a>                 <span class="sc">-</span>.<span class="dv">02</span>,  .<span class="dv">00</span>,  .<span class="dv">07</span>, .<span class="dv">05</span>, .<span class="dv">08</span>,  <span class="dv">1</span>), <span class="at">ncol =</span> <span class="dv">6</span>)</span>
<span id="cb183-10"><a href="#cb183-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating a covariance matrix</span></span>
<span id="cb183-11"><a href="#cb183-11" aria-hidden="true" tabindex="-1"></a>cov_mat <span class="ot">&lt;-</span> sd <span class="sc">%*%</span> <span class="fu">t</span>(sd) <span class="sc">*</span> r_mat</span>
<span id="cb183-12"><a href="#cb183-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-13"><a href="#cb183-13" aria-hidden="true" tabindex="-1"></a><span class="co">#Set random seed so that the following matrix always gets the same results.</span></span>
<span id="cb183-14"><a href="#cb183-14" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210409</span>)</span>
<span id="cb183-15"><a href="#cb183-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span></code></pre></div>
<pre><code>## Warning: package &#39;MASS&#39; was built under R version 4.0.5</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:formattable&#39;:
## 
##     area</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>Kim_df <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(<span class="at">n =</span> <span class="dv">156</span>, <span class="at">mu=</span>mu, <span class="at">Sigma =</span> cov_mat, <span class="at">empirical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(Kim_df)</span></code></pre></div>
<pre><code>## [1] 0.34 3.00 2.98 2.36 3.50 1.64</code></pre>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="#cb190-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking our work against the original correlation matrix</span></span>
<span id="cb190-2"><a href="#cb190-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">cor</span>(Kim_df),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>##       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]
## [1,]  1.00  0.59  0.26  0.34 -0.25 -0.02
## [2,]  0.59  1.00  0.12  0.19 -0.28  0.00
## [3,]  0.26  0.12  1.00  0.66 -0.55  0.07
## [4,]  0.34  0.19  0.66  1.00 -0.66  0.05
## [5,] -0.25 -0.28 -0.55 -0.66  1.00  0.08
## [6,] -0.02  0.00  0.07  0.05  0.08  1.00</code></pre>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="#cb192-1" aria-hidden="true" tabindex="-1"></a><span class="co">#look at the first 6 rows of the new df</span></span>
<span id="cb192-2"><a href="#cb192-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Kim_df)</span></code></pre></div>
<pre><code>##        REMS      CMI      ANX      DEP      PWB    HlpSk
## 1 0.5632213 3.659748 4.104905 1.955481 3.287428 1.918057
## 2 0.4164574 2.405398 3.189049 1.574824 4.250802 1.701437
## 3 0.2823777 1.822439 3.820871 2.515103 3.272359 1.342201
## 4 0.3301192 4.877980 3.298069 2.219149 3.310993 1.450270
## 5 0.2119648 2.110152 3.068806 2.145528 3.429861 1.909203
## 6 0.5961068 4.087986 3.420916 3.129796 2.914344 1.900283</code></pre>
<p>Let’s check the descriptives to see if they align with those in the article.</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="#cb194-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb194-2"><a href="#cb194-2" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">describe</span>(Kim_df)</span></code></pre></div>
<pre><code>##       vars   n mean   sd median trimmed  mad   min  max range  skew kurtosis
## REMS     1 156 0.34 0.16   0.32    0.34 0.16 -0.12 0.77  0.89 -0.02    -0.01
## CMI      2 156 3.00 0.83   3.01    3.00 0.73  0.90 5.42  4.51 -0.01     0.07
## ANX      3 156 2.98 0.99   2.98    2.98 0.88  0.32 5.53  5.21 -0.04     0.17
## DEP      4 156 2.36 0.90   2.41    2.37 0.90 -0.24 4.73  4.96 -0.11    -0.17
## PWB      5 156 3.50 0.90   3.52    3.50 0.85  1.16 6.48  5.32  0.01     0.22
## HlpSk    6 156 1.64 0.53   1.69    1.66 0.53 -0.07 2.90  2.97 -0.36     0.28
##         se
## REMS  0.01
## CMI   0.07
## ANX   0.08
## DEP   0.07
## PWB   0.07
## HlpSk 0.04</code></pre>
<p>There are a number of reasons I love the Kim et al. <span class="citation">(<a href="#ref-kim_racial_2017" role="doc-biblioref">2017</a>)</span> manuscript. One is that their approach was openly one that tested <em>alternate models</em>. Byrne <span class="citation">(<a href="#ref-byrne_structural_2016" role="doc-biblioref">2016</a>)</span> credits Joreskog <span class="citation">(<a href="#ref-bollen_testing_1993" role="doc-biblioref">Joreskog, 1993</a>)</span> with classifying the researcher’s model testing approach in three ways. If someone is <em>strictly confirmatory</em>, they only test the model they proposed and then accept or reject it without further alteration. While this is the tradition of null hypothesis significance testing, it contributes to the “file drawer problem” of unpublished, non-significant, findings. Additionally, the data are them discarded – potentially losing valuable resource. The <em>alternative models</em> approach is to propose a handful of competing models before beginning the analysis and then evaluating to see if one model is superior to the other. The third option is <em>model generating</em>. In this case the researcher begins with a theoretically proposed model. In the presence of poor fit, the researcher seeks to identify the source of misfit – respecifying it to best represent the sample data. The researcher must use caution to produce a model that fits well and is meaningful.</p>
<p>Several of the Kim et al. <span class="citation">(<a href="#ref-kim_racial_2017" role="doc-biblioref">2017</a>)</span> models were non-significant. To demonstrate a model that is statistically significant, I will test the hypothesis that racial microaggressions (REMS, the X variable) influence depression (DEP, the Y variable) through cultural mistrust (CMI, the M variable).</p>
<div class="figure">
<img src="images/SimpleMed/Kim_SimpMed.jpg" alt="" />
<p class="caption">Image of the simple mediation model from Kim et al.</p>
</div>
</div>
<div id="specify-the-model-in-lavaan" class="section level3" number="6.5.2">
<h3 number="6.5.2"><span class="header-section-number">6.5.2</span> Specify the Model in <em>lavaan</em></h3>
<p>I am a big fan of “copying the model.” In specifying my model I used our simple mediation template above</p>
<ul>
<li>replaced the Y, X, and M with variables names</li>
<li>replacing the name of the df</li>
<li>updated the object names (so I could use them in the same .rmd file)</li>
</ul>
<div class="sourceCode" id="cb196"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb196-1"><a href="#cb196-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb196-2"><a href="#cb196-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210410</span>) <span class="co">#reset in case you choose to separate these sections</span></span>
<span id="cb196-3"><a href="#cb196-3" aria-hidden="true" tabindex="-1"></a>Kim_model <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb196-4"><a href="#cb196-4" aria-hidden="true" tabindex="-1"></a><span class="st">          PWB ~ b*CMI + c_p*REMS </span></span>
<span id="cb196-5"><a href="#cb196-5" aria-hidden="true" tabindex="-1"></a><span class="st">          CMI ~a*REMS</span></span>
<span id="cb196-6"><a href="#cb196-6" aria-hidden="true" tabindex="-1"></a><span class="st">          </span></span>
<span id="cb196-7"><a href="#cb196-7" aria-hidden="true" tabindex="-1"></a><span class="st">          indirect :=  a*b</span></span>
<span id="cb196-8"><a href="#cb196-8" aria-hidden="true" tabindex="-1"></a><span class="st">          direct  := c_p</span></span>
<span id="cb196-9"><a href="#cb196-9" aria-hidden="true" tabindex="-1"></a><span class="st">          total_c  := c_p + (a*b)</span></span>
<span id="cb196-10"><a href="#cb196-10" aria-hidden="true" tabindex="-1"></a><span class="st">          &#39;</span></span></code></pre></div>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>Kim_fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(Kim_model, <span class="at">data =</span> Kim_df, <span class="at">se=</span><span class="st">&quot;bootstrap&quot;</span>, <span class="at">missing=</span> <span class="st">&#39;fiml&#39;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb198-1"><a href="#cb198-1" aria-hidden="true" tabindex="-1"></a>Kim_summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(Kim_fit, <span class="at">standardized=</span>T, <span class="at">rsq=</span>T, <span class="at">fit=</span><span class="cn">TRUE</span>, <span class="at">ci=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## lavaan 0.6-8 ended normally after 23 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                         7
##                                                       
##   Number of observations                           156
##   Number of missing patterns                         1
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                 0.000
##   Degrees of freedom                                 0
## 
## Model Test Baseline Model:
## 
##   Test statistic                                81.362
##   Degrees of freedom                                 3
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    1.000
##   Tucker-Lewis Index (TLI)                       1.000
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)               -355.521
##   Loglikelihood unrestricted model (H1)       -355.521
##                                                       
##   Akaike (AIC)                                 725.042
##   Bayesian (BIC)                               746.391
##   Sample-size adjusted Bayesian (BIC)          724.234
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.000
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.000
##   P-value RMSEA &lt;= 0.05                             NA
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.000
## 
## Parameter Estimates:
## 
##   Standard errors                            Bootstrap
##   Number of requested bootstrap draws             1000
##   Number of successful bootstrap draws            1000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##   PWB ~                                                                 
##     CMI        (b)   -0.220    0.118   -1.873    0.061   -0.452    0.015
##     REMS     (c_p)   -0.732    0.509   -1.437    0.151   -1.718    0.266
##   CMI ~                                                                 
##     REMS       (a)    3.061    0.292   10.494    0.000    2.469    3.616
##    Std.lv  Std.all
##                   
##    -0.220   -0.203
##    -0.732   -0.130
##                   
##     3.061    0.590
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .PWB               4.410    0.275   16.009    0.000    3.912    4.958
##    .CMI               1.959    0.113   17.351    0.000    1.754    2.194
##    Std.lv  Std.all
##     4.410    4.916
##     1.959    2.368
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .PWB               0.733    0.085    8.601    0.000    0.567    0.901
##    .CMI               0.446    0.053    8.465    0.000    0.339    0.553
##    Std.lv  Std.all
##     0.733    0.911
##     0.446    0.652
## 
## R-Square:
##                    Estimate
##     PWB               0.089
##     CMI               0.348
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     indirect         -0.675    0.367   -1.839    0.066   -1.433    0.053
##     direct           -0.732    0.510   -1.436    0.151   -1.718    0.266
##     total_c          -1.406    0.365   -3.856    0.000   -2.122   -0.713
##    Std.lv  Std.all
##    -0.675   -0.120
##    -0.732   -0.130
##    -1.406   -0.250</code></pre>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="#cb200-1" aria-hidden="true" tabindex="-1"></a>Kim_ParamEsts <span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(Kim_fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span>
<span id="cb200-2"><a href="#cb200-2" aria-hidden="true" tabindex="-1"></a>Kim_summary</span></code></pre></div>
<pre><code>## $FIT
##              npar              fmin             chisq                df 
##             7.000             0.000             0.000             0.000 
##            pvalue    baseline.chisq       baseline.df   baseline.pvalue 
##                NA            81.362             3.000             0.000 
##               cfi               tli              logl unrestricted.logl 
##             1.000             1.000          -355.521          -355.521 
##               aic               bic            ntotal              bic2 
##           725.042           746.391           156.000           724.234 
##             rmsea    rmsea.ci.lower    rmsea.ci.upper      rmsea.pvalue 
##             0.000             0.000             0.000                NA 
##              srmr 
##             0.000 
## 
## $PE
##         lhs op       rhs    label exo        est         se         z
## 1       PWB  ~       CMI        b   0 -0.2203938 0.11768579 -1.872731
## 2       PWB  ~      REMS      c_p   0 -0.7317072 0.50927052 -1.436775
## 3       CMI  ~      REMS        a   0  3.0606250 0.29164729 10.494269
## 4       PWB ~~       PWB            0  0.7328330 0.08520156  8.601169
## 5       CMI ~~       CMI            0  0.4462151 0.05271274  8.465033
## 6      REMS ~~      REMS            1  0.0254359 0.00000000        NA
## 7       PWB ~1                      0  4.4099618 0.27546349 16.009242
## 8       CMI ~1                      0  1.9593875 0.11292431 17.351335
## 9      REMS ~1                      1  0.3400000 0.00000000        NA
## 10 indirect :=       a*b indirect   0 -0.6745428 0.36683075 -1.838839
## 11   direct :=       c_p   direct   0 -0.7317072 0.50952535 -1.436057
## 12  total_c := c_p+(a*b)  total_c   0 -1.4062500 0.36467949 -3.856126
## 13      PWB r2       PWB            0  0.0894309         NA        NA
## 14      CMI r2       CMI            0  0.3481000         NA        NA
##          pvalue   ci.lower    ci.upper     std.lv    std.all    std.nox
## 1  0.0611055748 -0.4520943  0.01517990 -0.2203938 -0.2032521 -0.2032521
## 2  0.1507819099 -1.7176138  0.26594569 -0.7317072 -0.1300813 -0.8156264
## 3  0.0000000000  2.4693608  3.61560824  3.0606250  0.5900000  3.6993761
## 4  0.0000000000  0.5671305  0.90093387  0.7328330  0.9105691  0.9105691
## 5  0.0000000000  0.3389408  0.55289361  0.4462151  0.6519000  0.6519000
## 6            NA  0.0254359  0.02543590  0.0254359  1.0000000  0.0254359
## 7  0.0000000000  3.9116153  4.95818727  4.4099618  4.9157385  4.9157385
## 8  0.0000000000  1.7537845  2.19372375  1.9593875  2.3683108  2.3683108
## 9            NA  0.3400000  0.34000000  0.3400000  2.1318438  0.3400000
## 10 0.0659388362 -1.4331562  0.05265107 -0.6745428 -0.1199187 -0.7519058
## 11 0.1509862575 -1.7176138  0.26594569 -0.7317072 -0.1300813 -0.8156264
## 12 0.0001151982 -2.1222575 -0.71330366 -1.4062500 -0.2500000 -1.5675322
## 13           NA         NA          NA         NA         NA         NA
## 14           NA         NA          NA         NA         NA         NA</code></pre>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="#cb202-1" aria-hidden="true" tabindex="-1"></a>Kim_ParamEsts</span></code></pre></div>
<pre><code>##         lhs op       rhs    label    est    se      z pvalue ci.lower ci.upper
## 1       PWB  ~       CMI        b -0.220 0.118 -1.873  0.061   -0.456    0.012
## 2       PWB  ~      REMS      c_p -0.732 0.509 -1.437  0.151   -1.697    0.293
## 3       CMI  ~      REMS        a  3.061 0.292 10.494  0.000    2.458    3.598
## 4       PWB ~~       PWB           0.733 0.085  8.601  0.000    0.589    0.923
## 5       CMI ~~       CMI           0.446 0.053  8.465  0.000    0.355    0.569
## 6      REMS ~~      REMS           0.025 0.000     NA     NA    0.025    0.025
## 7       PWB ~1                     4.410 0.275 16.009  0.000    3.915    4.959
## 8       CMI ~1                     1.959 0.113 17.351  0.000    1.753    2.193
## 9      REMS ~1                     0.340 0.000     NA     NA    0.340    0.340
## 10 indirect :=       a*b indirect -0.675 0.367 -1.839  0.066   -1.443    0.032
## 11   direct :=       c_p   direct -0.732 0.510 -1.436  0.151   -1.697    0.293
## 12  total_c := c_p+(a*b)  total_c -1.406 0.365 -3.856  0.000   -2.133   -0.722
##    std.lv std.all std.nox
## 1  -0.220  -0.203  -0.203
## 2  -0.732  -0.130  -0.816
## 3   3.061   0.590   3.699
## 4   0.733   0.911   0.911
## 5   0.446   0.652   0.652
## 6   0.025   1.000   0.025
## 7   4.410   4.916   4.916
## 8   1.959   2.368   2.368
## 9   0.340   2.132   0.340
## 10 -0.675  -0.120  -0.752
## 11 -0.732  -0.130  -0.816
## 12 -1.406  -0.250  -1.568</code></pre>
</div>
<div id="interpret-the-output-1" class="section level3" number="6.5.3">
<h3 number="6.5.3"><span class="header-section-number">6.5.3</span> Interpret the Output</h3>
<ul>
<li>Overall, our model accounted for 8.94% of the variance in the IV and 34.81% of the variance in the mediator.</li>
<li>a path = 3.061, <span class="math inline">\(p\)</span> = 0.000</li>
<li>b path = -0.220, <span class="math inline">\(p\)</span> = 0.061</li>
<li>the indirect effect is a product of the a and b paths (-0.675); while we don’t hand calculate it’s significance, we see that it is <span class="math inline">\(p\)</span> = 0.066; the bias-corrected bootstrapped confidence intervals can sometimes be more lenient than <span class="math inline">\(p\)</span> values; it is important they don’t cross zero. They don’t: CI95 -1.443 to 0.032<br />
</li>
<li>the direct effect (c’, c prime, or c_p) is the isolated effect of X on Y when including M. We hope this value is LOWER than the total effect because this means that including M shared some of the variance in predicting Y: c’ = -0.732, <span class="math inline">\(p\)</span> = 0.151, and it is no longer signifcant.</li>
<li>we also see the total effect; this value is</li>
<li>identical to the value of simply predicting Y on X (with no M it the model)</li>
<li>the value of a(b) + c_p: 3.061(-0.220) + -0.732 = -1.406 (<span class="math inline">\(p\)</span> = 0.000)</li>
</ul>
</div>
<div id="a-figure-and-a-table" class="section level3" number="6.5.4">
<h3 number="6.5.4"><span class="header-section-number">6.5.4</span> A Figure and a Table</h3>
<p>I make it a practice to immediately plot what I did. Because the plotting packages use our models, this can be a helpful self-check of our work.</p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb204-2"><a href="#cb204-2" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(Kim_fit, <span class="co">#must identiy the model you want to map</span></span>
<span id="cb204-3"><a href="#cb204-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb204-4"><a href="#cb204-4" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb204-5"><a href="#cb204-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;tree&#39;</span>, <span class="at">rotation =</span> <span class="dv">2</span>, <span class="co">#together, puts predictors on left, IVs on right </span></span>
<span id="cb204-6"><a href="#cb204-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb204-7"><a href="#cb204-7" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb204-8"><a href="#cb204-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb204-9"><a href="#cb204-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb204-10"><a href="#cb204-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb204-11"><a href="#cb204-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb204-12"><a href="#cb204-12" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb204-13"><a href="#cb204-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb204-14"><a href="#cb204-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb204-15"><a href="#cb204-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb204-16"><a href="#cb204-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb204-17"><a href="#cb204-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb204-18"><a href="#cb204-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb204-19"><a href="#cb204-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb204-20"><a href="#cb204-20" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Depression by Racial Microaggressions via Cultural Mistrust&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/semPLOT%20of%20PMI-1.svg" width="672" /></p>
<p>The semTable package can be used to write results to an outfile.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semTable)</span>
<span id="cb205-2"><a href="#cb205-2" aria-hidden="true" tabindex="-1"></a>fitTab1 <span class="ot">&lt;-</span> <span class="fu">semTable</span>(Kim_fit, <span class="at">columns =</span> <span class="fu">c</span>(<span class="st">&quot;est&quot;</span>, <span class="st">&quot;se&quot;</span>, <span class="st">&quot;p&quot;</span>, <span class="st">&quot;rsquare&quot;</span>),  <span class="at">columnLabels =</span> <span class="fu">c</span>(<span class="at">eststars =</span> <span class="st">&quot;Estimate&quot;</span>), <span class="at">paramSets =</span> <span class="fu">c</span>(<span class="st">&quot;composites&quot;</span>, <span class="st">&quot;loadings&quot;</span>, <span class="st">&quot;slopes&quot;</span>, <span class="st">&quot;intercepts&quot;</span>, <span class="st">&quot;residualvariances&quot;</span>), <span class="at">file =</span> <span class="st">&quot;pmi_fitTABLE&quot;</span>, <span class="at">type =</span> <span class="st">&quot;csv&quot;</span>, <span class="at">print.results =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>For the purpose of the OER, and because it’s good trainng, I also think it can be useful to make our own table. For me, it facilitates my conceptual understanding of (a) what the statistic is doing and (b) the results of our specific data.</p>
<p>Table 1</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Model Coefficients Assessing Cultural Mistrust as a Mediator Between Racial Microaggressions and Well-Being</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center">Cultural Mistrust (M)</td>
<td align="center"></td>
<td align="center">Well-Being (Y)</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left">Antecedent</td>
<td align="center">path</td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
<td align="center">path</td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="left">constant</td>
<td align="center"><span class="math inline">\(i_{M}\)</span></td>
<td align="center">1.959</td>
<td align="center">0.113</td>
<td align="center">0.000</td>
<td align="center"><span class="math inline">\(i_{Y}\)</span></td>
<td align="center">4.410</td>
<td align="center">0.275</td>
<td align="center">0.000</td>
</tr>
<tr class="odd">
<td align="left">REMS (X)</td>
<td align="center"><span class="math inline">\(a\)</span></td>
<td align="center">3.061</td>
<td align="center">0.292</td>
<td align="center">0.000</td>
<td align="center"><span class="math inline">\(c&#39;\)</span></td>
<td align="center">-0.732</td>
<td align="center">0.509</td>
<td align="center">0.151</td>
</tr>
<tr class="even">
<td align="left">CMI (M)</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(b\)</span></td>
<td align="center">-0.220</td>
<td align="center">0.118</td>
<td align="center">0.061</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center"><span class="math inline">\(R^2\)</span> = 34.81%</td>
<td align="center"></td>
<td align="center"><span class="math inline">\(R^2\)</span> = 8.94%</td>
</tr>
</tbody>
</table>
</div>
<div id="results-3" class="section level3" number="6.5.5">
<h3 number="6.5.5"><span class="header-section-number">6.5.5</span> Results</h3>
<p>A simple mediation model examined the degree to which cultural mistrust mediated the relation of racial microaggressions on depressive symptoms Using the <em>lavaan</em> package (v 0.6-7) in R, coefficients for each path, the indirect effect, and total effects were calculated. These values are presented in Table 1 and illustrated in Figure 1. Results suggested that 34.81% of the variance in cultural mistrust and 8.94%of the variance in depression were accounted for by the model. When the mediator was included in the model, bias-corrected confidence intervals surrounding the indirect effect (<span class="math inline">\(B\)</span> = -0.675, <span class="math inline">\(p\)</span> = 0.066, CI95 -1.443 to 0.032) were not quite statistically significant. Consistent with mediation, the value of the total effect was larger in magnitude and statistically significant (<span class="math inline">\(B\)</span> = -1.406, <span class="math inline">\(p\)</span> = 0.000, CI95 -2.133 to -0.722) than the smaller and non-significant direct effect (<span class="math inline">\(B\)</span> = -0.732, <span class="math inline">\(p\)</span> = 0.151, CI95 -1.697 to 0.293).</p>
</div>
</div>
<div id="considering-covariates" class="section level2" number="6.6">
<h2 number="6.6"><span class="header-section-number">6.6</span> Considering Covariates</h2>
<p>Hayes Chapter 4 <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> considers the role of covariates (e.g., other variables that could account for some of the variance in the model). When previous research (or commonsense, or detractors) suggest you should include them…its worth a try. If they are non-significant and/or your variables continue to explain variance over-and-above their contribution, then you have gained ground in ruling out plausible rival hypotheses and are adding to causal evidence.</p>
<p>They are relatively easy to specify in <em>lavaan</em>. Just look at to where the arrows point and then write the path!</p>
<p>Let’s say we are concerned that anxiety covaries with cultural mistrust and PWB We’ll add it as a covariate to both.</p>
<div class="figure">
<img src="images/SimpleMed/Kim_wCovs.jpg" alt="" />
<p class="caption">Image of the simple mediation model from Kim et al.</p>
</div>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="#cb206-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210410</span>)</span>
<span id="cb206-2"><a href="#cb206-2" aria-hidden="true" tabindex="-1"></a>Kim_fit_covs <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb206-3"><a href="#cb206-3" aria-hidden="true" tabindex="-1"></a><span class="st">          PWB ~ b*CMI + c_p*REMS </span></span>
<span id="cb206-4"><a href="#cb206-4" aria-hidden="true" tabindex="-1"></a><span class="st">          CMI ~a*REMS</span></span>
<span id="cb206-5"><a href="#cb206-5" aria-hidden="true" tabindex="-1"></a><span class="st">          CMI ~ covM*ANX</span></span>
<span id="cb206-6"><a href="#cb206-6" aria-hidden="true" tabindex="-1"></a><span class="st">          PWB ~ covY*ANX</span></span>
<span id="cb206-7"><a href="#cb206-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb206-8"><a href="#cb206-8" aria-hidden="true" tabindex="-1"></a><span class="st">          indirect :=  a*b</span></span>
<span id="cb206-9"><a href="#cb206-9" aria-hidden="true" tabindex="-1"></a><span class="st">          direct  := c_p</span></span>
<span id="cb206-10"><a href="#cb206-10" aria-hidden="true" tabindex="-1"></a><span class="st">          total_c  := c_p + (a*b)</span></span>
<span id="cb206-11"><a href="#cb206-11" aria-hidden="true" tabindex="-1"></a><span class="st">          &#39;</span></span>
<span id="cb206-12"><a href="#cb206-12" aria-hidden="true" tabindex="-1"></a>Kim_fit_covs <span class="ot">&lt;-</span> <span class="fu">sem</span>(Kim_fit_covs, <span class="at">data =</span> Kim_df, <span class="at">se=</span><span class="st">&quot;bootstrap&quot;</span>, <span class="at">missing =</span> <span class="st">&#39;fiml&#39;</span>)</span>
<span id="cb206-13"><a href="#cb206-13" aria-hidden="true" tabindex="-1"></a>Kcov_sum <span class="ot">&lt;-</span> <span class="fu">summary</span>(Kim_fit_covs, <span class="at">standardized=</span>T, <span class="at">rsq=</span>T, <span class="at">fit=</span><span class="cn">TRUE</span>, <span class="at">ci=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## lavaan 0.6-8 ended normally after 25 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                         9
##                                                       
##   Number of observations                           156
##   Number of missing patterns                         1
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                 0.000
##   Degrees of freedom                                 0
## 
## Model Test Baseline Model:
## 
##   Test statistic                               134.067
##   Degrees of freedom                                 5
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    1.000
##   Tucker-Lewis Index (TLI)                       1.000
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)               -329.168
##   Loglikelihood unrestricted model (H1)       -329.168
##                                                       
##   Akaike (AIC)                                 676.337
##   Bayesian (BIC)                               703.785
##   Sample-size adjusted Bayesian (BIC)          675.297
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.000
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.000
##   P-value RMSEA &lt;= 0.05                             NA
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.000
## 
## Parameter Estimates:
## 
##   Standard errors                            Bootstrap
##   Number of requested bootstrap draws             1000
##   Number of successful bootstrap draws            1000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##   PWB ~                                                                 
##     CMI        (b)   -0.250    0.100   -2.509    0.012   -0.447   -0.066
##     REMS     (c_p)    0.131    0.511    0.256    0.798   -0.863    1.153
##   CMI ~                                                                 
##     REMS       (a)    3.109    0.312    9.972    0.000    2.486    3.718
##     ANX     (covM)   -0.030    0.052   -0.578    0.563   -0.129    0.073
##   PWB ~                                                                 
##     ANX     (covY)   -0.480    0.063   -7.596    0.000   -0.598   -0.356
##    Std.lv  Std.all
##                   
##    -0.250   -0.230
##     0.131    0.023
##                   
##     3.109    0.599
##    -0.030   -0.036
##                   
##    -0.480   -0.528
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .PWB               5.636    0.285   19.766    0.000    5.100    6.200
##    .CMI               2.032    0.164   12.388    0.000    1.701    2.355
##    Std.lv  Std.all
##     5.636    6.283
##     2.032    2.457
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .PWB               0.524    0.064    8.206    0.000    0.388    0.643
##    .CMI               0.445    0.053    8.457    0.000    0.335    0.550
##    Std.lv  Std.all
##     0.524    0.651
##     0.445    0.651
## 
## R-Square:
##                    Estimate
##     PWB               0.349
##     CMI               0.349
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     indirect         -0.776    0.321   -2.417    0.016   -1.455   -0.214
##     direct            0.131    0.511    0.256    0.798   -0.863    1.153
##     total_c          -0.646    0.373   -1.731    0.083   -1.398    0.079
##    Std.lv  Std.all
##    -0.776   -0.138
##     0.131    0.023
##    -0.646   -0.115</code></pre>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb208-1"><a href="#cb208-1" aria-hidden="true" tabindex="-1"></a>Kcov_ParEsts<span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(Kim_fit_covs, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span>
<span id="cb208-2"><a href="#cb208-2" aria-hidden="true" tabindex="-1"></a>Kcov_sum</span></code></pre></div>
<pre><code>## $FIT
##              npar              fmin             chisq                df 
##             9.000             0.000             0.000             0.000 
##            pvalue    baseline.chisq       baseline.df   baseline.pvalue 
##                NA           134.067             5.000             0.000 
##               cfi               tli              logl unrestricted.logl 
##             1.000             1.000          -329.168          -329.168 
##               aic               bic            ntotal              bic2 
##           676.337           703.785           156.000           675.297 
##             rmsea    rmsea.ci.lower    rmsea.ci.upper      rmsea.pvalue 
##             0.000             0.000             0.000                NA 
##              srmr 
##             0.000 
## 
## $PE
##         lhs op       rhs    label exo        est         se          z
## 1       PWB  ~       CMI        b   0 -0.2497502 0.09956147 -2.5085030
## 2       PWB  ~      REMS      c_p   0  0.1309468 0.51068059  0.2564162
## 3       CMI  ~      REMS        a   0  3.1089393 0.31175531  9.9723701
## 4       CMI  ~       ANX     covM   0 -0.0300322 0.05198649 -0.5776923
## 5       PWB  ~       ANX     covY   0 -0.4803760 0.06323940 -7.5961503
## 6       PWB ~~       PWB            0  0.5236894 0.06381737  8.2060640
## 7       CMI ~~       CMI            0  0.4453962 0.05266753  8.4567510
## 8      REMS ~~      REMS            1  0.0254359 0.00000000         NA
## 9      REMS ~~       ANX            1  0.0409200 0.00000000         NA
## 10      ANX ~~       ANX            1  0.9738173 0.00000000         NA
## 11      PWB ~1                      0  5.6362494 0.28514695 19.7661218
## 12      CMI ~1                      0  2.0324566 0.16407293 12.3875193
## 13     REMS ~1                      1  0.3400000 0.00000000         NA
## 14      ANX ~1                      1  2.9800000 0.00000000         NA
## 15 indirect :=       a*b indirect   0 -0.7764583 0.32118731 -2.4174627
## 16   direct :=       c_p   direct   0  0.1309468 0.51093612  0.2562879
## 17  total_c := c_p+(a*b)  total_c   0 -0.6455116 0.37291311 -1.7309973
## 18      PWB r2       PWB            0  0.3492987         NA         NA
## 19      CMI r2       CMI            0  0.3492964         NA         NA
##          pvalue   ci.lower    ci.upper     std.lv     std.all    std.nox
## 1  1.212439e-02 -0.4474766 -0.06635469 -0.2497502 -0.23032523 -0.2303252
## 2  7.976295e-01 -0.8627072  1.15281186  0.1309468  0.02327942  0.1459650
## 3  0.000000e+00  2.4857344  3.71801761  3.1089393  0.59931360  3.7577735
## 4  5.634719e-01 -0.1292826  0.07255185 -0.0300322 -0.03582154 -0.0362999
## 5  3.042011e-14 -0.5982298 -0.35643425 -0.4803760 -0.52841362 -0.5354701
## 6  2.220446e-16  0.3884796  0.64286913  0.5236894  0.65070130  0.6507013
## 7  0.000000e+00  0.3352469  0.54995342  0.4453962  0.65070356  0.6507036
## 8            NA  0.0254359  0.02543590  0.0254359  1.00000000  0.0254359
## 9            NA  0.0409200  0.04092000  0.0409200  0.26000000  0.0409200
## 10           NA  0.9738173  0.97381731  0.9738173  1.00000000  0.9738173
## 11 0.000000e+00  5.0996172  6.20009556  5.6362494  6.28266844  6.2826684
## 12 0.000000e+00  1.7013065  2.35450817  2.0324566  2.45662936  2.4566294
## 13           NA  0.3400000  0.34000000  0.3400000  2.13184382  0.3400000
## 14           NA  2.9800000  2.98000000  2.9800000  3.01979540  2.9800000
## 15 1.562914e-02 -1.4547978 -0.21398042 -0.7764583 -0.13803704 -0.8655100
## 16 7.977285e-01 -0.8627072  1.15281186  0.1309468  0.02327942  0.1459650
## 17 8.345224e-02 -1.3981671  0.07871598 -0.6455116 -0.11475762 -0.7195450
## 18           NA         NA          NA         NA          NA         NA
## 19           NA         NA          NA         NA          NA         NA</code></pre>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb210-1"><a href="#cb210-1" aria-hidden="true" tabindex="-1"></a>Kcov_ParEsts</span></code></pre></div>
<pre><code>##         lhs op       rhs    label    est    se      z pvalue ci.lower ci.upper
## 1       PWB  ~       CMI        b -0.250 0.100 -2.509  0.012   -0.447   -0.066
## 2       PWB  ~      REMS      c_p  0.131 0.511  0.256  0.798   -0.854    1.158
## 3       CMI  ~      REMS        a  3.109 0.312  9.972  0.000    2.480    3.717
## 4       CMI  ~       ANX     covM -0.030 0.052 -0.578  0.563   -0.129    0.074
## 5       PWB  ~       ANX     covY -0.480 0.063 -7.596  0.000   -0.594   -0.348
## 6       PWB ~~       PWB           0.524 0.064  8.206  0.000    0.424    0.681
## 7       CMI ~~       CMI           0.445 0.053  8.457  0.000    0.358    0.568
## 8      REMS ~~      REMS           0.025 0.000     NA     NA    0.025    0.025
## 9      REMS ~~       ANX           0.041 0.000     NA     NA    0.041    0.041
## 10      ANX ~~       ANX           0.974 0.000     NA     NA    0.974    0.974
## 11      PWB ~1                     5.636 0.285 19.766  0.000    5.091    6.192
## 12      CMI ~1                     2.032 0.164 12.388  0.000    1.709    2.368
## 13     REMS ~1                     0.340 0.000     NA     NA    0.340    0.340
## 14      ANX ~1                     2.980 0.000     NA     NA    2.980    2.980
## 15 indirect :=       a*b indirect -0.776 0.321 -2.417  0.016   -1.486   -0.229
## 16   direct :=       c_p   direct  0.131 0.511  0.256  0.798   -0.854    1.158
## 17  total_c := c_p+(a*b)  total_c -0.646 0.373 -1.731  0.083   -1.392    0.079
##    std.lv std.all std.nox
## 1  -0.250  -0.230  -0.230
## 2   0.131   0.023   0.146
## 3   3.109   0.599   3.758
## 4  -0.030  -0.036  -0.036
## 5  -0.480  -0.528  -0.535
## 6   0.524   0.651   0.651
## 7   0.445   0.651   0.651
## 8   0.025   1.000   0.025
## 9   0.041   0.260   0.041
## 10  0.974   1.000   0.974
## 11  5.636   6.283   6.283
## 12  2.032   2.457   2.457
## 13  0.340   2.132   0.340
## 14  2.980   3.020   2.980
## 15 -0.776  -0.138  -0.866
## 16  0.131   0.023   0.146
## 17 -0.646  -0.115  -0.720</code></pre>
<div id="a-figure-and-a-table-1" class="section level3" number="6.6.1">
<h3 number="6.6.1"><span class="header-section-number">6.6.1</span> A Figure and a Table</h3>
<p>Let’s look at a figure to see see if we did what we think we did. And to also get a graphic representation of our results. The semplot package does this easily, but the figure is more statistical than conceptual and would require more tinkering for a journal article.</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb212-1"><a href="#cb212-1" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(Kim_fit_covs, <span class="co">#must identiy the model you want to map</span></span>
<span id="cb212-2"><a href="#cb212-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb212-3"><a href="#cb212-3" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb212-4"><a href="#cb212-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;tree&#39;</span>, <span class="at">rotation =</span> <span class="dv">2</span>, <span class="co">#together, puts predictors on left, IVs on right </span></span>
<span id="cb212-5"><a href="#cb212-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb212-6"><a href="#cb212-6" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb212-7"><a href="#cb212-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb212-8"><a href="#cb212-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb212-9"><a href="#cb212-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb212-10"><a href="#cb212-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb212-11"><a href="#cb212-11" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb212-12"><a href="#cb212-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb212-13"><a href="#cb212-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb212-14"><a href="#cb212-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb212-15"><a href="#cb212-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb212-16"><a href="#cb212-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb212-17"><a href="#cb212-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb212-18"><a href="#cb212-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb212-19"><a href="#cb212-19" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Entrepreneurial Withdrawal by eDistress via Negative Affect (&amp; some covariates(&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/semPLOT%20for%20model%20w%20covs-1.svg" width="672" /></p>
<p>The path coefficients appear to be correct, but this is really a statistical map and doesn’t relay the concept of mediation well.</p>
<p>Below is code to create an outfile that could help with creating a table in a word document or spreadsheet. There will be output that is produced with SEM models that won’t be relevant for this project.</p>
<div class="sourceCode" id="cb213"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>KimCOVTab <span class="ot">&lt;-</span> <span class="fu">semTable</span>(Kim_fit_covs, <span class="at">columns =</span> <span class="fu">c</span>(<span class="st">&quot;est&quot;</span>, <span class="st">&quot;se&quot;</span>, <span class="st">&quot;p&quot;</span>, <span class="st">&quot;rsquare&quot;</span>),  <span class="at">columnLabels =</span> <span class="fu">c</span>(<span class="at">eststars =</span> <span class="st">&quot;Estimate&quot;</span>), <span class="at">paramSets =</span> <span class="fu">c</span>(<span class="st">&quot;composites&quot;</span>, <span class="st">&quot;loadings&quot;</span>, <span class="st">&quot;slopes&quot;</span>, <span class="st">&quot;intercepts&quot;</span>, <span class="st">&quot;residualvariances&quot;</span>), <span class="at">file =</span> <span class="st">&quot;ESTRESScov_fitTABLE&quot;</span>, <span class="at">type =</span> <span class="st">&quot;csv&quot;</span>, <span class="at">print.results =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>Table 2</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Model Coefficients Assessing Cultural Mistrust as a Mediator Between Racial Microaggressions and Well-Being</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center">Cultural Mistrust (M)</td>
<td align="center"></td>
<td align="center">Well-Being (Y)</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left">Antecedent</td>
<td align="center">path</td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
<td align="center">path</td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="left">constant</td>
<td align="center"><span class="math inline">\(i_{M}\)</span></td>
<td align="center">2.032</td>
<td align="center">0.164</td>
<td align="center">0.000</td>
<td align="center"><span class="math inline">\(i_{Y}\)</span></td>
<td align="center">5.636</td>
<td align="center">0.285</td>
<td align="center">0.000</td>
</tr>
<tr class="odd">
<td align="left">REMS (X)</td>
<td align="center"><span class="math inline">\(a\)</span></td>
<td align="center">3.109</td>
<td align="center">0.312</td>
<td align="center">0.000</td>
<td align="center"><span class="math inline">\(c&#39;\)</span></td>
<td align="center">0.131</td>
<td align="center">0.511</td>
<td align="center">0.798</td>
</tr>
<tr class="even">
<td align="left">CMI (M)</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(b\)</span></td>
<td align="center">-0.250</td>
<td align="center">0.100</td>
<td align="center">0.012</td>
</tr>
<tr class="odd">
<td align="left">ANX (Cov)</td>
<td align="center"></td>
<td align="center">-0.030</td>
<td align="center">0.052</td>
<td align="center">0.563</td>
<td align="center"></td>
<td align="center">-0.480</td>
<td align="center">0.063</td>
<td align="center">0.000</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center"><span class="math inline">\(R^2\)</span> = 34.93%</td>
<td align="center"></td>
<td align="center"><span class="math inline">\(R^2\)</span> = 34.93%</td>
</tr>
</tbody>
</table>
</div>
<div id="apa-style-write-up" class="section level3" number="6.6.2">
<h3 number="6.6.2"><span class="header-section-number">6.6.2</span> APA Style Write-up</h3>
<p>There are varying models for reporting the results of mediation. The Kim et al. <span class="citation">(<a href="#ref-kim_racial_2017" role="doc-biblioref">Paul Youngbin Kim et al., 2017</a>)</span> writeup is a great example. Rather than copying it directly, I have modeled my table after the ones in Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> text. You’ll notice that information in the table and text are minimally overlapping. APA style cautions us against redundancy in text and table.</p>
<p><strong>Results</strong></p>
<p>A simple mediation model examined the degree to which cultural mistrust mediated the effect of racial microaggressions on psychological well-being. Using the <em>lavaan</em> package (v 0.6-7) in R, coefficients for the each path, the indirect effect, and total effects were calculated. The effect of covariate, anxiety, was mapped onto both the mediator and dependent variable. These values are presented in Table 3 and illustrated in Figure 3. Results suggested that 34.93% of the variance in cultural mistrust and 34.93% of the variance in well-being were accounted for by the model. Supporting the notion of a mediated model, there was a statistically significant indirect effect (<span class="math inline">\(B\)</span> = -0.776, <span class="math inline">\(p\)</span> = 0.016, CI95 -1.486 to -0.229) in combination with a non-significant direct effect (<span class="math inline">\(B\)</span> = 0.131, <span class="math inline">\(p\)</span> = 0.798, CI95 -0.854 to 1.158). Curiously, though, the total effect (<span class="math inline">\(B\)</span> = -0.646, <span class="math inline">\(p\)</span> = 0.083, CI95 -1.392 to 0.079) was also non-significant.</p>
</div>
</div>
<div id="residual-and-related-questions" class="section level2" number="6.7">
<h2 number="6.7"><span class="header-section-number">6.7</span> Residual and Related Questions…</h2>
<p>..that you might have; or at least I had, but if had answered them earlier it would have disrupt the flow.</p>
<ol style="list-style-type: decimal">
<li>Are you sure you can claim a significant indirect effect in the presence of a non-significant total effect? Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> is.
<ul>
<li>In the section subtitled, “What about Baron &amp; Kenny” (chapter 4), Hayes argues from both logical/philosophical and statistical perspectives that the size of the total effect does not constrain or determine the size of the indirect effect. That is, an indirect effect can be different from zero even when the total effect is not (pp. 117-119).<br />
</li>
</ul></li>
<li>The output we get is different from the output in the journal article being used as the research vignette. Why? And should we worry about it?
<ul>
<li>We are simulating data. This gives us some advantages in that (unless we specify it), we never have missingness and our variables should be normally distributed. Because we are working from means, standard deviations, and correlations, our data will never be the same as the original researcher. That said, we can compare our results to the journal to <em>check out work.</em> In fact, in this very chapter, I got turned around (e.g., first accidentally swapping the mediator and IV; then using the wrong DV) and was able to compare my work against the journal article to correct my errors.</li>
</ul></li>
<li>Some of the statistics you are reporting are different than the ones in Hayes and the ones that use the PROCESS macro (e.g., what happened to the <em>F</em> test)?
<ul>
<li>The default estimator for <em>lavaan</em> is maximum likelihood (ML) and Hayes uses ordinary least squares (OLS). This affects both the values of coefficients, standard errors, AND the type of statistics that are reported.</li>
<li>You can ask for OLS regression by adding the statement “estimator =”GLS". Even with this option, I have not discovered a way to obtain the <em>F</em> tests for the overall model. Researchers seem to be comfortable with this, even asking for less than we did (e.g., many do not request R square).</li>
<li>Best I can tell, researchers who do want this might use a combination of packages, using GLS estimators in <em>lavaan</em> (this easily gets them the bootstrapped CIs) and the move to a different regression package to get the intercepts and <em>F</em> tests. If I did this I would triple check to make sure that all the output really lined up.</li>
</ul></li>
<li>Why did we ignore the traditional fit statistics associated with structural equation modeling (e.g., CFI, RMSEA).
<ul>
<li>I hesitate to do this with models that do not include latent variables. Therefore, we asked for an “in-between” amount of info that should be sufficient for publication submission (any editor may have their own preferences and ask for more).</li>
</ul></li>
<li>What if I have missing data?
<ul>
<li>When we enter the <em>lavaan</em> world we do get options other than multiple imputation. In today’s example we used the “sem” fitting function. Unless otherwise specified, listwise deletion (deleting the entire case when one of its variables is used to estimate the model) is the default in <em>lavaan</em>. If data are MCAR or MAR, you can add the argument <em>missing = “ml”</em> (or its alias <em>missing = “fiml”</em>). More here <a href="https://users.ugent.be/~yrosseel/lavaan/lavaan2.pdf" class="uri">https://users.ugent.be/~yrosseel/lavaan/lavaan2.pdf</a> on the 1.7/Missing data in lavaan slide.</li>
<li>That said, the type of estimator matters. If you estimate your data with GLS (generalized least squares) or WLS (weighted least squares), you are required to have complete data (however you got it). We used maximum likelihood and, even though we had non-missing data, I used the <em>missing = “fiml”</em> code.</li>
</ul></li>
</ol>
</div>
<div id="practice-problems-4" class="section level2" number="6.8">
<h2 number="6.8"><span class="header-section-number">6.8</span> Practice Problems</h2>
<p>The three problems described below are designed to grow with the subsequent chapters on complex mediation and conditional process analysis (i.e,. moderated mediation). Therefore, I recommend that you select a dataset that includes at least four variables. If you are new to this topic, you may wish to select variables that are all continuously scaled. The IV and moderator (subsequent chapters) could be categorical (if they are dichotomous, please use 0/1 coding; if they have more than one category it is best if they are ordered). You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.</p>
<p>The suggested practice problem for this chapter is to conduct a simple mediation.</p>
<div id="problem-1-rework-the-research-vignette-as-demonstrated-but-change-the-random-seed" class="section level3" number="6.8.1">
<h3 number="6.8.1"><span class="header-section-number">6.8.1</span> Problem #1: Rework the research vignette as demonstrated, but change the random seed</h3>
<p>If this topic feels a bit overwhelming, simply change the random seed in the data simulation, then rework the problem. This should provide minor changes to the data (maybe in the second or third decimal point), but the results will likely be very similar.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, or M roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes regression output for the M and Y variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-2-rework-the-research-vignette-but-swap-one-or-more-variables" class="section level3" number="6.8.2">
<h3 number="6.8.2"><span class="header-section-number">6.8.2</span> Problem #2: Rework the research vignette, but swap one or more variables</h3>
<p>Use the simulated data, but select one of the other models that was evaluated in the Kim et al. <span class="citation">(<a href="#ref-kim_racial_2017" role="doc-biblioref">2017</a>)</span> study. Compare your results to those reported in the mansucript.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, or M roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes regression output for the M and Y variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-3-use-other-data-that-is-available-to-you" class="section level3" number="6.8.3">
<h3 number="6.8.3"><span class="header-section-number">6.8.3</span> Problem #3: Use other data that is available to you</h3>
<p>Using data for which you have permission and access (e.g., IRB approved data you have collected or from your lab; data you simulate from a published article; data from an open science repository; data from other chapters in this OER), complete a simple mediation.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, or M roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes regression output for the M and Y variables</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb214-1"><a href="#cb214-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] MASS_7.3-53.1     semTable_1.8      semPlot_1.1.2     lavaan_0.6-8     
##  [5] apaTables_2.0.8   mice_3.13.0       sjstats_0.18.1    formattable_0.2.1
##  [9] qualtRics_3.1.4   forcats_0.5.1     stringr_1.4.0     dplyr_1.0.5      
## [13] purrr_0.3.4       readr_1.4.0       tidyr_1.1.3       tibble_3.1.1     
## [17] ggplot2_3.3.3     tidyverse_1.3.1   psych_2.1.3      
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1        backports_1.2.1     Hmisc_4.5-0        
##   [4] systemfonts_1.0.1   igraph_1.2.6        plyr_1.8.6         
##   [7] splines_4.0.4       TH.data_1.0-10      digest_0.6.27      
##  [10] htmltools_0.5.1.1   matrixcalc_1.0-3    fansi_0.4.2        
##  [13] magrittr_2.0.1      Rsolnp_1.16         checkmate_2.0.0    
##  [16] lisrelToR_0.1.4     cluster_2.1.2       openxlsx_4.2.3     
##  [19] modelr_0.1.8        sandwich_3.0-0      svglite_2.0.0      
##  [22] jpeg_0.1-8.1        sem_3.1-11          MBESS_4.8.0        
##  [25] colorspace_2.0-0    rvest_1.0.0         haven_2.4.1        
##  [28] xfun_0.22           crayon_1.4.1        jsonlite_1.7.2     
##  [31] lme4_1.1-26         regsem_1.6.2        survival_3.2-11    
##  [34] zoo_1.8-9           glue_1.4.2          gtable_0.3.0       
##  [37] emmeans_1.6.0       mi_1.0              sjmisc_2.8.6       
##  [40] abind_1.4-5         scales_1.1.1        mvtnorm_1.1-1      
##  [43] DBI_1.1.1           Rcpp_1.0.6          xtable_1.8-4       
##  [46] performance_0.7.1   htmlTable_2.1.0     tmvnsim_1.0-2      
##  [49] foreign_0.8-81      Formula_1.2-4       stats4_4.0.4       
##  [52] truncnorm_1.0-8     htmlwidgets_1.5.3   httr_1.4.2         
##  [55] RColorBrewer_1.1-2  ellipsis_0.3.1      XML_3.99-0.6       
##  [58] pkgconfig_2.0.3     nnet_7.3-15         sass_0.3.1         
##  [61] kutils_1.70         dbplyr_2.1.1        utf8_1.2.1         
##  [64] reshape2_1.4.4      tidyselect_1.1.1    rlang_0.4.11       
##  [67] effectsize_0.4.4-1  munsell_0.5.0       cellranger_1.1.0   
##  [70] tools_4.0.4         cli_2.5.0           generics_0.1.0     
##  [73] sjlabelled_1.1.7    broom_0.7.6         fdrtool_1.2.16     
##  [76] evaluate_0.14       arm_1.11-2          yaml_2.2.1         
##  [79] knitr_1.33          fs_1.5.0            stationery_0.98.30 
##  [82] zip_2.1.1           glasso_1.11         pbapply_1.4-3      
##  [85] nlme_3.1-151        xml2_1.3.2          compiler_4.0.4     
##  [88] rstudioapi_0.13     curl_4.3.1          png_0.1-7          
##  [91] reprex_2.0.0        statmod_1.4.35      bslib_0.2.4        
##  [94] pbivnorm_0.6.0      stringi_1.5.3       highr_0.9          
##  [97] parameters_0.13.0   qgraph_1.6.9        rockchalk_1.8.144  
## [100] lattice_0.20-41     Matrix_1.2-18       nloptr_1.2.2.2     
## [103] vctrs_0.3.7         pillar_1.6.0        lifecycle_1.0.0    
## [106] jquerylib_0.1.4     OpenMx_2.19.5       estimability_1.3   
## [109] corpcor_1.6.9       data.table_1.14.0   insight_0.13.2     
## [112] R6_2.5.0            latticeExtra_0.6-29 bookdown_0.22      
## [115] gridExtra_2.3       codetools_0.2-18    gtools_3.8.2       
## [118] boot_1.3-27         assertthat_0.2.1    withr_2.4.2        
## [121] mnormt_2.0.2        multcomp_1.4-17     bayestestR_0.9.0   
## [124] parallel_4.0.4      hms_1.0.0           grid_4.0.4         
## [127] rpart_4.1-15        coda_0.19-4         minqa_1.2.4        
## [130] rmarkdown_2.7       carData_3.0-4       lubridate_1.7.10   
## [133] base64enc_0.1-3</code></pre>
<!--chapter:end:06-SimpleMed.Rmd-->
</div>
</div>
</div>
<div id="CompMed" class="section level1" number="7">
<h1 number="7"><span class="header-section-number">7</span> Complex Mediation</h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=6991fd3d-22b6-44f5-ab5b-ad1000314b7f">Screencasted Lecture Link</a></p>
<p>The focus of this chapter is the extension of simple mediation to models with multiple mediatrs. In these models with greater complexity we look at both parallel and serial mediation. There is also more elaboration on some of the conceptual issues related to the estimation of indirect effects.</p>
<div id="navigating-this-lesson-5" class="section level2" number="7.1">
<h2 number="7.1"><span class="header-section-number">7.1</span> Navigating this Lesson</h2>
<p>There is about 1 hour and 20 minutes of lecture. If you work through the materials with me it would be plan for an additional two hours.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, there are a few that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_MultivariateModeling">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="#ReCintro">introduction</a></p>
<div id="learning-objectives-5" class="section level3" number="7.1.1">
<h3 number="7.1.1"><span class="header-section-number">7.1.1</span> Learning Objectives</h3>
<p>Learning objectives from this lecture include the following:</p>
<ul>
<li>Define <em>epiphenomality</em> and explain how it is related to (and supports the notion of) multiple mediation.</li>
<li>Distinguish between parallel and serial mediation models.</li>
<li>Locate and interpret <em>lavaan</em> output from multiply mediated models including</li>
<li>identifying coefficients,</li>
<li>percentage of variance accounted for,<br />
</li>
<li>all the effects (total, direct, indirec. total indirect),</li>
<li>contrasts.</li>
<li>Explain the limitations of the classic approach <span class="citation">(<a href="#ref-baron_moderator-mediator_1986" role="doc-biblioref">Baron &amp; Kenny, 1986</a>)</span> to mediation.</li>
</ul>
</div>
<div id="planning-for-practice-5" class="section level3" number="7.1.2">
<h3 number="7.1.2"><span class="header-section-number">7.1.2</span> Planning for Practice</h3>
<p>The suggestions for practice in this chapter include conducting parallel, serial, and/or mediation models. Options of graded complexity could incude:</p>
<ul>
<li>Rework the problem in the chapter by changing the random seed in the code that simulates the data. This should provide minor changes to the data, but the results will likely be very similar.</li>
<li>There are a number of variables in the dataset that sourced the research vignettes for this and the prior chapter on <a href="#SimpleMed">simple mediation</a>. Swap out one or more variables in a parallel or serial (or both) model.</li>
<li>Conduct a parallel or serial (or both) mediation with data to which you have access. This could include data you simulate on your own or from a published article.</li>
</ul>
</div>
<div id="readings-resources-5" class="section level3" number="7.1.3">
<h3 number="7.1.3"><span class="header-section-number">7.1.3</span> Readings &amp; Resources</h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<ul>
<li>Hayes, A. F. (2018). <em>Introduction to mediation, moderation, and conditional process anlaysis: A regression-based approach</em>. New York, NY: Guilford Press. Available as an ebook from the SPU library: <a href="https://ebookcentral-proquest-com.ezproxy.spu.edu/lib/spu/detail.action?docID=5109647" class="uri">https://ebookcentral-proquest-com.ezproxy.spu.edu/lib/spu/detail.action?docID=5109647</a>
<ul>
<li><strong>Chapter 5: More than One Mediator</strong>: This chapter walks the reader through parallel and serial mediation models. We will do both!</li>
<li><strong>Appendix A: Using Process</strong>: An essential tool for PROCESS users because, even when we are in the R environment, this is the “idea book.” That is, the place where all the path models are presented in figures.</li>
</ul></li>
<li>Lewis, J. A., Williams, M. G., Peppers, E. J., &amp; Gadson, C. A. (2017). Applying intersectionality to explore the relations between gendered racism and health among Black women. <em>Journal of Counseling Psychology</em>, <em>64</em>(5), 475–486. <a href="https://doi-org.ezproxy.spu.edu/10.1037/cou0000231" class="uri">https://doi-org.ezproxy.spu.edu/10.1037/cou0000231</a></li>
</ul>
</div>
<div id="packages-6" class="section level3" number="7.1.4">
<h3 number="7.1.4"><span class="header-section-number">7.1.4</span> Packages</h3>
<p>The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<!-- TODO: Build out this section. -->
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="co">#will install the package if not already installed</span></span>
<span id="cb216-2"><a href="#cb216-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(lavaan)){<span class="fu">install.packages</span>(<span class="st">&quot;lavaan&quot;</span>)}</span>
<span id="cb216-3"><a href="#cb216-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(semPlot)){<span class="fu">install.packages</span>(<span class="st">&quot;semPlot&quot;</span>)}</span>
<span id="cb216-4"><a href="#cb216-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(tidyverse)){<span class="fu">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>)}</span>
<span id="cb216-5"><a href="#cb216-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(psych)){<span class="fu">install.packages</span>(<span class="st">&quot;psych&quot;</span>)}</span>
<span id="cb216-6"><a href="#cb216-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(apaTables)){<span class="fu">install.packages</span>(<span class="st">&quot;apaTables&quot;</span>)}</span>
<span id="cb216-7"><a href="#cb216-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(formattable)){<span class="fu">install.packages</span>(<span class="st">&quot;formattable&quot;</span>)}</span></code></pre></div>
</div>
</div>
<div id="complex-mediation" class="section level2" number="7.2">
<h2 number="7.2"><span class="header-section-number">7.2</span> Complex Mediation</h2>
<p>The simple mediation model is quite popular, but also limiting in that it:</p>
<ul>
<li>frequently oversimplifies the processes we want to study, and</li>
<li>is likely mis-specified, in that there are unmodeled mechanisms.</li>
</ul>
<p>Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> identified four reasons to consider multiply mediated models:</p>
<ul>
<li>We are generally interested in MULTIPLE mechanisms</li>
<li>A mechanism (such as a mediator) in the model, might, itself be mediated (i.e., mediated mediation)</li>
<li><em>Epiphenomenality</em> (“unknown confounds”): a proposed mediator could be related to an outcome not because it causes the outcome, but because it is correlated with another variable that is causally influencing the outcome. This is a noncausal alternative explanation for an association.</li>
<li>Including multiple mediators allows formal comparison of the strength of the mediating mechanisms.</li>
</ul>
<p>There are two multiple mediator models that we will consider: parallel, serial.</p>
</div>
<div id="parallel-mediation" class="section level2" number="7.3">
<h2 number="7.3"><span class="header-section-number">7.3</span> Parallel Mediation</h2>
<p><strong>Parallel multiple mediation</strong>: An antecedent variable X is modeled as influencing consequent Y directly as well as indirectly through two or more mediators, with the condition that no mediator causally influences another <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">Hayes, 2018, p. 149</a>)</span></p>
<p>With multiple mediation we introduce additional effects:</p>
<ul>
<li><em>Direct effect</em>, <span class="math inline">\(c&#39;\)</span> (this is not new) quantifies how much two cases that differ by a unit on X are estimated to differ on Y – independent of all mediators.</li>
<li><em>Specific indirect effect</em>, <span class="math inline">\(a_{i}b_{i}\)</span>, the individual mediated effects</li>
<li><em>Total indirect effects </em>, <span class="math inline">\(\sum_{i=1}^{k}a_{i}b_{i}\)</span> the sum of the values of the specific indirect effects. The total indirect effect can also be calculated by subtracting the direct effects from the total effects: <span class="math inline">\(c - c&#39;\)</span></li>
<li><em>Total effect of X on Y</em>, <span class="math inline">\(c = c&#39; + \sum_{i=1}^{k}a_{i}b_{i}\)</span> (also not new) the sum of the direct and indirect effects. The total effect can also be estimated by regressing Y on X alone.</li>
<li><em>Contrasts</em> allow us to directly compare separate mediating effects to see if one indirect effect is stronger than the other.</li>
</ul>
<p><img src="images/CompMed/ParaMed.jpg" alt="An image of the conceptual and statistical models of parallel mediation" />
In this parallel model, we can describe these effects this way:</p>
<ul>
<li><em>Direct effect</em>: The effect of IV on the DV, accounting for two mediators (indirect effects) in the model.</li>
<li><em>Specific indirect effects</em>: There are indirect (or mediating) paths from the IV to the DV; through M1 and M2, respectively.</li>
<li><em>Total indirect effect of X on Y</em>: A sum of the value of indirect effects through the specific indirect effects (M1 and M2).</li>
<li><em>Total effect</em>: The sum of the direct and indirect effects. Also calculated by regressing Y (dependent variable) on X (independent variable) alone, without any other variables in the model.</li>
</ul>
<p>Recall that for a complex mediation to be parallel, there can be no causal links between mediators. This is true in this example.</p>
<p>As before, let’s work a mechanical example with simulated data that assures a statistically significant outcome. Credit to this example is from the PAULOTOFFANIN website <span class="citation">(<a href="#ref-toffanin_multiple-mediator_2017" role="doc-biblioref">Toffanin, 2017</a>)</span>.</p>
<div id="a-mechanical-example" class="section level3" number="7.3.1">
<h3 number="7.3.1"><span class="header-section-number">7.3.1</span> A Mechanical Example</h3>
<p>We can bake our own data by updating the script we used in simple mediation to add a second mediator.</p>
<div id="data-simulation" class="section level4" number="7.3.1.1">
<h4 number="7.3.1.1"><span class="header-section-number">7.3.1.1</span> Data Simulation</h4>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Concerned that identical variable names across book chapters may be problematic, I&#39;m adding &quot;p&quot; in front the &quot;Data&quot; variable.</span></span>
<span id="cb217-2"><a href="#cb217-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210417</span>)</span>
<span id="cb217-3"><a href="#cb217-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb217-4"><a href="#cb217-4" aria-hidden="true" tabindex="-1"></a>M1 <span class="ot">&lt;-</span> <span class="fl">0.5</span><span class="sc">*</span>X <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb217-5"><a href="#cb217-5" aria-hidden="true" tabindex="-1"></a>M2 <span class="ot">&lt;-</span> <span class="sc">-</span><span class="fl">0.35</span><span class="sc">*</span>X <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb217-6"><a href="#cb217-6" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fl">0.7</span><span class="sc">*</span>M2 <span class="sc">+</span> <span class="fl">0.48</span><span class="sc">*</span>M1 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb217-7"><a href="#cb217-7" aria-hidden="true" tabindex="-1"></a>pData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">X =</span> X, <span class="at">Y =</span> Y, <span class="at">M1 =</span> M1, <span class="at">M2 =</span> M2)</span></code></pre></div>
<p>Using what we learned in conducting a simple mediation in <em>lavaan</em>, we can look at the figure of our proposed model and <em>backwardstrace</em> the paths to write the code.</p>
<p>Remember…</p>
<ul>
<li><p>The model exists between 2 single quotation marks (the odd looking ’ and ’ at the beginning and end).</p></li>
<li><p>You can write the Y as I have done in the R chunk below, or you can write the Y separately from each arrow, such as</p>
<ul>
<li>Y ~ b1*M1</li>
<li>Y ~ b2*M2</li>
<li>Y ~ c_p*X</li>
</ul></li>
<li><p>Everything else transfers from our simple mediation, remember that</p>
<ul>
<li>the asterisk ("*") allows us to assign labels (a1, a2, b1, b2, etc.) to the paths; these are helpful for intuitive interpretation</li>
<li>that eyes/nose notation (:=) is used when creating a new variable that is a function of variables in the model, but not in the dataset (i.e., the a and b path).</li>
<li>in traditional mediation speak, the direct path from X to Y is c’ (c prime) and the total effect of X to Y (with nothing else in the model) is just c. Hence the c_p label for c prime.</li>
</ul></li>
<li><p>Something new: the <em>contrast</em> statement (only one in this example, but you could have more) allows us to compare the indirect effects to each other. We specify it in the lavaan model, but then need to test it in a subsequent set of script.</p></li>
<li><p><em>Note</em>: In the online example, the writer adds code to correlate M1 and M2. This didn’t/doesn’t seem right to me and then, later, when we amend it to be a serial model, it made even less sense to have them be correlated.</p></li>
</ul>
</div>
<div id="specifying-lavaan-code" class="section level4" number="7.3.1.2">
<h4 number="7.3.1.2"><span class="header-section-number">7.3.1.2</span> Specifying <em>lavaan</em> code</h4>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210418</span>)</span>
<span id="cb218-3"><a href="#cb218-3" aria-hidden="true" tabindex="-1"></a>parallel_med <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb218-4"><a href="#cb218-4" aria-hidden="true" tabindex="-1"></a><span class="st">    Y ~ b1*M1 + b2*M2 + c_p*X</span></span>
<span id="cb218-5"><a href="#cb218-5" aria-hidden="true" tabindex="-1"></a><span class="st">    M1 ~ a1*X</span></span>
<span id="cb218-6"><a href="#cb218-6" aria-hidden="true" tabindex="-1"></a><span class="st">    M2 ~ a2*X</span></span>
<span id="cb218-7"><a href="#cb218-7" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect1 := a1 * b1</span></span>
<span id="cb218-8"><a href="#cb218-8" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect2 := a2 * b2</span></span>
<span id="cb218-9"><a href="#cb218-9" aria-hidden="true" tabindex="-1"></a><span class="st">    contrast := indirect1 - indirect2</span></span>
<span id="cb218-10"><a href="#cb218-10" aria-hidden="true" tabindex="-1"></a><span class="st">    total_indirects := indirect1 + indirect2</span></span>
<span id="cb218-11"><a href="#cb218-11" aria-hidden="true" tabindex="-1"></a><span class="st">    total_c    := c_p + (indirect1) + (indirect2)</span></span>
<span id="cb218-12"><a href="#cb218-12" aria-hidden="true" tabindex="-1"></a><span class="st">    direct := c_p</span></span>
<span id="cb218-13"><a href="#cb218-13" aria-hidden="true" tabindex="-1"></a><span class="st"> &#39;</span></span>
<span id="cb218-14"><a href="#cb218-14" aria-hidden="true" tabindex="-1"></a>parallel_fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(parallel_med, <span class="at">data =</span> pData, <span class="at">se =</span> <span class="st">&quot;bootstrap&quot;</span>, <span class="at">missing =</span> <span class="st">&#39;fiml&#39;</span>, <span class="at">bootstrap =</span> <span class="dv">1000</span>)</span>
<span id="cb218-15"><a href="#cb218-15" aria-hidden="true" tabindex="-1"></a>pfit_sum <span class="ot">&lt;-</span> <span class="fu">summary</span>(parallel_fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">rsq=</span>T, <span class="at">fit=</span><span class="cn">TRUE</span>, <span class="at">ci=</span><span class="cn">TRUE</span>)    </span></code></pre></div>
<pre><code>## lavaan 0.6-8 ended normally after 16 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        11
##                                                       
##   Number of observations                           100
##   Number of missing patterns                         1
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                 0.095
##   Degrees of freedom                                 1
##   P-value (Chi-square)                           0.757
## 
## Model Test Baseline Model:
## 
##   Test statistic                                91.109
##   Degrees of freedom                                 6
##   P-value                                        0.000
## 
## User Model versus Baseline Model:
## 
##   Comparative Fit Index (CFI)                    1.000
##   Tucker-Lewis Index (TLI)                       1.064
## 
## Loglikelihood and Information Criteria:
## 
##   Loglikelihood user model (H0)               -425.933
##   Loglikelihood unrestricted model (H1)       -425.885
##                                                       
##   Akaike (AIC)                                 873.866
##   Bayesian (BIC)                               902.522
##   Sample-size adjusted Bayesian (BIC)          867.782
## 
## Root Mean Square Error of Approximation:
## 
##   RMSEA                                          0.000
##   90 Percent confidence interval - lower         0.000
##   90 Percent confidence interval - upper         0.181
##   P-value RMSEA &lt;= 0.05                          0.785
## 
## Standardized Root Mean Square Residual:
## 
##   SRMR                                           0.009
## 
## Parameter Estimates:
## 
##   Standard errors                            Bootstrap
##   Number of requested bootstrap draws             1000
##   Number of successful bootstrap draws            1000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##   Y ~                                                                   
##     M1        (b1)    0.540    0.113    4.787    0.000    0.314    0.769
##     M2        (b2)    0.690    0.111    6.204    0.000    0.470    0.889
##     X        (c_p)    0.105    0.137    0.771    0.441   -0.164    0.373
##   M1 ~                                                                  
##     X         (a1)    0.528    0.111    4.745    0.000    0.315    0.756
##   M2 ~                                                                  
##     X         (a2)   -0.324    0.105   -3.093    0.002   -0.540   -0.116
##    Std.lv  Std.all
##                   
##     0.540    0.478
##     0.690    0.529
##     0.105    0.074
##                   
##     0.528    0.419
##                   
##    -0.324   -0.297
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .Y                -0.187    0.102   -1.843    0.065   -0.394   -0.000
##    .M1                0.010    0.109    0.094    0.925   -0.212    0.216
##    .M2               -0.043    0.101   -0.428    0.668   -0.244    0.150
##    Std.lv  Std.all
##    -0.187   -0.142
##     0.010    0.009
##    -0.043   -0.043
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .Y                 0.948    0.151    6.275    0.000    0.644    1.242
##    .M1                1.131    0.120    9.398    0.000    0.889    1.360
##    .M2                0.938    0.125    7.475    0.000    0.676    1.166
##    Std.lv  Std.all
##     0.948    0.542
##     1.131    0.825
##     0.938    0.912
## 
## R-Square:
##                    Estimate
##     Y                 0.458
##     M1                0.175
##     M2                0.088
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     indirect1         0.285    0.085    3.355    0.001    0.129    0.465
##     indirect2        -0.224    0.079   -2.828    0.005   -0.394   -0.080
##     contrast          0.509    0.117    4.339    0.000    0.289    0.756
##     total_indircts    0.061    0.115    0.533    0.594   -0.158    0.291
##     total_c           0.167    0.158    1.052    0.293   -0.151    0.483
##     direct            0.105    0.137    0.771    0.441   -0.164    0.373
##    Std.lv  Std.all
##     0.285    0.200
##    -0.224   -0.157
##     0.509    0.357
##     0.061    0.043
##     0.167    0.117
##     0.105    0.074</code></pre>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>pfit_ParEsts <span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(parallel_fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span>
<span id="cb220-2"><a href="#cb220-2" aria-hidden="true" tabindex="-1"></a>pfit_sum</span></code></pre></div>
<pre><code>## $FIT
##              npar              fmin             chisq                df 
##            11.000             0.000             0.095             1.000 
##            pvalue    baseline.chisq       baseline.df   baseline.pvalue 
##             0.757            91.109             6.000             0.000 
##               cfi               tli              logl unrestricted.logl 
##             1.000             1.064          -425.933          -425.885 
##               aic               bic            ntotal              bic2 
##           873.866           902.522           100.000           867.782 
##             rmsea    rmsea.ci.lower    rmsea.ci.upper      rmsea.pvalue 
##             0.000             0.000             0.181             0.785 
##              srmr 
##             0.009 
## 
## $PE
##                lhs op                         rhs           label exo
## 1                Y  ~                          M1              b1   0
## 2                Y  ~                          M2              b2   0
## 3                Y  ~                           X             c_p   0
## 4               M1  ~                           X              a1   0
## 5               M2  ~                           X              a2   0
## 6                Y ~~                           Y                   0
## 7               M1 ~~                          M1                   0
## 8               M2 ~~                          M2                   0
## 9                X ~~                           X                   1
## 10               Y ~1                                               0
## 11              M1 ~1                                               0
## 12              M2 ~1                                               0
## 13               X ~1                                               1
## 14       indirect1 :=                       a1*b1       indirect1   0
## 15       indirect2 :=                       a2*b2       indirect2   0
## 16        contrast :=         indirect1-indirect2        contrast   0
## 17 total_indirects :=         indirect1+indirect2 total_indirects   0
## 18         total_c := c_p+(indirect1)+(indirect2)         total_c   0
## 19          direct :=                         c_p          direct   0
## 20               Y r2                           Y                   0
## 21              M1 r2                          M1                   0
## 22              M2 r2                          M2                   0
##             est         se           z       pvalue     ci.lower      ci.upper
## 1   0.539767993 0.11274814  4.78737823 1.689742e-06  0.313843559  0.7689409032
## 2   0.689953781 0.11121140  6.20398416 5.505132e-10  0.470226008  0.8889490507
## 3   0.105290636 0.13651696  0.77126415 4.405504e-01 -0.164108640  0.3729922725
## 4   0.527902465 0.11124423  4.74543702 2.080566e-06  0.315477913  0.7556891595
## 5  -0.324244632 0.10484432 -3.09262959 1.983916e-03 -0.539732116 -0.1162331922
## 6   0.947724641 0.15103546  6.27484860 3.499747e-10  0.644485452  1.2418345927
## 7   1.130774696 0.12032086  9.39799366 0.000000e+00  0.889499232  1.3599755402
## 8   0.937829247 0.12546927  7.47457301 7.749357e-14  0.675554155  1.1664102455
## 9   0.861707097 0.00000000          NA           NA  0.861707097  0.8617070970
## 10 -0.187153801 0.10152756 -1.84337931 6.527365e-02 -0.393783206 -0.0003186578
## 11  0.010201774 0.10903660  0.09356284 9.254564e-01 -0.211921383  0.2157226430
## 12 -0.043300480 0.10110370 -0.42827788 6.684488e-01 -0.243658750  0.1499584876
## 13  0.009968596 0.00000000          NA           NA  0.009968596  0.0099685964
## 14  0.284944854 0.08493462  3.35487276 7.940150e-04  0.128745673  0.4653026012
## 15 -0.223713810 0.07910773 -2.82796394 4.684508e-03 -0.394065828 -0.0796967852
## 16  0.508658664 0.11721760  4.33943942 1.428466e-05  0.288663004  0.7559242433
## 17  0.061231044 0.11490814  0.53286949 5.941239e-01 -0.158441194  0.2912145292
## 18  0.166521681 0.15830894  1.05187793 2.928556e-01 -0.150959419  0.4832956301
## 19  0.105290636 0.13658527  0.77087842 4.407790e-01 -0.164108640  0.3729922725
## 20  0.457671604         NA          NA           NA           NA            NA
## 21  0.175168565         NA          NA           NA           NA            NA
## 22  0.088091268         NA          NA           NA           NA            NA
##          std.lv      std.all      std.nox
## 1   0.539767993  0.478082287  0.478082287
## 2   0.689953781  0.529293162  0.529293162
## 3   0.105290636  0.073936633  0.079648910
## 4   0.527902465  0.418531438  0.450866794
## 5  -0.324244632 -0.296801732 -0.319732362
## 6   0.947724641  0.542328396  0.542328396
## 7   1.130774696  0.824831435  0.824831435
## 8   0.937829247  0.911908732  0.911908732
## 9   0.861707097  1.000000000  0.861707097
## 10 -0.187153801 -0.141575707 -0.141575707
## 11  0.010201774  0.008713051  0.008713051
## 12 -0.043300480 -0.042697900 -0.042697900
## 13  0.009968596  0.010738761  0.009968596
## 14  0.284944854  0.200092467  0.215551428
## 15 -0.223713810 -0.157095127 -0.169232153
## 16  0.508658664  0.357187594  0.384783581
## 17  0.061231044  0.042997340  0.046319275
## 18  0.166521681  0.116933973  0.125968185
## 19  0.105290636  0.073936633  0.079648910
## 20           NA           NA           NA
## 21           NA           NA           NA
## 22           NA           NA           NA</code></pre>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a>pfit_ParEsts</span></code></pre></div>
<pre><code>##                lhs op                         rhs           label    est    se
## 1                Y  ~                          M1              b1  0.540 0.113
## 2                Y  ~                          M2              b2  0.690 0.111
## 3                Y  ~                           X             c_p  0.105 0.137
## 4               M1  ~                           X              a1  0.528 0.111
## 5               M2  ~                           X              a2 -0.324 0.105
## 6                Y ~~                           Y                  0.948 0.151
## 7               M1 ~~                          M1                  1.131 0.120
## 8               M2 ~~                          M2                  0.938 0.125
## 9                X ~~                           X                  0.862 0.000
## 10               Y ~1                                             -0.187 0.102
## 11              M1 ~1                                              0.010 0.109
## 12              M2 ~1                                             -0.043 0.101
## 13               X ~1                                              0.010 0.000
## 14       indirect1 :=                       a1*b1       indirect1  0.285 0.085
## 15       indirect2 :=                       a2*b2       indirect2 -0.224 0.079
## 16        contrast :=         indirect1-indirect2        contrast  0.509 0.117
## 17 total_indirects :=         indirect1+indirect2 total_indirects  0.061 0.115
## 18         total_c := c_p+(indirect1)+(indirect2)         total_c  0.167 0.158
## 19          direct :=                         c_p          direct  0.105 0.137
##         z pvalue ci.lower ci.upper std.lv std.all std.nox
## 1   4.787  0.000    0.331    0.791  0.540   0.478   0.478
## 2   6.204  0.000    0.467    0.888  0.690   0.529   0.529
## 3   0.771  0.441   -0.177    0.362  0.105   0.074   0.080
## 4   4.745  0.000    0.317    0.758  0.528   0.419   0.451
## 5  -3.093  0.002   -0.558   -0.120 -0.324  -0.297  -0.320
## 6   6.275  0.000    0.697    1.322  0.948   0.542   0.542
## 7   9.398  0.000    0.923    1.394  1.131   0.825   0.825
## 8   7.475  0.000    0.703    1.201  0.938   0.912   0.912
## 9      NA     NA    0.862    0.862  0.862   1.000   0.862
## 10 -1.843  0.065   -0.388    0.003 -0.187  -0.142  -0.142
## 11  0.094  0.925   -0.219    0.212  0.010   0.009   0.009
## 12 -0.428  0.668   -0.249    0.144 -0.043  -0.043  -0.043
## 13     NA     NA    0.010    0.010  0.010   0.011   0.010
## 14  3.355  0.001    0.143    0.489  0.285   0.200   0.216
## 15 -2.828  0.005   -0.399   -0.088 -0.224  -0.157  -0.169
## 16  4.339  0.000    0.295    0.785  0.509   0.357   0.385
## 17  0.533  0.594   -0.151    0.306  0.061   0.043   0.046
## 18  1.052  0.293   -0.162    0.463  0.167   0.117   0.126
## 19  0.771  0.441   -0.177    0.362  0.105   0.074   0.080</code></pre>
</div>
<div id="a-note-on-indirect-effects-and-confidence-intervals" class="section level4" number="7.3.1.3">
<h4 number="7.3.1.3"><span class="header-section-number">7.3.1.3</span> A note on indirect effects and confidence intervals</h4>
<p>Before we move onto interpretation, I want to stop and look at both <span class="math inline">\(p\)</span> values and confidence intervals. Especially with Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> PROCESS macro, there is a great deal of emphasis on the use of bootstrapped confidence intervals to determine the statistical significance of the indirect effects. In fact, PROCESS output has (at least historically) not provided <span class="math inline">\(p\)</span> values with the indirect effects. This is because, especially in the ordinary least squares context, bias-corrected bootstrapped confidence intervals are more powerful (i.e., they are more likely to support a statistically significant result) than <span class="math inline">\(p\)</span> values.</p>
<p>An excellent demonstration of this phenomena was provided by Mallinckrodt et al. <span class="citation">(<a href="#ref-mallinckrodt_advances_2006" role="doc-biblioref">2006</a>)</span> where they compared confidence intervals produced by the normal theory method to those that are bias corrected. The bias corrected intervals were more powerful to determining if there were statistically significant indirect effects.</p>
<p>The method we have specified in <em>lavaan</em> produced bias-corrected confidence intervals. The <span class="math inline">\(p\)</span> values and corresponding confidence intervals should be consistent with each other. That is, if <span class="math inline">\(p\)</span> &lt; .05, then the CI95s should not pass through zero. Of course we can always check to be certain this is true. For this reason, I will report <span class="math inline">\(p\)</span> values in my results. There are reviewers, though, who may prefer that you report CI95s (or both).</p>
</div>
<div id="figures-and-tables" class="section level4" number="7.3.1.4">
<h4 number="7.3.1.4"><span class="header-section-number">7.3.1.4</span> Figures and Tables</h4>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semTable)</span>
<span id="cb224-2"><a href="#cb224-2" aria-hidden="true" tabindex="-1"></a>Tb1FDataparallel <span class="ot">&lt;-</span> <span class="fu">semTable</span>(parallel_fit, <span class="at">columns =</span> <span class="fu">c</span>(<span class="st">&quot;est&quot;</span>, <span class="st">&quot;se&quot;</span>, <span class="st">&quot;p&quot;</span>, <span class="st">&quot;rsquare&quot;</span>),  <span class="at">columnLabels =</span> <span class="fu">c</span>(<span class="at">eststars =</span> <span class="st">&quot;Estimate&quot;</span>), <span class="at">paramSets =</span> <span class="fu">c</span>(<span class="st">&quot;composites&quot;</span>, <span class="st">&quot;loadings&quot;</span>, <span class="st">&quot;slopes&quot;</span>, <span class="st">&quot;intercepts&quot;</span>, <span class="st">&quot;residualvariances&quot;</span>), <span class="at">file =</span> <span class="st">&quot;Tb1FakyDataparallel&quot;</span>, <span class="at">type =</span> <span class="st">&quot;csv&quot;</span>, <span class="at">print.results =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb225-2"><a href="#cb225-2" aria-hidden="true" tabindex="-1"></a><span class="co">#note change in layout </span></span>
<span id="cb225-3"><a href="#cb225-3" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(parallel_fit, <span class="co">#must identiy the model you want to map</span></span>
<span id="cb225-4"><a href="#cb225-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb225-5"><a href="#cb225-5" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb225-6"><a href="#cb225-6" aria-hidden="true" tabindex="-1"></a>         <span class="co">#layout = &#39;tree&#39;, rotation = 2, #together, puts predictors on left, IVs on right </span></span>
<span id="cb225-7"><a href="#cb225-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;spring&#39;</span>, </span>
<span id="cb225-8"><a href="#cb225-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb225-9"><a href="#cb225-9" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb225-10"><a href="#cb225-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb225-11"><a href="#cb225-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb225-12"><a href="#cb225-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb225-13"><a href="#cb225-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb225-14"><a href="#cb225-14" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb225-15"><a href="#cb225-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb225-16"><a href="#cb225-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb225-17"><a href="#cb225-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb225-18"><a href="#cb225-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb225-19"><a href="#cb225-19" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb225-20"><a href="#cb225-20" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb225-21"><a href="#cb225-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb225-22"><a href="#cb225-22" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Baked Data:  Parallel Mediation&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/Fake%20Data%20Simple%20Plot-1.svg" width="672" /></p>
<p>There are a number of ways to tabalize the data. You might be surprised to learn that a number of articles that analyze mediating effects focus their presentation on those values and not the traditional intercepts and B weights. This is the approach I have taken in this chapter.</p>
<p><strong>Table 1 </strong></p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Model Coefficients Assessing M1 and M2 as Parallel Mediators Between X and Y</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="center">IV</td>
<td align="center"></td>
<td align="center">M</td>
<td align="center"></td>
<td align="center">DV</td>
<td align="center"><span class="math inline">\(B\)</span> for <em>a</em> and <em>b</em> paths</td>
<td align="center"></td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="center">X</td>
<td align="center">–&gt;</td>
<td align="center">M1</td>
<td align="center">–&gt;</td>
<td align="center">DV</td>
<td align="center">(0.528) X (0.540)</td>
<td align="center">=</td>
<td align="center">0.285</td>
<td align="center">0.085</td>
<td align="center">0.001</td>
</tr>
<tr class="odd">
<td align="center">X</td>
<td align="center">–&gt;</td>
<td align="center">M2</td>
<td align="center">–&gt;</td>
<td align="center">DV</td>
<td align="center">(-0.324) X (0.690)</td>
<td align="center">=</td>
<td align="center">-0.224</td>
<td align="center">0.079</td>
<td align="center">0.005</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="center">Total indirect effect</td>
<td align="center">0.061</td>
<td align="center">0.115</td>
<td align="center">0.594</td>
</tr>
<tr class="odd">
<td align="center">Total effect of X on Y (c path)</td>
<td align="center">0.167</td>
<td align="center">0.158</td>
<td align="center">0.293</td>
</tr>
<tr class="even">
<td align="center">Direct effect of X on Y (c’)</td>
<td align="center">0.105</td>
<td align="center">0.137</td>
<td align="center">0.137</td>
</tr>
</tbody>
</table>
<table>
<tbody>
</tbody>
</table>
<p><em>Note</em>. X =definition; M1 = definition; M2 = definition; Y = definition. The significance of the indirect effects was calculated with bias-corrected confidence intervals (.95) bootstrap analysis.</p>
</div>
<div id="apa-style-writeup" class="section level4" number="7.3.1.5">
<h4 number="7.3.1.5"><span class="header-section-number">7.3.1.5</span> APA Style Writeup</h4>
<p>A model of parallel multiple mediation was analyzed examining the degree to which importance of M1 and M2 mediated the relation of X on Y. Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> recommended this strategy over simple mediation models because it allows for all mediators to be examined, simultaneously. The resultant direct and indirect values for each path account for other mediation paths. Using the <em>lavaan (v. 0.6-7)</em> package in R, coefficients for specific indirect, total indirect, direct, and total were computed. Path coefficients refer to regression weights, or slopes, of the expected changes in the dependent variable given a unit change in the independent variables.</p>
<p>Results (depicted in Figure 1 and presented in Table 2) suggest that 45.77% of the variance in Y is accounted for by the model. While each of the specific indirect effects (X through M1 and M2, respectively) were statistically significant, the total indirect effect (i.e., the sum of the specific indirect effects was not. This is likely because the indirect effect passing through M1 was positive in valence and the indirect effect passing through M2 was negative; hence, they “cancelled each other out.” A pairwise comparison of the specific indirect effects indicated that the strength of the effects were statistically significantly different from each other (<span class="math inline">\(B\)</span> = 0.509, <span class="math inline">\(p\)</span> = 0.000). This means that the indirect effect passing through M1 was statistically stronger than the indirect effect passing through M2.</p>
<p>Let’s turn now to the research vignette and work an example with simulated data from that example. Because the research vignette use an entirely new set of output I will either restart R or clear my environment so that there are a few less objects “in the way.”</p>
</div>
</div>
<div id="research-vignette-5" class="section level3" number="7.3.2">
<h3 number="7.3.2"><span class="header-section-number">7.3.2</span> Research Vignette</h3>
<p>The research vignette comes from the Lewis, Williams, Peppers, and Gadson’s <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">2017</a>)</span> study titled, “Applying Intersectionality to Explore the Relations Between Gendered Racism and Health Among Black Women.” The study was published in the Journal of Counseling Psychology. Participants were 231 Black women who completed an online survey.</p>
<p>Variables used in the study included:</p>
<ul>
<li><p><strong>GRMS</strong>: Gendered Racial Microaggressions Scale <span class="citation">(<a href="#ref-lewis_construction_2015" role="doc-biblioref">J. A. Lewis &amp; Neville, 2015</a>)</span> is a 26-item scale that assesses the frequency of nonverbal, verbal, and behavioral negative racial and gender slights experienced by Black women. Scaling is along six points ranging from 0 (never) to 5 (once a week or more). Higher scores indicate a greater frequency of gendered racial microaggressions. An example item is, “Someone has made a sexually inappropriate comment about my butt, hips, or thighs.”</p></li>
<li><p><strong>MntlHlth</strong> and <strong>PhysHlth</strong>: Short Form Health Survey - Version 2 <span class="citation">(<a href="#ref-ware_comparison_1995" role="doc-biblioref">Ware et al., 1995</a>)</span> is a 12-item scale used to report self-reported mental (six items) and physical health (six items).
Higher scores indicate higher mental health (e.g., little or no psychological ldistress) and physical health (e.g., little or no reported symptoms in physical functioning). An example of an item assessing mental health was, “How much of the time during the last 4 weeks have you felt calm and peaceful?”; an example of a physical health item was, “During the past 4 weeks, how much did pain interfere with your normal work?”</p></li>
<li><p><strong>Sprtlty</strong>, <strong>SocSup</strong>, <strong>Engmgt</strong>, and <strong>DisEngmt</strong> are four subscales from the Brief Coping with Problems Experienced Inventory <span class="citation">(<a href="#ref-carver_you_1997" role="doc-biblioref">Carver, 1997</a>)</span>. The 28 items on this scale are presented on a 4-point scale ranging from 1 (<em>I usually do not do this at all</em>) to 4(<em>I usually do this a lot</em>). Higher scores indicate a respondents’ tendency to engage in a particular strategy. Instructions were modified to ask how the female participants responded to recent experiences of racism and sexism as Black women. The four subscales included spirituality (religion, acceptance, planning), interconnectedness/social support (vent emotions, emotional support,instrumental social support), problem-oriented/engagement coping (active coping, humor, positive reinterpretation/positive reframing), and disengagement coping (behavioral disengagement, substance abuse, denial, self-blame, self-distraction).</p></li>
<li><p><strong>GRIcntlty</strong>: The Multidimensional Inventory of Black Identity Centrality subscale <span class="citation">(<a href="#ref-sellers_multidimensional_nodate" role="doc-biblioref">Sellers et al., n.d.</a>)</span> was modified to measure the intersection of racial and gender identity centrality. The scale included 10 items scaled from 1 (<em>strongly disagree</em>) to 7 (<em>strongly agree</em>). An example item was, “Being a <em>Black woman</em> is important to my self-image.” Higher scores indicated higher levels of gendered racial identity centrality.</p></li>
</ul>
<div id="data-simulation-1" class="section level4" number="7.3.2.1">
<h4 number="7.3.2.1"><span class="header-section-number">7.3.2.1</span> Data Simulation</h4>
<p>Simulating the data:</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Entering the intercorrelations, means, and standard deviations from the journal article</span></span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.99</span>, <span class="fl">2.82</span>, <span class="fl">2.48</span>, <span class="fl">2.32</span>, <span class="fl">1.75</span>, <span class="fl">5.71</span>, <span class="fl">21.37</span>, <span class="fl">21.07</span>)</span>
<span id="cb226-3"><a href="#cb226-3" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">90</span>, .<span class="dv">70</span>, .<span class="dv">81</span>, .<span class="dv">61</span>, .<span class="dv">53</span>, <span class="fl">1.03</span>, <span class="fl">3.83</span>, <span class="fl">4.66</span>)</span>
<span id="cb226-4"><a href="#cb226-4" aria-hidden="true" tabindex="-1"></a>r_mat <span class="ot">&lt;-</span> <span class="fu">matrix</span> (<span class="fu">c</span>(<span class="dv">1</span>, .<span class="dv">20</span>, .<span class="dv">28</span>, .<span class="dv">30</span>, .<span class="dv">41</span>, .<span class="dv">19</span>, <span class="sc">-</span>.<span class="dv">32</span>, <span class="sc">-</span>.<span class="dv">18</span>,</span>
<span id="cb226-5"><a href="#cb226-5" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">20</span>, <span class="dv">1</span>, .<span class="dv">49</span>, .<span class="dv">57</span>, .<span class="dv">22</span>, .<span class="dv">13</span>, <span class="sc">-</span>.<span class="dv">06</span>, <span class="sc">-</span>.<span class="dv">13</span>,</span>
<span id="cb226-6"><a href="#cb226-6" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">28</span>, .<span class="dv">49</span>, <span class="dv">1</span>, .<span class="dv">46</span>, .<span class="dv">26</span>, .<span class="dv">38</span>, <span class="sc">-</span>.<span class="dv">18</span>,<span class="sc">-</span>.<span class="dv">08</span>, </span>
<span id="cb226-7"><a href="#cb226-7" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">30</span>, .<span class="dv">57</span>, .<span class="dv">46</span>,  <span class="dv">1</span>, .<span class="dv">37</span>, .<span class="dv">08</span>, <span class="sc">-</span>.<span class="dv">14</span>, <span class="sc">-</span>.<span class="dv">06</span>,</span>
<span id="cb226-8"><a href="#cb226-8" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">41</span>, .<span class="dv">22</span>, .<span class="dv">26</span>, .<span class="dv">37</span>, <span class="dv">1</span>, .<span class="dv">05</span>, <span class="sc">-</span>.<span class="dv">54</span>, <span class="sc">-</span>.<span class="dv">28</span>, </span>
<span id="cb226-9"><a href="#cb226-9" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">19</span>, .<span class="dv">13</span>, .<span class="dv">38</span>, .<span class="dv">08</span>, .<span class="dv">05</span>, <span class="dv">1</span>, <span class="sc">-</span>.<span class="dv">10</span>, .<span class="dv">14</span>, </span>
<span id="cb226-10"><a href="#cb226-10" aria-hidden="true" tabindex="-1"></a>        <span class="sc">-</span>.<span class="dv">32</span>, <span class="sc">-</span>.<span class="dv">06</span>, <span class="sc">-</span>.<span class="dv">18</span>, <span class="sc">-</span>.<span class="dv">14</span>, <span class="sc">-</span>.<span class="dv">54</span>, <span class="sc">-</span>.<span class="dv">10</span>, <span class="dv">1</span>, .<span class="dv">47</span>,</span>
<span id="cb226-11"><a href="#cb226-11" aria-hidden="true" tabindex="-1"></a>        <span class="sc">-</span>.<span class="dv">18</span>, <span class="sc">-</span>.<span class="dv">13</span>, <span class="sc">-</span>.<span class="dv">08</span>, <span class="sc">-</span>.<span class="dv">06</span>, <span class="sc">-</span>.<span class="dv">28</span>, .<span class="dv">14</span>, .<span class="dv">47</span>, <span class="dv">1</span>), <span class="at">ncol =</span> <span class="dv">8</span>)</span>
<span id="cb226-12"><a href="#cb226-12" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating a covariance matrix</span></span>
<span id="cb226-13"><a href="#cb226-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb226-14"><a href="#cb226-14" aria-hidden="true" tabindex="-1"></a>cov_mat <span class="ot">&lt;-</span> sd <span class="sc">%*%</span> <span class="fu">t</span>(sd) <span class="sc">*</span> r_mat</span>
<span id="cb226-15"><a href="#cb226-15" aria-hidden="true" tabindex="-1"></a>cov_mat</span></code></pre></div>
<pre><code>##          [,1]     [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
## [1,]  0.81000  0.12600  0.204120  0.164700  0.195570  0.176130 -1.103040
## [2,]  0.12600  0.49000  0.277830  0.243390  0.081620  0.093730 -0.160860
## [3,]  0.20412  0.27783  0.656100  0.227286  0.111618  0.317034 -0.558414
## [4,]  0.16470  0.24339  0.227286  0.372100  0.119621  0.050264 -0.327082
## [5,]  0.19557  0.08162  0.111618  0.119621  0.280900  0.027295 -1.096146
## [6,]  0.17613  0.09373  0.317034  0.050264  0.027295  1.060900 -0.394490
## [7,] -1.10304 -0.16086 -0.558414 -0.327082 -1.096146 -0.394490 14.668900
## [8,] -0.75492 -0.42406 -0.301968 -0.170556 -0.691544  0.671972  8.388466
##           [,8]
## [1,] -0.754920
## [2,] -0.424060
## [3,] -0.301968
## [4,] -0.170556
## [5,] -0.691544
## [6,]  0.671972
## [7,]  8.388466
## [8,] 21.715600</code></pre>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="#cb228-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set random seed so that the following matrix always gets the same results.</span></span>
<span id="cb228-2"><a href="#cb228-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210403</span>)</span>
<span id="cb228-3"><a href="#cb228-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb228-4"><a href="#cb228-4" aria-hidden="true" tabindex="-1"></a>Lewis_df <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(<span class="at">n =</span> <span class="dv">212</span>, <span class="at">mu=</span>mu, <span class="at">Sigma =</span> cov_mat, <span class="at">empirical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb228-5"><a href="#cb228-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(Lewis_df)</span></code></pre></div>
<pre><code>## [1]  1.99  2.82  2.48  2.32  1.75  5.71 21.37 21.07</code></pre>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking our work against the original correlation matrix</span></span>
<span id="cb230-2"><a href="#cb230-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(Lewis_df)</span></code></pre></div>
<pre><code>##       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]
## [1,]  1.00  0.20  0.28  0.30  0.41  0.19 -0.32 -0.18
## [2,]  0.20  1.00  0.49  0.57  0.22  0.13 -0.06 -0.13
## [3,]  0.28  0.49  1.00  0.46  0.26  0.38 -0.18 -0.08
## [4,]  0.30  0.57  0.46  1.00  0.37  0.08 -0.14 -0.06
## [5,]  0.41  0.22  0.26  0.37  1.00  0.05 -0.54 -0.28
## [6,]  0.19  0.13  0.38  0.08  0.05  1.00 -0.10  0.14
## [7,] -0.32 -0.06 -0.18 -0.14 -0.54 -0.10  1.00  0.47
## [8,] -0.18 -0.13 -0.08 -0.06 -0.28  0.14  0.47  1.00</code></pre>
<p>Rename the variables</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(Lewis_df, <span class="at">row.names =</span> <span class="cn">NULL</span>, <span class="at">optional =</span> <span class="cn">FALSE</span>, <span class="at">make.names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb232-2"><a href="#cb232-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb232-3"><a href="#cb232-3" aria-hidden="true" tabindex="-1"></a>Lewis_df <span class="ot">&lt;-</span> Lewis_df<span class="sc">%&gt;%</span></span>
<span id="cb232-4"><a href="#cb232-4" aria-hidden="true" tabindex="-1"></a>  as.data.frame <span class="sc">%&gt;%</span></span>
<span id="cb232-5"><a href="#cb232-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">GRMS =</span> V1, <span class="at">Sprtlty =</span> V2, <span class="at">SocSup =</span> V3, <span class="at">Engmt =</span> V4, <span class="at">DisEngmt =</span> V5, <span class="at">GRIcntlty =</span> V6, <span class="at">MtnlHlth =</span> V7, <span class="at">PhysHlth =</span> V8)</span></code></pre></div>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Lewis_df)</span></code></pre></div>
<pre><code>##        GRMS  Sprtlty   SocSup    Engmt  DisEngmt GRIcntlty MtnlHlth PhysHlth
## 1 1.6527393 2.022990 1.705523 1.360615 1.0830779  5.517213 22.75649 19.41684
## 2 0.7640948 1.644033 2.505362 2.242470 1.7132075  5.413544 22.62540 22.26355
## 3 2.0107291 2.321768 2.660635 2.004928 1.5158907  4.842883 19.07803 23.23430
## 4 1.2409552 1.920184 1.470588 1.096715 1.4677302  4.124888 23.94831 18.74295
## 5 1.4613106 3.775331 2.939616 1.825157 0.9183584  5.558731 22.77763 18.81243
## 6 3.3326679 2.432105 2.709137 2.427134 1.7561275  8.816758 19.26199 24.46558</code></pre>
</div>
<div id="quick-descriptives" class="section level4" number="7.3.2.2">
<h4 number="7.3.2.2"><span class="header-section-number">7.3.2.2</span> Quick Descriptives</h4>
<p>Of course it is is a good idea to examine our data ahead of time. While we won’t take time to do a thorough analysis, we can at least take a peek.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb235-2"><a href="#cb235-2" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">describe</span>(Lewis_df)</span></code></pre></div>
<pre><code>##           vars   n  mean   sd median trimmed  mad   min   max range  skew
## GRMS         1 212  1.99 0.90   1.97    1.99 0.80 -1.07  3.97  5.05 -0.12
## Sprtlty      2 212  2.82 0.70   2.80    2.83 0.75  1.08  4.57  3.49 -0.10
## SocSup       3 212  2.48 0.81   2.44    2.47 0.80  0.62  4.78  4.17  0.11
## Engmt        4 212  2.32 0.61   2.32    2.33 0.60  0.75  3.93  3.18 -0.14
## DisEngmt     5 212  1.75 0.53   1.76    1.75 0.56  0.47  3.00  2.53 -0.05
## GRIcntlty    6 212  5.71 1.03   5.64    5.68 0.95  2.72  9.56  6.84  0.37
## MtnlHlth     7 212 21.37 3.83  21.59   21.46 4.23 11.79 31.77 19.98 -0.14
## PhysHlth     8 212 21.07 4.66  20.79   21.03 4.68  8.43 33.73 25.30  0.07
##           kurtosis   se
## GRMS          0.25 0.06
## Sprtlty      -0.41 0.05
## SocSup       -0.16 0.06
## Engmt        -0.22 0.04
## DisEngmt     -0.56 0.04
## GRIcntlty     0.76 0.07
## MtnlHlth     -0.56 0.26
## PhysHlth     -0.18 0.32</code></pre>
<p>We note that our means and standard deviations map exactly onto those in the article. Because we asked for a normal distribution, we do not violate any of the assumptions related to univariate normality; our skew and kurtosis are well within the limits.</p>
<p>The pairs panel from the <em>psych</em> package is an efficient way to see</p>
<ul>
<li>the distribution of each variable with a normal curve superimposed (on the diagonal)</li>
<li>the value of the bivariate correlation (upper diagonal)</li>
<li>a scatterplot with a regression line between each pair of variables (lower diagonal)</li>
</ul>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">pairs.panels</span>(Lewis_df)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/unnamed-chunk-15-1.svg" width="672" /></p>
<p>The Lewis et al. article <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">2017</a>)</span> reports four mediation analyses, each repeated for mental and physical outcomes. Thus, their write-up reports eight simple mediation models. Graphically, this is efficiently represented in a figure that looks like parallel mediation. Note that the figure is reporting standardized estimates. In Hayes’ <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> we have been using raw, <span class="math inline">\(B\)</span> weights. However, the standardized weights are reported in the output.</p>
<p><img src="images/CompMed/LewisMedFig.jpg" alt="An image of Figure 1 from the Lewis article illustrating the mediated models that were tested" />
Because the figure looked like a parallel mediation, it made sense to me that we could try this in our research vignette. In the chapter on conditional process analysis, we will work the moderated mediation as they have done. Below is the model we will work. Specifically, we will evaluate whether gendered racial microaggressions impact mental health separately, thorough mediated paths of engagement and disengagement. We will also be able to see if the strength of those mediated paths are statistically, significantly, different from each other.</p>
<div class="figure">
<img src="images/CompMed/LewisParaMed.jpg" alt="" />
<p class="caption">An image of the parallel mediation we will work</p>
</div>
</div>
<div id="specifying-the-lavaan-model" class="section level4" number="7.3.2.3">
<h4 number="7.3.2.3"><span class="header-section-number">7.3.2.3</span> Specifying the <em>lavaan</em> model</h4>
<p>We can use the guidelines above to specify our model and then request summaries of the fit indices and parameter estimates.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="#cb238-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210403</span>)</span>
<span id="cb238-2"><a href="#cb238-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb238-3"><a href="#cb238-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb238-4"><a href="#cb238-4" aria-hidden="true" tabindex="-1"></a>parallel_Lewis <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb238-5"><a href="#cb238-5" aria-hidden="true" tabindex="-1"></a><span class="st">    MtnlHlth ~ b1*Engmt + b2*DisEngmt + c_p*GRMS</span></span>
<span id="cb238-6"><a href="#cb238-6" aria-hidden="true" tabindex="-1"></a><span class="st">    Engmt ~ a1*GRMS    </span></span>
<span id="cb238-7"><a href="#cb238-7" aria-hidden="true" tabindex="-1"></a><span class="st">    DisEngmt ~ a2*GRMS</span></span>
<span id="cb238-8"><a href="#cb238-8" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect1 := a1 * b1</span></span>
<span id="cb238-9"><a href="#cb238-9" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect2 := a2 * b2</span></span>
<span id="cb238-10"><a href="#cb238-10" aria-hidden="true" tabindex="-1"></a><span class="st">    contrast := indirect1 - indirect2</span></span>
<span id="cb238-11"><a href="#cb238-11" aria-hidden="true" tabindex="-1"></a><span class="st">    total_indirects := indirect1 + indirect2</span></span>
<span id="cb238-12"><a href="#cb238-12" aria-hidden="true" tabindex="-1"></a><span class="st">    total_c := c_p + (indirect1) + (indirect2)</span></span>
<span id="cb238-13"><a href="#cb238-13" aria-hidden="true" tabindex="-1"></a><span class="st">    direct := c_p</span></span>
<span id="cb238-14"><a href="#cb238-14" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span></span>
<span id="cb238-15"><a href="#cb238-15" aria-hidden="true" tabindex="-1"></a>para_Lewis_fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(parallel_Lewis, <span class="at">data =</span> Lewis_df, <span class="at">se =</span> <span class="st">&quot;bootstrap&quot;</span>, <span class="at">bootstrap =</span> <span class="dv">1000</span>, <span class="at">missing =</span> <span class="st">&#39;fiml&#39;</span>) <span class="co">#holds the &quot;whole&quot; result</span></span>
<span id="cb238-16"><a href="#cb238-16" aria-hidden="true" tabindex="-1"></a>pLewis_sum <span class="ot">&lt;-</span> <span class="fu">summary</span>(para_Lewis_fit , <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">rsq=</span>T, <span class="at">fit=</span><span class="cn">TRUE</span>, <span class="at">ci=</span><span class="cn">TRUE</span>) <span class="co">#today, we really only need the R-squared from here    </span></span>
<span id="cb238-17"><a href="#cb238-17" aria-hidden="true" tabindex="-1"></a>pLewis_ParEsts <span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(para_Lewis_fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>) <span class="co">#provides our estimates, se, p values for all the elements we specified</span></span></code></pre></div>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>pLewis_sum</span></code></pre></div>
<pre><code>## $FIT
##              npar              fmin             chisq                df 
##            11.000             0.042            17.813             1.000 
##            pvalue    baseline.chisq       baseline.df   baseline.pvalue 
##             0.000           155.625             6.000             0.000 
##               cfi               tli              logl unrestricted.logl 
##             0.888             0.326          -877.337          -868.431 
##               aic               bic            ntotal              bic2 
##          1776.675          1813.597           212.000          1778.742 
##             rmsea    rmsea.ci.lower    rmsea.ci.upper      rmsea.pvalue 
##             0.282             0.177             0.403             0.000 
##              srmr 
##             0.075 
## 
## $PE
##                lhs op                         rhs           label exo
## 1         MtnlHlth  ~                       Engmt              b1   0
## 2         MtnlHlth  ~                    DisEngmt              b2   0
## 3         MtnlHlth  ~                        GRMS             c_p   0
## 4            Engmt  ~                        GRMS              a1   0
## 5         DisEngmt  ~                        GRMS              a2   0
## 6         MtnlHlth ~~                    MtnlHlth                   0
## 7            Engmt ~~                       Engmt                   0
## 8         DisEngmt ~~                    DisEngmt                   0
## 9             GRMS ~~                        GRMS                   1
## 10        MtnlHlth ~1                                               0
## 11           Engmt ~1                                               0
## 12        DisEngmt ~1                                               0
## 13            GRMS ~1                                               1
## 14       indirect1 :=                       a1*b1       indirect1   0
## 15       indirect2 :=                       a2*b2       indirect2   0
## 16        contrast :=         indirect1-indirect2        contrast   0
## 17 total_indirects :=         indirect1+indirect2 total_indirects   0
## 18         total_c := c_p+(indirect1)+(indirect2)         total_c   0
## 19          direct :=                         c_p          direct   0
## 20        MtnlHlth r2                    MtnlHlth                   0
## 21           Engmt r2                       Engmt                   0
## 22        DisEngmt r2                    DisEngmt                   0
##            est         se         z       pvalue    ci.lower    ci.upper
## 1   0.58067170 0.45080355  1.288081 1.977176e-01 -0.25535127  1.55057232
## 2  -3.74952953 0.44764668 -8.376091 0.000000e+00 -4.58391877 -2.86769099
## 3  -0.57454463 0.26922168 -2.134095 3.283501e-02 -1.09766058 -0.06462847
## 4   0.20333329 0.04468537  4.550333 5.356116e-06  0.11504500  0.29007149
## 5   0.24144446 0.03518030  6.863059 6.740164e-12  0.16777845  0.30968363
## 6  10.06733737 0.83862778 12.004536 0.000000e+00  8.24746315 11.66410471
## 7   0.33701378 0.03116807 10.812790 0.000000e+00  0.27585878  0.40038675
## 8   0.23257844 0.01865156 12.469649 0.000000e+00  0.19335369  0.26815157
## 9   0.80617925 0.00000000        NA           NA  0.80617925  0.80617925
## 10 27.72786217 0.94560927 29.322748 0.000000e+00 25.80236594 29.38520327
## 11  1.91536675 0.10610584 18.051474 0.000000e+00  1.70846228  2.11781441
## 12  1.26952551 0.07569600 16.771368 0.000000e+00  1.12123049  1.41811477
## 13  1.99000000 0.00000000        NA           NA  1.99000000  1.99000000
## 14  0.11806989 0.09943864  1.187364 2.350839e-01 -0.05775972  0.33448712
## 15 -0.90530315 0.16781382 -5.394688 6.864280e-08 -1.23706667 -0.60499559
## 16  1.02337304 0.21918552  4.668981 3.026974e-06  0.62841479  1.48950107
## 17 -0.78723326 0.16750148 -4.699859 2.603418e-06 -1.11075150 -0.47350426
## 18 -1.36177790 0.29278899 -4.651056 3.302401e-06 -1.95099520 -0.77628755
## 19 -0.57454463 0.26935639 -2.133028 3.292246e-02 -1.09766058 -0.06462847
## 20  0.32641007         NA        NA           NA          NA          NA
## 21  0.08999997         NA        NA           NA          NA          NA
## 22  0.16810002         NA        NA           NA          NA          NA
##        std.lv     std.all     std.nox
## 1   0.5806717  0.09140591  0.09140591
## 2  -3.7495295 -0.51282175 -0.51282175
## 3  -0.5745446 -0.13343817 -0.14861555
## 4   0.2033333  0.29999995  0.33412223
## 5   0.2414445  0.41000003  0.45663383
## 6  10.0673374  0.67358993  0.67358993
## 7   0.3370138  0.91000003  0.91000003
## 8   0.2325784  0.83189998  0.83189998
## 9   0.8061792  1.00000000  0.80617925
## 10 27.7278622  7.17227393  7.17227393
## 11  1.9153668  3.14737739  3.14737739
## 12  1.2695255  2.40100054  2.40100054
## 13  1.9900000  2.21634452  1.99000000
## 14  0.1180699  0.02742177  0.03054075
## 15 -0.9053032 -0.21025693 -0.23417176
## 16  1.0233730  0.23767870  0.26471250
## 17 -0.7872333 -0.18283516 -0.20363101
## 18 -1.3617779 -0.31627333 -0.35224656
## 19 -0.5745446 -0.13343817 -0.14861555
## 20         NA          NA          NA
## 21         NA          NA          NA
## 22         NA          NA          NA</code></pre>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>pLewis_ParEsts</span></code></pre></div>
<pre><code>##                lhs op                         rhs           label    est    se
## 1         MtnlHlth  ~                       Engmt              b1  0.581 0.451
## 2         MtnlHlth  ~                    DisEngmt              b2 -3.750 0.448
## 3         MtnlHlth  ~                        GRMS             c_p -0.575 0.269
## 4            Engmt  ~                        GRMS              a1  0.203 0.045
## 5         DisEngmt  ~                        GRMS              a2  0.241 0.035
## 6         MtnlHlth ~~                    MtnlHlth                 10.067 0.839
## 7            Engmt ~~                       Engmt                  0.337 0.031
## 8         DisEngmt ~~                    DisEngmt                  0.233 0.019
## 9             GRMS ~~                        GRMS                  0.806 0.000
## 10        MtnlHlth ~1                                             27.728 0.946
## 11           Engmt ~1                                              1.915 0.106
## 12        DisEngmt ~1                                              1.270 0.076
## 13            GRMS ~1                                              1.990 0.000
## 14       indirect1 :=                       a1*b1       indirect1  0.118 0.099
## 15       indirect2 :=                       a2*b2       indirect2 -0.905 0.168
## 16        contrast :=         indirect1-indirect2        contrast  1.023 0.219
## 17 total_indirects :=         indirect1+indirect2 total_indirects -0.787 0.168
## 18         total_c := c_p+(indirect1)+(indirect2)         total_c -1.362 0.293
## 19          direct :=                         c_p          direct -0.575 0.269
##         z pvalue ci.lower ci.upper std.lv std.all std.nox
## 1   1.288  0.198   -0.230    1.576  0.581   0.091   0.091
## 2  -8.376  0.000   -4.596   -2.873 -3.750  -0.513  -0.513
## 3  -2.134  0.033   -1.094   -0.047 -0.575  -0.133  -0.149
## 4   4.550  0.000    0.115    0.289  0.203   0.300   0.334
## 5   6.863  0.000    0.167    0.309  0.241   0.410   0.457
## 6  12.005  0.000    8.509   11.926 10.067   0.674   0.674
## 7  10.813  0.000    0.284    0.405  0.337   0.910   0.910
## 8  12.470  0.000    0.203    0.277  0.233   0.832   0.832
## 9      NA     NA    0.806    0.806  0.806   1.000   0.806
## 10 29.323  0.000   25.795   29.374 27.728   7.172   7.172
## 11 18.051  0.000    1.715    2.129  1.915   3.147   3.147
## 12 16.771  0.000    1.128    1.436  1.270   2.401   2.401
## 13     NA     NA    1.990    1.990  1.990   2.216   1.990
## 14  1.187  0.235   -0.035    0.375  0.118   0.027   0.031
## 15 -5.395  0.000   -1.240   -0.616 -0.905  -0.210  -0.234
## 16  4.669  0.000    0.646    1.494  1.023   0.238   0.265
## 17 -4.700  0.000   -1.114   -0.475 -0.787  -0.183  -0.204
## 18 -4.651  0.000   -1.933   -0.774 -1.362  -0.316  -0.352
## 19 -2.133  0.033   -1.094   -0.047 -0.575  -0.133  -0.149</code></pre>
</div>
<div id="figures-and-tables-1" class="section level4" number="7.3.2.4">
<h4 number="7.3.2.4"><span class="header-section-number">7.3.2.4</span> Figures and Tables</h4>
<p>When I interpret the data I first plot it and then create the table. Both processes force me to slow down and work conceptually through and deeply in the data.</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb243-2"><a href="#cb243-2" aria-hidden="true" tabindex="-1"></a><span class="co">#note change in layout </span></span>
<span id="cb243-3"><a href="#cb243-3" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(para_Lewis_fit, <span class="co">#must identiy the model you want to map</span></span>
<span id="cb243-4"><a href="#cb243-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb243-5"><a href="#cb243-5" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb243-6"><a href="#cb243-6" aria-hidden="true" tabindex="-1"></a>         <span class="co">#layout = &#39;tree&#39;, rotation = 2, #together, puts predictors on left, IVs on right </span></span>
<span id="cb243-7"><a href="#cb243-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;spring&#39;</span>, </span>
<span id="cb243-8"><a href="#cb243-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb243-9"><a href="#cb243-9" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb243-10"><a href="#cb243-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb243-11"><a href="#cb243-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb243-12"><a href="#cb243-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb243-13"><a href="#cb243-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb243-14"><a href="#cb243-14" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb243-15"><a href="#cb243-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb243-16"><a href="#cb243-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb243-17"><a href="#cb243-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb243-18"><a href="#cb243-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb243-19"><a href="#cb243-19" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb243-20"><a href="#cb243-20" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb243-21"><a href="#cb243-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb243-22"><a href="#cb243-22" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Mental Health from Gendered Racial Microaggressions, Mediated by Engagement and Disengagement Coping&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/Lewis%20Parallel%20model%20plot-1.svg" width="672" /></p>
<p>Now let’s make a table.</p>
<p><strong>Table 2 </strong></p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Model Coefficients Assessing Engagement and Disengagement Coping as Parallel Mediators Between Predicting Mental Health from Gendered Racial Microaggressions</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="center">IV</td>
<td align="center"></td>
<td align="center">M</td>
<td align="center"></td>
<td align="center">DV</td>
<td align="center"><span class="math inline">\(B\)</span> for <em>a</em> and <em>b</em> paths</td>
<td align="center"></td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="center">GRMS</td>
<td align="center">–&gt;</td>
<td align="center">Engmt</td>
<td align="center">–&gt;</td>
<td align="center">MntlHlth</td>
<td align="center">(0.203) X (0.581)</td>
<td align="center">=</td>
<td align="center">0.118</td>
<td align="center">0.099</td>
<td align="center">0.235</td>
</tr>
<tr class="odd">
<td align="center">GRMS</td>
<td align="center">–&gt;</td>
<td align="center">DisEngmt</td>
<td align="center">–&gt;</td>
<td align="center">MntlHlth</td>
<td align="center">(0.241) X (-3.750)</td>
<td align="center">=</td>
<td align="center">-0.905</td>
<td align="center">0.168</td>
<td align="center">0.000</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="center">Total indirect effect</td>
<td align="center">-0.787</td>
<td align="center">0.168</td>
<td align="center">0.000</td>
</tr>
<tr class="odd">
<td align="center">Total effect of X on Y (c path)</td>
<td align="center">-1.362</td>
<td align="center">0.293</td>
<td align="center">0.000</td>
</tr>
<tr class="even">
<td align="center">Direct effect of X on Y (c’)</td>
<td align="center">-0.575</td>
<td align="center">0.269</td>
<td align="center">0.269</td>
</tr>
</tbody>
</table>
<table>
<tbody>
</tbody>
</table>
<p><em>Note</em>. IV = gendered racial microaggressions; M1 = engagement coping; M2 = disengagement coping; Y = mental health. The significance of the indirect effects was calculated with bias-corrected confidence intervals (.95) bootstrap analysis.</p>
<ul>
<li>The model accounts for 32.64% of the variance in predicting mental health outcomes.</li>
<li>The total effect of GRMS on mental health is -1.362 (<span class="math inline">\(p\)</span> = 0.000) is negative and statistically significant. That is, gendered racial microaggressions have a statistically significant negative effect on mental health.</li>
<li>The direct effect of GRMS on mental health is -0.575 (<em>p</em> = 0.269) is still negative but not statistically significant.
<ul>
<li>Using Baron and Kenny’s <span class="citation">(<a href="#ref-baron_moderator-mediator_1986" role="doc-biblioref">1986</a>)</span> causal steps logic, the smaller and non-significant direct effect (compared to the total effect) provides helpful, logical support for mediation. According to Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> this difference is not necessary. However it is logically helpful.</li>
</ul></li>
<li>Indirect effect #1 (a1 x b1 or GRMS through engagement coping) is 0.118 (<span class="math inline">\(p\)</span> = 0.000) and not statistically significant. Looking at the paths we see that <em>a1</em> is positive and statistically significant (GRMS leds to increased engagement coping), but the next link, <em>b1</em> (engagement to mental health) is not statistically significant.</li>
<li>Indirect effect #2 (a2 x b2, or GRMS through disengagement to coping) is -0.905(<span class="math inline">\(p\)</span> = 0.000). Gendered racial microaggressions lead to greater disengagement (<em>a1</em>). In turn, disengagement has negative effects on mental health (<em>b2</em>)</li>
<li>The total indirect effect (i.e., sum of M1 and M2) -0.787 (<span class="math inline">\(p\)</span> = 0.000 ) The sum of all specific indirect effects; statistically significant.</li>
<li>We look at the contrast to see if the indirect effects statistically significantly different from each other? <span class="math inline">\(B\)</span> = 1.023, <span class="math inline">\(p\)</span> = 0.000. They are. This is not surprising since the path mediated by engagement was not statistically significant but the path mediated by disengagement was statistically significant.</li>
</ul>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="#cb244-1" aria-hidden="true" tabindex="-1"></a>LewisparaTable <span class="ot">&lt;-</span> <span class="fu">semTable</span>(para_Lewis_fit, <span class="at">columns =</span> <span class="fu">c</span>(<span class="st">&quot;est&quot;</span>, <span class="st">&quot;se&quot;</span>, <span class="st">&quot;p&quot;</span>, <span class="st">&quot;rsquare&quot;</span>),  <span class="at">columnLabels =</span> <span class="fu">c</span>(<span class="at">eststars =</span> <span class="st">&quot;Estimate&quot;</span>), <span class="at">paramSets =</span> <span class="fu">c</span>(<span class="st">&quot;composites&quot;</span>, <span class="st">&quot;loadings&quot;</span>, <span class="st">&quot;slopes&quot;</span>, <span class="st">&quot;intercepts&quot;</span>, <span class="st">&quot;residualvariances&quot;</span>), <span class="at">file =</span> <span class="st">&quot;LewisParaTable&quot;</span>, <span class="at">type =</span> <span class="st">&quot;csv&quot;</span>, <span class="at">print.results =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## ,Model,
##  
## ,Estimate,Std. Err.,p,R Square,
## 
## ,Regression Slopes,
##  MtnlHlth,
## 
## Engmt,0.58,0.45,.198,,
## 
## DisEngmt,-3.75,0.45,.000,,
## 
## GRMS,-0.57,0.27,.033,,
## 
##  Engmt,
## 
## GRMS,0.20,0.04,.000,,
## 
##  DisEngmt,
## 
## GRMS,0.24,0.04,.000,,
## 
## ,Intercepts,
## 
## MtnlHlth,27.73,0.95,.000,,
## 
## Engmt,1.92,0.11,.000,,
## 
## DisEngmt,1.27,0.08,.000,,
## 
## GRMS,1.99+,,,,
## 
## ,Residual Variances,
## 
## MtnlHlth,10.07,0.84,.000,,
## 
## Engmt,0.34,0.03,.000,,
## 
## DisEngmt,0.23,0.02,.000,,
## 
## GRMS,0.81+,,,,
## 
## ,Fit Indices,
## 
## chi^2,17.81(1),,.000,,
## 
## CFI,0.89,,,,
## 
## TLI,0.33,,,,
## 
## RMSEA,0.28,,,,
## 
## +Fixed parameter,
## 
## 
## 
## </code></pre>
</div>
<div id="apa-style-writeup-1" class="section level4" number="7.3.2.5">
<h4 number="7.3.2.5"><span class="header-section-number">7.3.2.5</span> APA Style Writeup</h4>
<p>Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> provides helpful guidelines for presenting statistical results. Here is a summary of his recommendations.</p>
<ul>
<li>Pack as much statistical info as possible into a table(s) or figure (s).</li>
<li>Use statistics in the text as punctuation; avoid redundancy in text and table.</li>
<li>Avoid using abbreviations for variables in the text itself; rather focus on the construct names rather than their shorthand</li>
<li>Avoid focusing on what you hypothesized (e.g., avoid, “Results supported/did not support hypothesis A1”) and instead focus on what you found. The reader is more interested in the results, not your forecasts.</li>
<li>Hayes uses unstandardized metrics. He prefers reporting unstandardized metrics because they map onto the measurement scales used in the study. He believes this is especially important when dichotomous variables are used.</li>
<li>There is “no harm” in reporting hypothesis tests and CIs for the a and b paths, but whether/not these paths are statistically significant does not determine the significance of the indirect effect.</li>
<li>Be precise with language:</li>
<li>OK: X exerts an effect on Y directly and/or indirectly through M.</li>
<li>Not OK: the indirect effect of M<br />
</li>
<li>Report direct and indirect effects and their corresponding inferential tests</li>
<li>Hayes argues that a statistically significant indirect effect is, in fact statistic. He dislikes narration of the Baron and Kenny <span class="citation">(<a href="#ref-baron_moderator-mediator_1986" role="doc-biblioref">1986</a>)</span> process and steps.</li>
</ul>
<p>Here’s my attempt to write up the simulated data from the Lewis et al. <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">2017</a>)</span> article.</p>
<p><strong>Method</strong></p>
<p>Data Analysis</p>
<p>Parallel multiple mediation is appropriate when testing the influence of an independent variable (X) on the dependent variable (Y) directly, as well as indirectly through two or more mediators. A condition of parallel multiple mediation is that no mediator causally influences another <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">Hayes, 2018</a>)</span>. Using data simulated from Lewis et al. <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">2017</a>)</span> we utilized parallel multiple mediation analysis to test the influence of gendered racial microaggressions (X, GRMS) on mental health outcomes (Y, MntlHlth) directly as well as indirectly through the mediators engagement coping (M1, Engmt) and disengaged coping (M2, DisEngmt). Using the <em>lavaan</em> (v. 0.6-7) package in R we followed the procedures outlined in Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> by analyzing the strength and significance of four sets of effects: specific indirect, the total indirect, the direct, and total.</p>
<p><strong>Results</strong></p>
<p><strong>Preliminary Analyses</strong>
Descriptive statistics were computed, and all variables were assessed for skewness and kurtosis. <em>More narration,here.</em> A summary of descriptive statistics and a correlation matrix for the study is provided in Table #. These bivariate relations provide evidence to support the test of mediation analysis.</p>
<p><strong>Parallel Multiple Mediation Analysis</strong>
A model of parallel multiple mediation was analyzed examining the degree to which engagement and disengagement coping strategies mediated the relation of gendered racial microaggressions on mental health outcomes in Black women. Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> recommended this strategy over simple mediation models because it allows for all mediators to be examined, simultaneously. The resultant direct and indirect values for each path account for other mediation paths. Using the <em>lavaan</em> (v. 0.6-7) package in R, coefficients for specific indirect, total indirect, direct, and total were computed. Path coefficients refer to regression weights, or slopes, of the expected changes in the dependent variable given a unit change in the independent variables.</p>
<p>Results (depicted in Figure # and presented in Table #) suggest that 32.64% of the variance in mental health outcomes is accounted for by the three variables in the model. The indirect effect predicting mental health from gendered racial microaggressions via engagement coping was not statistically significant (<span class="math inline">\(B\)</span> = 0.118, <span class="math inline">\(p\)</span> = 0.000). Looking at the individual paths we see that <span class="math inline">\(a_{1}\)</span> was positive and statistically significant (GRMS leds to increased engagement coping), but the subsequent link, <span class="math inline">\(b_{1}\)</span> (engagement to mental health) was not. The indirect effect predicting mental health from gendered racial microaggressions through disengagement to coping was statistically significant (<span class="math inline">\(B\)</span> = -0.905, <span class="math inline">\(p\)</span> = 0.000). In this case, gendered racial microaggressions led to greater disengagement coping (<span class="math inline">\(a_{2}\)</span>). In turn, disengagement coping had negative effects on mental health (<span class="math inline">\(b_{2}\)</span>). Correspondingly, the total indirect effect (i.e., the sum of the specific indirect effects was statistically significant. A pairwise comparison of the specific indirect effects indicated that the strength of the effects were statistically significantly different from each other (<span class="math inline">\(B\)</span> = 1.023, <span class="math inline">\(p\)</span> = 0.000). Given that the path through engagement coping was not significant, but the path through disengagement coping was, this statistically signifciant difference is not surprising. Further support for understanding mediation as the mechanism of change is found in the drop in statistical significance from the total effect (<em>c</em>) to the direct effect (<em>c’</em>).</p>
<p><strong>Hints for Writing Method/Results Sections</strong></p>
<ul>
<li>When you find an article you like, make note of it and put it in a very special folder. In recent years, I have learned to rely on full-text versions stored in my Zotero app.</li>
<li>Once you know your method (measure, statistic, etc.) begin collecting others articles that are similar to it. To write results sections I will often reference multiple articles.<br />
</li>
<li>When it iss time to write have all these resources handy and use them as guides/models.</li>
<li>Put as much info as possible in the table. Become a table-pro. That is, learn how to merge/split cells, use borders/shading, the decimal tab, and so forth. Don’t make the borders disappear until the last thing you do before submitting. This is because you ALWAYS have to update your tables and seeing the borders makes it easier.</li>
</ul>
</div>
</div>
</div>
<div id="serial-multiple-mediator-model" class="section level2" number="7.4">
<h2 number="7.4"><span class="header-section-number">7.4</span> Serial Multiple Mediator Model</h2>
<p>Recall that one of the conditions of the <em>parallel mediator model</em> was that “no mediator causally influences another.”</p>
<p>Regarding these correlated mediators <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span>:</p>
<ul>
<li>Typically, two or more mediators that are causally located between X and Y will be correlated - if for no other reason than that they share a common cause (X).</li>
<li>Estimating the partial correlation between two mediators after controlling for X is one way to examine whether all of their association is accounted for by this common cause.</li>
<li><em>Partial correlation</em> is the Pearson correlation between the residuals from a model estimating Y from a set of covariates, and the residuals from a model estimating X from the same set of covariates.</li>
<li>Partial correlations allow the assessment of their association, independent of what they have in common with the covariates that were regressed onto Y and X, separately.</li>
<li>If two (or more) mediators remain correlated after adjusting for X, then</li>
<li>the correlation is <em>spurious,</em> they share another (unmodeled) common cause.</li>
<li>the remaining association is <em>epiphenomenal</em>. That is, a proposed mediator could be related to an outcome not because it causes the outcome, but because it is correlated with another variable that is causally influencing the outcome. This is a noncausal alternative explanation for an association. Also, many things correlated with the cause of Y will also tend to be correlated with X, but it doesn’t make all those things cause Y</li>
<li><em>or one mediator causally affects another</em></li>
</ul>
<p>The goal of a serial multiple mediator model is to investigate the direct and indirect effects of X on Y while modeling a process in which X causes M1, which in turn causes M2, and so forth, concluding with Y as the final consequent.</p>
<p>As before, we will calculate:</p>
<ul>
<li><em>Direct effect, c’:</em> the estimated difference in Y between two cases that differ by one unit on X but who are equal on all mediators in the model.</li>
<li><em>Specific indirect effects, a1b1, a2b2, a3b3, etc.:</em> constructed by multiplying the regression weights corresponding to each step in an indirect pathway; interpreted as the estimated difference in Y between two cases that differ by one unit on X through the causal sequence from X to mediator(s) to Y.</li>
<li><em>Total indirect effect of X:</em> sum of all specific indirect effects</li>
<li><em>Total effect of X:</em> the total indirect effect of X plus the direct effect of X; can also be estimated by regressing Y from X only.</li>
<li><em>Pairwise comparisons (contrasts) between indirect effects</em> (i.e., is one indirect effect stronger than another)</li>
</ul>
<div id="we-stick-with-the-lewis-et-al.--lewis_applying_2017-example-but-modify-it." class="section level3" number="7.4.1">
<h3 number="7.4.1"><span class="header-section-number">7.4.1</span> We stick with the Lewis et al. <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">2017</a>)</span> example, but modify it.</h3>
<div class="figure">
<img src="images/CompMed/LewisSerialMed.jpg" alt="" />
<p class="caption">An image of the serial mediation we will work</p>
</div>
<p>Our parallel multiple mediator model of gendered racial microaggressions on mental health through engagement and disengagement coping strategies assumed no causal association between the mediators. Noting the statistically significant correlation between engagement and disengagement, what if engagement influenced disengagement, which, in turn influenced mental health.</p>
<p>If this is our goal (image), how many direct and indirect effects are contained in this model? Using the same processes as before, let’s plan our model:</p>
<ul>
<li>We add a path predicting disengagement from engagement, and label it with a <span class="math inline">\(d_{21}\)</span>
<ul>
<li>Regarding the notation, it makes sense that we use a <em>d</em> to designate a new type of path; I don’t know why we use a subscript of 21</li>
</ul></li>
<li>We specify a third indirect path that multiplies those 3 paths (a1, d21, b2) together</li>
<li>We add a third contrast so that we get all the combinations of indirect comparisons: 1-2, 1-3 2-3</li>
<li>We update our total_indirects calculation to include indirect#3</li>
<li>We update our total_c calculation to include indirect#3</li>
</ul>
</div>
<div id="specify-the-lavaan-model" class="section level3" number="7.4.2">
<h3 number="7.4.2"><span class="header-section-number">7.4.2</span> Specify the <em>lavaan</em> model</h3>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="#cb246-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210403</span>)</span>
<span id="cb246-2"><a href="#cb246-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb246-3"><a href="#cb246-3" aria-hidden="true" tabindex="-1"></a>serial_Lewis <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb246-4"><a href="#cb246-4" aria-hidden="true" tabindex="-1"></a><span class="st">    MtnlHlth ~ b1*Engmt + b2*DisEngmt + c_p*GRMS</span></span>
<span id="cb246-5"><a href="#cb246-5" aria-hidden="true" tabindex="-1"></a><span class="st">    Engmt ~ a1*GRMS    </span></span>
<span id="cb246-6"><a href="#cb246-6" aria-hidden="true" tabindex="-1"></a><span class="st">    DisEngmt ~ a2*GRMS</span></span>
<span id="cb246-7"><a href="#cb246-7" aria-hidden="true" tabindex="-1"></a><span class="st">    DisEngmt ~ d21*Engmt</span></span>
<span id="cb246-8"><a href="#cb246-8" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect1 := a1 * b1</span></span>
<span id="cb246-9"><a href="#cb246-9" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect2 := a2 * b2</span></span>
<span id="cb246-10"><a href="#cb246-10" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect3 := a1 * d21 * b2</span></span>
<span id="cb246-11"><a href="#cb246-11" aria-hidden="true" tabindex="-1"></a><span class="st">    contrast1 := indirect1 - indirect2</span></span>
<span id="cb246-12"><a href="#cb246-12" aria-hidden="true" tabindex="-1"></a><span class="st">    contrast2 := indirect1 - indirect3</span></span>
<span id="cb246-13"><a href="#cb246-13" aria-hidden="true" tabindex="-1"></a><span class="st">    contrast3 := indirect2 - indirect3</span></span>
<span id="cb246-14"><a href="#cb246-14" aria-hidden="true" tabindex="-1"></a><span class="st">    total_indirects := indirect1 + indirect2 + indirect3</span></span>
<span id="cb246-15"><a href="#cb246-15" aria-hidden="true" tabindex="-1"></a><span class="st">    total_c := c_p + indirect1 + indirect2 + indirect3</span></span>
<span id="cb246-16"><a href="#cb246-16" aria-hidden="true" tabindex="-1"></a><span class="st">    direct := c_p</span></span>
<span id="cb246-17"><a href="#cb246-17" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span></span>
<span id="cb246-18"><a href="#cb246-18" aria-hidden="true" tabindex="-1"></a>serial_Lewis_fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(serial_Lewis, <span class="at">data =</span> Lewis_df, <span class="at">se =</span> <span class="st">&quot;bootstrap&quot;</span>, <span class="at">missing =</span> <span class="st">&#39;fiml&#39;</span>, <span class="at">bootstrap =</span> <span class="dv">1000</span>)</span>
<span id="cb246-19"><a href="#cb246-19" aria-hidden="true" tabindex="-1"></a>sLewis_sum <span class="ot">&lt;-</span> <span class="fu">summary</span>(serial_Lewis_fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">rsq=</span>T, <span class="at">fit=</span><span class="cn">TRUE</span>, <span class="at">ci=</span><span class="cn">TRUE</span>)    </span>
<span id="cb246-20"><a href="#cb246-20" aria-hidden="true" tabindex="-1"></a>sLewis_ParEsts <span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(serial_Lewis_fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a>sLewis_sum</span></code></pre></div>
<pre><code>## $FIT
##              npar              fmin             chisq                df 
##            12.000             0.000             0.000             0.000 
##            pvalue    baseline.chisq       baseline.df   baseline.pvalue 
##                NA           155.625             6.000             0.000 
##               cfi               tli              logl unrestricted.logl 
##             1.000             1.000          -868.431          -868.431 
##               aic               bic            ntotal              bic2 
##          1760.862          1801.141           212.000          1763.117 
##             rmsea    rmsea.ci.lower    rmsea.ci.upper      rmsea.pvalue 
##             0.000             0.000             0.000                NA 
##              srmr 
##             0.000 
## 
## $PE
##                lhs op                               rhs           label exo
## 1         MtnlHlth  ~                             Engmt              b1   0
## 2         MtnlHlth  ~                          DisEngmt              b2   0
## 3         MtnlHlth  ~                              GRMS             c_p   0
## 4            Engmt  ~                              GRMS              a1   0
## 5         DisEngmt  ~                              GRMS              a2   0
## 6         DisEngmt  ~                             Engmt             d21   0
## 7         MtnlHlth ~~                          MtnlHlth                   0
## 8            Engmt ~~                             Engmt                   0
## 9         DisEngmt ~~                          DisEngmt                   0
## 10            GRMS ~~                              GRMS                   1
## 11        MtnlHlth ~1                                                     0
## 12           Engmt ~1                                                     0
## 13        DisEngmt ~1                                                     0
## 14            GRMS ~1                                                     1
## 15       indirect1 :=                             a1*b1       indirect1   0
## 16       indirect2 :=                             a2*b2       indirect2   0
## 17       indirect3 :=                         a1*d21*b2       indirect3   0
## 18       contrast1 :=               indirect1-indirect2       contrast1   0
## 19       contrast2 :=               indirect1-indirect3       contrast2   0
## 20       contrast3 :=               indirect2-indirect3       contrast3   0
## 21 total_indirects :=     indirect1+indirect2+indirect3 total_indirects   0
## 22         total_c := c_p+indirect1+indirect2+indirect3         total_c   0
## 23          direct :=                               c_p          direct   0
## 24        MtnlHlth r2                          MtnlHlth                   0
## 25           Engmt r2                             Engmt                   0
## 26        DisEngmt r2                          DisEngmt                   0
##           est         se         z       pvalue    ci.lower    ci.upper
## 1   0.5806718 0.45080370  1.288081 1.977177e-01 -0.25535128  1.55057238
## 2  -3.7495295 0.44764672 -8.376091 0.000000e+00 -4.58391895 -2.86769103
## 3  -0.5745446 0.26922160 -2.134096 3.283495e-02 -1.09766028 -0.06462864
## 4   0.2033333 0.04468537  4.550334 5.356091e-06  0.11504500  0.29007149
## 5   0.1934921 0.03654478  5.294657 1.192400e-07  0.11799538  0.26328150
## 6   0.2358314 0.05038989  4.680133 2.866887e-06  0.13355108  0.33598329
## 7  10.0673374 0.83862789 12.004534 0.000000e+00  8.24746418 11.66410467
## 8   0.3370138 0.03116807 10.812790 0.000000e+00  0.27585878  0.40038675
## 9   0.2138349 0.01793862 11.920365 0.000000e+00  0.17704981  0.24794098
## 10  0.8061792 0.00000000        NA           NA  0.80617925  0.80617925
## 11 27.7278621 0.94560942 29.322743 0.000000e+00 25.80236540 29.38520563
## 12  1.9153667 0.10610583 18.051474 0.000000e+00  1.70846228  2.11781443
## 13  0.8178220 0.12758575  6.409979 1.455398e-10  0.54356422  1.06554992
## 14  1.9900000 0.00000000        NA           NA  1.99000000  1.99000000
## 15  0.1180699 0.09943867  1.187364 2.350839e-01 -0.05775972  0.33448715
## 16 -0.7255042 0.16091508 -4.508615 6.525210e-06 -1.05030410 -0.42154627
## 17 -0.1797989 0.05906713 -3.043975 2.334747e-03 -0.31175956 -0.08071553
## 18  0.8435741 0.20532268  4.108529 3.981878e-05  0.46848070  1.25685324
## 19  0.2978688 0.13036128  2.284948 2.231585e-02  0.08708742  0.60218767
## 20 -0.5457053 0.17493913 -3.119401 1.812190e-03 -0.89612134 -0.18981627
## 21 -0.7872332 0.16750149 -4.699858 2.603430e-06 -1.11075160 -0.47350422
## 22 -1.3617778 0.29278893 -4.651056 3.302391e-06 -1.95099481 -0.77628758
## 23 -0.5745446 0.26935631 -2.133028 3.292240e-02 -1.09766028 -0.06462864
## 24  0.3104425         NA        NA           NA          NA          NA
## 25  0.0900000         NA        NA           NA          NA          NA
## 26  0.2351429         NA        NA           NA          NA          NA
##        std.lv     std.all     std.nox
## 1   0.5806718  0.09248297  0.09248297
## 2  -3.7495295 -0.51886440 -0.51886440
## 3  -0.5745446 -0.13501049 -0.15036671
## 4   0.2033333  0.30000000  0.33412229
## 5   0.1934921  0.32857143  0.36594346
## 6   0.2358314  0.27142857  0.27142857
## 7  10.0673374  0.68955748  0.68955748
## 8   0.3370138  0.91000000  0.91000000
## 9   0.2138349  0.76485714  0.76485714
## 10  0.8061792  1.00000000  0.80617925
## 11 27.7278621  7.25678592  7.25678592
## 12  1.9153667  3.14737717  3.14737717
## 13  0.8178220  1.54671257  1.54671257
## 14  1.9900000  2.21634452  1.99000000
## 15  0.1180699  0.02774489  0.03090062
## 16 -0.7255042 -0.17048402 -0.18987503
## 17 -0.1797989 -0.04225039 -0.04705599
## 18  0.8435741  0.19822891  0.22077566
## 19  0.2978688  0.06999528  0.07795661
## 20 -0.5457053 -0.12823363 -0.14281905
## 21 -0.7872332 -0.18498951 -0.20603040
## 22 -1.3617778 -0.32000000 -0.35639711
## 23 -0.5745446 -0.13501049 -0.15036671
## 24         NA          NA          NA
## 25         NA          NA          NA
## 26         NA          NA          NA</code></pre>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="#cb249-1" aria-hidden="true" tabindex="-1"></a>sLewis_ParEsts</span></code></pre></div>
<pre><code>##                lhs op                               rhs           label    est
## 1         MtnlHlth  ~                             Engmt              b1  0.581
## 2         MtnlHlth  ~                          DisEngmt              b2 -3.750
## 3         MtnlHlth  ~                              GRMS             c_p -0.575
## 4            Engmt  ~                              GRMS              a1  0.203
## 5         DisEngmt  ~                              GRMS              a2  0.193
## 6         DisEngmt  ~                             Engmt             d21  0.236
## 7         MtnlHlth ~~                          MtnlHlth                 10.067
## 8            Engmt ~~                             Engmt                  0.337
## 9         DisEngmt ~~                          DisEngmt                  0.214
## 10            GRMS ~~                              GRMS                  0.806
## 11        MtnlHlth ~1                                                   27.728
## 12           Engmt ~1                                                    1.915
## 13        DisEngmt ~1                                                    0.818
## 14            GRMS ~1                                                    1.990
## 15       indirect1 :=                             a1*b1       indirect1  0.118
## 16       indirect2 :=                             a2*b2       indirect2 -0.726
## 17       indirect3 :=                         a1*d21*b2       indirect3 -0.180
## 18       contrast1 :=               indirect1-indirect2       contrast1  0.844
## 19       contrast2 :=               indirect1-indirect3       contrast2  0.298
## 20       contrast3 :=               indirect2-indirect3       contrast3 -0.546
## 21 total_indirects :=     indirect1+indirect2+indirect3 total_indirects -0.787
## 22         total_c := c_p+indirect1+indirect2+indirect3         total_c -1.362
## 23          direct :=                               c_p          direct -0.575
##       se      z pvalue ci.lower ci.upper std.lv std.all std.nox
## 1  0.451  1.288  0.198   -0.230    1.576  0.581   0.092   0.092
## 2  0.448 -8.376  0.000   -4.596   -2.873 -3.750  -0.519  -0.519
## 3  0.269 -2.134  0.033   -1.094   -0.047 -0.575  -0.135  -0.150
## 4  0.045  4.550  0.000    0.115    0.289  0.203   0.300   0.334
## 5  0.037  5.295  0.000    0.119    0.264  0.193   0.329   0.366
## 6  0.050  4.680  0.000    0.134    0.336  0.236   0.271   0.271
## 7  0.839 12.005  0.000    8.509   11.926 10.067   0.690   0.690
## 8  0.031 10.813  0.000    0.284    0.405  0.337   0.910   0.910
## 9  0.018 11.920  0.000    0.184    0.258  0.214   0.765   0.765
## 10 0.000     NA     NA    0.806    0.806  0.806   1.000   0.806
## 11 0.946 29.323  0.000   25.795   29.374 27.728   7.257   7.257
## 12 0.106 18.051  0.000    1.715    2.129  1.915   3.147   3.147
## 13 0.128  6.410  0.000    0.567    1.073  0.818   1.547   1.547
## 14 0.000     NA     NA    1.990    1.990  1.990   2.216   1.990
## 15 0.099  1.187  0.235   -0.035    0.375  0.118   0.028   0.031
## 16 0.161 -4.509  0.000   -1.046   -0.416 -0.726  -0.170  -0.190
## 17 0.059 -3.044  0.002   -0.328   -0.089 -0.180  -0.042  -0.047
## 18 0.205  4.109  0.000    0.485    1.264  0.844   0.198   0.221
## 19 0.130  2.285  0.022    0.101    0.621  0.298   0.070   0.078
## 20 0.175 -3.119  0.002   -0.898   -0.201 -0.546  -0.128  -0.143
## 21 0.168 -4.700  0.000   -1.114   -0.475 -0.787  -0.185  -0.206
## 22 0.293 -4.651  0.000   -1.933   -0.774 -1.362  -0.320  -0.356
## 23 0.269 -2.133  0.033   -1.094   -0.047 -0.575  -0.135  -0.150</code></pre>
</div>
<div id="figures-and-tables-2" class="section level3" number="7.4.3">
<h3 number="7.4.3"><span class="header-section-number">7.4.3</span> Figures and Tables</h3>
<p><strong>Table 2 </strong></p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Model Coefficients Assessing Engagement and Disengagement Coping as Serial Mediators Between Predicting Mental Health from Gendered Racial Microaggressions</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<colgroup>
<col width="4%" />
<col width="2%" />
<col width="6%" />
<col width="2%" />
<col width="6%" />
<col width="2%" />
<col width="8%" />
<col width="30%" />
<col width="2%" />
<col width="9%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">IV</td>
<td align="center"></td>
<td align="center">M1</td>
<td align="center"></td>
<td align="center">M2</td>
<td align="center"></td>
<td align="center">DV</td>
<td align="center"><span class="math inline">\(B\)</span> for <em>a</em>, <em>b</em>, and <span class="math inline">\(d_{21}\)</span> paths</td>
<td align="center"></td>
<td align="right"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="center">GRMS</td>
<td align="center">–&gt;</td>
<td align="center">Engmt</td>
<td align="center">–&gt;</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">MntlHlth</td>
<td align="center">(0.203) X (0.581)</td>
<td align="center">=</td>
<td align="right">0.118</td>
<td align="center">0.099</td>
<td align="center">0.235</td>
</tr>
<tr class="odd">
<td align="center">GRMS</td>
<td align="center">–&gt;</td>
<td align="center">DisEngmt</td>
<td align="center">–&gt;</td>
<td align="center"></td>
<td align="center"></td>
<td align="center">MntlHlth</td>
<td align="center">(0.193) X (-3.750)</td>
<td align="center">=</td>
<td align="right">-0.726</td>
<td align="center">0.161</td>
<td align="center">0.000</td>
</tr>
<tr class="even">
<td align="center">GRMS</td>
<td align="center">–&gt;</td>
<td align="center">Engmt</td>
<td align="center">–&gt;</td>
<td align="center">DisEngmt</td>
<td align="center">–&gt;</td>
<td align="center">MntlHlth</td>
<td align="center">(0.203) X (0.236) X (-3.750)</td>
<td align="center">=</td>
<td align="right">-0.180</td>
<td align="center">0.059</td>
<td align="center">0.000</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="68%" />
<col width="9%" />
<col width="11%" />
<col width="10%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="center">Total indirect effect</td>
<td align="center">-0.787</td>
<td align="center">0.168</td>
<td align="center">0.000</td>
</tr>
<tr class="odd">
<td align="center">Total effect of GRMS (X) on mental health (Y; c path)</td>
<td align="center">-1.362</td>
<td align="center">0.293</td>
<td align="center">0.000</td>
</tr>
<tr class="even">
<td align="center">Direct effect of GRMS (X) on mental health (Y; c’ path)</td>
<td align="center">-0.575</td>
<td align="center">0.269</td>
<td align="center">0.033</td>
</tr>
<tr class="odd">
<td align="center">Contrast comparing indirects 1 (via engagement) and 2 (via disengagement)</td>
<td align="center">0.844</td>
<td align="center">0.205</td>
<td align="center">0.000</td>
</tr>
<tr class="even">
<td align="center">Contrast comparing indirects 1 (via engagement) and 3 (serially via disengagement)</td>
<td align="center">0.298</td>
<td align="center">0.130</td>
<td align="center">0.022</td>
</tr>
<tr class="odd">
<td align="center">Contrast comparing indirects 2 (via disengagement) and 3 (serially via disengagement)</td>
<td align="center">-0.546</td>
<td align="center">0.175</td>
<td align="center">0.002</td>
</tr>
</tbody>
</table>
<table>
<tbody>
</tbody>
</table>
<p><em>Note</em>. IV = gendered racial microaggressions; M1 = engagement coping; M2 = disengagement coping; Y = mental health. The significance of the indirect effects was calculated with bias-corrected confidence intervals (.95) bootstrap analysis.</p>
<p>Working through the data, we should be able to find these items:</p>
<ul>
<li>The model accounts for 31.04% of the variance in predicting mental health outcomes.</li>
<li>The total effect of GRMS (X) on mental health (Y) is -1.362 (<span class="math inline">\(p\)</span> = 0.000) is negative and statistically significant.</li>
<li>The direct effect of GRMS (X) on mental health (Y) (-0.575, <span class="math inline">\(p\)</span> = 0.033) is still negative, but weaker in magnitude (relative to the total effect). While the <span class="math inline">\(p\)</span> value is statistically significant, it is closer to being not significant (than the total effect). This reduction in magnitude and strength of significance is consistent with the Baron and Kenny <span class="citation">(<a href="#ref-baron_moderator-mediator_1986" role="doc-biblioref">1986</a>)</span> logic of mediation.</li>
<li>Indirect effect #1 (<span class="math inline">\(a_{1}\)</span> x <span class="math inline">\(b_{1}\)</span> or GRMS through engagement coping to mental health) is 0.118 (<span class="math inline">\(p\)</span> = 0.235). Again, <span class="math inline">\(p\)</span> is &gt; .05. Examining the individual paths, there is a statistically significant relationship from GRMS to engagement, but not from engagement to mental health.</li>
<li>Indirect effect #2 (<span class="math inline">\(a_{2}\)</span> x <span class="math inline">\(b_{2}\)</span>, or GRMS through disengagement coping to mental health, is -0.726 (<span class="math inline">\(p\)</span> = 0.000). Each of the paths is statistically significant from zero and so is the indirect effect.</li>
<li>Indirect effect #3 (<span class="math inline">\(a_{2}\)</span> x <span class="math inline">\(d_{21}\)</span> x <span class="math inline">\(b_{2}\)</span>; GRMS through engagement coping through disengagement coping to mental health) is -0.180 (<span class="math inline">\(p\)</span> = 0.000). This indirect effect involves <span class="math inline">\(a_{1}\)</span> (GRMS to engagement) which is not significant. However, the remaining paths were significant. That is engagement coping led to increased disengagement coping, which led to poorer mental health outcomes.</li>
<li>Total indirect: -0.787 (<span class="math inline">\(p\)</span> = 0.000) is the sum of all specific indirect effects and is statistically significant.</li>
<li>With <strong>contrasts</strong> we ask: Are the indirect effects statistically significantly different from each other?
<ul>
<li>Contrast 1 (indirect 1 v 2) = 0.844 (<span class="math inline">\(p\)</span> = 0.000), yes</li>
<li>Contrast 2 (indirect 1 v 3) = 0.844 (<span class="math inline">\(p\)</span> = 0.022), yes</li>
<li>Contrast 3 (indirect 2 v 3) = 0.844 (<span class="math inline">\(p\)</span> = -0.546), yes</li>
<li>This formal test of contrasts is an important one. It is not ok to infer that effects are statistically significantly different than each other on the basis of their estimates or <span class="math inline">\(p\)</span> values. The formal test allows us to claim (with justification) that the strongest indirect effect is #2 – GRMS through disengagement coping to mental health.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semTable)</span>
<span id="cb251-2"><a href="#cb251-2" aria-hidden="true" tabindex="-1"></a>LewisserialTbl <span class="ot">&lt;-</span> <span class="fu">semTable</span>(serial_Lewis_fit, <span class="at">columns =</span> <span class="fu">c</span>(<span class="st">&quot;est&quot;</span>, <span class="st">&quot;se&quot;</span>, <span class="st">&quot;p&quot;</span>, <span class="st">&quot;rsquare&quot;</span>),  <span class="at">columnLabels =</span> <span class="fu">c</span>(<span class="at">eststars =</span> <span class="st">&quot;Estimate&quot;</span>), <span class="at">paramSets =</span> <span class="fu">c</span>(<span class="st">&quot;composites&quot;</span>, <span class="st">&quot;loadings&quot;</span>, <span class="st">&quot;slopes&quot;</span>, <span class="st">&quot;intercepts&quot;</span>, <span class="st">&quot;residualvariances&quot;</span>), <span class="at">file =</span> <span class="st">&quot;LewisSerialTbl&quot;</span>, <span class="at">type =</span> <span class="st">&quot;csv&quot;</span>, <span class="at">print.results =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>This is not the greatest figure. There is much to learn in <em>semPlot</em>.</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(serial_Lewis_fit, <span class="co">#must identiy the model you want to map</span></span>
<span id="cb252-2"><a href="#cb252-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb252-3"><a href="#cb252-3" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb252-4"><a href="#cb252-4" aria-hidden="true" tabindex="-1"></a>         <span class="co">#layout = &#39;tree&#39;, rotation = 2, #together, puts predictors on left, IVs on right </span></span>
<span id="cb252-5"><a href="#cb252-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;circle&#39;</span>,</span>
<span id="cb252-6"><a href="#cb252-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb252-7"><a href="#cb252-7" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb252-8"><a href="#cb252-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb252-9"><a href="#cb252-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb252-10"><a href="#cb252-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb252-11"><a href="#cb252-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb252-12"><a href="#cb252-12" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb252-13"><a href="#cb252-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb252-14"><a href="#cb252-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb252-15"><a href="#cb252-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb252-16"><a href="#cb252-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb252-17"><a href="#cb252-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb252-18"><a href="#cb252-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb252-19"><a href="#cb252-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb252-20"><a href="#cb252-20" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;The Effect of Gendered Racial Microaggressions on Mental Health through Engaged and Disengaged Coping Styles&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/semPlot%20of%20serial%20PMI%20model-1.svg" width="672" /></p>
</div>
<div id="apa-style-writeup-2" class="section level3" number="7.4.4">
<h3 number="7.4.4"><span class="header-section-number">7.4.4</span> APA Style Writeup</h3>
<p><strong>Method</strong>
<strong>Data Analysis</strong>
Serial multiple mediation is appropriate when testing the influence of an independent variable (X) on the dependent variable (Y) directly, as well as indirectly through two or more mediators (M) and there is reason to hypothesize that variables that are causally prior in the model affect all variables later in the causal sequence <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">Hayes, 2018</a>)</span>. We utilized serial multiple mediation analysis to test the influence of gendered racial microaggressions (X, GRMS) on mental health (Y, MntlHlth) directly as well as indirectly through the mediators engagement coping (M1, Engmt) and disengagement coping (M2, DisEngmt). Moreover, we hypothesized a causal linkage between from the engagement coping mediator to the disengagement coping mediator such that a third specific indirect effect began with GRMS (X) through engagement coping (M1) through disengagement coping (M2) to mental health (Y). Using the <em>lavaan</em> (v. 0.6-7) package in R we followed the procedures outlined in Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> by analyzing the strength and significance of four sets of effects: specific indirect, the total indirect, the direct, and total. Bootstrap analysis, a nonparametric sampling procedure, was used to test the significance of the indirect effects.</p>
<p><em>Hayes would likely recommend that we say this with fewer acronyms and more words/story.</em></p>
<p><strong>Results</strong>
<strong>Preliminary Analyses</strong>
Descriptive statistics were computed, and all variables were assessed univariate normality. <em>You would give your results regarding skew, kurtosis, Shapiro Wilks’, here. If relevant, you could also describe multivariate normality.</em> A summary of descriptive statistics and a correlation matrix for the study is provided in Table 1. These bivariate relations provide evidence to support the test of mediation analysis.</p>
<p><strong>Serial Multiple Mediation Analysis</strong>
A model of serial multiple mediation was analyzed examining the degree to which engagement and disengagement coping mediated the relationship between gendered racial microaggressions and mental health outcomes. Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> recommended this strategy over simple mediation models because it allows for all mediators to be examined, simultaneously and allows the testing of the seriated effect of prior mediators onto subsequent ones. Using the <em>lavaan</em> (v. 0.6-7) package in R, coefficients for specific indirect, total indirect, direct, and total were computed. Path coefficients refer to regression weights, or slopes, of the expected changes in the dependent variable given a unit change in the independent variables.</p>
<p>Results (depicted in Figure # and presented in Table #) suggest that 31.04% of the variance in behavioral intentions is accounted for by the three variables in the model. Two of the specific indirect effects were significant and were statistically significantly different from each other. Specifically, the effect of gendered racial microaggressions through disengagement coping to mental health (<span class="math inline">\(B\)</span> = 0.118, <span class="math inline">\(p\)</span> = 0.235) was stronger than the indirect effect from gendered racial microaggressions through engagement coping through disengagement coping to mental health (<span class="math inline">\(B\)</span> = -0.180, <span class="math inline">\(p\)</span> = 0.000). Interpreting the results suggests that, mental health outcomes are negatively impacted by gendered racial microaggressions direct and indirectly through disengagement coping. It is this latter path that has the greatest impact.</p>
<p><em>Note</em>: In a manner consistent with the Lewis et al. <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">2017</a>)</span> article, the APA Results section can be fairly short. This is especially true when a well-organized table presents the results. In fact, I oculd have left all the numbers out of this except for the <span class="math inline">\(R^2\)</span> (because it was not reported in the table).</p>
</div>
</div>
<div id="troubleshooting-and-faqs" class="section level2" number="7.5">
<h2 number="7.5"><span class="header-section-number">7.5</span> Troubleshooting and FAQs</h2>
<p>An indirect effect that was (seemingly) significant in a simple (single) mediation disappears when additional mediators are added.</p>
<ul>
<li>Correlated mediators (e.g., multicollinearity) is a likely possibility.</li>
<li>Which is correct? Maybe both…</li>
</ul>
<p>A total effect was not significant, but there is one or more statistically significant specific indirect effect</p>
<ul>
<li>Recall that a total effect equals the sum of direct and indirect effects. If one specific indirect effect is positive and another is negative, this could account for the NS total effect.</li>
<li>If the direct effect is NS, but the indirect effects are significant, this might render the total effect NS.</li>
<li>The indirect effects might operate differently in subpopulations (males, females).</li>
</ul>
<p>Your editor/peer reviewer/dissertation chair-or-committee member may insist that you do this the Baron &amp; Kenny way (aka “the causal steps approach”).</p>
<ul>
<li>Hayes 4.1 <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> provides fabulous narration and justification for how to justify your (I believe correct) decision to just use the PROCESS (aka, bootstrapped, bias corrected, CIs )approach.</li>
<li>My favorite line in his text reads, " (the B&amp;K way).is still being taught and recommended by researchers who don’t follow the methodology literature."</li>
</ul>
<p>How can I extend a mediation (only) model to include multiple Xs, Ys, or COVs?</p>
<ul>
<li>There is fabulous, fabulous narration and syntax for doing all of this in Hayes text. Of course his mechanics are in PROCESS, but <em>lavaan</em> is easy to use by just “drawing more paths” via the syntax. We’ll get more practice as we go along.</li>
</ul>
<p>What about effect sizes? Shouldn’t we be including/reporting them?</p>
<ul>
<li>Yes! The closest thing we have reported to an effect size is <span class="math inline">\(R^2\)</span>, which assess proportion of variance accounted for in the M and Y variables.<br />
</li>
<li>In PROCESS and path analysis this is still emerging. Hayes chapter 4 presents a handful of options for effect sizes beyond <span class="math inline">\(R^2\)</span>.</li>
</ul>
</div>
<div id="practice-problems-5" class="section level2" number="7.6">
<h2 number="7.6"><span class="header-section-number">7.6</span> Practice Problems</h2>
<p>The three problems described below are designed to be grow in this series of chapters that begins with simple mediation and progresses through complex mediation, moderated moderation, and conditional process analysis. I recommend that you select a dataset that includes at least four variables. If you are new to this topic, you may wish to select variables that are all continuously scaled. The IV and moderator (in subsequent chapters) could be categorical (if they are dichotomous, please use 0/1 coding; if they have more than one category it is best if they are ordered). You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.</p>
<p>The suggested practice problem for this chapter is to conduct a parallel or serial mediation (or both).</p>
<div id="problem-1-rework-the-research-vignette-as-demonstrated-but-change-the-random-seed-1" class="section level3" number="7.6.1">
<h3 number="7.6.1"><span class="header-section-number">7.6.1</span> Problem #1: Rework the research vignette as demonstrated, but change the random seed</h3>
<p>If this topic feels a bit overwhelming, simply change the random seed in the data simulation, then rework the problem. This should provide minor changes to the data (maybe in the second or third decimal point), but the results will likely be very similar.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, M1, and M2 roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes a summary of the effects (indirect, direct, total, total indirect) as well as contrasts (if you chose a serially mediated model)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-2-rework-the-research-vignette-but-swap-one-or-more-variables-1" class="section level3" number="7.6.2">
<h3 number="7.6.2"><span class="header-section-number">7.6.2</span> Problem #2: Rework the research vignette, but swap one or more variables</h3>
<p>Use the simulated data provided in this chapter, but swap out one or more of the variables. This could mean changing roles for the variables that were the focus of the chapter, or substituting one or more variables for those in the simulated data but not modeled in the chapter.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, M1, and M2 roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes a summary of the effects (indirect, direct, total, total indirect) as well as contrasts (if you chose a serially mediated model)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-3-use-other-data-that-is-available-to-you-1" class="section level3" number="7.6.3">
<h3 number="7.6.3"><span class="header-section-number">7.6.3</span> Problem #3: Use other data that is available to you</h3>
<p>Use data for which you have permission and access. This could be IRB approved data you have collected or from your lab; data you simulate from a published article; data from an open science repository; or data from other chapters in this OER.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, M1, and M2 roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes a summary of the effects (indirect, direct, total, total indirect) as well as contrasts (if you chose a serially mediated model)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] MASS_7.3-53.1     semTable_1.8      semPlot_1.1.2     lavaan_0.6-8     
##  [5] apaTables_2.0.8   mice_3.13.0       sjstats_0.18.1    formattable_0.2.1
##  [9] qualtRics_3.1.4   forcats_0.5.1     stringr_1.4.0     dplyr_1.0.5      
## [13] purrr_0.3.4       readr_1.4.0       tidyr_1.1.3       tibble_3.1.1     
## [17] ggplot2_3.3.3     tidyverse_1.3.1   psych_2.1.3      
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1        backports_1.2.1     Hmisc_4.5-0        
##   [4] systemfonts_1.0.1   igraph_1.2.6        plyr_1.8.6         
##   [7] splines_4.0.4       TH.data_1.0-10      digest_0.6.27      
##  [10] htmltools_0.5.1.1   matrixcalc_1.0-3    fansi_0.4.2        
##  [13] magrittr_2.0.1      Rsolnp_1.16         checkmate_2.0.0    
##  [16] lisrelToR_0.1.4     cluster_2.1.2       openxlsx_4.2.3     
##  [19] modelr_0.1.8        sandwich_3.0-0      svglite_2.0.0      
##  [22] jpeg_0.1-8.1        sem_3.1-11          MBESS_4.8.0        
##  [25] colorspace_2.0-0    rvest_1.0.0         haven_2.4.1        
##  [28] xfun_0.22           crayon_1.4.1        jsonlite_1.7.2     
##  [31] lme4_1.1-26         regsem_1.6.2        survival_3.2-11    
##  [34] zoo_1.8-9           glue_1.4.2          gtable_0.3.0       
##  [37] emmeans_1.6.0       mi_1.0              sjmisc_2.8.6       
##  [40] abind_1.4-5         scales_1.1.1        mvtnorm_1.1-1      
##  [43] DBI_1.1.1           Rcpp_1.0.6          xtable_1.8-4       
##  [46] performance_0.7.1   htmlTable_2.1.0     tmvnsim_1.0-2      
##  [49] foreign_0.8-81      Formula_1.2-4       stats4_4.0.4       
##  [52] truncnorm_1.0-8     htmlwidgets_1.5.3   httr_1.4.2         
##  [55] RColorBrewer_1.1-2  ellipsis_0.3.1      XML_3.99-0.6       
##  [58] pkgconfig_2.0.3     nnet_7.3-15         sass_0.3.1         
##  [61] kutils_1.70         dbplyr_2.1.1        utf8_1.2.1         
##  [64] reshape2_1.4.4      tidyselect_1.1.1    rlang_0.4.11       
##  [67] effectsize_0.4.4-1  munsell_0.5.0       cellranger_1.1.0   
##  [70] tools_4.0.4         cli_2.5.0           generics_0.1.0     
##  [73] sjlabelled_1.1.7    broom_0.7.6         fdrtool_1.2.16     
##  [76] evaluate_0.14       arm_1.11-2          yaml_2.2.1         
##  [79] knitr_1.33          fs_1.5.0            stationery_0.98.30 
##  [82] zip_2.1.1           glasso_1.11         pbapply_1.4-3      
##  [85] nlme_3.1-151        xml2_1.3.2          compiler_4.0.4     
##  [88] rstudioapi_0.13     curl_4.3.1          png_0.1-7          
##  [91] reprex_2.0.0        statmod_1.4.35      bslib_0.2.4        
##  [94] pbivnorm_0.6.0      stringi_1.5.3       highr_0.9          
##  [97] parameters_0.13.0   qgraph_1.6.9        rockchalk_1.8.144  
## [100] lattice_0.20-41     Matrix_1.2-18       nloptr_1.2.2.2     
## [103] vctrs_0.3.7         pillar_1.6.0        lifecycle_1.0.0    
## [106] jquerylib_0.1.4     OpenMx_2.19.5       estimability_1.3   
## [109] corpcor_1.6.9       data.table_1.14.0   insight_0.13.2     
## [112] R6_2.5.0            latticeExtra_0.6-29 bookdown_0.22      
## [115] gridExtra_2.3       codetools_0.2-18    gtools_3.8.2       
## [118] boot_1.3-27         assertthat_0.2.1    withr_2.4.2        
## [121] mnormt_2.0.2        multcomp_1.4-17     bayestestR_0.9.0   
## [124] parallel_4.0.4      hms_1.0.0           grid_4.0.4         
## [127] rpart_4.1-15        coda_0.19-4         minqa_1.2.4        
## [130] rmarkdown_2.7       carData_3.0-4       lubridate_1.7.10   
## [133] base64enc_0.1-3</code></pre>
<!--chapter:end:07-ComplexMed.Rmd-->
</div>
</div>
</div>
<div id="CPA" class="section level1 unnumbered">
<h1 class="unnumbered">CONDITIONAL PROCESS ANLAYSIS</h1>
</div>
<div id="ModMed" class="section level1" number="8">
<h1 number="8"><span class="header-section-number">8</span> Moderated Mediation</h1>
<p><a href="https://spu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?pid=1d28d076-efad-4471-b52d-ad1601826f92">Screencasted Lecture Link</a></p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="#cb255-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">scipen=</span><span class="dv">999</span>)<span class="co">#eliminates scientific notation</span></span></code></pre></div>
<p>The focus of this lecture is the moderated mediation. That is, are the effects of the indirect effect (sign, significance, strength, presence/absence) <em>conditional</em> on the effects of the moderator.</p>
<p>At the outset, please note that although I rely heavily on Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> text and materials, I am using the R package <em>lavaan</em> in these chapters. Very recently, Hayes has introduced a <a href="https://www.processmacro.org/index.html">PROCESS macro for R</a>. Because I am not yet up-to-speed on using this macro (it is not a typical R package) and because we will use <em>lavaan</em> for confirmatory factor analysis and structural equation modeling, I have chosen to utilize the <em>lavaan</em> package. A substantial difference is that the PROCESS macros use ordinary least squares and <em>lavaan</em> uses maximum likelihood estimators.</p>
<div id="navigating-this-lesson-6" class="section level2" number="8.1">
<h2 number="8.1"><span class="header-section-number">8.1</span> Navigating this Lesson</h2>
<p>There is about 1 hour and 15 minutes of lecture. If you work through the materials with me it would be plan for an additional hour and a half.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, occasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_MultivariateModeling">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="#ReCintro">introduction</a></p>
<div id="learning-objectives-6" class="section level3" number="8.1.1">
<h3 number="8.1.1"><span class="header-section-number">8.1.1</span> Learning Objectives</h3>
<p>Learning objectives from this lecture include the following:</p>
<ul>
<li>Outline a process of evaluating a moderated mediation in a piecewise <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">Hayes, 2018</a>)</span> approach to model building</li>
<li>Recognize conditional process modeling from R script.</li>
<li>Using the R package <em>lavaan</em>,
<ul>
<li>specify a model with indirect effects,</li>
<li>identify and interpret B weights, <em>p</em> values, and <em>CIs</em> for total, direct, and indirect effects,<br />
</li>
<li>calculate the total effects of X and M on Y,</li>
<li>identify the proportion of variance accounted for in predicting M and Y.</li>
</ul></li>
<li>Regarding conditional indirect effects
<ul>
<li>Interpret an index of moderated mediation</li>
<li>Know the essential components of calculating an index of moderated mediation</li>
<li>Probe a conditional indirect effect</li>
</ul></li>
<li>Interpret “the usual” things we find in regression: B/beta weights, R, <span class="math inline">\(R^{2}\)</span>, and figures</li>
</ul>
</div>
<div id="planning-for-practice-6" class="section level3" number="8.1.2">
<h3 number="8.1.2"><span class="header-section-number">8.1.2</span> Planning for Practice</h3>
<p>The suggestions for homework are graded in complexity and, if you like, can extend from the prior chapter on simple moderation. If you choose the first or second options, you can further amend the simulated data by making further variations such as sample size.</p>
<ul>
<li>Rework the problem in the chapter by changing the random seed in the code that simulates the data. This should provide minor changes to the data, but the results will likely be very similar.</li>
<li>There are a number of variables in the dataset. Swap out one or more variables in the moderated mediation and compare your solution to the one in the chapter (and/or oe you mimicked in the journal article).</li>
<li>Conduct a moderated mediation with data to which you have access. This could include data you simulate on your own or from a published article.</li>
</ul>
</div>
<div id="readings-resources-6" class="section level3" number="8.1.3">
<h3 number="8.1.3"><span class="header-section-number">8.1.3</span> Readings &amp; Resources</h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<ul>
<li>Hayes, A. F. (2018). <em>Introduction to mediation, moderation, and conditional process anlaysis: A regression-based approach</em>. New York, NY: Guilford Press. Available as an ebook from the SPU library: <a href="https://ebookcentral-proquest-com.ezproxy.spu.edu/lib/spu/detail.action?docID=5109647" class="uri">https://ebookcentral-proquest-com.ezproxy.spu.edu/lib/spu/detail.action?docID=5109647</a>
<ul>
<li><strong>Chapter 11, CPA fundamentals</strong>: In this chapter Hayes disentangles conditional indirect effects.</li>
<li><strong>Chapter 12, More CPA examples</strong>: Among the examples is one that includes covariates.<br />
</li>
<li><strong>Appendix A: Using Process</strong>: An essential tool for PROCESS users because, even when we are in the R environment, this is the “idea book.” That is, the place where all the path models are presented in figures.</li>
</ul></li>
<li>Lewis, J. A., Williams, M. G., Peppers, E. J., &amp; Gadson, C. A. (2017). Applying intersectionality to explore the relations between gendered racism and health among Black women. <em>Journal of Counseling Psychology, 64</em>(5), 475–486. <a href="https://doi-org.ezproxy.spu.edu/10.1037/cou0000231" class="uri">https://doi-org.ezproxy.spu.edu/10.1037/cou0000231</a></li>
</ul>
</div>
<div id="packages-7" class="section level3" number="8.1.4">
<h3 number="8.1.4"><span class="header-section-number">8.1.4</span> Packages</h3>
<p>The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a><span class="co">#will install the package if not already installed</span></span>
<span id="cb256-2"><a href="#cb256-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(lavaan)){<span class="fu">install.packages</span>(<span class="st">&quot;lavaan&quot;</span>)}</span>
<span id="cb256-3"><a href="#cb256-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(semPlot)){<span class="fu">install.packages</span>(<span class="st">&quot;semPlot&quot;</span>)}</span>
<span id="cb256-4"><a href="#cb256-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(tidyverse)){<span class="fu">install.packages</span>(<span class="st">&quot;tidyverse&quot;</span>)}</span>
<span id="cb256-5"><a href="#cb256-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(psych)){<span class="fu">install.packages</span>(<span class="st">&quot;psych&quot;</span>)}</span>
<span id="cb256-6"><a href="#cb256-6" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(<span class="sc">!</span><span class="fu">require</span>(jtools)){<span class="fu">install.packages</span>(<span class="st">&quot;jtools&quot;</span>)}</span></code></pre></div>
<pre><code>## Loading required package: jtools</code></pre>
<pre><code>## Warning: package &#39;jtools&#39; was built under R version 4.0.5</code></pre>
</div>
</div>
<div id="conditional-process-analysis" class="section level2" number="8.2">
<h2 number="8.2"><span class="header-section-number">8.2</span> Conditional Process Analysis</h2>
<div id="the-definitional-and-conceptual-1" class="section level3" number="8.2.1">
<h3 number="8.2.1"><span class="header-section-number">8.2.1</span> The definitional and conceptual</h3>
<p>Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> coined the term and suggests we also talk about “conditional process modeling.”</p>
<p><strong>Conditional process analysis</strong>: used when the analytical goal is to describe and understand the conditional nature of the mechanism or mechanisms by which a variable transmits its effect on another.</p>
<p>We are integrating moderation and mediation mechanisms together into a single integrated analytical model.</p>
<ul>
<li><strong>Mediator</strong>: Any causal system in which at least one causal antecedent X variable is proposed as influencing an outcome Y through a intervening variable M. In this model, there are two pathways by which X can influence Y: <em>direct</em> effect of X on Y, and <em>indirect</em> effect of X on Y through M.
<ul>
<li>Answers question, “How does X affect Y”</li>
<li>Partitions the X-to-Y relationship into two paths of influence: direct, indirect.</li>
<li>Indirect effect contains two components (a,b) that when multipled (a*b) yield an estimate of how much these two cases that differ by one unit on X are estimated to differ on Y through the effect of X on M, which in turn affects Y.</li>
<li>Keywords: how, through, via, indirect effect</li>
</ul></li>
<li><strong>Moderator</strong>: The effect of X on some variable Y is moderated by W if its size, sign, or strength depends on or can be predicted by W.
<ul>
<li>Stated another way, W and X <em>interact</em> in their influence on Y.<br />
</li>
<li>Moderators help establish the boundary conditions of an effect or the circumstances, stimuli, or type of people for which the effect is large v. small, present v. absent, positive v. negative, and so forth.</li>
<li>Keywords: “it depends,” interaction effect.</li>
</ul></li>
</ul>
<p><strong>Why should we engage both mediators and moderators?</strong> Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> suggest that if we have only a mediator(s) in the model that we lose information if we “reduce complex responses that no doubt differ from person to person or situation to situation” (p. 394). He adds that “all effects are moderated by something” (p. 394). Correspondingly, he recommends we add them to a mediation anlaysis.</p>
<p>Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> suggests that “more complete” (p. 395) analyses model the mechanisms at work linking X to Y (mediator[s]) while simultaneously allowing those effects to be contingent on context, circumstance, or individual difference (moderator[s]).</p>
<p><strong>What are conditional direct and indirect effects?</strong>. Mediation analyses produce indirect (the product of a sequence of effects that are assumed to be causal) and direct (the unique contribution of X to Y, controlling for other variables in the model) effects. These effects (the X-to-Y/direct and X-to-M-to-Y/indirect), can also be moderated. This is our quest! Figure 11.2 in Hayes’ text <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> illustrates conceptually and statistically that we can specify moderation of any combination of direct and indirect paths/effects.</p>
<div class="figure">
<img src="images/SimpleMed/CPAmodel.jpg" alt="" />
<p class="caption">Image of conditional process analysis model where the moderator is hypothesized to change the a path; the path between the IV and mediator</p>
</div>
<p>Within the CPA framework we have lots of options that generally fall into two categories:</p>
<ul>
<li><em>Moderated mediation</em>: when an indirect effect of X on Y through M is moderated; the mechanism represented by the <em>X-to-M-to-Y</em> chain of events operates to varying degrees (or not at all) for certain people or in certain contexts.
<ul>
<li>Any model in which the indirect effect (a*b) changes as a function of one or more moderators. These moderators can be operating on the a, b, or c’ paths or any possible combination of the three</li>
<li>X could moderate its own indirect effect on Y through M if the effect of M on Y depends on X, or</li>
<li>The indirect effect of X on Y through M could be contingent on a fourth variable if that fourth variable W moderates one or more of the relationships in a three-variable causal system, or</li>
<li>An indirect effect could be contingent on a moderator variable</li>
</ul></li>
<li><em>Mediated moderation</em>: an interaction between X and some moderator W on Y is carried through a mediator M;
<ul>
<li>mediated moderation analysis is simply a mediation analysis with the product of two variables serving as the causal agent of focus</li>
<li>An interaction between a moderator W and causal agent X on outcome Y could operate through a mediator M</li>
</ul></li>
</ul>
<p>Hayes argues that the mediated moderation hypotheses are “regularly articulated and tested by scientists” <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018, p. 459</a>)</span>. He warns, though, that we should not confuse the “abundance of published examples of mediated moderation anlayses…with the meaningfulness of the procedure itself” (p. 460). He later adds that mediation moderation is “neither interesting nor meaningful.” Why?</p>
<ul>
<li>Conceptualizing a process in terms of a mediated moderation misdirects attention toward a variable in the model that actually doesn’t measure anything.</li>
<li>Most often there are moderated mediation models that are identical in equations and resulting coefficients - the difference is in the resulting attentional focus and interpretation.</li>
<li>Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> recommends that models proposing mediated moderation be recast in terms of moderated mediation process.</li>
<li>Consequently, we will not work a mediated moderation, but there is an example in chapter 12.</li>
</ul>
</div>
<div id="hayes--hayes_introduction_2018-piecewise-approach-to-building-models" class="section level3" number="8.2.2">
<h3 number="8.2.2"><span class="header-section-number">8.2.2</span> Hayes’ <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> Piecewise Approach to Building Models</h3>
<p>In summarizing a strategic approach for testing structural equation models, Joreskog <span class="citation">(<a href="#ref-bollen_testing_1993" role="doc-biblioref">Joreskog, 1993</a>)</span> identified three scenarios:</p>
<ul>
<li><em>strictly confirmatory</em>: the traditional NHST approach of proposing a single, theoretically derived, model, and after analyzing the data either rejects or fails to reject the model. No further modifications are made/allowed.</li>
<li><em>alternative models</em>: the reseacher proposes competing (also theoretically derived) models. Following analysis of a single set of empirical data, he or she selects one model as appropriate in representing the sample data.</li>
<li><em>model generating</em>: A priori, the researcher acknowledges that they may/may not find what they have theoretically proposed. So, a priori, they acknowledge that in the absence of ideal fit (which is the usual circumstance), they will proceed in an exploratory fashion to respecify/re-estimate the model. The goal is to find a model that is both substantively meaningful and statistically well-fitting.</li>
</ul>
<p>A legacy of our field is the <em>strictly confirmatory</em> approach. I am thrilled when I see research experts (e.g., <span class="citation">(<a href="#ref-byrne_structural_2016" role="doc-biblioref">Byrne, 2016</a>)</span>) openly endorse a model building approach. In Chapter 12, Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> demonstrates the piecewise approach to building (and understanding) a complex model.</p>
</div>
</div>
<div id="workflow-for-moderated-mediation" class="section level2" number="8.3">
<h2 number="8.3"><span class="header-section-number">8.3</span> Workflow for Moderated Mediation</h2>
<p>At this point in this OER’s development, I don’t have a workflow graphic developed for this statistic. However, Hayes’ <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> <em>piecewise</em> approach to model testing/building is really the workflow. The secret is to decompose the model into its simplest moderations and mediations and analyze them separately before assembling them. When we get to the model we will analyze with this research vignette, a series of diagrams will make this more clear.</p>
<p>Additionally, at the end of the chapter, I offer a template of R script for the popular moderated mediation (a single moderator influencin both the <em>a</em> and <em>c’</em> paths).</p>
</div>
<div id="research-vignette-6" class="section level2" number="8.4">
<h2 number="8.4"><span class="header-section-number">8.4</span> Research Vignette</h2>
<p>Once again the research vignette comes from the Lewis, Williams, Peppers, and Gadson’s <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">2017</a>)</span> study titled, “Applying Intersectionality to Explore the Relations Between Gendered Racism and Health Among Black Women.” The study was published in the Journal of Counseling Psychology. Participants were 231 Black women who completed an online survey.</p>
<p>Variables used in the study included:</p>
<ul>
<li><p><strong>GRMS</strong>: Gendered Racial Microaggressions Scale <span class="citation">(<a href="#ref-lewis_construction_2015" role="doc-biblioref">J. A. Lewis &amp; Neville, 2015</a>)</span> is a 26-item scale that assesses the frequency of nonverbal, verbal, and behavioral negative racial and gender slights experienced by Black women. Scaling is along six points ranging from 0 (never) to 5 (once a week or more). Higher scores indicate a greater frequency of gendered racial microaggressions. An example item is, “Someone has made a sexually inappropriate comment about my butt, hips, or thighs.”</p></li>
<li><p><strong>MntlHlth</strong> and <strong>PhysHlth</strong>: Short Form Health Survey - Version 2 <span class="citation">(<a href="#ref-ware_comparison_1995" role="doc-biblioref">Ware et al., 1995</a>)</span> is a 12-item scale used to report self-reported mental (six items) and physical health (six items).
Higher scores indicate higher mental health (e.g., little or no psychological ldistress) and physical health (e.g., little or no reported symptoms in physical functioning). An example of an item assessing mental health was, “How much of the time during the last 4 weeks have you felt calm and peaceful?”; an example of a physical health item was, “During the past 4 weeks, how much did pain interfere with your normal work?”</p></li>
<li><p><strong>Sprtlty</strong>, <strong>SocSup</strong>, <strong>Engmgt</strong>, and <strong>DisEngmt</strong> are four subscales from the Brief Coping with Problems Experienced Inventory <span class="citation">(<a href="#ref-carver_you_1997" role="doc-biblioref">Carver, 1997</a>)</span>. The 28 items on this scale are presented on a 4-point scale ranging from 1 (<em>I usually do not do this at all</em>) to 4(<em>I usually do this a lot</em>). Higher scores indicate a respondents’ tendency to engage in a particular strategy. Instructions were modified to ask how the female participants responded to recent experiences of racism and sexism as Black women. The four subscales included spirituality (religion, acceptance, planning), interconnectedness/social support (vent emotions, emotional support,instrumental social support), problem-oriented/engagement coping (active coping, humor, positive reinterpretation/positive reframing), and disengagement coping (behavioral disengagement, substance abuse, denial, self-blame, self-distraction).</p></li>
<li><p><strong>GRIcntlty</strong>: The Multidimensional Inventory of Black Identity Centrality subscale <span class="citation">(<a href="#ref-sellers_multidimensional_nodate" role="doc-biblioref">Sellers et al., n.d.</a>)</span> was modified to measure the intersection of racial and gender identity centrality. The scale included 10 items scaled from 1 (<em>strongly disagree</em>) to 7 (<em>strongly agree</em>). An example item was, “Being a <em>Black woman</em> is important to my self-image.” Higher scores indicated higher levels of gendered racial identity centrality.</p></li>
</ul>
<div id="simulating-the-data-from-the-journal-article" class="section level3" number="8.4.1">
<h3 number="8.4.1"><span class="header-section-number">8.4.1</span> Simulating the data from the journal article</h3>
<p>First, we simulate the data from the means, standard deviations, and correlation matrix from the journal article.</p>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="#cb259-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Entering the intercorrelations, means, and standard deviations from the journal article</span></span>
<span id="cb259-2"><a href="#cb259-2" aria-hidden="true" tabindex="-1"></a>LEWmu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.99</span>, <span class="fl">2.82</span>, <span class="fl">2.48</span>, <span class="fl">2.32</span>, <span class="fl">1.75</span>, <span class="fl">5.71</span>, <span class="fl">21.37</span>, <span class="fl">21.07</span>)</span>
<span id="cb259-3"><a href="#cb259-3" aria-hidden="true" tabindex="-1"></a>LEWsd <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">90</span>, .<span class="dv">70</span>, .<span class="dv">81</span>, .<span class="dv">61</span>, .<span class="dv">53</span>, <span class="fl">1.03</span>, <span class="fl">3.83</span>, <span class="fl">4.66</span>)</span>
<span id="cb259-4"><a href="#cb259-4" aria-hidden="true" tabindex="-1"></a>LEWr_mat <span class="ot">&lt;-</span> <span class="fu">matrix</span> (<span class="fu">c</span>(<span class="dv">1</span>, .<span class="dv">20</span>, .<span class="dv">28</span>, .<span class="dv">30</span>, .<span class="dv">41</span>, .<span class="dv">19</span>, <span class="sc">-</span>.<span class="dv">32</span>, <span class="sc">-</span>.<span class="dv">18</span>,</span>
<span id="cb259-5"><a href="#cb259-5" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">20</span>, <span class="dv">1</span>, .<span class="dv">49</span>, .<span class="dv">57</span>, .<span class="dv">22</span>, .<span class="dv">13</span>, <span class="sc">-</span>.<span class="dv">06</span>, <span class="sc">-</span>.<span class="dv">13</span>,</span>
<span id="cb259-6"><a href="#cb259-6" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">28</span>, .<span class="dv">49</span>, <span class="dv">1</span>, .<span class="dv">46</span>, .<span class="dv">26</span>, .<span class="dv">38</span>, <span class="sc">-</span>.<span class="dv">18</span>,<span class="sc">-</span>.<span class="dv">08</span>, </span>
<span id="cb259-7"><a href="#cb259-7" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">30</span>, .<span class="dv">57</span>, .<span class="dv">46</span>,  <span class="dv">1</span>, .<span class="dv">37</span>, .<span class="dv">08</span>, <span class="sc">-</span>.<span class="dv">14</span>, <span class="sc">-</span>.<span class="dv">06</span>,</span>
<span id="cb259-8"><a href="#cb259-8" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">41</span>, .<span class="dv">22</span>, .<span class="dv">26</span>, .<span class="dv">37</span>, <span class="dv">1</span>, .<span class="dv">05</span>, <span class="sc">-</span>.<span class="dv">54</span>, <span class="sc">-</span>.<span class="dv">28</span>, </span>
<span id="cb259-9"><a href="#cb259-9" aria-hidden="true" tabindex="-1"></a>        .<span class="dv">19</span>, .<span class="dv">13</span>, .<span class="dv">38</span>, .<span class="dv">08</span>, .<span class="dv">05</span>, <span class="dv">1</span>, <span class="sc">-</span>.<span class="dv">10</span>, .<span class="dv">14</span>, </span>
<span id="cb259-10"><a href="#cb259-10" aria-hidden="true" tabindex="-1"></a>        <span class="sc">-</span>.<span class="dv">32</span>, <span class="sc">-</span>.<span class="dv">06</span>, <span class="sc">-</span>.<span class="dv">18</span>, <span class="sc">-</span>.<span class="dv">14</span>, <span class="sc">-</span>.<span class="dv">54</span>, <span class="sc">-</span>.<span class="dv">10</span>, <span class="dv">1</span>, .<span class="dv">47</span>,</span>
<span id="cb259-11"><a href="#cb259-11" aria-hidden="true" tabindex="-1"></a>        <span class="sc">-</span>.<span class="dv">18</span>, <span class="sc">-</span>.<span class="dv">13</span>, <span class="sc">-</span>.<span class="dv">08</span>, <span class="sc">-</span>.<span class="dv">06</span>, <span class="sc">-</span>.<span class="dv">28</span>, .<span class="dv">14</span>, .<span class="dv">47</span>, <span class="dv">1</span>), <span class="at">ncol =</span> <span class="dv">8</span>)</span>
<span id="cb259-12"><a href="#cb259-12" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating a covariance matrix</span></span>
<span id="cb259-13"><a href="#cb259-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb259-14"><a href="#cb259-14" aria-hidden="true" tabindex="-1"></a>LEWcov_mat <span class="ot">&lt;-</span> LEWsd <span class="sc">%*%</span> <span class="fu">t</span>(LEWsd) <span class="sc">*</span> LEWr_mat</span>
<span id="cb259-15"><a href="#cb259-15" aria-hidden="true" tabindex="-1"></a>LEWcov_mat</span></code></pre></div>
<pre><code>##          [,1]     [,2]      [,3]      [,4]      [,5]      [,6]      [,7]
## [1,]  0.81000  0.12600  0.204120  0.164700  0.195570  0.176130 -1.103040
## [2,]  0.12600  0.49000  0.277830  0.243390  0.081620  0.093730 -0.160860
## [3,]  0.20412  0.27783  0.656100  0.227286  0.111618  0.317034 -0.558414
## [4,]  0.16470  0.24339  0.227286  0.372100  0.119621  0.050264 -0.327082
## [5,]  0.19557  0.08162  0.111618  0.119621  0.280900  0.027295 -1.096146
## [6,]  0.17613  0.09373  0.317034  0.050264  0.027295  1.060900 -0.394490
## [7,] -1.10304 -0.16086 -0.558414 -0.327082 -1.096146 -0.394490 14.668900
## [8,] -0.75492 -0.42406 -0.301968 -0.170556 -0.691544  0.671972  8.388466
##           [,8]
## [1,] -0.754920
## [2,] -0.424060
## [3,] -0.301968
## [4,] -0.170556
## [5,] -0.691544
## [6,]  0.671972
## [7,]  8.388466
## [8,] 21.715600</code></pre>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Set random seed so that the following matrix always gets the same results.</span></span>
<span id="cb261-2"><a href="#cb261-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210403</span>)</span>
<span id="cb261-3"><a href="#cb261-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb261-4"><a href="#cb261-4" aria-hidden="true" tabindex="-1"></a>Lewis_df <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(<span class="at">n =</span> <span class="dv">212</span>, <span class="at">mu=</span>LEWmu, <span class="at">Sigma =</span> LEWcov_mat, <span class="at">empirical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb261-5"><a href="#cb261-5" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(Lewis_df)</span></code></pre></div>
<pre><code>## [1]  1.99  2.82  2.48  2.32  1.75  5.71 21.37 21.07</code></pre>
<div class="sourceCode" id="cb263"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking our work against the original correlation matrix</span></span>
<span id="cb263-2"><a href="#cb263-2" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(Lewis_df)</span></code></pre></div>
<pre><code>##       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]
## [1,]  1.00  0.20  0.28  0.30  0.41  0.19 -0.32 -0.18
## [2,]  0.20  1.00  0.49  0.57  0.22  0.13 -0.06 -0.13
## [3,]  0.28  0.49  1.00  0.46  0.26  0.38 -0.18 -0.08
## [4,]  0.30  0.57  0.46  1.00  0.37  0.08 -0.14 -0.06
## [5,]  0.41  0.22  0.26  0.37  1.00  0.05 -0.54 -0.28
## [6,]  0.19  0.13  0.38  0.08  0.05  1.00 -0.10  0.14
## [7,] -0.32 -0.06 -0.18 -0.14 -0.54 -0.10  1.00  0.47
## [8,] -0.18 -0.13 -0.08 -0.06 -0.28  0.14  0.47  1.00</code></pre>
<p>Rename the variables</p>
<div class="sourceCode" id="cb265"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb265-1"><a href="#cb265-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(Lewis_df, <span class="at">row.names =</span> <span class="cn">NULL</span>, <span class="at">optional =</span> <span class="cn">FALSE</span>, <span class="at">make.names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb265-2"><a href="#cb265-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb265-3"><a href="#cb265-3" aria-hidden="true" tabindex="-1"></a>Lewis_df <span class="ot">&lt;-</span> Lewis_df<span class="sc">%&gt;%</span></span>
<span id="cb265-4"><a href="#cb265-4" aria-hidden="true" tabindex="-1"></a>  as.data.frame <span class="sc">%&gt;%</span></span>
<span id="cb265-5"><a href="#cb265-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">GRMS =</span> V1, <span class="at">Sprtlty =</span> V2, <span class="at">SocSup =</span> V3, <span class="at">Engmgt =</span> V4, <span class="at">DisEngmt =</span> V5, <span class="at">GRIcntlty =</span> V6, <span class="at">MntlHlth =</span> V7, <span class="at">PhysHlth =</span> V8)</span></code></pre></div>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(Lewis_df)</span></code></pre></div>
<pre><code>##        GRMS  Sprtlty   SocSup   Engmgt  DisEngmt GRIcntlty MntlHlth PhysHlth
## 1 1.6527393 2.022990 1.705523 1.360615 1.0830779  5.517213 22.75649 19.41684
## 2 0.7640948 1.644033 2.505362 2.242470 1.7132075  5.413544 22.62540 22.26355
## 3 2.0107291 2.321768 2.660635 2.004928 1.5158907  4.842883 19.07803 23.23430
## 4 1.2409552 1.920184 1.470588 1.096715 1.4677302  4.124888 23.94831 18.74295
## 5 1.4613106 3.775331 2.939616 1.825157 0.9183584  5.558731 22.77763 18.81243
## 6 3.3326679 2.432105 2.709137 2.427134 1.7561275  8.816758 19.26199 24.46558</code></pre>
</div>
<div id="quick-peek-at-the-data" class="section level3" number="8.4.2">
<h3 number="8.4.2"><span class="header-section-number">8.4.2</span> Quick peek at the data</h3>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="#cb268-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb268-2"><a href="#cb268-2" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">describe</span>(Lewis_df)</span></code></pre></div>
<pre><code>##           vars   n  mean   sd median trimmed  mad   min   max range  skew
## GRMS         1 212  1.99 0.90   1.97    1.99 0.80 -1.07  3.97  5.05 -0.12
## Sprtlty      2 212  2.82 0.70   2.80    2.83 0.75  1.08  4.57  3.49 -0.10
## SocSup       3 212  2.48 0.81   2.44    2.47 0.80  0.62  4.78  4.17  0.11
## Engmgt       4 212  2.32 0.61   2.32    2.33 0.60  0.75  3.93  3.18 -0.14
## DisEngmt     5 212  1.75 0.53   1.76    1.75 0.56  0.47  3.00  2.53 -0.05
## GRIcntlty    6 212  5.71 1.03   5.64    5.68 0.95  2.72  9.56  6.84  0.37
## MntlHlth     7 212 21.37 3.83  21.59   21.46 4.23 11.79 31.77 19.98 -0.14
## PhysHlth     8 212 21.07 4.66  20.79   21.03 4.68  8.43 33.73 25.30  0.07
##           kurtosis   se
## GRMS          0.25 0.06
## Sprtlty      -0.41 0.05
## SocSup       -0.16 0.06
## Engmgt       -0.22 0.04
## DisEngmt     -0.56 0.04
## GRIcntlty     0.76 0.07
## MntlHlth     -0.56 0.26
## PhysHlth     -0.18 0.32</code></pre>
<p>And a quick peek at a correlation matrix.</p>
<div class="sourceCode" id="cb270"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb270-1"><a href="#cb270-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(apaTables)</span>
<span id="cb270-2"><a href="#cb270-2" aria-hidden="true" tabindex="-1"></a><span class="fu">apa.cor.table</span> (Lewis_df, <span class="at">show.conf.interval =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## The ability to suppress reporting of reporting confidence intervals has been deprecated in this version.
## The function argument show.conf.interval will be removed in a later version.</code></pre>
<pre><code>## 
## 
## Means, standard deviations, and correlations with confidence intervals
##  
## 
##   Variable     M     SD   1            2           3            4           
##   1. GRMS      1.99  0.90                                                   
##                                                                             
##   2. Sprtlty   2.82  0.70 .20**                                             
##                           [.07, .33]                                        
##                                                                             
##   3. SocSup    2.48  0.81 .28**        .49**                                
##                           [.15, .40]   [.38, .59]                           
##                                                                             
##   4. Engmgt    2.32  0.61 .30**        .57**       .46**                    
##                           [.17, .42]   [.47, .65]  [.35, .56]               
##                                                                             
##   5. DisEngmt  1.75  0.53 .41**        .22**       .26**        .37**       
##                           [.29, .52]   [.09, .34]  [.13, .38]   [.25, .48]  
##                                                                             
##   6. GRIcntlty 5.71  1.03 .19**        .13         .38**        .08         
##                           [.06, .32]   [-.00, .26] [.26, .49]   [-.06, .21] 
##                                                                             
##   7. MntlHlth  21.37 3.83 -.32**       -.06        -.18**       -.14*       
##                           [-.44, -.19] [-.19, .08] [-.31, -.05] [-.27, -.01]
##                                                                             
##   8. PhysHlth  21.07 4.66 -.18**       -.13        -.08         -.06        
##                           [-.31, -.05] [-.26, .00] [-.21, .06]  [-.19, .08] 
##                                                                             
##   5            6           7         
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##                                      
##   .05                                
##   [-.09, .18]                        
##                                      
##   -.54**       -.10                  
##   [-.63, -.44] [-.23, .04]           
##                                      
##   -.28**       .14*        .47**     
##   [-.40, -.15] [.01, .27]  [.36, .57]
##                                      
## 
## Note. M and SD are used to represent mean and standard deviation, respectively.
## Values in square brackets indicate the 95% confidence interval.
## The confidence interval is a plausible range of population correlations 
## that could have caused the sample correlation (Cumming, 2014).
##  * indicates p &lt; .05. ** indicates p &lt; .01.
## </code></pre>
</div>
</div>
<div id="working-the-moderated-mediation" class="section level2" number="8.5">
<h2 number="8.5"><span class="header-section-number">8.5</span> Working the Moderated Mediation</h2>
<p>The model we are testing is predicting a mental health (MntlHlth, Y) from gendered racial microaggressions (GRMS,X), mediated by disengagement coping (DisEngmt, M). The relationship between gendered racial microaggressions and disengagement coping (i.e., the <em>a</em> path) is expected to be moderated by gendered racial identity centrality (GRIcntlty, W). Gendered racial identity centrality is also expected to moderate the path between gendered racial microaggressions and mental health (i.e., the <em>c’</em> path). Thus, the specified model involves the evaluation of a conditional indirect effect.</p>
<div class="figure">
<img src="images/ModMed/LewisModMed.jpg" alt="" />
<p class="caption">Image of conceptual representation of the conditional process analysis model where the moderator is hypothesized to change the a and c’ paths</p>
</div>
<p>Hayes’ <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> textbook and training materials frequently display the conceptual (above) and statistical models (below). These help facilitate understanding.</p>
<div class="figure">
<img src="images/ModMed/LewisStatistical.jpg" alt="" />
<p class="caption">Image of statistical reprsentation of the conditional process analysis model where the moderator is hypothesized to change the a and c’ paths</p>
</div>
<p>Looking at the diagram, with two consequent variables (i.e., those with arrows pointing to them) we can see two equations are needed to explain the model:</p>
<p><span class="math display">\[M = i_{M}+a_{1}X + a_{2}W + a_{3}XW + e_{M}\]</span></p>
<p><span class="math display">\[Y = i_{Y}+c_{1}^{&#39;}X+ c_{2}^{&#39;}W+c_{3}^{&#39;}XW+ bM+e_{Y}\]</span></p>
<p>When we have complicated models such as these, Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> suggests a piecewise approach to model building. Specifically, he decompose the model into its aggregate parts: a simple mediation and two simple moderation.</p>
<div class="figure">
<img src="images/ModMed/PiecewiseAssembly.jpg" alt="" />
<p class="caption">Image of statistical reprsentation of the conditional process analysis model where the moderator is hypothesized to change the a and c’ paths</p>
</div>
<p>Let’s start with the the simple moderations.</p>
<div id="piecewise-assembly-of-the-moderated-mediation" class="section level3" number="8.5.1">
<h3 number="8.5.1"><span class="header-section-number">8.5.1</span> Piecewise Assembly of the Moderated Mediation</h3>
<div id="analysis-1-a-simple-moderation" class="section level4" number="8.5.1.1">
<h4 number="8.5.1.1"><span class="header-section-number">8.5.1.1</span> Analysis #1: A simple moderation</h4>
<p>We are asking, "Does GRI centrality moderate the relationship between gendered racial microaggressiona and disengagement coping?</p>
<p>Y = disengagement coping
X = gendered racial microaggressions
W = GRI centrality</p>
<div class="figure">
<img src="images/ModMed/LewisMod1.jpg" alt="" />
<p class="caption">Image of statistical representation of the simple moderation estimating DisEngmt from GRMS, moderated by GRIcntlty</p>
</div>
<p>The formula we are estimating:
<span class="math display">\[Y=b_{0}+b_{1}X+b_{2}W+b_{3}XW+e_{Y}\]</span></p>
<p>Let’s specify this simple moderation model with base R’s <em>lm()</em> function. Let’s use the <em>jtools</em> package so we get that great summ function and <em>interactions</em> for the awesome plot.</p>
<p>Since we are just working to understand our moderations, we can run them with “regular old” ordinary least squares.</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="#cb273-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jtools) <span class="co">#the summ function creates a terrific regression table</span></span>
<span id="cb273-2"><a href="#cb273-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(interactions)</span>
<span id="cb273-3"><a href="#cb273-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb273-4"><a href="#cb273-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb273-5"><a href="#cb273-5" aria-hidden="true" tabindex="-1"></a>Mod_a_path <span class="ot">&lt;-</span> <span class="fu">lm</span>(DisEngmt<span class="sc">~</span>GRMS<span class="sc">*</span>GRIcntlty, <span class="at">data=</span>Lewis_df)</span>
<span id="cb273-6"><a href="#cb273-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summ</span>(Mod_a_path, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Observations
</td>
<td style="text-align:right;">
212
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Dependent variable
</td>
<td style="text-align:right;">
DisEngmt
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Type
</td>
<td style="text-align:right;">
OLS linear regression
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
F(3,208)
</td>
<td style="text-align:right;">
14.099
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
R²
</td>
<td style="text-align:right;">
0.169
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Adj. R²
</td>
<td style="text-align:right;">
0.157
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Est.
</th>
<th style="text-align:right;">
S.E.
</th>
<th style="text-align:right;">
t val.
</th>
<th style="text-align:right;">
p
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
(Intercept)
</td>
<td style="text-align:right;">
1.417
</td>
<td style="text-align:right;">
0.517
</td>
<td style="text-align:right;">
2.741
</td>
<td style="text-align:right;">
0.007
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
GRMS
</td>
<td style="text-align:right;">
0.212
</td>
<td style="text-align:right;">
0.231
</td>
<td style="text-align:right;">
0.919
</td>
<td style="text-align:right;">
0.359
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
GRIcntlty
</td>
<td style="text-align:right;">
-0.027
</td>
<td style="text-align:right;">
0.090
</td>
<td style="text-align:right;">
-0.299
</td>
<td style="text-align:right;">
0.765
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
GRMS:GRIcntlty
</td>
<td style="text-align:right;">
0.006
</td>
<td style="text-align:right;">
0.039
</td>
<td style="text-align:right;">
0.144
</td>
<td style="text-align:right;">
0.886
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<sup></sup> Standard errors: OLS
</td>
</tr>
</tfoot>
</table>
<p>Looking at these results we can see that the predictors account for about 17% of variance in disengagement coping. However, there is no significance in the predictors. Neither the IV variable (GRMS, [X]), nor the moderator (GRIcntlty, [Y])), nor its interaction (GRMS:GRIcntlty, [XW]) are significant.</p>
<p>It’s always helpful to graph the relationship. The <em>interaction_plot()</em> function from the package, <em>interactions</em> can make helpful illustrations. In the case of interactions/moderations, I like to run them “both ways” to see which makes more sense.</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interact_plot</span>(Mod_a_path, <span class="at">pred =</span> GRMS, <span class="at">modx =</span> GRIcntlty)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/MOD%20a%20path%20plot-1.svg" width="672" /></p>
<div class="sourceCode" id="cb275"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interact_plot</span>(Mod_a_path, <span class="at">pred =</span> GRIcntlty, <span class="at">modx =</span> GRMS)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/MOD%20a%20path%20plot-2.svg" width="672" />
The figure with GRIcntrlty as the moderator, shows a very similar prediction of disengagement coping from gendered racial microaggressions. The figure that uses GRMS as the moderator, visually, looks like there are big differences as a function of GRMS. Looking at the Y axis (disengagement), though, shows that the scaling variables are not well-spaced.</p>
<p>Next, let’s probe the interaction with simple slopes. Probing the interaction is a common follow-up. With these additional inferential tests we can see where in the distribution of the moderator, X has an effect on Y that is different from zero (and where it does not). There are two common approaches.</p>
<p>The Johnson-Neyman is a <em>floodlight</em> approach and provides an indication of the places in the distribution of W (moderator) that X has an effect on Y that is different than zero. The pick-a-point is sometimes called the <em>analysis of simple slopes</em> or a <em>spotlight</em> approach, probes the distribution at specific values (often the <em>M</em> +/- 1<em>SD</em>).</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sim_slopes</span>(Mod_a_path, <span class="at">pred =</span> GRMS, <span class="at">modx =</span> GRIcntlty)</span></code></pre></div>
<pre><code>## JOHNSON-NEYMAN INTERVAL 
## 
## When GRIcntlty is INSIDE the interval [3.02, 9.11], the slope of GRMS is p
## &lt; .05.
## 
## Note: The range of observed values of GRIcntlty is [2.72, 9.56]
## 
## SIMPLE SLOPES ANALYSIS 
## 
## Slope of GRMS when GRIcntlty = 4.68 (- 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.24   0.06     4.06   0.00
## 
## Slope of GRMS when GRIcntlty = 5.71 (Mean): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.24   0.04     6.39   0.00
## 
## Slope of GRMS when GRIcntlty = 6.74 (+ 1 SD): 
## 
##   Est.   S.E.   t val.      p
## ------ ------ -------- ------
##   0.25   0.05     4.81   0.00</code></pre>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a><span class="co">#sim_slopes(Mod_a_path, pred=GRIcntlty, modx = GRMS) #sometimes I like to look at it in reverse -- like in the plots</span></span></code></pre></div>
<p>The Johnson-Neyman suggests that between the GRIcntlty values of 3.02 and 9.03, the relationship between GRMS is statistically significant. We see the same result in the pick-a-point approach where at the GRIcntlty values of 4.68, 5.71, and 6.74, X has a statistically significant effect on Y. Is this a contradiction to the non-significant interaction effect?</p>
<p>No. The test of interaction is an interaction about the relationship between <em>W</em> and <em>X</em>’s effect on <em>Y</em>. Just showing that <em>X</em> is significantly related to <em>Y</em> for a specific value does not address any dependence upon the moderator (<em>W</em>). Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> covers this well in his Chapter 14, in the section “Reporting a Moderation Analysis.”</p>
<p><strong>What have we learned in this simple moderation?</strong></p>
<ul>
<li>While there are no significant predictors (neither X, W, nor XW), the model accounts for about 17% of variance in the DV.</li>
<li>Although there was a non-significant effect of GRMS on disengagement coping, analysis of simple slopes suggested a significant relationship between these variables at a given ranges of GRIcntlty.</li>
<li>We’ll keep these in mind.</li>
</ul>
</div>
<div id="analysis-2-another-simple-moderation" class="section level4" number="8.5.1.2">
<h4 number="8.5.1.2"><span class="header-section-number">8.5.1.2</span> Analysis #2: Another simple moderation</h4>
<p>We are asking, “Does gendered racial identity centrality moderate the relationship between gendered racial microaggressions and mental health?”</p>
<p>Y = mental health
X = gendered racial microaggressions
W = GRI centrality</p>
<div class="figure">
<img src="images/ModMed/LewisMod2.jpg" alt="" />
<p class="caption">Image of statistical representation of the simple moderation estimating MntlHlth from GRMS, moderated by GRIcntlty</p>
</div>
<p>As before, this is our formulaic rendering:<br />
<span class="math display">\[Y=b_{0}+b_{1}X+b_{2}W+b_{3}XW+e_{Y}\]</span></p>
<div class="sourceCode" id="cb279"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb279-1"><a href="#cb279-1" aria-hidden="true" tabindex="-1"></a>Mod_c_path <span class="ot">&lt;-</span> <span class="fu">lm</span>(MntlHlth<span class="sc">~</span>GRMS<span class="sc">*</span>GRIcntlty, <span class="at">data=</span>Lewis_df)</span>
<span id="cb279-2"><a href="#cb279-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summ</span>(Mod_c_path, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Observations
</td>
<td style="text-align:right;">
212
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Dependent variable
</td>
<td style="text-align:right;">
MntlHlth
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Type
</td>
<td style="text-align:right;">
OLS linear regression
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
F(3,208)
</td>
<td style="text-align:right;">
8.137
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
R²
</td>
<td style="text-align:right;">
0.105
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Adj. R²
</td>
<td style="text-align:right;">
0.092
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Est.
</th>
<th style="text-align:right;">
S.E.
</th>
<th style="text-align:right;">
t val.
</th>
<th style="text-align:right;">
p
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
(Intercept)
</td>
<td style="text-align:right;">
26.647
</td>
<td style="text-align:right;">
3.877
</td>
<td style="text-align:right;">
6.873
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
GRMS
</td>
<td style="text-align:right;">
-2.168
</td>
<td style="text-align:right;">
1.729
</td>
<td style="text-align:right;">
-1.254
</td>
<td style="text-align:right;">
0.211
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
GRIcntlty
</td>
<td style="text-align:right;">
-0.460
</td>
<td style="text-align:right;">
0.674
</td>
<td style="text-align:right;">
-0.682
</td>
<td style="text-align:right;">
0.496
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
GRMS:GRIcntlty
</td>
<td style="text-align:right;">
0.144
</td>
<td style="text-align:right;">
0.293
</td>
<td style="text-align:right;">
0.492
</td>
<td style="text-align:right;">
0.623
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<sup></sup> Standard errors: OLS
</td>
</tr>
</tfoot>
</table>
<p>In this model that is, overall, statistically significant, we account for about 11% of variance in the DV. Looking at these results we can see that there is no significance in the predictors. Neither the IV (GRMS, [X]), nor the moderator (GRIcntlty, [Y])), nor its interaction (GRMS:GRIcntlty, [XW]) are significant.</p>
<p>Let’s look at the plots.</p>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interact_plot</span>(Mod_c_path, <span class="at">pred =</span> GRMS, <span class="at">modx =</span> GRIcntlty)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/MOD%20c%20path%20plot-1.svg" width="672" /></p>
<div class="sourceCode" id="cb281"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb281-1"><a href="#cb281-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interact_plot</span>(Mod_c_path, <span class="at">pred =</span> GRIcntlty, <span class="at">modx =</span> GRMS)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/MOD%20c%20path%20plot-2.svg" width="672" />
The figure with GRIcntrlty as the moderator, shows fanning out when mental health is high and GRMS is low.</p>
<p>Next, let’s probe the interaction with simple slopes. Probing the interaction is a common follow-up. With these additional inferential tests we can see where in the distribution of the moderator, X has an effect on Y that is different from zero (and where it does not). There are two common approaches.</p>
<p>The Johnson-Neyman is a <em>floodlight</em> approach and provides an indication of the places in the distribution of W (moderator) that X has an effect on Y that is different than zero. The pick-a-point is sometimes called the <em>analysis of simple slopes</em> or a <em>spotlight</em> approach, probes the distribution at specific values (often the <em>M</em> +/- 1<em>SD</em>).</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sim_slopes</span>(Mod_c_path, <span class="at">pred =</span> GRMS, <span class="at">modx =</span> GRIcntlty)</span></code></pre></div>
<pre><code>## JOHNSON-NEYMAN INTERVAL 
## 
## When GRIcntlty is INSIDE the interval [2.97, 7.46], the slope of GRMS is p
## &lt; .05.
## 
## Note: The range of observed values of GRIcntlty is [2.72, 9.56]
## 
## SIMPLE SLOPES ANALYSIS 
## 
## Slope of GRMS when GRIcntlty = 4.68 (- 1 SD): 
## 
##    Est.   S.E.   t val.      p
## ------- ------ -------- ------
##   -1.49   0.44    -3.39   0.00
## 
## Slope of GRMS when GRIcntlty = 5.71 (Mean): 
## 
##    Est.   S.E.   t val.      p
## ------- ------ -------- ------
##   -1.35   0.29    -4.70   0.00
## 
## Slope of GRMS when GRIcntlty = 6.74 (+ 1 SD): 
## 
##    Est.   S.E.   t val.      p
## ------- ------ -------- ------
##   -1.20   0.39    -3.08   0.00</code></pre>
<div class="sourceCode" id="cb284"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb284-1"><a href="#cb284-1" aria-hidden="true" tabindex="-1"></a><span class="co">#sim_slopes(Mod_c_path, pred=GRIcntlty, modx = GRMS) #sometimes I like to look at it in reverse -- like in the plots</span></span></code></pre></div>
<p>The Johnson-Neyman suggests that between the GRIcntlty values of 2.972 and 7.46, the relationship between GRMS is statistically significant. We see the same result in the pick-a-point approach where at the GRIcntlty values of 4.68, 5.71, and 6.74, X has a statistically significant effect on Y. Is this a contradiction to the non-significant interaction effect?</p>
<p>Again. No. The test of interaction is an interaction about the relationship between <em>W</em> and <em>X</em>’s effect on <em>Y</em>. Just showing that <em>X</em> is significantly related to <em>Y</em> for a specific value does not address any dependence upon the moderator (<em>W</em>). Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> covers this well in his Chapter 14, in the section “Reporting a Moderation Analysis.”</p>
<p><strong>What have we learned in this simple moderation?</strong></p>
<ul>
<li>As predictors to the DV, disengagement coping, the IV (X), moderator (W), and its interaction term (XW) have non-significant effects. That said, the overall model was significant and accounted for 11% of variance in the DV.</li>
<li>Although there was a non-significant effect of GRMS on mental health, analysis of simple slopes suggested a significant relationship between these variables at a given range of GRIcntlty.</li>
<li>We’ll keep these in mind.</li>
</ul>
</div>
<div id="analysis-3-a-simple-mediation" class="section level4" number="8.5.1.3">
<h4 number="8.5.1.3"><span class="header-section-number">8.5.1.3</span> Analysis #3: A simple mediation</h4>
<p>We are asking, “Does disengagement coping mediate the relationship between gendered racial microaggressions and mental health?”</p>
<p>Y = mental health
X = gendered racial microaggressions
M = GRI centrality</p>
<p><img src="images/ModMed/LewisMed.jpg" alt="Image of statistical representation of the simple mediation estimating MntlHlth from GRMS, mediated by DisEngmt" />
Looking at the diagram, with two consequent variables (i.e., those with arrows pointing to them) we can see two equations are needed to explain the model:</p>
<p><span class="math display">\[M = i_{M}+aX + e_{M}\]</span></p>
<p><span class="math display">\[Y = i_{Y}+c&#39;X+ bM+e_{Y}\]</span></p>
<p>To conduct this analysis, I am using the guidelines in the <a href="#SimpleMed">chapter on simple mediation</a>. We are switching to the <em>lavaan</em> package.</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb285-2"><a href="#cb285-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210421</span>) <span class="co">#reset in case you choose to separate these sections</span></span>
<span id="cb285-3"><a href="#cb285-3" aria-hidden="true" tabindex="-1"></a>LMedModel <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb285-4"><a href="#cb285-4" aria-hidden="true" tabindex="-1"></a><span class="st">          MntlHlth ~ b*DisEngmt + c_p*GRMS </span></span>
<span id="cb285-5"><a href="#cb285-5" aria-hidden="true" tabindex="-1"></a><span class="st">          DisEngmt ~a*GRMS</span></span>
<span id="cb285-6"><a href="#cb285-6" aria-hidden="true" tabindex="-1"></a><span class="st">          </span></span>
<span id="cb285-7"><a href="#cb285-7" aria-hidden="true" tabindex="-1"></a><span class="st">          #intercepts</span></span>
<span id="cb285-8"><a href="#cb285-8" aria-hidden="true" tabindex="-1"></a><span class="st">          DisEngmt ~ DisEngmt.mean*1</span></span>
<span id="cb285-9"><a href="#cb285-9" aria-hidden="true" tabindex="-1"></a><span class="st">          MntlHlth ~ MntlHlth.mean*1</span></span>
<span id="cb285-10"><a href="#cb285-10" aria-hidden="true" tabindex="-1"></a><span class="st">          </span></span>
<span id="cb285-11"><a href="#cb285-11" aria-hidden="true" tabindex="-1"></a><span class="st">          indirect :=  a*b</span></span>
<span id="cb285-12"><a href="#cb285-12" aria-hidden="true" tabindex="-1"></a><span class="st">          direct  := c_p</span></span>
<span id="cb285-13"><a href="#cb285-13" aria-hidden="true" tabindex="-1"></a><span class="st">          total_c  := c_p + (a*b)</span></span>
<span id="cb285-14"><a href="#cb285-14" aria-hidden="true" tabindex="-1"></a><span class="st">          &#39;</span></span>
<span id="cb285-15"><a href="#cb285-15" aria-hidden="true" tabindex="-1"></a>LMed_fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(LMedModel, <span class="at">data =</span> Lewis_df, <span class="at">se=</span><span class="st">&quot;bootstrap&quot;</span>, <span class="at">missing =</span> <span class="st">&#39;fiml&#39;</span>)</span>
<span id="cb285-16"><a href="#cb285-16" aria-hidden="true" tabindex="-1"></a>LMed_Sum <span class="ot">&lt;-</span>  <span class="fu">summary</span>(LMed_fit, <span class="at">standardized=</span>T, <span class="at">rsq=</span>T, <span class="at">ci=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## lavaan 0.6-8 ended normally after 30 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                         7
##                                                       
##   Number of observations                           212
##   Number of missing patterns                         1
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                                 0.000
##   Degrees of freedom                                 0
## 
## Parameter Estimates:
## 
##   Standard errors                            Bootstrap
##   Number of requested bootstrap draws             1000
##   Number of successful bootstrap draws            1000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##   MntlHlth ~                                                            
##     DisEngmt   (b)   -3.551    0.398   -8.914    0.000   -4.311   -2.740
##     GRMS     (c_p)   -0.504    0.274   -1.844    0.065   -1.042    0.040
##   DisEngmt ~                                                            
##     GRMS       (a)    0.241    0.034    7.137    0.000    0.176    0.308
##    Std.lv  Std.all
##                   
##    -3.551   -0.491
##    -0.504   -0.119
##                   
##     0.241    0.410
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .DsEngmt (DsE.)    1.270    0.073   17.400    0.000    1.122    1.414
##    .MntlHlt (MnH.)   28.588    0.752   38.039    0.000   27.036   30.058
##    Std.lv  Std.all
##     1.270    2.401
##    28.588    7.482
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .MntlHlth         10.172    0.866   11.739    0.000    8.313   11.877
##    .DisEngmt          0.233    0.020   11.810    0.000    0.195    0.272
##    Std.lv  Std.all
##    10.172    0.697
##     0.233    0.832
## 
## R-Square:
##                    Estimate
##     MntlHlth          0.303
##     DisEngmt          0.168
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     indirect         -0.857    0.155   -5.547    0.000   -1.163   -0.575
##     direct           -0.504    0.274   -1.843    0.065   -1.042    0.040
##     total_c          -1.362    0.298   -4.568    0.000   -1.951   -0.781
##    Std.lv  Std.all
##    -0.857   -0.201
##    -0.504   -0.119
##    -1.362   -0.320</code></pre>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a>LMed_ParEsts<span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(LMed_fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span>
<span id="cb287-2"><a href="#cb287-2" aria-hidden="true" tabindex="-1"></a>LMed_Sum</span></code></pre></div>
<pre><code>## $PE
##         lhs op       rhs         label exo        est         se         z
## 1  MntlHlth  ~  DisEngmt             b   0 -3.5510981 0.39835676 -8.914366
## 2  MntlHlth  ~      GRMS           c_p   0 -0.5043849 0.27353191 -1.843971
## 3  DisEngmt  ~      GRMS             a   0  0.2414444 0.03382987  7.137019
## 4  DisEngmt ~1           DisEngmt.mean   0  1.2695256 0.07296232 17.399743
## 5  MntlHlth ~1           MntlHlth.mean   0 28.5881475 0.75155311 38.038759
## 6  MntlHlth ~~  MntlHlth                 0 10.1718137 0.86646385 11.739455
## 7  DisEngmt ~~  DisEngmt                 0  0.2325784 0.01969341 11.809963
## 8      GRMS ~~      GRMS                 1  0.8061792 0.00000000        NA
## 9      GRMS ~1                           1  1.9900000 0.00000000        NA
## 10 indirect :=       a*b      indirect   0 -0.8573929 0.15457758 -5.546683
## 11   direct :=       c_p        direct   0 -0.5043849 0.27366878 -1.843049
## 12  total_c := c_p+(a*b)       total_c   0 -1.3617778 0.29811174 -4.568011
## 13 MntlHlth r2  MntlHlth                 0  0.3032865         NA        NA
## 14 DisEngmt r2  DisEngmt                 0  0.1681000         NA        NA
##                   pvalue   ci.lower    ci.upper     std.lv    std.all
## 1  0.0000000000000000000 -4.3111930 -2.73988833 -3.5510981 -0.4914052
## 2  0.0651873898745749525 -1.0421481  0.04025633 -0.5043849 -0.1185239
## 3  0.0000000000009536816  0.1755652  0.30832526  0.2414444  0.4100000
## 4  0.0000000000000000000  1.1217602  1.41401013  1.2695256  2.4010007
## 5  0.0000000000000000000 27.0361334 30.05840757 28.5881475  7.4819352
## 6  0.0000000000000000000  8.3134145 11.87663252 10.1718137  0.6967135
## 7  0.0000000000000000000  0.1949968  0.27192324  0.2325784  0.8319000
## 8                     NA  0.8061792  0.80617925  0.8061792  1.0000000
## 9                     NA  1.9900000  1.99000000  1.9900000  2.2163445
## 10 0.0000000291139363728 -1.1633703 -0.57549700 -0.8573929 -0.2014761
## 11 0.0653219113923206862 -1.0421481  0.04025633 -0.5043849 -0.1185239
## 12 0.0000049237374675215 -1.9513442 -0.78147274 -1.3617778 -0.3200000
## 13                    NA         NA          NA         NA         NA
## 14                    NA         NA          NA         NA         NA
##       std.nox
## 1  -0.4914052
## 2  -0.1320049
## 3   0.4566338
## 4   2.4010007
## 5   7.4819352
## 6   0.6967135
## 7   0.8319000
## 8   0.8061792
## 9   1.9900000
## 10 -0.2243922
## 11 -0.1320049
## 12 -0.3563971
## 13         NA
## 14         NA</code></pre>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="#cb289-1" aria-hidden="true" tabindex="-1"></a>LMed_ParEsts</span></code></pre></div>
<pre><code>##         lhs op       rhs         label    est    se      z pvalue ci.lower
## 1  MntlHlth  ~  DisEngmt             b -3.551 0.398 -8.914  0.000   -4.328
## 2  MntlHlth  ~      GRMS           c_p -0.504 0.274 -1.844  0.065   -1.069
## 3  DisEngmt  ~      GRMS             a  0.241 0.034  7.137  0.000    0.177
## 4  DisEngmt ~1           DisEngmt.mean  1.270 0.073 17.400  0.000    1.115
## 5  MntlHlth ~1           MntlHlth.mean 28.588 0.752 38.039  0.000   27.125
## 6  MntlHlth ~~  MntlHlth               10.172 0.866 11.739  0.000    8.620
## 7  DisEngmt ~~  DisEngmt                0.233 0.020 11.810  0.000    0.197
## 8      GRMS ~~      GRMS                0.806 0.000     NA     NA    0.806
## 9      GRMS ~1                          1.990 0.000     NA     NA    1.990
## 10 indirect :=       a*b      indirect -0.857 0.155 -5.547  0.000   -1.207
## 11   direct :=       c_p        direct -0.504 0.274 -1.843  0.065   -1.069
## 12  total_c := c_p+(a*b)       total_c -1.362 0.298 -4.568  0.000   -1.962
##    ci.upper std.lv std.all std.nox
## 1    -2.759 -3.551  -0.491  -0.491
## 2     0.018 -0.504  -0.119  -0.132
## 3     0.311  0.241   0.410   0.457
## 4     1.410  1.270   2.401   2.401
## 5    30.125 28.588   7.482   7.482
## 6    12.275 10.172   0.697   0.697
## 7     0.279  0.233   0.832   0.832
## 8     0.806  0.806   1.000   0.806
## 9     1.990  1.990   2.216   1.990
## 10   -0.597 -0.857  -0.201  -0.224
## 11    0.018 -0.504  -0.119  -0.132
## 12   -0.789 -1.362  -0.320  -0.356</code></pre>
<p><strong>In this simple mediation we learn</strong>*:</p>
<ul>
<li>The <em>a</em> path (GRMS –&gt; DisEngmt) is statistically significant.</li>
<li>The <em>b</em> path (DisEngmt –&gt; MntlHlth) is statistically significant.</li>
<li>The total effect (GRMS –&gt; MntlHlth) is statistically significant.</li>
<li>The direct effect (GRMS –&gt; MntlHlth when DisEngmt is in the model) falls out of significance.</li>
<li>The indirect effect is statistically significant.</li>
<li>The model accounts for 30% of the variance in mental health (DV) and 17% of the variance in disengagement coping (M).</li>
</ul>
<p>Recall how the bootstrapped, bias-corrected confidence intervals can be different? It’s always good to check. In this case, CI95s and the <span class="math inline">\(p\)</span> values are congruent.</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="#cb291-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210421</span>)</span>
<span id="cb291-2"><a href="#cb291-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb291-3"><a href="#cb291-3" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(LMed_fit, <span class="co">#must identiy the model you want to map</span></span>
<span id="cb291-4"><a href="#cb291-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb291-5"><a href="#cb291-5" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb291-6"><a href="#cb291-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;tree&#39;</span>, <span class="at">rotation =</span> <span class="dv">2</span>, <span class="co">#together, puts predictors on left, IVs on right </span></span>
<span id="cb291-7"><a href="#cb291-7" aria-hidden="true" tabindex="-1"></a>         <span class="co">#layout = &#39;circle&#39;,</span></span>
<span id="cb291-8"><a href="#cb291-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb291-9"><a href="#cb291-9" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb291-10"><a href="#cb291-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb291-11"><a href="#cb291-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb291-12"><a href="#cb291-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb291-13"><a href="#cb291-13" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb291-14"><a href="#cb291-14" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb291-15"><a href="#cb291-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb291-16"><a href="#cb291-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb291-17"><a href="#cb291-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb291-18"><a href="#cb291-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb291-19"><a href="#cb291-19" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb291-20"><a href="#cb291-20" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb291-21"><a href="#cb291-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb291-22"><a href="#cb291-22" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Disengagement Coping as Mediator between GRMS and Mental Health&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/semPlot%20of%20simple%20med%20in%20the%20modmed-1.svg" width="672" /></p>
</div>
</div>
</div>
<div id="the-moderated-mediation-a-combined-analysis" class="section level2" number="8.6">
<h2 number="8.6"><span class="header-section-number">8.6</span> The Moderated Mediation: A Combined analysis</h2>
<p>For a quick reminder, the diagram with labeled paths will help specify this in <em>lavaan</em>.</p>
<div class="figure">
<img src="images/ModMed/LewisStatistical.jpg" alt="" />
<p class="caption">Image of statistical reprsentation of the conditional process analysis model where the moderator is hypothesized to change the a and c’ paths</p>
</div>
<p>Looking at the diagram, with two consequent variables (i.e., those with arrows pointing to them) we can see two equations are needed to explain the model:</p>
<p><span class="math display">\[M = i_{M}+a_{1}X + a_{2}W + a_{3}XW + e_{M}\]</span></p>
<p><span class="math display">\[Y = i_{Y}+c_{1}^{&#39;}X+ c_{2}^{&#39;}W+c_{3}^{&#39;}XW+ bM+e_{Y}\]</span>
Y = MntlHlth
X = GRMS
W = DisEngmt
M = GRIcntlty</p>
<div id="specification-in-lavaan" class="section level3" number="8.6.1">
<h3 number="8.6.1"><span class="header-section-number">8.6.1</span> Specification in <em>lavaan</em></h3>
<p>In the code below</p>
<ul>
<li>First specify the equations, hints
<ul>
<li>the a,b,c, labels are affixed with the *(asterisk)</li>
<li>interaction terms are identifed with the colon</li>
</ul></li>
<li>Create code for the intercepts (Y and M) with the form: VarName ~ VarName.mean*1</li>
<li>Create code for the mean and variance of all moderators (W, Z, etc.); these will be used in simple slopes.
<ul>
<li>Means use the form: VarName ~ VarName.mean*1</li>
<li>Variances use the form: VarName ~~VarName.var*VarName</li>
</ul></li>
<li>Calculate the <em>index of moderated mediation</em>: quantifies the relationship between the moderator and the indirect effect.
<ul>
<li>To the degree that the value of the IMM is different from zero and the associated inferential test is statistically significant (bootstrapped confidence intervals are preferred; more powerful), we can conclude that the indirect effect is moderated.
<ul>
<li>The IMM is used in the formula to calculate the conditional indirect effects.</li>
<li>Hayes argues that a statistically significant IMM suggest they are (boom, done, p. 430).</li>
</ul></li>
</ul></li>
<li>Create code to calculate indirect effects conditional on (<em>M</em> +/- 1<em>SD</em>) moderator with the general form:
<ul>
<li>product of the indirect effect (a*b) PLUS</li>
<li>the product of the IMM and the moderated value</li>
</ul></li>
<li>Because our direct path is moderated, we will use a similar process to specify the direct effects conditional on (<em>M</em> +/- 1<em>SD</em>) moderator with the general form:
<ul>
<li>the direct effect (c_p1) PLUS</li>
<li>the moderated value (c_p3) at each of the three levels (<em>M</em> +/- 1<em>SD</em>)</li>
</ul></li>
<li>Although they don’t tend to be reported, you can create total effects conditional on the (<em>M</em> +/- 1<em>SD</em>). These are simply the sum of the c_p and all indirect paths, specified individually, at their <em>M</em> +/- 1<em>SD</em> conditional values.</li>
</ul>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">190505</span>)</span>
<span id="cb292-2"><a href="#cb292-2" aria-hidden="true" tabindex="-1"></a>Combined <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb292-3"><a href="#cb292-3" aria-hidden="true" tabindex="-1"></a><span class="st">    #equations</span></span>
<span id="cb292-4"><a href="#cb292-4" aria-hidden="true" tabindex="-1"></a><span class="st">    DisEngmt ~ a1*GRMS + a2*GRIcntlty + a3*GRMS:GRIcntlty</span></span>
<span id="cb292-5"><a href="#cb292-5" aria-hidden="true" tabindex="-1"></a><span class="st">    MntlHlth ~ c_p1*GRMS + c_p2*GRIcntlty + c_p3*GRMS:GRIcntlty + b*DisEngmt</span></span>
<span id="cb292-6"><a href="#cb292-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb292-7"><a href="#cb292-7" aria-hidden="true" tabindex="-1"></a><span class="st">    #intercepts</span></span>
<span id="cb292-8"><a href="#cb292-8" aria-hidden="true" tabindex="-1"></a><span class="st">    DisEngmt ~ DisEngmt.mean*1</span></span>
<span id="cb292-9"><a href="#cb292-9" aria-hidden="true" tabindex="-1"></a><span class="st">    MntlHlth ~ MntlHlth.mean*1</span></span>
<span id="cb292-10"><a href="#cb292-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb292-11"><a href="#cb292-11" aria-hidden="true" tabindex="-1"></a><span class="st">    #means, variances of W for simple slopes</span></span>
<span id="cb292-12"><a href="#cb292-12" aria-hidden="true" tabindex="-1"></a><span class="st">    GRIcntlty ~ GRIcntlty.mean*1</span></span>
<span id="cb292-13"><a href="#cb292-13" aria-hidden="true" tabindex="-1"></a><span class="st">    GRIcntlty ~~ GRIcntlty.var*GRIcntlty</span></span>
<span id="cb292-14"><a href="#cb292-14" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb292-15"><a href="#cb292-15" aria-hidden="true" tabindex="-1"></a><span class="st">    #index of moderated mediation, there will be an a and b path in the product</span></span>
<span id="cb292-16"><a href="#cb292-16" aria-hidden="true" tabindex="-1"></a><span class="st">    #if the a and/or b path is moderated, select the label that represents the moderation</span></span>
<span id="cb292-17"><a href="#cb292-17" aria-hidden="true" tabindex="-1"></a><span class="st">    imm := a3*b</span></span>
<span id="cb292-18"><a href="#cb292-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb292-19"><a href="#cb292-19" aria-hidden="true" tabindex="-1"></a><span class="st">    #Note that we first create the indirect product, then add to it the product of the imm and the W level</span></span>
<span id="cb292-20"><a href="#cb292-20" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect.SDbelow := a1*b + imm*(GRIcntlty.mean - sqrt(GRIcntlty.var))</span></span>
<span id="cb292-21"><a href="#cb292-21" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect.mean := a1*b + imm*(GRIcntlty.mean)</span></span>
<span id="cb292-22"><a href="#cb292-22" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect.SDabove := a1*b + imm*(GRIcntlty.mean + sqrt(GRIcntlty.var))</span></span>
<span id="cb292-23"><a href="#cb292-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb292-24"><a href="#cb292-24" aria-hidden="true" tabindex="-1"></a><span class="st">    #direct effect is also moderated so calculate with c_p1 + c_p3</span></span>
<span id="cb292-25"><a href="#cb292-25" aria-hidden="true" tabindex="-1"></a><span class="st">    direct.SDbelow := c_p1 + c_p3*(GRIcntlty.mean - sqrt(GRIcntlty.var)) </span></span>
<span id="cb292-26"><a href="#cb292-26" aria-hidden="true" tabindex="-1"></a><span class="st">    direct.Smean := c_p1 + c_p3*(GRIcntlty.mean)</span></span>
<span id="cb292-27"><a href="#cb292-27" aria-hidden="true" tabindex="-1"></a><span class="st">    direct.SDabove := c_p1 + c_p3*(GRIcntlty.mean + sqrt(GRIcntlty.var))</span></span>
<span id="cb292-28"><a href="#cb292-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb292-29"><a href="#cb292-29" aria-hidden="true" tabindex="-1"></a><span class="st">    #total effect</span></span>
<span id="cb292-30"><a href="#cb292-30" aria-hidden="true" tabindex="-1"></a><span class="st">    total.SDbelow := direct.SDbelow + indirect.SDbelow</span></span>
<span id="cb292-31"><a href="#cb292-31" aria-hidden="true" tabindex="-1"></a><span class="st">    total.mean := direct.Smean + indirect.mean</span></span>
<span id="cb292-32"><a href="#cb292-32" aria-hidden="true" tabindex="-1"></a><span class="st">    total.SDabove := direct.SDabove + indirect.SDabove</span></span>
<span id="cb292-33"><a href="#cb292-33" aria-hidden="true" tabindex="-1"></a><span class="st"> &#39;</span></span>
<span id="cb292-34"><a href="#cb292-34" aria-hidden="true" tabindex="-1"></a>Combined_fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(Combined, <span class="at">data =</span> Lewis_df, <span class="at">se =</span> <span class="st">&quot;bootstrap&quot;</span>, <span class="at">missing =</span> <span class="st">&#39;fiml&#39;</span>, <span class="at">bootstrap =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## Warning in lav_partable_vnames(FLAT, &quot;ov.x&quot;, warn = TRUE): lavaan WARNING:
##     model syntax contains variance/covariance/intercept formulas
##     involving (an) exogenous variable(s): [GRIcntlty]; These variables
##     will now be treated as random introducing additional free
##     parameters. If you wish to treat those variables as fixed, remove
##     these formulas from the model syntax. Otherwise, consider adding
##     the fixed.x = FALSE option.</code></pre>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="#cb294-1" aria-hidden="true" tabindex="-1"></a>cFITsum <span class="ot">&lt;-</span> <span class="fu">summary</span>(Combined_fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">rsq=</span>T, <span class="at">ci=</span><span class="cn">TRUE</span>)    </span></code></pre></div>
<pre><code>## lavaan 0.6-8 ended normally after 47 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        13
##                                                       
##   Number of observations                           212
##   Number of missing patterns                         1
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                               431.115
##   Degrees of freedom                                 2
##   P-value (Chi-square)                           0.000
## 
## Parameter Estimates:
## 
##   Standard errors                            Bootstrap
##   Number of requested bootstrap draws             1000
##   Number of successful bootstrap draws            1000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##   DisEngmt ~                                                            
##     GRMS      (a1)    0.212    0.194    1.092    0.275   -0.191    0.582
##     GRIcntl   (a2)   -0.027    0.078   -0.345    0.730   -0.186    0.123
##     GRMS:GR   (a3)    0.006    0.032    0.174    0.862   -0.053    0.074
##   MntlHlth ~                                                            
##     GRMS    (c_p1)   -1.412    1.420   -0.994    0.320   -3.953    1.625
##     GRIcntl (c_p2)   -0.556    0.521   -1.067    0.286   -1.545    0.549
##     GRMS:GR (c_p3)    0.164    0.234    0.701    0.483   -0.323    0.584
##     DsEngmt    (b)   -3.567    0.399   -8.933    0.000   -4.287   -2.791
##    Std.lv  Std.all
##                   
##     0.212    0.358
##    -0.027   -0.052
##     0.006    0.065
##                   
##    -1.412   -0.331
##    -0.556   -0.149
##     0.164    0.261
##    -3.567   -0.495
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .DsEngmt (DsE.)    1.417    0.453    3.128    0.002    0.543    2.326
##    .MntlHlt (MnH.)   31.703    3.017   10.508    0.000   25.395   37.661
##     GRIcntl (GRI.)    5.710    0.072   78.874    0.000    5.571    5.865
##    Std.lv  Std.all
##     1.417    2.666
##    31.703    8.273
##     5.710    5.557
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     GRIcntl (GRI.)    1.056    0.120    8.826    0.000    0.831    1.301
##    .DsEngmt           0.232    0.020   11.718    0.000    0.192    0.271
##    .MntlHlt          10.110    0.825   12.254    0.000    8.248   11.508
##    Std.lv  Std.all
##     1.056    1.000
##     0.232    0.822
##    10.110    0.688
## 
## R-Square:
##                    Estimate
##     DisEngmt          0.178
##     MntlHlth          0.312
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     imm              -0.020    0.115   -0.174    0.862   -0.262    0.194
##     indirect.SDblw   -0.850    0.206   -4.128    0.000   -1.241   -0.451
##     indirect.mean    -0.870    0.158   -5.523    0.000   -1.192   -0.566
##     indirect.SDabv   -0.891    0.186   -4.782    0.000   -1.272   -0.547
##     direct.SDbelow   -0.644    0.410   -1.572    0.116   -1.417    0.165
##     direct.Smean     -0.476    0.289   -1.644    0.100   -1.046    0.120
##     direct.SDabove   -0.307    0.335   -0.919    0.358   -0.994    0.324
##     total.SDbelow    -1.494    0.426   -3.510    0.000   -2.280   -0.649
##     total.mean       -1.346    0.307   -4.390    0.000   -1.954   -0.766
##     total.SDabove    -1.198    0.384   -3.121    0.002   -1.977   -0.461
##    Std.lv  Std.all
##    -0.020   -0.032
##    -0.850   -0.323
##    -0.870   -0.355
##    -0.891   -0.387
##    -0.644    0.861
##    -0.476    1.122
##    -0.307    1.383
##    -1.494    0.538
##    -1.346    0.767
##    -1.198    0.997</code></pre>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="#cb296-1" aria-hidden="true" tabindex="-1"></a>cParamEsts <span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(Combined_fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<div id="a-quick-plot" class="section level3" number="8.6.2">
<h3 number="8.6.2"><span class="header-section-number">8.6.2</span> A quick plot</h3>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb297-2"><a href="#cb297-2" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(Combined_fit, <span class="co">#must identiy the model you want to map</span></span>
<span id="cb297-3"><a href="#cb297-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb297-4"><a href="#cb297-4" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb297-5"><a href="#cb297-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;tree&#39;</span>, <span class="at">rotation =</span> <span class="dv">2</span>, <span class="co">#together, puts predictors on left, IVs on right </span></span>
<span id="cb297-6"><a href="#cb297-6" aria-hidden="true" tabindex="-1"></a>         <span class="co">#layout = &#39;circle&#39;,</span></span>
<span id="cb297-7"><a href="#cb297-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb297-8"><a href="#cb297-8" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb297-9"><a href="#cb297-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb297-10"><a href="#cb297-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb297-11"><a href="#cb297-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb297-12"><a href="#cb297-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb297-13"><a href="#cb297-13" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb297-14"><a href="#cb297-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb297-15"><a href="#cb297-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb297-16"><a href="#cb297-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb297-17"><a href="#cb297-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb297-18"><a href="#cb297-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb297-19"><a href="#cb297-19" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb297-20"><a href="#cb297-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb297-21"><a href="#cb297-21" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Moderated Mediation&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/semPlot%20of%20the%20modmed-1.svg" width="672" /></p>
<div class="sourceCode" id="cb298"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb298-1"><a href="#cb298-1" aria-hidden="true" tabindex="-1"></a><span class="fu">write.csv</span> (cParamEsts, <span class="at">file=</span><span class="st">&quot;Combined_fit.csv&quot;</span>) <span class="co">#optional to write it to a .csv file</span></span></code></pre></div>
</div>
<div id="beginning-the-interpretation" class="section level3" number="8.6.3">
<h3 number="8.6.3"><span class="header-section-number">8.6.3</span> Beginning the interpretation</h3>
<p>We have already looked at some of the simple effects found within the more complex model. Let’s grab the formulae.</p>
<p><span class="math display">\[\hat{M} = i_{M}+a_{1}X + a_{2}W + a_{3}XW + e_{M}\]</span></p>
<p><span class="math display">\[\hat{Y} = i_{Y}+c_{1}^{&#39;}X+ c_{2}^{&#39;}W+c_{3}^{&#39;}XW+ bM+e_{Y}\]</span></p>
<p>And substitute in our values</p>
<p><span class="math display">\[\hat{M} = 1.417 + 0.212X + (-0.027) W + 0.006XW\]</span>
<span class="math display">\[\hat{Y} = 31.703 + (-1.4115)X + (-0.556)W + 0.164XW + (-3.567)M\]</span></p>
</div>
<div id="tabling-the-data" class="section level3" number="8.6.4">
<h3 number="8.6.4"><span class="header-section-number">8.6.4</span> Tabling the data</h3>
<p>Table 1</p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Analysis of Moderated Mediation for GRMS, Gendered Racial Identity Centrality, Coping, and Mental Health</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center">Disengagement Coping (M)</td>
<td align="center">Mental Health (Y)</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left">Antecedent</td>
<td align="center">path</td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
<td align="center">path</td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="left">constant</td>
<td align="center"><span class="math inline">\(i_{M}\)</span></td>
<td align="center">1.417</td>
<td align="center">0.453</td>
<td align="center">0.002</td>
<td align="center"><span class="math inline">\(i_{Y}\)</span></td>
<td align="center">31.703</td>
<td align="center">3.017</td>
<td align="center">0.000</td>
</tr>
<tr class="odd">
<td align="left">GRMS (X)</td>
<td align="center"><span class="math inline">\(a_{1}\)</span></td>
<td align="center">0.212</td>
<td align="center">0.194</td>
<td align="center">0.275</td>
<td align="center"><span class="math inline">\(c_{1}\)</span></td>
<td align="center">-1.412</td>
<td align="center">1.420</td>
<td align="center">0.320</td>
</tr>
<tr class="even">
<td align="left">GRIcntrlty (W)</td>
<td align="center"><span class="math inline">\(a_{2}\)</span></td>
<td align="center">-0.027</td>
<td align="center">0.078</td>
<td align="center">0.730</td>
<td align="center"><span class="math inline">\(c_{2}\)</span></td>
<td align="center">-0.556</td>
<td align="center">0.521</td>
<td align="center">0.286</td>
</tr>
<tr class="odd">
<td align="left">GRMS*GRIcntrlty(XW)</td>
<td align="center"><span class="math inline">\(a_{3}\)</span></td>
<td align="center">0.006</td>
<td align="center">0.032</td>
<td align="center">0.862</td>
<td align="center"><span class="math inline">\(c_{3}\)</span></td>
<td align="center">0.164</td>
<td align="center">0.234</td>
<td align="center">0.483</td>
</tr>
<tr class="even">
<td align="left">DisEngmt (M)</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(b\)</span></td>
<td align="center">-3.567</td>
<td align="center">0.399</td>
<td align="center">0.000</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center"><span class="math inline">\(R^2\)</span> = 17.78%</td>
<td align="center"><span class="math inline">\(R^2\)</span> = 31.16%</td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Conditional Indirect, Direct, and Total Effects at Gendered Racial Identity Centrality Values</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center">Boot effect</td>
<td align="center">Boot SE</td>
<td align="center">Boot CI95 lower</td>
<td align="center">Boot CI95 upper</td>
</tr>
<tr class="even">
<td align="left">Index of moderated mediation</td>
<td align="center">-0.020</td>
<td align="center">0.115</td>
<td align="center">-0.264</td>
<td align="center">0.188</td>
</tr>
<tr class="odd">
<td align="left">Indirect</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">-1 <em>SD</em></td>
<td align="center">-0.850</td>
<td align="center">0.206</td>
<td align="center">-1.267</td>
<td align="center">-0.462</td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="center">-0.870</td>
<td align="center">0.158</td>
<td align="center">-1.236</td>
<td align="center">-0.594</td>
</tr>
<tr class="even">
<td align="left">+1 <em>SD</em></td>
<td align="center">-0.891</td>
<td align="center">0.186</td>
<td align="center">-1.299</td>
<td align="center">-0.565</td>
</tr>
<tr class="odd">
<td align="left">Direct</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">-1 <em>SD</em></td>
<td align="center">-0.644</td>
<td align="center">0.410</td>
<td align="center">-1.420</td>
<td align="center">0.153</td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="center">-0.476</td>
<td align="center">0.289</td>
<td align="center">-1.019</td>
<td align="center">0.159</td>
</tr>
<tr class="even">
<td align="left">+1 <em>SD</em></td>
<td align="center">-0.307</td>
<td align="center">0.335</td>
<td align="center">-0.980</td>
<td align="center">0.331</td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">-1 <em>SD</em></td>
<td align="center">-1.494</td>
<td align="center">0.426</td>
<td align="center">-2.295</td>
<td align="center">-0.662</td>
</tr>
<tr class="odd">
<td align="left">Mean</td>
<td align="center">-1.346</td>
<td align="center">0.307</td>
<td align="center">-1.944</td>
<td align="center">-0.739</td>
</tr>
<tr class="even">
<td align="left">+1 <em>SD</em></td>
<td align="center">-1.198</td>
<td align="center">0.384</td>
<td align="center">-1.948</td>
<td align="center">-0.455</td>
</tr>
</tbody>
</table>
<table>
<tbody>
</tbody>
</table>
<p><em>Note</em>. IV(X) = gendered racial microaggressions; M = disengagement coping; W; gendered racial identity centrality; Y = mental health. The significance of the indirect and direct effects were calculated with bias-corrected confidence intervals (.95) bootstrap analysis.</p>
<p>17.78% of the variance in disengagement coping (mediator) and 31.16% of the variance in mental health (DV) are predicted by their respective models.</p>
<p>The model we tested suggested that both the indirect and direct effects should be moderated. Hayes provides a more detailed and elaborate explanation of this on pp. 447 - 458.</p>
<div id="conditional-indirect-effects" class="section level4" number="8.6.4.1">
<h4 number="8.6.4.1"><span class="header-section-number">8.6.4.1</span> Conditional Indirect effects</h4>
<ul>
<li>An indirect effect can be moderated if either the <em>a</em> or <em>b</em> path (or both) is(are) moderated.</li>
<li>If at least one of the indirect paths is part of a moderation, then the whole indirect (axb) path would be moderated.
<ul>
<li>In this model, we specified a moderation of the <em>a</em> path.</li>
</ul></li>
<li>We know if the <em>a</em> path is moderated if the moderation term is statistically significant.
<ul>
<li>In our case, <span class="math inline">\(a_{3}\)</span> GRMS:GRIcntlty was not statistically significant (<span class="math inline">\(B\)</span> = 0.006, <span class="math inline">\(p\)</span> = 0.862).</li>
</ul></li>
<li>We also look at the <em>Index of Moderated Mediation</em>. The IMM is the product of the moderated path (in this case, the value of <span class="math inline">\(a_{3}\)</span>) and <em>b</em>. If this index is 0, then the slope of the line for the indirect effect is flat. The bootstrap confidence interval associated with this test is the way to determine whether/not this slope is statistically significant from zero. In our case, IMM = -0.020, CI095 = -0.264 to 0.188. This suggests that we do not have a moderated mediation. Hayes claims the IMM saves us from formally comparing (think “contrasts” pairs of conditional indirect effects)</li>
<li>We can even get more information about the potentially moderated indirect effect by <em>probing the conditional indirect effect</em>. Because an indirect effect is not normally distributed, Hayes discourages using a Johnson-Neyman approach and suggests that we use the pick-a-point. He usually selects the 16th, 50th, and 84th percentiles of the distribution. However, many researchers commonly report the mean+/-1SD.</li>
<li>at 1SD below the mean <span class="math inline">\(B\)</span> = -0.850, CI95 -1.267 to -0.462;</li>
<li>at the mean <span class="math inline">\(B\)</span> = -0.870, CI95 -1.236 to -0.594).<br />
</li>
<li>at 1SD above the mean, the conditional indirect effect was significant (<span class="math inline">\(B\)</span> = -0.891, CI95 -1.299 to -0.565).<br />
</li>
<li>Looking at the relative consistency of the <span class="math inline">\(B\)</span> weights and the consistently significant <span class="math inline">\(p\)</span> values, we see that there was an indirect effect throughout the varying levels of the moderator, gendered racial identity centrality. Thus, it makes sense that this was not a moderated mediation.</li>
</ul>
</div>
<div id="conditional-direct-effect" class="section level4" number="8.6.4.2">
<h4 number="8.6.4.2"><span class="header-section-number">8.6.4.2</span> Conditional Direct effect</h4>
<ul>
<li>The direct effect of X to Y estimates how differences in X relate to differences in Y holding constant the proposed mediator(s).</li>
<li>We know the direct effect is moderated if the interaction term (c_p3)is statistically significant. In our case, it was not (<em>B</em> = 0.164, <em>p</em> = 0.483).</li>
<li>Probing a conditional direct effect is straightforward…we typically use the same points as we did in the probing of the conditional indirect effect.
<ul>
<li>For both my values (mean and +/- 1SD) and Hayes values (16th, 50th, 84th percentiles), the direct effect (e.g., the effect of skepticism on willingness to donate) was not statistically significant from zero at any level of the moderator.</li>
</ul></li>
</ul>
</div>
</div>
<div id="model-trimming" class="section level3" number="8.6.5">
<h3 number="8.6.5"><span class="header-section-number">8.6.5</span> Model trimming</h3>
<p>Hayes terms it <em>pruning</em>, but suggests that when there is no moderation of an effect, the researcher may want to delete that interaction term. In our case, neither the direct nor indirect effect was moderated (although the +1<em>SD</em> was close (<span class="math inline">\(B\)</span> = -0.307, <span class="math inline">\(p\)</span> = 0.331). Deleting these paths one at a time is typical practice because the small boost of power with each deleted path may “turn on” significance elsewhere. If I were to engage in model trimming, I would start with the indirect effect to see if the direct effect became moderated. This is consistent with the simple moderation we ran earlier where we saw a fanning out at one end of the distribution.</p>
</div>
<div id="apa-style-write-up-1" class="section level3" number="8.6.6">
<h3 number="8.6.6"><span class="header-section-number">8.6.6</span> APA Style Write-up</h3>
<p><em>Note</em>: Make sure to look at the write-up in the Lewis et al. <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">J. A. Lewis et al., 2017</a>)</span> manuscript. I am a little confused in that Figure 2 of their manuscript suggests there was a moderation of both the <em>a</em> and <em>c’</em> paths. However, the results in Table 4 do not provide information about the moderation to the <em>c’</em> path. The Lewis et al. write-up is an efficient one, simultaneously presenting the results of two outcome variables – mental and physical health. While our <em>B</em> weights from our simulated data map similarly onto those reported in the Lewis et al. manuscript, we do not get get the statistically significant moderated mediation that they get.</p>
<p><strong>Results</strong></p>
<p><strong>Preliminary Analyses</strong></p>
<ul>
<li>Missing data anlaysis and managing missing data</li>
<li>Bivariate correlations, means, SDs</li>
<li>Distributional characteristics, assumptions, etc.</li>
<li>Address limitations and concerns</li>
</ul>
<p><strong>Primary Analyses</strong>
Our analysis evaluated a moderation mediation model predicting mental health (Y/MntlHlth) from gendered racial microaggressions (X/GRMS) mediated by disengagement coping (M/DisEngmt). Gendered racial identity centrality (W/GRIcntrlty) was our moderating variable. We specified a moderation of path <em>a</em> (X/GRMS to M/DisEngmt) and the direct path, <em>c’</em> (X/GRMS to Y/MntlHlth). Data were analyzed with maximum likelihood estimation in the R package <em>lavaan</em> (v. 0.6-7); the significance of effects were tested with 1000 bootstrap confidence intervals. Results of the full model are presented in Table 1 and illustrated in Figure 1 (<em>a variation of the semPlot or Hayes style representation</em>). The formula for the mediator and dependent variable are expressed below.</p>
<p><span class="math display">\[\hat{M} = 1.417 + 0.212X + (-0.027) W + 0.006XW\]</span>
<span class="math display">\[\hat{Y} = 31.703 + (-1.4115)X + (-0.556)W + 0.164XW + (-3.567)M\]</span></p>
<p>Results suggested a strong and negative total effect of gendered racial microaggressions on mental health that is mediated through disengagement coping. That is, in the presence of gendered racial microaggressions, participants increased disengagement coping which, in turn, had negative effects on mental health. The index of moderated mediation was -0.020 (CI95 -0.264 to 0.188) and suggested that the indirect effects were not conditional on the values of the moderator. While there was no evidence of moderation on the indirect or direct paths, there was a statistically significant, and consistently strong, mediation throughout the range of the gendered racial identity centrality (moderator). **Because we did not have a moderated mediation, I would probably not include the rest of this paragraph (nor include the moderation figure). I just wanted to demonstrate how to talk about findings if they were significant (although I acnowledg throughat that these are non-significant).* Figure 2 illustrates the conditional effects (non-significant) of GRMS (X) on mental health (Y) among those at the traditional levels of mean and +/- 1 <em>SD</em> where there is a fanning out of the effect of GRMS on when the presence of gendered racial microaggressions is low and mental health is at its highest. In this combination, mental health is even more positive in the presence of positive gendered racial identity centrality. Our model accounted for 17.78% of the variance in the mediator (disengagement coping) and 31.16% of the variance in the dependent variable (mental health).</p>
<div class="figure">
<img src="images/ModMed/GRMS_MH_GRIC.jpg" alt="" />
<p class="caption">Figure 2. The non-significant moderating effect of gendered racial identity centrality on the relationship between gendered racial microaggressions and mental health</p>
</div>
</div>
</div>
<div id="residual-and-related-questions-1" class="section level2" number="8.7">
<h2 number="8.7"><span class="header-section-number">8.7</span> Residual and Related Questions…</h2>
<p>..that you might have; or at least I had, but if had answered them earlier it would have disrupt the flow.</p>
<ol style="list-style-type: decimal">
<li>Would you stop here? Or keep tinkering?
<ul>
<li>I am tempted (but out of time, at least today, so stay tuned) to delete moderation of the indirect effect to see if I can get a moderated direct effect. My choice would also depend on to what I committed in any kind of pre-registration. My approach to science tends to be <em>model generating</em> <span class="citation">(<a href="#ref-bollen_testing_1993" role="doc-biblioref">Joreskog, 1993</a>)</span> and in his text, Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">2018</a>)</span> advised authors to write about what they found – not all the things they tried. This <em>tinkering</em> remains strongly in the vein of theoretically driven analyses.</li>
</ul></li>
<li>The output we get is different from the output in the journal article being used as the research vignette. Why? And should we worry about it?
<ul>
<li>We are simulating data. This gives us some advantages in that (unless we specify it), we never have missingness and our variables should be normally distributed. Because we are working from means, standard deviations, and correlations, our data will never be the same as the original researcher. That said, we can compare our results to the journal to <em>check out work.</em> I am somewhat reassured that our <span class="math inline">\(B\)</span> weights align and somewhat concerned that the index of moderated moderation was so far off. I suppose I will always doubt myself, and will therefore be open to anyone who finds an error in the specification of the model.</li>
</ul></li>
<li>Some of the statistics you are reporting are different than the ones in Hayes and the ones that use the PROCESS macro (e.g., what happened to the <em>F</em> test)?
<ul>
<li>The default estimator for <em>lavaan</em> is maximum likelihood (ML) and Hayes uses ordinary least squares (OLS). This affects both the values of coefficients, standard errors, AND the type of statistics that are reported.</li>
<li>You can ask for OLS regression by adding the statement “estimator =”GLS". Even with this option, I have not discovered a way to obtain the <em>F</em> tests for the overall model. Researchers seem to be comfortable with this, even asking for less than we did (e.g., many do not request R square).</li>
<li>Best I can tell, researchers who do want this might use a combination of packages, using GLS estimators in <em>lavaan</em> (this easily gets them the bootstrapped CIs) and the move to a different regression package to get the intercepts and <em>F</em> tests. If I did this I would triple check to make sure that all the output really lined up.</li>
</ul></li>
<li>Why did we ignore the traditional fit statistics associated with structural equation modeling (e.g., CFI, RMSEA).
<ul>
<li>I hesitate to do this with models that do not include latent variables. Therefore, we asked for an “in-between” amount of info that should be sufficient for publication submission (any editor may have their own preferences and ask for more).</li>
</ul></li>
<li>What if I have missing data?
<ul>
<li>When we enter the <em>lavaan</em> world we do get options other than multiple imputation. In today’s example we used the “sem” fitting function. Unless otherwise specified, listwise deletion (deleting the entire case when one of its variables is used to estimate the model) is the default in <em>lavaan</em>. If data are MCAR or MAR, you can add the argument <em>missing = “ml”</em> (or its alias <em>missing = “fiml”</em>). More here <a href="https://users.ugent.be/~yrosseel/lavaan/lavaan2.pdf" class="uri">https://users.ugent.be/~yrosseel/lavaan/lavaan2.pdf</a> on the 1.7/Missing data in lavaan slide.</li>
<li>That said, the type of estimator matters. If you estimate your data with GLS (generalized least squares) or WLS (weighted least squares), you are required to have complete data (however you got it). We used maximum likelihood and, even though we had non-missing data, I used the <em>missing = “fiml”</em> code.</li>
</ul></li>
</ol>
</div>
<div id="practice-problems-6" class="section level2" number="8.8">
<h2 number="8.8"><span class="header-section-number">8.8</span> Practice Problems</h2>
<p>The three problems described below were designed to grow during the series of chapters on simple and complex mediation, complex moderation, and conditional process analysis (i.e,. this chapter). I have recommended that you select a dataset that includes at least four variables. If you are new to this topic, you may wish to select variables that are all continuously scaled. The IV and moderator (next chapters) could be categorical (if they are dichotomous, please use 0/1 coding; if they have more than one category it is best if they are ordered). You will likely encounter challenges that were not covered in this chapter. Search for and try out solutions, knowing that there are multiple paths through the analysis.</p>
<p>The suggested practice problem for this chapter is to conduct a simple mediation.</p>
<ul>
<li>There are a number of variables in the dataset. Swap out one or more variables in the model of simple mediation and compare your solution to the one in the chapter.</li>
<li>Conduct a simple mediation with data to which you have access. This could include data you simulate on your own or from a published article.</li>
</ul>
<div id="problem-1-rework-the-research-vignette-as-demonstrated-but-change-the-random-seed-2" class="section level3" number="8.8.1">
<h3 number="8.8.1"><span class="header-section-number">8.8.1</span> Problem #1: Rework the research vignette as demonstrated, but change the random seed</h3>
<p>If this topic feels a bit overwhelming, simply change the random seed in the data simulation, then rework the problem. This should provide minor changes to the data (maybe in the second or third decimal point), but the results will likely be very similar.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, M, or W roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes regression output for the M and Y variables and the moderated effects</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-2-rework-the-research-vignette-but-swap-one-or-more-variables-2" class="section level3" number="8.8.2">
<h3 number="8.8.2"><span class="header-section-number">8.8.2</span> Problem #2: Rework the research vignette, but swap one or more variables</h3>
<p>Use the simulated data, but select one of the other models that was evaluated in the Lewis et al. <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">J. A. Lewis et al., 2017</a>)</span> study. Compare your results to those reported in the mansucript.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, M, or W roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes regression output for the M and Y variables and the moderated effects</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-3-use-other-data-that-is-available-to-you-2" class="section level3" number="8.8.3">
<h3 number="8.8.3"><span class="header-section-number">8.8.3</span> Problem #3: Use other data that is available to you</h3>
<p>Using data for which you have permission and access (e.g., IRB approved data you have collected or from your lab; data you simulate from a published article; data from an open science repository; data from other chapters in this OER), complete a simple mediation.</p>
<table>
<colgroup>
<col width="76%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, M, or W roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the lavaan model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Use semPlot to create a figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create a table that includes regression output for the M and Y variables and the moderated effects</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Be able to hand-calculate the indirect, direct, and total effects from the a, b, &amp; c’ paths</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left"><strong>Totals</strong></td>
<td align="center">35</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="bonus-track-1" class="section level2" number="8.9">
<h2 number="8.9"><span class="header-section-number">8.9</span> Bonus Track:</h2>
<div class="figure">
<img src="images/film-strip-1.jpg" id="id" class="class" width="620" height="211" alt="" />
<p class="caption">Image of a filmstrip</p>
</div>
<p>I find it useful to have script with the variables labeled merely by their role. Below, I quickly create an ModMeddemo_df from the Lewis et al. <span class="citation">(<a href="#ref-lewis_applying_2017" role="doc-biblioref">J. A. Lewis et al., 2017</a>)</span> simulated data and then run the analysis with the variables named in their roles.</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb299-2"><a href="#cb299-2" aria-hidden="true" tabindex="-1"></a>ModMedDemo_df <span class="ot">&lt;-</span> <span class="fu">rename</span>(Lewis_df, <span class="at">X =</span> GRMS, <span class="at">Y =</span> MntlHlth, <span class="at">W =</span> GRIcntlty, <span class="at">M =</span> DisEngmt )</span></code></pre></div>
<div class="sourceCode" id="cb300"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb300-2"><a href="#cb300-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">190505</span>)</span>
<span id="cb300-3"><a href="#cb300-3" aria-hidden="true" tabindex="-1"></a>ModMedDemo <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb300-4"><a href="#cb300-4" aria-hidden="true" tabindex="-1"></a><span class="st">    #equations</span></span>
<span id="cb300-5"><a href="#cb300-5" aria-hidden="true" tabindex="-1"></a><span class="st">    M ~ a1*X + a2*W + a3*X:W</span></span>
<span id="cb300-6"><a href="#cb300-6" aria-hidden="true" tabindex="-1"></a><span class="st">    Y ~ c_p1*X + c_p2*W + c_p3*X:W + b*M</span></span>
<span id="cb300-7"><a href="#cb300-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-8"><a href="#cb300-8" aria-hidden="true" tabindex="-1"></a><span class="st">    #intercepts</span></span>
<span id="cb300-9"><a href="#cb300-9" aria-hidden="true" tabindex="-1"></a><span class="st">    M ~ M.mean*1</span></span>
<span id="cb300-10"><a href="#cb300-10" aria-hidden="true" tabindex="-1"></a><span class="st">    Y ~ Y.mean*1</span></span>
<span id="cb300-11"><a href="#cb300-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-12"><a href="#cb300-12" aria-hidden="true" tabindex="-1"></a><span class="st">    #means, variances of W for simple slopes</span></span>
<span id="cb300-13"><a href="#cb300-13" aria-hidden="true" tabindex="-1"></a><span class="st">    W ~ W.mean*1</span></span>
<span id="cb300-14"><a href="#cb300-14" aria-hidden="true" tabindex="-1"></a><span class="st">    W ~~ W.var*W</span></span>
<span id="cb300-15"><a href="#cb300-15" aria-hidden="true" tabindex="-1"></a><span class="st">    </span></span>
<span id="cb300-16"><a href="#cb300-16" aria-hidden="true" tabindex="-1"></a><span class="st">    #index of moderated mediation, there will be an a and b path in the product</span></span>
<span id="cb300-17"><a href="#cb300-17" aria-hidden="true" tabindex="-1"></a><span class="st">    #if the a and/or b path is moderated, select the label that represents the moderation</span></span>
<span id="cb300-18"><a href="#cb300-18" aria-hidden="true" tabindex="-1"></a><span class="st">    imm := a3*b</span></span>
<span id="cb300-19"><a href="#cb300-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-20"><a href="#cb300-20" aria-hidden="true" tabindex="-1"></a><span class="st">    #Note that we first create the indirect product, then add to it the product of the imm and the W level</span></span>
<span id="cb300-21"><a href="#cb300-21" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect.SDbelow := a1*b + imm*(W.mean - sqrt(W.var))</span></span>
<span id="cb300-22"><a href="#cb300-22" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect.mean := a1*b + imm*(W.mean)</span></span>
<span id="cb300-23"><a href="#cb300-23" aria-hidden="true" tabindex="-1"></a><span class="st">    indirect.SDabove := a1*b + imm*(W.mean + sqrt(W.var))</span></span>
<span id="cb300-24"><a href="#cb300-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-25"><a href="#cb300-25" aria-hidden="true" tabindex="-1"></a><span class="st">    #direct effect is also moderated so calculate with c_p1 + c_p3</span></span>
<span id="cb300-26"><a href="#cb300-26" aria-hidden="true" tabindex="-1"></a><span class="st">    direct.SDbelow := c_p1 + c_p3*(W.mean - sqrt(W.var)) </span></span>
<span id="cb300-27"><a href="#cb300-27" aria-hidden="true" tabindex="-1"></a><span class="st">    direct.Smean := c_p1 + c_p3*(W.mean)</span></span>
<span id="cb300-28"><a href="#cb300-28" aria-hidden="true" tabindex="-1"></a><span class="st">    direct.SDabove := c_p1 + c_p3*(W.mean + sqrt(W.var))</span></span>
<span id="cb300-29"><a href="#cb300-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb300-30"><a href="#cb300-30" aria-hidden="true" tabindex="-1"></a><span class="st">    #total effect</span></span>
<span id="cb300-31"><a href="#cb300-31" aria-hidden="true" tabindex="-1"></a><span class="st">    total.SDbelow := direct.SDbelow + indirect.SDbelow</span></span>
<span id="cb300-32"><a href="#cb300-32" aria-hidden="true" tabindex="-1"></a><span class="st">    total.mean := direct.Smean + indirect.mean</span></span>
<span id="cb300-33"><a href="#cb300-33" aria-hidden="true" tabindex="-1"></a><span class="st">    total.SDabove := direct.SDabove + indirect.SDabove</span></span>
<span id="cb300-34"><a href="#cb300-34" aria-hidden="true" tabindex="-1"></a><span class="st"> &#39;</span></span>
<span id="cb300-35"><a href="#cb300-35" aria-hidden="true" tabindex="-1"></a>ModMedDemo_fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(ModMedDemo, <span class="at">data =</span> ModMedDemo_df, <span class="at">se =</span> <span class="st">&quot;bootstrap&quot;</span>, <span class="at">missing =</span> <span class="st">&#39;fiml&#39;</span>, <span class="at">bootstrap =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## Warning in lav_partable_vnames(FLAT, &quot;ov.x&quot;, warn = TRUE): lavaan WARNING:
##     model syntax contains variance/covariance/intercept formulas
##     involving (an) exogenous variable(s): [W]; These variables will
##     now be treated as random introducing additional free parameters.
##     If you wish to treat those variables as fixed, remove these
##     formulas from the model syntax. Otherwise, consider adding the
##     fixed.x = FALSE option.</code></pre>
<div class="sourceCode" id="cb302"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb302-1"><a href="#cb302-1" aria-hidden="true" tabindex="-1"></a>ModMed_FitSum <span class="ot">&lt;-</span> <span class="fu">summary</span>(ModMedDemo_fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">rsq=</span>T, <span class="at">ci=</span><span class="cn">TRUE</span>)    </span></code></pre></div>
<pre><code>## lavaan 0.6-8 ended normally after 47 iterations
## 
##   Estimator                                         ML
##   Optimization method                           NLMINB
##   Number of model parameters                        13
##                                                       
##   Number of observations                           212
##   Number of missing patterns                         1
##                                                       
## Model Test User Model:
##                                                       
##   Test statistic                               431.115
##   Degrees of freedom                                 2
##   P-value (Chi-square)                           0.000
## 
## Parameter Estimates:
## 
##   Standard errors                            Bootstrap
##   Number of requested bootstrap draws             1000
##   Number of successful bootstrap draws            1000
## 
## Regressions:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##   M ~                                                                   
##     X         (a1)    0.212    0.194    1.092    0.275   -0.191    0.582
##     W         (a2)   -0.027    0.078   -0.345    0.730   -0.186    0.123
##     X:W       (a3)    0.006    0.032    0.174    0.862   -0.053    0.074
##   Y ~                                                                   
##     X       (c_p1)   -1.412    1.420   -0.994    0.320   -3.953    1.625
##     W       (c_p2)   -0.556    0.521   -1.067    0.286   -1.545    0.549
##     X:W     (c_p3)    0.164    0.234    0.701    0.483   -0.323    0.584
##     M          (b)   -3.567    0.399   -8.933    0.000   -4.287   -2.791
##    Std.lv  Std.all
##                   
##     0.212    0.358
##    -0.027   -0.052
##     0.006    0.065
##                   
##    -1.412   -0.331
##    -0.556   -0.149
##     0.164    0.261
##    -3.567   -0.495
## 
## Intercepts:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##    .M       (M.mn)    1.417    0.453    3.128    0.002    0.543    2.326
##    .Y       (Y.mn)   31.703    3.017   10.508    0.000   25.395   37.661
##     W       (W.mn)    5.710    0.072   78.874    0.000    5.571    5.865
##    Std.lv  Std.all
##     1.417    2.666
##    31.703    8.273
##     5.710    5.557
## 
## Variances:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     W       (W.vr)    1.056    0.120    8.826    0.000    0.831    1.301
##    .M                 0.232    0.020   11.718    0.000    0.192    0.271
##    .Y                10.110    0.825   12.254    0.000    8.248   11.508
##    Std.lv  Std.all
##     1.056    1.000
##     0.232    0.822
##    10.110    0.688
## 
## R-Square:
##                    Estimate
##     M                 0.178
##     Y                 0.312
## 
## Defined Parameters:
##                    Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
##     imm              -0.020    0.115   -0.174    0.862   -0.262    0.194
##     indirect.SDblw   -0.850    0.206   -4.128    0.000   -1.241   -0.451
##     indirect.mean    -0.870    0.158   -5.523    0.000   -1.192   -0.566
##     indirect.SDabv   -0.891    0.186   -4.782    0.000   -1.272   -0.547
##     direct.SDbelow   -0.644    0.410   -1.572    0.116   -1.417    0.165
##     direct.Smean     -0.476    0.289   -1.644    0.100   -1.046    0.120
##     direct.SDabove   -0.307    0.335   -0.919    0.358   -0.994    0.324
##     total.SDbelow    -1.494    0.426   -3.510    0.000   -2.280   -0.649
##     total.mean       -1.346    0.307   -4.390    0.000   -1.954   -0.766
##     total.SDabove    -1.198    0.384   -3.121    0.002   -1.977   -0.461
##    Std.lv  Std.all
##    -0.020   -0.032
##    -0.850   -0.323
##    -0.870   -0.355
##    -0.891   -0.387
##    -0.644    0.861
##    -0.476    1.122
##    -0.307    1.383
##    -1.494    0.538
##    -1.346    0.767
##    -1.198    0.997</code></pre>
<div class="sourceCode" id="cb304"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb304-1"><a href="#cb304-1" aria-hidden="true" tabindex="-1"></a>ModMed_ParamEsts <span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(ModMedDemo_fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb305"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>## R version 4.0.4 (2021-02-15)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 18362)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] interactions_1.1.3 jtools_2.1.3       MASS_7.3-53.1      semTable_1.8      
##  [5] semPlot_1.1.2      lavaan_0.6-8       apaTables_2.0.8    mice_3.13.0       
##  [9] sjstats_0.18.1     formattable_0.2.1  qualtRics_3.1.4    forcats_0.5.1     
## [13] stringr_1.4.0      dplyr_1.0.5        purrr_0.3.4        readr_1.4.0       
## [17] tidyr_1.1.3        tibble_3.1.1       ggplot2_3.3.3      tidyverse_1.3.1   
## [21] psych_2.1.3       
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1        backports_1.2.1     Hmisc_4.5-0        
##   [4] systemfonts_1.0.1   igraph_1.2.6        plyr_1.8.6         
##   [7] splines_4.0.4       TH.data_1.0-10      digest_0.6.27      
##  [10] htmltools_0.5.1.1   matrixcalc_1.0-3    fansi_0.4.2        
##  [13] magrittr_2.0.1      Rsolnp_1.16         checkmate_2.0.0    
##  [16] lisrelToR_0.1.4     cluster_2.1.2       openxlsx_4.2.3     
##  [19] modelr_0.1.8        sandwich_3.0-0      svglite_2.0.0      
##  [22] jpeg_0.1-8.1        sem_3.1-11          MBESS_4.8.0        
##  [25] colorspace_2.0-0    rvest_1.0.0         haven_2.4.1        
##  [28] xfun_0.22           crayon_1.4.1        jsonlite_1.7.2     
##  [31] lme4_1.1-26         regsem_1.6.2        survival_3.2-11    
##  [34] zoo_1.8-9           glue_1.4.2          kableExtra_1.3.4   
##  [37] gtable_0.3.0        emmeans_1.6.0       webshot_0.5.2      
##  [40] mi_1.0              sjmisc_2.8.6        abind_1.4-5        
##  [43] scales_1.1.1        mvtnorm_1.1-1       DBI_1.1.1          
##  [46] Rcpp_1.0.6          viridisLite_0.4.0   xtable_1.8-4       
##  [49] performance_0.7.1   htmlTable_2.1.0     tmvnsim_1.0-2      
##  [52] foreign_0.8-81      Formula_1.2-4       stats4_4.0.4       
##  [55] truncnorm_1.0-8     htmlwidgets_1.5.3   httr_1.4.2         
##  [58] RColorBrewer_1.1-2  ellipsis_0.3.1      farver_2.1.0       
##  [61] XML_3.99-0.6        pkgconfig_2.0.3     nnet_7.3-15        
##  [64] sass_0.3.1          kutils_1.70         dbplyr_2.1.1       
##  [67] utf8_1.2.1          labeling_0.4.2      reshape2_1.4.4     
##  [70] tidyselect_1.1.1    rlang_0.4.11        effectsize_0.4.4-1 
##  [73] munsell_0.5.0       cellranger_1.1.0    tools_4.0.4        
##  [76] cli_2.5.0           generics_0.1.0      sjlabelled_1.1.7   
##  [79] broom_0.7.6         fdrtool_1.2.16      evaluate_0.14      
##  [82] arm_1.11-2          yaml_2.2.1          knitr_1.33         
##  [85] fs_1.5.0            stationery_0.98.30  pander_0.6.3       
##  [88] zip_2.1.1           glasso_1.11         pbapply_1.4-3      
##  [91] nlme_3.1-151        xml2_1.3.2          compiler_4.0.4     
##  [94] rstudioapi_0.13     curl_4.3.1          png_0.1-7          
##  [97] reprex_2.0.0        statmod_1.4.35      bslib_0.2.4        
## [100] pbivnorm_0.6.0      stringi_1.5.3       highr_0.9          
## [103] parameters_0.13.0   qgraph_1.6.9        rockchalk_1.8.144  
## [106] lattice_0.20-41     Matrix_1.2-18       nloptr_1.2.2.2     
## [109] vctrs_0.3.7         pillar_1.6.0        lifecycle_1.0.0    
## [112] jquerylib_0.1.4     OpenMx_2.19.5       estimability_1.3   
## [115] corpcor_1.6.9       data.table_1.14.0   insight_0.13.2     
## [118] R6_2.5.0            latticeExtra_0.6-29 bookdown_0.22      
## [121] gridExtra_2.3       codetools_0.2-18    gtools_3.8.2       
## [124] boot_1.3-27         assertthat_0.2.1    withr_2.4.2        
## [127] mnormt_2.0.2        multcomp_1.4-17     bayestestR_0.9.0   
## [130] parallel_4.0.4      hms_1.0.0           grid_4.0.4         
## [133] rpart_4.1-15        coda_0.19-4         minqa_1.2.4        
## [136] rmarkdown_2.7       carData_3.0-4       lubridate_1.7.10   
## [139] base64enc_0.1-3</code></pre>
<!--chapter:end:08-CPA.Rmd-->
</div>
</div>
<div id="MOD" class="section level1 unnumbered">
<h1 class="unnumbered">MODERATION</h1>
</div>
<div id="SimpMod" class="section level1" number="9">
<h1 number="9"><span class="header-section-number">9</span> Simple Moderation in OLS and MLE</h1>
<p><a href="link%20here">Screencasted Lecture Link</a></p>
<div class="sourceCode" id="cb307"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb307-1"><a href="#cb307-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">scipen=</span><span class="dv">999</span>)<span class="co">#eliminates scientific notation</span></span></code></pre></div>
<p>The focus of this lecture is an overview of simple moderation. Sounds simple? Wait, there’s more! The focus of this lecture is the transition:</p>
<ul>
<li>from null hypothesis significance testing (NHST) to moderling</li>
<li>from <em>ordinary least squares</em> (OLS) to <em>maximum likelihood estimation</em> (MLE)</li>
</ul>
<p>In making the transition we will work a moderation/interaction problem from Hayes’ text with both <em>lm()</em> and <em>lavvan/sem()</em> functions. Subsequent chapters will involve Hayes’ <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">Hayes, 2018</a>)</span> style demonstrations in <em>additive</em> and <em>moderated</em> moderation.</p>
<div id="navigating-this-lesson-7" class="section level2" number="9.1">
<h2 number="9.1"><span class="header-section-number">9.1</span> Navigating this Lesson</h2>
<p>There is about # hour and ## minutes of lecture. If you work through the materials with me it would be plan for an additional TIME.</p>
<p>While the majority of R objects and data you will need are created within the R script that sources the chapter, occasionally there are some that cannot be created from within the R framework. Additionally, sometimes links fail. All original materials are provided at the <a href="https://github.com/lhbikos/ReC_CPA">Github site</a> that hosts the book. More detailed guidelines for ways to access all these materials are provided in the OER’s <a href="#ReCintro">introduction</a></p>
<div id="learning-objectives-7" class="section level3" number="9.1.1">
<h3 number="9.1.1"><span class="header-section-number">9.1.1</span> Learning Objectives</h3>
<p>Learning objectives from this lecture include the following:</p>
<ul>
<li>Distinguish between NHST and model building approaches</li>
<li>Name the primary characteristics that distinguish ordinary least squares from maximum likelihood approaches to regression.</li>
<li>Articulate Hayes’ general opinions about
<ul>
<li>centering</li>
<li>standardizing regression coefficients</li>
</ul></li>
<li>Interpret “the usual” things we find in regression: B/beta weights, R, <span class="math inline">\(R^{2}\)</span>.</li>
<li>Define and interpret simple slopes and probing an interaction, this includes
<ul>
<li>pick-a-point and Johnson-Neyman approaches</li>
<li>interpreting interaction plots/figures</li>
</ul></li>
<li>Recognize the path specification in <em>lavaan</em>. That is, you should be able to figure out a diagram from the <em>lavaan</em> code. In reverse, you should be able to write (or identify) the proper code in <em>lavaan</em>.</li>
</ul>
</div>
<div id="planning-for-practice-7" class="section level3" number="9.1.2">
<h3 number="9.1.2"><span class="header-section-number">9.1.2</span> Planning for Practice</h3>
<p>Although I provide more complete descriptions at the end of the chapter follow these suggestions, providing an overview of them here may help you plan for what you might want to do as you work through the chapter. As is typical for this OER, the suggestions for homework are graded in complexity. I recommend you select an option that builds on your confidence but provides a bit of stretch. I also suggest you utilize a dataset that has at least four variables that are suitable for growing into a complex moderation (additive or moderated) or moderated mediation. This will be easiest if the variables are continuous in nature. In these chapters, I do not describe how to use categorical variables in dependent (e.g., consequent or endogenous) roles. However, dichotomous and ordered factors are suitable as independent variables and covariates.</p>
<ul>
<li>Rework the problem in the chapter by changing the random seed in the code that simulates the data. This should provide minor changes to the data, but the results will likely be very similar.</li>
<li>There are a number of variables in the dataset. Swap out one or more variables in the simple moderation and compare your solution to the one in the chapter (and/or one you mimicked in the journal article).</li>
<li>Conduct a simple moderation with data to which you have access. This could include data you simulate on your own or from a published article.</li>
</ul>
</div>
<div id="readings-resources-7" class="section level3" number="9.1.3">
<h3 number="9.1.3"><span class="header-section-number">9.1.3</span> Readings &amp; Resources</h3>
<p>In preparing this chapter, I drew heavily from the following resource(s). Other resources are cited (when possible, linked) in the text with complete citations in the reference list.</p>
<p>Regarding ordinary least squares (OLS) versus maximum likelihood estimation (MLE), these articles are extremely helpful:</p>
<ul>
<li>Cohen, J. (2003). <strong>Maximum likelihood estimation. Section 13.2.9 (pp. 498-499) only</strong>. <em>Applied multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). Erlbaum Associates.</li>
<li>Cumming, G. (2014). The New Statistics: Why and How. Psychological Science, 25(1), 7–29. <a href="https://doi.org/10.1177/0956797613504966" class="uri">https://doi.org/10.1177/0956797613504966</a></li>
<li>Myung, I. J. (2003). Tutorial on maximum likelihood estimation. <em>Journal of Mathematical Psychology, 47</em>(1), 90–100. <a href="https://doi.org/10.1016/S0022-2496(02)00028-7" class="uri">https://doi.org/10.1016/S0022-2496(02)00028-7</a> (skim for big ideas)</li>
<li>Rodgers, J. L. (2010). The epistemology of mathematical and statistical modeling: A quiet methodological revolution. <em>American Psychologist, 65</em>(1), 1–12. <a href="https://doi.org/10.1037/a0018326" class="uri">https://doi.org/10.1037/a0018326</a></li>
</ul>
<p>Regarding the topic of moderation, I drew heavily from these resources.</p>
<ul>
<li>Hayes, A. F. (2017). <em>Introduction to Mediation, Moderation, and Conditional Process Analysis, Second Edition: A Regression-Based Approach</em>. Guilford Publications. <a href="http://ebookcentral.proquest.com/lib/spu/detail.action?docID=5109647" class="uri">http://ebookcentral.proquest.com/lib/spu/detail.action?docID=5109647</a>
<ul>
<li>Chapter 7: Fundamentals of Moderation Analysis: This chapter focuses on the basics of moderation analysis. Our goal is to transfer and apply the knowledge to models we run in lavaan. An excellent review of centering, visualizations, and probing moderations.</li>
<li>Chapter 8: Extending the Fundamental Principles of Moderation Analysis (pp. 267-301): Hayes addresses common regression concerns such as (a) hierarchival vs. simultanous entry and (b) comparison of moderated regression with 2x2 factorial ANOVA.</li>
<li>Chapter 9: Some Myths and Additional Extensions of Moderation Analysis (pp. 303-347). Hayes identifies “truths and myths” about mean centering and standardization. For sure these are important topics and his take on them is clear and compelling.</li>
<li>Appendix A: An essential tool for PROCESS users because, even when we are in the R environment, this is the “idea book.” That is, the place where all the path models are presented in figures.</li>
</ul></li>
</ul>
<p>The research vignette for this chapter:</p>
<ul>
<li>Kim, P. Y., Kendall, D. L., &amp; Cheon, H.-S. (2017). Racial microaggressions, cultural mistrust, and mental health outcomes among Asian American college students. <em>American Journal of Orthopsychiatry, 87</em>(6), 663–670. <a href="https://doi-org.ezproxy.spu.edu/10.1037/ort0000203" class="uri">https://doi-org.ezproxy.spu.edu/10.1037/ort0000203</a></li>
</ul>
</div>
<div id="packages-8" class="section level3" number="9.1.4">
<h3 number="9.1.4"><span class="header-section-number">9.1.4</span> Packages</h3>
<p>The script below will (a) check to see if the following packages are installed on your computer and, if not (b) install them.</p>
</div>
</div>
<div id="on-modeling-introductory-comments-on-the-simultaneously-invisible-and-paradigm-shifting-transition-we-are-making" class="section level2" number="9.2">
<h2 number="9.2"><span class="header-section-number">9.2</span> On <em>Modeling</em>: Introductory Comments on the simultaneously invisible and paradigm-shifting transition we are making</h2>
<div id="nhst-versus-modeling" class="section level3" number="9.2.1">
<h3 number="9.2.1"><span class="header-section-number">9.2.1</span> NHST versus modeling</h3>
<p>At least a decade old now, Rogers’ <span class="citation">(<a href="#ref-rodgers_epistemology_2010" role="doc-biblioref">2010</a>)</span> article in the <em>American Psychologist</em> is one of my favorites. In it, he explores the notion of <em>statistical modeling</em>. He begins with criticisms of null hypothesis statistical testing by describing how it has become a awkward and incongruent blend of Fisherian (i.e., R.A. Fisher) and Neyman-Pearson (i.e., Jerzy Neyman and E. S. Pearson) approaches.</p>
<p><strong>Table 1</strong></p>
<table>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Contributions of the Fisherian and Neyman-Pearson Approaches to NHST <span class="citation">(<a href="#ref-rodgers_epistemology_2010" role="doc-biblioref">Rodgers, 2010</a>)</span></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="center"><strong>Fisher</strong></td>
<td align="center"><strong>Neyman-Pearson</strong></td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="50%" />
<col width="49%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">Developed NHST to answer scientific questions and evaluate theory.</td>
<td align="left">Sought to draw conclusions in applied settings such as quality control.</td>
</tr>
<tr class="even">
<td align="left">Took an incremental approach to hypothesis testing that involved replication and (potentially) self-correcting; as such viewed <em>replication</em> as a critical element.</td>
<td align="left">Placed emphasis on the importance of each individual decision.</td>
</tr>
<tr class="odd">
<td align="left">Never used the terms, “alternative hypothesis” or “alpha level.” Rather, Fisher used the distribution of the null model to examine “whether the data look weird or not.”</td>
<td align="left">Designed their approach to detect an “alternative hypothesis.”</td>
</tr>
<tr class="even">
<td align="left">Gave us the null hypothesis and <em>p</em> value.</td>
<td align="left">Gave us the alternative hypothesis, alpha level, and power.</td>
</tr>
</tbody>
</table>
<p>Overtime, these overlapping, but inconsistent, approaches became intertwined. Many students of statistics do not recognize the incompatibilities. Undoubtedly, it makes statistics more difficult to learn (and teach). Below are some of the challenges that Rodgers <span class="citation">(<a href="#ref-rodgers_epistemology_2010" role="doc-biblioref">2010</a>)</span> outlined.</p>
<ul>
<li>Rejecting the null does not provide logical or strong support for the alternative</li>
<li>Failing to rejct the null does not provide logical or strong support for the null.</li>
<li>NHST is backwards because it evaluates the probability of the data given the hypothesis, rather than the probability of the hypothesis given the data.</li>
<li>All point-estimate null hypotheses can be rejected if the sample size is large enough.</li>
<li>Statistical significance does not necessitate practical significance.</li>
</ul>
<p>Consequently, we have ongoing discussion/debates about power, effect sizes, sample size, Type I and II errors, confidence intervals, fit statistics, and the relations between them.</p>
</div>
<div id="introducing-the-model" class="section level3" number="9.2.2">
<h3 number="9.2.2"><span class="header-section-number">9.2.2</span> Introducing: <em>The Model</em></h3>
<p>Understanding modeling in our <em>scientist-practitioner</em> context probably needs to start with understanding the <em>mathematical model</em>. Niemark and Este <span class="citation">(<a href="#ref-niemark_stimulus_1967" role="doc-biblioref">1967</a>)</span> defined a mathematical model as a set of assumptions together with implications drawn from them by mathematical reasoning. Luce [luce_four_1995] suggested that mathematical equations capture model-specific features by highlighting some aspects while ignoring others. The use of mathematics helps us uncover the “structure.” For example, the <em>mean</em> is a mathematical model. <em>I always like to stop and think about that notion…about what the mean represents and what it doesn’t.</em> Pearl <span class="citation">(<a href="#ref-pearl_causality_2000" role="doc-biblioref">2000</a>)</span> defined the model as an idealized representation of reality that highlights some aspects and ignores others by suggesting that a model:</p>
<ul>
<li>matches the reality it describes in some important ways.</li>
<li>is simpler than that reality.</li>
</ul>
<p>As we transition from the NHST approach to statistical modeling there is <span class="citation">(<a href="#ref-rodgers_epistemology_2010" role="doc-biblioref">Rodgers, 2010</a>)</span>:</p>
<ul>
<li>decreased emphasis on
<ul>
<li>null hypothesis</li>
<li><em>p</em> values</li>
</ul></li>
<li>increased emphasis on
<ul>
<li>model residuals</li>
<li>degrees of freedom</li>
<li>additional indices of <em>fit</em></li>
</ul></li>
</ul>
<p>Further, statistical models <span class="citation">(<a href="#ref-rodgers_epistemology_2010" role="doc-biblioref">Rodgers, 2010</a>)</span>:</p>
<ul>
<li>are more readily falsifiable</li>
<li>require greater theoretical precision</li>
<li>include assumptions that are more readily evaluated</li>
<li>offer more practical application</li>
</ul>
<p>Circling back around to Fisher and Neyman-Pearson, Rogers <span class="citation">(<a href="#ref-rodgers_epistemology_2010" role="doc-biblioref">2010</a>)</span> contended that Fisher’s work provided a framework for modeling because of the model process of specifications, estimation, and goodness of fit. As we move into more complex modeling, we will spend a great deal of time understanding parameters and their relationship to degrees of freedom. Fisher viewed degrees of freedom as <em>statistical currency</em> that could be used in exchange for the estimation of parameters.</p>
<p>If this topic is exciting to you, let me refer you to Cumming’s <span class="citation">(<a href="#ref-cumming_new_2014" role="doc-biblioref">Cumming, 2014</a>)</span> article, “The New Statistics: Why and How,” in the Journal, *Psychological Science"</p>
</div>
</div>
<div id="ols-to-ml-for-estimation" class="section level2" number="9.3">
<h2 number="9.3"><span class="header-section-number">9.3</span> OLS to ML for Estimation</h2>
<div id="ordinary-least-squares-ols" class="section level3" number="9.3.1">
<h3 number="9.3.1"><span class="header-section-number">9.3.1</span> Ordinary least squares (OLS)</h3>
<p>Known by a variety of names, the estimation algorithm typically used in regression models (linear, hierarchical, multiple, sequential) is <em>ordinary least squares</em> (OLS; also termed least squares criterion, general least squares, etc.). As we move into multivariate (and then psychometrics) we are going to transition our estimation method from OLS to MLE. Consequently, it is essential to understand some underlying differences <span class="citation">(<a href="#ref-cohen_applied_2003" role="doc-biblioref">J. Cohen et al., 2003</a>; <a href="#ref-myung_tutorial_2003" role="doc-biblioref">Myung, 2003</a>)</span></p>
<p>OLS regression:</p>
<ul>
<li>Estimated values of regression coefficients are chosen so that the sum of squared errors is minimized (aka, the <em>least squares criteria</em>). Consequently,
<ul>
<li>the mean of errors is zero, and</li>
<li>the errors correlate <em>zero</em> with each predictor</li>
</ul></li>
<li>The solution to OLS regression is <em>analytic</em>
<ul>
<li>the equations from which the coefficients are created are <em>known normal equations</em>. Among other places, you can look them up in CCW&amp;A <span class="citation">(<a href="#ref-cohen_introduction_1934" role="doc-biblioref">M. R. Cohen &amp; Nagel, 1934</a>)</span> Appendix 1)</li>
</ul></li>
</ul>
<p><img src="ReC_MultMod_files/figure-html/drawing%20a%20line%20of%20best%20fit-1.svg" width="672" /></p>
</div>
<div id="maximum-likelihood-estimation-mle-a-brief-orientation" class="section level3" number="9.3.2">
<h3 number="9.3.2"><span class="header-section-number">9.3.2</span> Maximum likelihood estimation (MLE): A brief orientation</h3>
<p>Although I started this chapter with a critique of NHST, Fisher is credited <span class="citation">(<a href="#ref-myung_tutorial_2003" role="doc-biblioref">Myung, 2003</a>)</span> with the original development of the central principal of <em>maximum likelihood estimation</em> which is that the desired probability distribution is the one that makes the observed data <em>most likely</em>. As such, the <em>MLE estimate</em> is a resulting parameter vector that maximizes the likelihood function. Myung’s <span class="citation">(<a href="#ref-myung_tutorial_2003" role="doc-biblioref">Myung, 2003</a>)</span> tutorial provides an excellent review. My summary is derived from Dr. Myung article. A <em>likelihood</em> is a measure of how <em>typical</em> a person (or sample) is of that population.</p>
<ul>
<li>When there is one IV the MLE distribution behaves like a chi-square distribution (which also tests observed versus expected data).</li>
<li>There is a point in the MLE curve that represents where the maximum likelihood exists that the data is likely given the model.</li>
<li>When there are multiple IVs, this simple curve takes the shape of a <em>k</em> dimensional geometrical surface.</li>
</ul>
<p>Extended to regression, we are interested in the <em>likelihoods</em> of individuals having particular scores on Y, given values on predictors x_{1} to x_{k} (and the specific values of regression coefficients chosen as the parameter estimates)</p>
<ul>
<li>MLE provides <em>maximum likelihood estimates</em> of the regression coefficients (and SEs) that is, estimates that make a sample as likely or typical as possible</li>
<li><em>L</em> is a symbol for <em>maximum likelihood of a sample</em></li>
<li>The solutions are <em>iterative</em> (i.e., identified by trial-and-error; with each trial informed by the prior)
<ul>
<li>a statistical criteria is specified for the coefficients to be chosen</li>
<li>different values of coefficients are tried</li>
<li>these <em>iterations</em> continue until the regression coefficients cease to change by more than a small amount (i.e., the <em>convergence criteria</em>)</li>
<li>hopefully, a set of coefficients is found that makes the solution as close to the statistical criteria (i.e., maximum likelihood) as possible</li>
</ul></li>
<li>The <em>optimization algorithm</em> does not guarantee that a set of parameters will be found; convergence failures may be caused by
<ul>
<li>multicollinearity among predictors</li>
<li>a large number of predictors</li>
<li>the <em>local maxima problem</em>; the optimization algorithm returns sub-optimal parameter values <span class="citation">(<a href="#ref-myung_tutorial_2003" role="doc-biblioref">Myung, 2003</a>)</span></li>
</ul></li>
<li>MLE is a <em>full information model</em>
<ul>
<li>calculates the estimates of model parameters all at once</li>
</ul></li>
<li>MLE is for large samples</li>
<li>MLE assumptions include
<ul>
<li>independence of observations</li>
<li>multivariate normality of endogenous variables</li>
<li>independence of exogeneous variables and disturbances</li>
<li>correct specification of the model (MLE is only appropriate for testing theoretically informed models)</li>
</ul></li>
</ul>
</div>
<div id="ols-and-mle-comparison" class="section level3" number="9.3.3">
<h3 number="9.3.3"><span class="header-section-number">9.3.3</span> OLS and MLE Comparison</h3>
<p>In this table we can compare OLS and MLE in a side-by-side manner.
<strong>Table 2</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">Comparing OLS and MLE <span class="citation">(<a href="#ref-cohen_applied_2003" role="doc-biblioref">J. Cohen et al., 2003</a>; <a href="#ref-myung_tutorial_2003" role="doc-biblioref">Myung, 2003</a>)</span></th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="center"><strong>Criterion</strong></td>
<td align="center"><strong>Ordinary Least Squares (OSL)</strong></td>
<td align="center"><strong>Maximum Likelihood Estimation (MLE)</strong></td>
</tr>
</tbody>
</table>
<table>
<colgroup>
<col width="16%" />
<col width="41%" />
<col width="41%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="center">Parameter values chosen to…</td>
<td align="center">minimize the distance between the predictions from regression line and the observations; considered to be those that are <em>most accurate</em></td>
<td align="center">be those that are <em>most likely</em> to have produced the data</td>
</tr>
<tr class="even">
<td align="center">Parameter values are obtained by</td>
<td align="center">equations that are known and linear (you can find them in the “back of the book”)</td>
<td align="center">a non-linear optimization algorithm</td>
</tr>
<tr class="odd">
<td align="center">Preferred when…</td>
<td align="center">sample size is small</td>
<td align="center">for complex models, non-linear models, and when OLS and MLE results differ</td>
</tr>
<tr class="even">
<td align="center">In R…</td>
<td align="center">the <em>lm()</em> function in base R</td>
<td align="center"><em>lavaan</em> and other packages*; specifying the FIML option allows for missing data (without imputation)</td>
</tr>
</tbody>
</table>
</div>
<div id="hayes-and-process-aka-conditional-process-analysis" class="section level3" number="9.3.4">
<h3 number="9.3.4"><span class="header-section-number">9.3.4</span> Hayes and PROCESS (aka conditional process analysis)</h3>
<p>In the early 2000s, the bias-corrected, bootstrapped, confidence interval (CI) was identifed as a more powerful approach to assessing indirect effects than the classic Sobel test. Because programs did not produce them, no one was using them. Preacher, Edwards, Lambert, Hayes (and colleagues) created Excel worksheets that would create such (they were so painful). Hayes turned this process into a <em>series</em> of macros (to do a variety of things for SPSS and other programs. Because of his clear, instructional, text, PROCESS probably has the most popularity. In 2021, Hayes released the PROCESS macro for R. It can be downloaded at the <a href="https://www.processmacro.org/download.html">ProcessMacro website</a>. Documention for it is newly emerging. Although PROCESS produces bias-corrected, bootstrapped confidence intervals, for models with indirect effects, PROCESS utilizes OLS as the estimator.</p>
<p>Although most regression models can be completed with the <em>lm()</em> function in base R, it can be instructive to run a handful of these familiar models with <em>lavaan</em> (or even PROCESS) as a precurser to more complicated models.</p>
</div>
</div>
<div id="introducing-the-lavaan-package" class="section level2" number="9.4">
<h2 number="9.4"><span class="header-section-number">9.4</span> Introducing the <em>lavaan</em> package</h2>
<p>In the regression classes (as well as in research designs that are cross-sectional, non-linear, and can be parsimoniously and adequately measured with OLS regression) we typically use the base R function, <em>lm()</em> (“linear model”) which relies on an OLS algorithm. The <em>lm()</em> function is part of base R. You can learn about it with this simple code:</p>
<p>Rosseel’s <span class="citation">(<a href="#ref-rosseel_lavaan_2020" role="doc-biblioref">2020</a>)</span> <em>lavaan</em> package was developed for SEM, but is readily adaptable to most multiple regression models. Which do we use and when?</p>
<ul>
<li>For relatively simple models that involve only predictors, covariates, and moderators, <em>lm()</em> is adequate.</li>
<li>Models that involve mediation need to use <em>lavaan</em></li>
<li>SEM/CFA needs <em>lavaan</em></li>
<li>If your sample size is small, <em>but</em> you are planning a mediation, it gets tricky (try to increase your sample size) because MLE estimators rely on large sample sizes (how big? hard to say).</li>
</ul>
<div id="the-fiml-magic-for-which-we-have-been-waiting" class="section level3" number="9.4.1">
<h3 number="9.4.1"><span class="header-section-number">9.4.1</span> The FIML magic for which we have been waiting</h3>
<p>There are different types of maximum likelihood. In this chapter we’ll utilize <em>full information maximum likelihood</em> (FIML). FIML is one of the most practical missing data estimation approaches around and is especially used in SEM and CFA. When data are thought to be MAR (missing at random) or MCAR (missing completely at random), it has been shown to produce unbiased parameter estimates and standard errors.</p>
<p>The FIML approach works by estimating a likelihood function for each individual based on the variables that are present so that all available data are used. Model fit is calculated from (or informed by) the fit functions for all individual cases. Hence, “FIML” is <em>full information</em> maximum likelihood.</p>
<p>When I am able to use <em>lavaan</em>, my approach is to use Parent’s <span class="citation">(- <a href="#ref-parent_handling_2013" role="doc-biblioref">Parent, 2013</a>)</span> AIA (available information analysis) approach to scoring data, then specify a FIML approach (i.e., adding <em>missing = ‘fiml’</em>) in my lavaan code. Even though the text-book examples we work have complete data, I will try to include this code so that it will be readily available for you, should you use the as templates for your own data.</p>
<p>In this portion of the ReCentering Psych Stats series we are headed toward more complex models that include both mediation and moderation. Hayes <span class="citation">(<a href="#ref-hayes_introduction_2018" role="doc-biblioref">Hayes, 2018</a>)</span> would call this “conditional process analysis.” Others would simply refer to it as “path analysis.” Although all these terms are sometimes overlapping, <em>path analysis</em> is a distinction from <em>structural equation modeling</em> (SEM) where latent variables are composed of the observed variables. Let’s take a look at some of the nuances of the whole SEM world and how it relates to PROCESS.</p>
<p><strong>SEM</strong> is broad term (that could include CFA and path analysis) but is mostly reserved for models with some type of latent variable (i.e., some might exclude path analysis from its definitions). SEM typically uses some form of MLE (not ordinary least squares).</p>
<p><em>Latent variables</em> (circles in the model, below) are those that are “created” in the analytic process but will never appear as a column in your dataset. It may be easiest to think of a latent variable as a scale score – where you sum (or average) the indicator item values to get the score (except we don’t do that). Rather, the LV is “indicated” by variance the indicator/observed/manifest variables share with each other.</p>
<p>The image below is of a simple mediation model but the variables in the model are latent, and indicated by each of the 3 observed/manifest variables. PROCESS (in SPSS) could not assess this model because PROCESS uses ordinary least squares regression and SEM will use a maximum likelihood estimator.</p>
<div class="figure">
<img src="images/SimpleMod/SimpleMedLV.jpg" alt="" />
<p class="caption">Image of a simple mediation model with latent variables</p>
</div>
<p><strong>Confirmatory factor analysis</strong> (CFA) is what we’ll do in psychometrics. Purely SEM, CFA is used to evaluate the structural validity of a scale or measure. In pure CFA, first-order factors represent subscales and a second-order factor (not required) might provide support for a total scale score. For example, in the above figure, the three squares represent the observed (or manifest) items to which a person respond. In CFA, we evaluate their adequacy to represent the latent variable (circle) construct. It’s a little more complicated than this, but this will get you started. Mediation/indirect effects are not assessed in a pure CFA.</p>
<p><strong>Path analysis</strong> is a form of SEM, but without latent variables. That is, all the variables in the model are directly observed. They are represented by squares/rectangles and each has a corresponding column in a dataset. PROCESS in SPSS is entirely path analysis.</p>
<div class="figure">
<img src="images/SimpleMod/SimpleMed.jpg" alt="" />
<p class="caption">Image of a simple mediation in path analysis</p>
</div>
<p><strong>Hybrid models</strong> are a form of SEM that include observed/manifest variables as predictors along with other latent variables. In the diagram below, you see tiny little measurement models (3 indicators that “create” or “inform” an LV, think baby CFA) and one predictor that is manifest. An example might be a categorical predictor (e.g., treatment, control).</p>
<div class="figure">
<img src="images/SimpleMod/HybridMed.jpg" alt="" />
<p class="caption">Image of a simple mediation in path analysis</p>
</div>
</div>
</div>
<div id="picking-up-with-moderation" class="section level2" number="9.5">
<h2 number="9.5"><span class="header-section-number">9.5</span> Picking up with Moderation</h2>
<p><strong>Moderation</strong>: The effect of X (IV) on some variable Y (DV) is moderated if its size, sign, or strength depends on or can be predicted by W (moderator). In that case, W is said to be a <em>moderator</em> of X’s effect on Y. Or, that W and X <em>interact</em> in their influence on Y.</p>
<p>Identifying a moderator of an effect helps establish the <em>boundary conditions</em> of that effect or the circumstances, stimuli, or type of people for which the effect is large versus small, present versus absent, positive versus negative, and so forth.</p>
<p><strong>Conditional vs Unconditional Effects</strong>: Consider the following two equations:</p>
<p><span class="math display">\[\hat{Y} = i_{y}+b_{1}X + b_{2}W + e_{y}\]</span></p>
<p>and</p>
<p><span class="math display">\[\hat{Y} = i_{y}+b_{1}X + b_{2}W + b_{3}XW+ e_{y}\]</span></p>
<p>The first equation constrains X’s effect to be unconditional on W, meaning that it is invariant across all values of W. By introducting the interaction term (<span class="math inline">\(b_{3}XW\)</span>), we can evaluate a model where X’s effect can be dependent on W. That is, for different values of W, X’s effect on Y is different. The resulting equation (#2) is the <em>simple linear moderation model.</em> In it, X’s effect on Y is <em>conditional</em>.</p>
</div>
<div id="workflow-for-name-of-statistic" class="section level2" number="9.6">
<h2 number="9.6"><span class="header-section-number">9.6</span> Workflow for NAME OF STATISTIC</h2>
<p>The workflow for running the analysis is straightforward. Below is a workflow comparing the approaches to analyzing a regression model (moderators only) with OLS and MLE.</p>
<p><img src="images/SimpleMod/OLS_MLEwrkflow.jpg" alt="Image of a simple mediation in path analysis" />
The Bonus Track at the end of the chapter includes script templates with just X and Y variables.</p>
</div>
<div id="research-vignette-7" class="section level2" number="9.7">
<h2 number="9.7"><span class="header-section-number">9.7</span> Research Vignette</h2>
<p>The research vignette comes from the Kim, Kendall, and Cheon’s <span class="citation">(<a href="#ref-kim_racial_2017" role="doc-biblioref">2017</a>)</span>, “Racial Microaggressions, Cultural Mistrust, and Mental Health Outcomes Among Asian American College Students.” Participants were 156 Asian American undergraduate students in the Pacific Northwest. The researchers posited the a priori hypothesis that cultural mistrust would mediate the relationship between racial microaggressions and two sets of outcomes: mental health (e.g., depression, anxiety, well-being) and help-seeking.</p>
<p>Variables used in the study included:</p>
<ul>
<li><strong>REMS</strong>: Racial and Ethnic Microaggressions Scale (Nadal, 2011). The scale includes 45 items on a 2-point scale where 0 indicates no experience of a microaggressive event and 1 indicates it was experienced at least once within the past six months. Higher scores indicate more experience of microaggressions.</li>
<li><strong>CMI</strong>: Cultural Mistrust Inventory (Terrell &amp; Terrell, 1981). This scale was adapted to assess cultural mistrust harbored among Asian Americans toward individuals from the mainstream U.S. culture (e.g., Whites). The CMI includes 47 items on a 7-point scale where higher scores indicate a higher degree of cultural mistrust.</li>
<li><strong>ANX</strong>, <strong>DEP</strong>, <strong>PWB</strong>: Subscales of the Mental Health Inventory (Veit &amp; Ware, 1983) that assess the mental health outcomes of anxiety (9 items), depression (4 items), and psychological well-being (14 items). Higher scores (on a 6 point scale) indicate stronger endorsement of the mental health outcome being assessed.</li>
<li><strong>HlpSkg</strong>: The Attiudes Toward Seeking Professional Psychological Help – Short Form (Fischer &amp; Farina, 1995) includes 10 items on a 4-point scale (0 = disagree, 3 = agree) where higher scores indicate more favorable attitudes toward help seeking.</li>
</ul>
<div id="simulate-data-from-the-journal-article-1" class="section level3" number="9.7.1">
<h3 number="9.7.1"><span class="header-section-number">9.7.1</span> Simulate Data from the Journal Article</h3>
<p>First, we simulate the data from the means, standard deviations, and correlation matrix from the journal article.</p>
<div class="sourceCode" id="cb308"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb308-1"><a href="#cb308-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Entering the intercorrelations, means, and standard deviations from the journal article</span></span>
<span id="cb308-2"><a href="#cb308-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">34</span>, <span class="fl">3.00</span>, <span class="fl">2.98</span>, <span class="fl">2.36</span>, <span class="fl">3.50</span>, <span class="fl">1.64</span>)</span>
<span id="cb308-3"><a href="#cb308-3" aria-hidden="true" tabindex="-1"></a>sd <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">16</span>, .<span class="dv">83</span>, .<span class="dv">99</span>, .<span class="dv">90</span>, .<span class="dv">90</span>, .<span class="dv">53</span>)</span>
<span id="cb308-4"><a href="#cb308-4" aria-hidden="true" tabindex="-1"></a>r_mat <span class="ot">&lt;-</span> <span class="fu">matrix</span> (<span class="fu">c</span>(<span class="dv">1</span>,   .<span class="dv">59</span>, .<span class="dv">26</span>,   .<span class="dv">34</span>,  <span class="sc">-</span>.<span class="dv">25</span>, <span class="sc">-</span>.<span class="dv">02</span>,</span>
<span id="cb308-5"><a href="#cb308-5" aria-hidden="true" tabindex="-1"></a>                  .<span class="dv">59</span>, <span class="fl">1.00</span>, .<span class="dv">12</span>,   .<span class="dv">19</span>,  <span class="sc">-</span>.<span class="dv">28</span>, .<span class="dv">00</span>, </span>
<span id="cb308-6"><a href="#cb308-6" aria-hidden="true" tabindex="-1"></a>                  .<span class="dv">26</span>,  .<span class="dv">12</span>, <span class="fl">1.00</span>, .<span class="dv">66</span>,  <span class="sc">-</span>.<span class="dv">55</span>, .<span class="dv">07</span>,</span>
<span id="cb308-7"><a href="#cb308-7" aria-hidden="true" tabindex="-1"></a>                  .<span class="dv">34</span>,  .<span class="dv">19</span>, .<span class="dv">66</span>,  <span class="fl">1.00</span>, <span class="sc">-</span>.<span class="dv">66</span>, .<span class="dv">05</span>,</span>
<span id="cb308-8"><a href="#cb308-8" aria-hidden="true" tabindex="-1"></a>                 <span class="sc">-</span>.<span class="dv">25</span>, <span class="sc">-</span>.<span class="dv">28</span>, <span class="sc">-</span>.<span class="dv">55</span>,<span class="sc">-</span>.<span class="dv">66</span>,  <span class="fl">1.00</span>, .<span class="dv">08</span>, </span>
<span id="cb308-9"><a href="#cb308-9" aria-hidden="true" tabindex="-1"></a>                 <span class="sc">-</span>.<span class="dv">02</span>,  .<span class="dv">00</span>,  .<span class="dv">07</span>, .<span class="dv">05</span>, .<span class="dv">08</span>,  <span class="dv">1</span>), <span class="at">ncol =</span> <span class="dv">6</span>)</span>
<span id="cb308-10"><a href="#cb308-10" aria-hidden="true" tabindex="-1"></a><span class="co">#Creating a covariance matrix</span></span>
<span id="cb308-11"><a href="#cb308-11" aria-hidden="true" tabindex="-1"></a>cov_mat <span class="ot">&lt;-</span> sd <span class="sc">%*%</span> <span class="fu">t</span>(sd) <span class="sc">*</span> r_mat</span>
<span id="cb308-12"><a href="#cb308-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb308-13"><a href="#cb308-13" aria-hidden="true" tabindex="-1"></a><span class="co">#Set random seed so that the following matrix always gets the same results.</span></span>
<span id="cb308-14"><a href="#cb308-14" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210409</span>)</span>
<span id="cb308-15"><a href="#cb308-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb308-16"><a href="#cb308-16" aria-hidden="true" tabindex="-1"></a>Kim_df <span class="ot">&lt;-</span> <span class="fu">mvrnorm</span>(<span class="at">n =</span> <span class="dv">156</span>, <span class="at">mu=</span>mu, <span class="at">Sigma =</span> cov_mat, <span class="at">empirical =</span> <span class="cn">TRUE</span>)</span>
<span id="cb308-17"><a href="#cb308-17" aria-hidden="true" tabindex="-1"></a><span class="co">#renaming the variables</span></span>
<span id="cb308-18"><a href="#cb308-18" aria-hidden="true" tabindex="-1"></a><span class="fu">as.data.frame</span>(Kim_df, <span class="at">row.names =</span> <span class="cn">NULL</span>, <span class="at">optional =</span> <span class="cn">FALSE</span>, <span class="at">make.names =</span> <span class="cn">TRUE</span>)</span>
<span id="cb308-19"><a href="#cb308-19" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb308-20"><a href="#cb308-20" aria-hidden="true" tabindex="-1"></a>Kim_df <span class="ot">&lt;-</span> Kim_df<span class="sc">%&gt;%</span></span>
<span id="cb308-21"><a href="#cb308-21" aria-hidden="true" tabindex="-1"></a>  as.data.frame <span class="sc">%&gt;%</span></span>
<span id="cb308-22"><a href="#cb308-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">REMS =</span> V1, <span class="at">CMI =</span> V2, <span class="at">ANX =</span> V3, <span class="at">DEP =</span> V4, <span class="at">PWB =</span> V5, <span class="at">HlpSk =</span> V6)</span>
<span id="cb308-23"><a href="#cb308-23" aria-hidden="true" tabindex="-1"></a><span class="co">#Checking our work against the original correlation matrix</span></span>
<span id="cb308-24"><a href="#cb308-24" aria-hidden="true" tabindex="-1"></a><span class="co">#round(cor(Kim_df),3)</span></span></code></pre></div>
<p>We can perform a quick check of our data to check its alignment with the journal article, and also get a sense of the bivariate relations with a couple of useful tools. The package <em>apaTables</em> produces a journal-ready table with means, standard deviations, and the correlation matrix.</p>
<div class="sourceCode" id="cb309"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb309-1"><a href="#cb309-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(psych)</span>
<span id="cb309-2"><a href="#cb309-2" aria-hidden="true" tabindex="-1"></a>psych<span class="sc">::</span><span class="fu">pairs.panels</span>(Kim_df)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/pairs%20panels%20for%20Kim%20et%20al-1.svg" width="672" /></p>
<p>Kim et al. <span class="citation">(<a href="#ref-kim_racial_2017" role="doc-biblioref">2017</a>)</span> did not conduct any moderation analyses in their article. Core to their analysis was predicting mental health outcomes (e.g., anxiety, depression, psychological well-being). Their predictors were racial/ethnic microaggressions, cultural mistrust, and help-seeking behaviors. In the majority of their models, REMS was the independent variable, predicting one of the mental health outcomes, mediated by cultural mistrust. Given the strong correlation with REMS (<em>r</em> = 0.59) the choice of CMI as a mediator is sensible.</p>
<p>In looking at the data, I will ask the question, “Does help-seeking (HlpSk) moderate the relationship between REMS and ANX?”</p>
<div class="figure">
<img src="images/SimpleMod/KimMod.jpg" alt="" />
<p class="caption">Conceptual diagram of a proposed simple moderation model using Kim et al. data</p>
</div>
<div class="figure">
<img src="images/SimpleMod/KimModStatistical.jpg" alt="" />
<p class="caption">Statistical diagram of a proposed simple moderation model using Kim et al. data</p>
</div>
<p>Here is the formulaic rendering:
<span class="math display">\[Y = i_{Y}+ b_{1}X+ b_{2}W + b_{3}XW +e_{Y}\]</span></p>
</div>
</div>
<div id="working-the-simple-moderation-with-ols-and-mle" class="section level2" number="9.8">
<h2 number="9.8"><span class="header-section-number">9.8</span> Working the Simple Moderation with OLS and MLE</h2>
<div id="ols-with-lm" class="section level3" number="9.8.1">
<h3 number="9.8.1"><span class="header-section-number">9.8.1</span> OLS with <em>lm()</em></h3>
<p>In this demonstration we will use the <em>lm()</em> function in base R to evaluate help seeking behaviors (HlpSK) as a moderator to the relationship between racial/ethnic microaggressions (REMS) on psychological well-being (PWB). Ordinary least squares is the estimator used in <em>lm()</em>. We will probe the moderating effect with both pick-a-point and Johnson-Neyman approaches.</p>
<p>Let’s specify this simple moderation model with base R’s <em>lm()</em> function. We’ll use the <em>jtools</em> package so we get that great summ function and <em>interactions</em> for an awesome plot.</p>
<div class="sourceCode" id="cb310"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb310-1"><a href="#cb310-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jtools) <span class="co">#the summ function creates a terrific regression table</span></span>
<span id="cb310-2"><a href="#cb310-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(interactions)</span>
<span id="cb310-3"><a href="#cb310-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb310-4"><a href="#cb310-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb310-5"><a href="#cb310-5" aria-hidden="true" tabindex="-1"></a>KimSimpMod <span class="ot">&lt;-</span> <span class="fu">lm</span>(ANX<span class="sc">~</span>REMS<span class="sc">*</span>HlpSk, <span class="at">data=</span>Kim_df)</span>
<span id="cb310-6"><a href="#cb310-6" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(KimSimpMod)</span></span></code></pre></div>
<p><strong>Table 3</strong></p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="#cb311-1" aria-hidden="true" tabindex="-1"></a>KimSimpMod_summ <span class="ot">&lt;-</span> <span class="fu">summ</span>(KimSimpMod, <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb311-2"><a href="#cb311-2" aria-hidden="true" tabindex="-1"></a>KimSimpMod_summ</span></code></pre></div>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
Observations
</td>
<td style="text-align:right;">
156
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Dependent variable
</td>
<td style="text-align:right;">
ANX
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Type
</td>
<td style="text-align:right;">
OLS linear regression
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
F(3,152)
</td>
<td style="text-align:right;">
5.426
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
R²
</td>
<td style="text-align:right;">
0.097
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
Adj. R²
</td>
<td style="text-align:right;">
0.079
</td>
</tr>
</tbody>
</table>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Est.
</th>
<th style="text-align:right;">
S.E.
</th>
<th style="text-align:right;">
t val.
</th>
<th style="text-align:right;">
p
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;font-weight: bold;">
(Intercept)
</td>
<td style="text-align:right;">
3.262
</td>
<td style="text-align:right;">
0.613
</td>
<td style="text-align:right;">
5.325
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
REMS
</td>
<td style="text-align:right;">
-1.565
</td>
<td style="text-align:right;">
1.671
</td>
<td style="text-align:right;">
-0.937
</td>
<td style="text-align:right;">
0.350
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
HlpSk
</td>
<td style="text-align:right;">
-0.518
</td>
<td style="text-align:right;">
0.361
</td>
<td style="text-align:right;">
-1.433
</td>
<td style="text-align:right;">
0.154
</td>
</tr>
<tr>
<td style="text-align:left;font-weight: bold;">
REMS:HlpSk
</td>
<td style="text-align:right;">
1.978
</td>
<td style="text-align:right;">
0.995
</td>
<td style="text-align:right;">
1.987
</td>
<td style="text-align:right;">
0.049
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<sup></sup> Standard errors: OLS
</td>
</tr>
</tfoot>
</table>
<p>Looking at these results we can see that the predictors account for about 10% of variance in anxiety. It appears that there is a statistically significant interaction of REMS and HlpSk on Anxiety. The <em>interaction_plot()</em> function from the package, <em>interactions</em> can make helpful illustrations. In the case of interactions/moderations, I like to run them “both ways” to see which makes more sense.</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="#cb312-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interact_plot</span>(KimSimpMod, <span class="at">pred =</span> HlpSk, <span class="at">modx =</span> REMS)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/Plot%20Kim%20SimpMod-1.svg" width="672" /></p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="fu">interact_plot</span>(KimSimpMod, <span class="at">pred =</span> REMS, <span class="at">modx =</span> HlpSk)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/Plot%20Kim%20SimpMod-2.svg" width="672" />
The first figure (where REMS is the moderator) illustrates that for those with the highest experience of racial/ethnic microaggression, the relationship between help-seeking and anxiety is strong ad positive. Anxiety is the highest for those who are +1SD above the mean on REMS and who have sought help. This slope is far less strong for those at the mean on REMS and the slope trends negative for those at the lowest REMS.</p>
<p>The second figure places HlpSg as the moderator. The results are the same, merely presented differently. Here we see that at all levels of help seeking, there is a positive relationship between REMS and anxiety. The relationship is the sharpest for those who are at +1SD above the mean on help-seeking. That is, the highest levels of anxiety are among those who experience the most racial and ethnic microaggressions and have the most favorable attitudes toward help-seeking.</p>
<p>Next, let’s probe the interaction with simple slopes. With these additional inferential tests we can see where in the distribution of the moderator, X has an effect on Y that is different from zero (and where it does not). There are two common approaches.</p>
<p>The Johnson-Neyman is a <em>floodlight</em> approach and provides an indication of the places in the distribution of W (moderator) that X has an effect on Y that is different than zero. The pick-a-point is sometimes called the <em>analysis of simple slopes</em> or a <em>spotlight</em> approach, probes the distribution at specific values (often the <em>M</em> +/- 1<em>SD</em>).</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sim_slopes</span>(KimSimpMod, <span class="at">pred =</span> REMS, <span class="at">modx =</span> HlpSk)</span></code></pre></div>
<pre><code>JOHNSON-NEYMAN INTERVAL 

When HlpSk is OUTSIDE the interval [-139.08, 1.34], the slope of REMS is p
&lt; .05.

Note: The range of observed values of HlpSk is [-0.07, 2.90]

SIMPLE SLOPES ANALYSIS 

Slope of REMS when HlpSk = 1.11 (- 1 SD): 

  Est.   S.E.   t val.      p
------ ------ -------- ------
  0.63   0.69     0.91   0.36

Slope of REMS when HlpSk = 1.64 (Mean): 

  Est.   S.E.   t val.      p
------ ------ -------- ------
  1.68   0.48     3.51   0.00

Slope of REMS when HlpSk = 2.17 (+ 1 SD): 

  Est.   S.E.   t val.      p
------ ------ -------- ------
  2.73   0.73     3.71   0.00</code></pre>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="#cb316-1" aria-hidden="true" tabindex="-1"></a><span class="co">#sim_slopes(KimSimpMod, pred=GRIcntlty, modx = GRMS) #sometimes I like to look at it in reverse -- like in the plots</span></span></code></pre></div>
<p>The Johnson-Neyman suggests that the relationship between REMS and ANX is statistically significant when HlpSk is above 1.34 (the mean of help-seeking is 1.64). We see the same result in the pick-a-point approach where there is a non-significant relationship between REMS and anxiety when help-seeking is 1SD below the mean. However, there is a statistically significant relationship between help-seeking and REMS when help-seeking is at and above the mean.</p>
<div id="an-apa-style-write-up-of-ols-results" class="section level4" number="9.8.1.1">
<h4 number="9.8.1.1"><span class="header-section-number">9.8.1.1</span> An APA Style Write-up of OLS results</h4>
<p><strong>Method/Analytic Strategy</strong></p>
<p>Data were analyzed with an ordinary least squares approach with the base R function (v. 4.0.4), <em>lm()</em>. We specified a model predicting anxiety (ANX) from the interacting effects of racial and ethnic microaggressions (REMS) and attitudes toward help-seeking (HlpSk).</p>
<p><strong>Results</strong></p>
<p><strong>Preliminary Analyses</strong></p>
<ul>
<li>Missing data analyses and managing missing data</li>
<li>Bivariate correlations, means, SDs</li>
<li>Distributional characteristics, assumptions, etc.</li>
<li>Address limitations and concerns</li>
</ul>
<p><strong>Primary Analyses</strong>
A multiple regression analysis was conducted to predict anxiety from racial and ethnic microaggressions and attitudes toward help-seeking. Results supported a statistically significant interaction effect that accounted for 8% of the variance. Probing the interaction effect with Johnson-Neyman and pick-a-point approaches indicated that the relationship between REMS and anxiety is non-significant when help-seeking is 1SD below the mean, but is significant when help-seeking is at and above the mean. Results are listed in Table 3. As illustrated in Figure 1, the relationship between REMS and anxiety is the sharpest for those who are at +1SD above the mean on help-seeking. That is, the highest levels of anxiety are among those who experience the most racial and ethnic microaggressions and have the most favorable attitudes toward help-seeking.</p>
</div>
</div>
<div id="mle-with-lavaansem" class="section level3" number="9.8.2">
<h3 number="9.8.2"><span class="header-section-number">9.8.2</span> MLE with <em>lavaan::sem()</em></h3>
<p>Specifying the path analysis in lavaan</p>
<p>Things to note:</p>
<ul>
<li>MLE has an element of random, by setting the seed we tell it where to “start”…so we all get the same answer</li>
<li>The code below “draws our model.” It opens and close with ’ marks</li>
<li>“Labels” (e.g., b1, b2) are useful for identifying the paths. But later in path analysis (mediation) we will use them to do some calculations (i.e., multiplying paths to create an indirect effect). In SEM/CFA (latent variable modeling) we can use them to “fix and free” constraints; the asterisk makes them look like interactions, but they are not</li>
<li>Interactions are created with the colon</li>
<li>We can use hashtags internal to the code to remind ourselves (or teach others)</li>
<li>Following specification of the model, we use the lavaan function <em>sem()</em> to conduct the estimation
<ul>
<li>adding <em>missing = ‘fiml’</em> is the magic we have been waiting for with regard to missing data</li>
<li>bootstraping is an MLE tool that gives us greater power (more later in mediation)</li>
<li>the <em>summary()</em> and <em>parameterEstimates()</em> functions get us the desired output</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="#cb317-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb317-2"><a href="#cb317-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">210501</span>)</span>
<span id="cb317-3"><a href="#cb317-3" aria-hidden="true" tabindex="-1"></a>KimSimpModMLE <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb317-4"><a href="#cb317-4" aria-hidden="true" tabindex="-1"></a><span class="st">    ANX ~ b1*REMS + b2*HlpSk + b3*REMS:HlpSk</span></span>
<span id="cb317-5"><a href="#cb317-5" aria-hidden="true" tabindex="-1"></a><span class="st">    #intercept (constant) of ANX</span></span>
<span id="cb317-6"><a href="#cb317-6" aria-hidden="true" tabindex="-1"></a><span class="st">    ANX ~ ANX.mean*1</span></span>
<span id="cb317-7"><a href="#cb317-7" aria-hidden="true" tabindex="-1"></a><span class="st">    #mean of W (HlpSk, in this case) for use in simple slopes</span></span>
<span id="cb317-8"><a href="#cb317-8" aria-hidden="true" tabindex="-1"></a><span class="st">    HlpSk ~ HlpSk.mean*1</span></span>
<span id="cb317-9"><a href="#cb317-9" aria-hidden="true" tabindex="-1"></a><span class="st">    #variance of W (age, in this case) for use in simple slopes</span></span>
<span id="cb317-10"><a href="#cb317-10" aria-hidden="true" tabindex="-1"></a><span class="st">    HlpSk ~~HlpSk.var*HlpSk</span></span>
<span id="cb317-11"><a href="#cb317-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb317-12"><a href="#cb317-12" aria-hidden="true" tabindex="-1"></a><span class="st">    #simple slopes</span></span>
<span id="cb317-13"><a href="#cb317-13" aria-hidden="true" tabindex="-1"></a><span class="st">    SD.below := b1 + b3*(HlpSk.mean - sqrt(HlpSk.var))</span></span>
<span id="cb317-14"><a href="#cb317-14" aria-hidden="true" tabindex="-1"></a><span class="st">    mean := b1 + b3*(HlpSk.mean)</span></span>
<span id="cb317-15"><a href="#cb317-15" aria-hidden="true" tabindex="-1"></a><span class="st">    SD.above := b1 + b3*(HlpSk.mean + sqrt(HlpSk.var))</span></span>
<span id="cb317-16"><a href="#cb317-16" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span></span>
<span id="cb317-17"><a href="#cb317-17" aria-hidden="true" tabindex="-1"></a>kMLE_fit <span class="ot">&lt;-</span> <span class="fu">sem</span>(KimSimpModMLE, <span class="at">data =</span> Kim_df, <span class="at">missing =</span> <span class="st">&#39;fiml&#39;</span>, <span class="at">se =</span> <span class="st">&quot;bootstrap&quot;</span>, <span class="at">bootstrap =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>Warning in lav_partable_vnames(FLAT, &quot;ov.x&quot;, warn = TRUE): lavaan WARNING:
    model syntax contains variance/covariance/intercept formulas
    involving (an) exogenous variable(s): [HlpSk]; These variables
    will now be treated as random introducing additional free
    parameters. If you wish to treat those variables as fixed, remove
    these formulas from the model syntax. Otherwise, consider adding
    the fixed.x = FALSE option.</code></pre>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="#cb319-1" aria-hidden="true" tabindex="-1"></a>k1summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(kMLE_fit, <span class="at">standardized =</span> <span class="cn">TRUE</span>, <span class="at">rsq=</span>T, <span class="at">ci=</span><span class="cn">TRUE</span>)    </span></code></pre></div>
<pre><code>lavaan 0.6-8 ended normally after 27 iterations

  Estimator                                         ML
  Optimization method                           NLMINB
  Number of model parameters                         7
                                                      
  Number of observations                           156
  Number of missing patterns                         1
                                                      
Model Test User Model:
                                                      
  Test statistic                               286.964
  Degrees of freedom                                 2
  P-value (Chi-square)                           0.000

Parameter Estimates:

  Standard errors                            Bootstrap
  Number of requested bootstrap draws             1000
  Number of successful bootstrap draws            1000

Regressions:
                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
  ANX ~                                                                 
    REMS      (b1)   -1.565    1.651   -0.948    0.343   -4.348    2.013
    HlpSk     (b2)   -0.518    0.357   -1.452    0.146   -1.078    0.284
    REMS:HlpS (b3)    1.978    0.968    2.042    0.041   -0.099    3.622
   Std.lv  Std.all
                  
   -1.565   -0.232
   -0.518   -0.254
    1.978    0.583

Intercepts:
                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
   .ANX     (ANX.)    3.262    0.628    5.192    0.000    1.836    4.233
    HlpSk   (HlS.)    1.640    0.042   39.145    0.000    1.559    1.719
   Std.lv  Std.all
    3.262    3.027
    1.640    3.104

Variances:
                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
    HlpSk   (HlS.)    0.279    0.034    8.255    0.000    0.210    0.344
   .ANX               0.880    0.105    8.416    0.000    0.658    1.075
   Std.lv  Std.all
    0.279    1.000
    0.880    0.757

R-Square:
                   Estimate
    ANX               0.243

Defined Parameters:
                   Estimate  Std.Err  z-value  P(&gt;|z|) ci.lower ci.upper
    SD.below          0.633    0.678    0.934    0.350   -0.568    2.098
    mean              1.678    0.415    4.045    0.000    0.825    2.547
    SD.above          2.723    0.638    4.267    0.000    1.366    3.833
   Std.lv  Std.all
    0.633    0.995
    1.678    1.578
    2.723    2.161</code></pre>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="#cb321-1" aria-hidden="true" tabindex="-1"></a>k1ParamEsts <span class="ot">&lt;-</span> <span class="fu">parameterEstimates</span>(kMLE_fit, <span class="at">boot.ci.type =</span> <span class="st">&quot;bca.simple&quot;</span>, <span class="at">standardized=</span><span class="cn">TRUE</span>)</span>
<span id="cb321-2"><a href="#cb321-2" aria-hidden="true" tabindex="-1"></a>k1summary</span></code></pre></div>
<pre><code>$PE
          lhs op                                rhs      label exo         est
1         ANX  ~                               REMS         b1   0 -1.56544552
2         ANX  ~                              HlpSk         b2   0 -0.51782360
3         ANX  ~                         REMS:HlpSk         b3   0  1.97795075
4         ANX ~1                                      ANX.mean   0  3.26190999
5       HlpSk ~1                                    HlpSk.mean   0  1.64000000
6       HlpSk ~~                              HlpSk  HlpSk.var   0  0.27909931
7         ANX ~~                                ANX              0  0.87962409
8        REMS ~~                               REMS              1  0.02543590
9        REMS ~~                         REMS:HlpSk              1  0.04037811
10 REMS:HlpSk ~~                         REMS:HlpSk              1  0.10084721
11       REMS ~1                                                 1  0.34000000
12 REMS:HlpSk ~1                                                 1  0.55591487
13   SD.below := b1+b3*(HlpSk.mean-sqrt(HlpSk.var))   SD.below   0  0.63344528
14       mean :=                 b1+b3*(HlpSk.mean)       mean   0  1.67839370
15   SD.above := b1+b3*(HlpSk.mean+sqrt(HlpSk.var))   SD.above   0  2.72334213
16        ANX r2                                ANX              0  0.24254430
           se          z                   pvalue    ci.lower   ci.upper
1  1.65074551 -0.9483264 0.3429633215769629650538 -4.34810874 2.01338756
2  0.35656589 -1.4522522 0.1464314929518111263462 -1.07773414 0.28414926
3  0.96845176  2.0423844 0.0411134172939178199613 -0.09912907 3.62168163
4  0.62826033  5.1919719 0.0000002080784049507400  1.83567879 4.23284817
5  0.04189583 39.1447097 0.0000000000000000000000  1.55947385 1.71942054
6  0.03380971  8.2550036 0.0000000000000002220446  0.20963886 0.34430050
7  0.10452295  8.4156075 0.0000000000000000000000  0.65750121 1.07494268
8  0.00000000         NA                       NA  0.02543590 0.02543590
9  0.00000000         NA                       NA  0.04037811 0.04037811
10 0.00000000         NA                       NA  0.10084721 0.10084721
11 0.00000000         NA                       NA  0.34000000 0.34000000
12 0.00000000         NA                       NA  0.55591487 0.55591487
13 0.67825599  0.9339324 0.3503387422955603902608 -0.56800474 2.09816467
14 0.41490005  4.0452964 0.0000522569589227472875  0.82458783 2.54688120
15 0.63822441  4.2670604 0.0000198065516987533385  1.36616966 3.83326607
16         NA         NA                       NA          NA         NA
        std.lv    std.all     std.nox
1  -1.56544552 -0.2316816 -1.45267353
2  -0.51782360 -0.2538583 -0.07663646
3   1.97795075  0.5828777  1.83546258
4   3.26190999  3.0269276  3.02692761
5   1.64000000  3.1043056  3.10430557
6   0.27909931  1.0000000  1.00000000
7   0.87962409  0.7574557  0.75745570
8   0.02543590  1.0000000  0.02543590
9   0.04037811  0.7972426  0.04037811
10  0.10084721  1.0000000  0.10084721
11  0.34000000  2.1318438  0.34000000
12  0.55591487  1.7505574  0.55591487
13  0.63344528  0.9948713  2.40970062
14  1.67839370  1.5777490  4.24516320
15  2.72334213  2.1606268  6.08062579
16          NA         NA          NA</code></pre>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="#cb323-1" aria-hidden="true" tabindex="-1"></a>k1ParamEsts</span></code></pre></div>
<pre><code>          lhs op                                rhs      label    est    se
1         ANX  ~                               REMS         b1 -1.565 1.651
2         ANX  ~                              HlpSk         b2 -0.518 0.357
3         ANX  ~                         REMS:HlpSk         b3  1.978 0.968
4         ANX ~1                                      ANX.mean  3.262 0.628
5       HlpSk ~1                                    HlpSk.mean  1.640 0.042
6       HlpSk ~~                              HlpSk  HlpSk.var  0.279 0.034
7         ANX ~~                                ANX             0.880 0.105
8        REMS ~~                               REMS             0.025 0.000
9        REMS ~~                         REMS:HlpSk             0.040 0.000
10 REMS:HlpSk ~~                         REMS:HlpSk             0.101 0.000
11       REMS ~1                                                0.340 0.000
12 REMS:HlpSk ~1                                                0.556 0.000
13   SD.below := b1+b3*(HlpSk.mean-sqrt(HlpSk.var))   SD.below  0.633 0.678
14       mean :=                 b1+b3*(HlpSk.mean)       mean  1.678 0.415
15   SD.above := b1+b3*(HlpSk.mean+sqrt(HlpSk.var))   SD.above  2.723 0.638
        z pvalue ci.lower ci.upper std.lv std.all std.nox
1  -0.948  0.343   -4.487    1.858 -1.565  -0.232  -1.453
2  -1.452  0.146   -1.115    0.257 -0.518  -0.254  -0.077
3   2.042  0.041    0.041    3.831  1.978   0.583   1.835
4   5.192  0.000    1.906    4.318  3.262   3.027   3.027
5  39.145  0.000    1.553    1.715  1.640   3.104   3.104
6   8.255  0.000    0.220    0.354  0.279   1.000   1.000
7   8.416  0.000    0.700    1.113  0.880   0.757   0.757
8      NA     NA    0.025    0.025  0.025   1.000   0.025
9      NA     NA    0.040    0.040  0.040   0.797   0.040
10     NA     NA    0.101    0.101  0.101   1.000   0.101
11     NA     NA    0.340    0.340  0.340   2.132   0.340
12     NA     NA    0.556    0.556  0.556   1.751   0.556
13  0.934  0.350   -0.644    2.003  0.633   0.995   2.410
14  4.045  0.000    0.832    2.551  1.678   1.578   4.245
15  4.267  0.000    1.488    4.064  2.723   2.161   6.081</code></pre>
<p>Recall, this was our formula:</p>
<p>Here is the formulaic rendering:
<span class="math display">\[Y = i_{Y}+ b_{1}X+ b_{2}W + b_{3}XW +e_{Y}\]</span></p>
<p>Looking at our data here’s what we’ve learned:
<span class="math display">\[\hat{Y} = 3.26 + (-1.57)X + (-0.52)W + 1.98XW\]</span></p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(semPlot)</span>
<span id="cb325-2"><a href="#cb325-2" aria-hidden="true" tabindex="-1"></a><span class="fu">semPaths</span>(kMLE_fit, <span class="co">#must identify the model you want to map</span></span>
<span id="cb325-3"><a href="#cb325-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">what =</span> <span class="st">&quot;est&quot;</span>, <span class="co">#&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb325-4"><a href="#cb325-4" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb325-5"><a href="#cb325-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">layout =</span> <span class="st">&#39;tree&#39;</span>, <span class="at">rotation =</span> <span class="dv">2</span>, <span class="co">#together, puts predictors on left, IVs on right </span></span>
<span id="cb325-6"><a href="#cb325-6" aria-hidden="true" tabindex="-1"></a>         <span class="co">#layout = &#39;circle&#39;,</span></span>
<span id="cb325-7"><a href="#cb325-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">edge.label.cex =</span> <span class="fl">1.00</span>, <span class="co">#font size of parameter values</span></span>
<span id="cb325-8"><a href="#cb325-8" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb325-9"><a href="#cb325-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">sizeMan=</span><span class="dv">10</span>, <span class="co">#size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb325-10"><a href="#cb325-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">fade=</span><span class="cn">FALSE</span>, <span class="co">#if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb325-11"><a href="#cb325-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">esize=</span><span class="dv">2</span>, </span>
<span id="cb325-12"><a href="#cb325-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">asize=</span><span class="dv">3</span>,</span>
<span id="cb325-13"><a href="#cb325-13" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb325-14"><a href="#cb325-14" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.font =</span> <span class="fl">2.5</span>, <span class="co">#controls size (I think) of font for labels</span></span>
<span id="cb325-15"><a href="#cb325-15" aria-hidden="true" tabindex="-1"></a>         <span class="at">label.scale =</span> <span class="cn">TRUE</span>, <span class="co">#if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb325-16"><a href="#cb325-16" aria-hidden="true" tabindex="-1"></a>         <span class="at">nDigits =</span> <span class="dv">3</span>, <span class="co">#decimal places (default is 2)</span></span>
<span id="cb325-17"><a href="#cb325-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">residuals =</span> <span class="cn">FALSE</span>,<span class="co">#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb325-18"><a href="#cb325-18" aria-hidden="true" tabindex="-1"></a>         <span class="at">nCharNodes =</span> <span class="dv">0</span>, <span class="co">#specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb325-19"><a href="#cb325-19" aria-hidden="true" tabindex="-1"></a>         <span class="at">intercepts =</span> <span class="cn">FALSE</span>, <span class="co">#gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb325-20"><a href="#cb325-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb325-21"><a href="#cb325-21" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Help Seeking as a Moderator in the Relationship between REMS and ANX&quot;</span>)</span></code></pre></div>
<p><img src="ReC_MultMod_files/figure-html/semPlot%20of%20simple%20mod-1.svg" width="672" /></p>
<p>If I had just run this with lavaan, I would want to plot the interaction and would do so with the OLS methods I demonstrated above.</p>
</div>
<div id="tabling-the-data-1" class="section level3" number="9.8.3">
<h3 number="9.8.3"><span class="header-section-number">9.8.3</span> Tabling the data</h3>
<p>In this table, I gather the output from both the OLS and MLE approaches. Youll notice below that the <span class="math inline">\(B\)</span> weights are identical to the third decimal place (shown). The standard errors and <em>p</em> values wiggle around a bit, but are consistent with each other (and lead to the same significant/non-significant conclusion). The <span class="math inline">\(R^2\)</span> vaues are quite divergent.</p>
<p>Further comparison shows that the OLS output provides an <span class="math inline">\(F\)</span> statistic that indicates whether or not the overall model is significant. These are commonly reported in Results. In contrast, the MLE output has a page or more of <em>fit statistics</em> (e.g., CFI, RMSEA, Chi-square goodness of fit) that are commonly reported in latent variable modeling such as SEM and CFA. Although some researchers will report them in path analysis, I tend to preer the focus on the strength and significance of the regression weights.</p>
<p>Table 4</p>
<table>
<thead>
<tr class="header">
<th align="left">A Comparison of OLS and MLE Regression Results</th>
</tr>
</thead>
<tbody>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="center"></td>
<td align="center">OLS with the <em>lm()</em> in base R</td>
<td align="center">MLE with <em>lavaan</em></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(SE\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="left">ANX (Intercept)</td>
<td align="center">3.262</td>
<td align="center">0.613</td>
<td align="center">0.000</td>
<td align="center">3.262</td>
<td align="center">0.628</td>
<td align="center">0.000</td>
</tr>
<tr class="odd">
<td align="left">REMS (X)</td>
<td align="center">-1.565</td>
<td align="center">1.671</td>
<td align="center">0.350</td>
<td align="center">-1.565</td>
<td align="center">1.651</td>
<td align="center">0.343</td>
</tr>
<tr class="even">
<td align="left">HlpSk (W)</td>
<td align="center">-0.518</td>
<td align="center">0.361</td>
<td align="center">0.154</td>
<td align="center">-0.518</td>
<td align="center">0.357</td>
<td align="center">0.146</td>
</tr>
<tr class="odd">
<td align="left">REMS:HlpSK (XY)</td>
<td align="center">1.978</td>
<td align="center">0.995</td>
<td align="center">0.049</td>
<td align="center">1.978</td>
<td align="center">0.968</td>
<td align="center">0.041</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left"><span class="math inline">\(R^2\)</span></td>
<td align="center"><span class="math inline">\(R^2\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">9.67%</td>
<td align="center">24.25%</td>
</tr>
</tbody>
</table>
<table>
<tbody>
</tbody>
</table>
</div>
<div id="apa-style-writeup-3" class="section level3" number="9.8.4">
<h3 number="9.8.4"><span class="header-section-number">9.8.4</span> APA Style Writeup</h3>
<p><strong>Method/Analytic Strategy</strong></p>
<p>Data were analyzed with a maximum likelihood approach the package, <em>lavaan</em> (v. 0.6-7) We specified a model predicting anxiety (ANX) from the interacting effects of racial and ethnic microaggressions (REMS) and attitudes toward help-seeking (HlpSk).</p>
<p><strong>Results</strong></p>
<p><strong>Preliminary Analyses</strong></p>
<ul>
<li>Missing data analyses and managing missing data</li>
<li>Bivariate correlations, means, SDs</li>
<li>Distributional characteristics, assumptions, etc.</li>
<li>Address limitations and concerns</li>
</ul>
<p><strong>Primary Analyses</strong>
A multiple regression analysis was conducted to predict anxiety from racial and ethnic microaggressions and attitudes toward help-seeking. Results supported a statistically significant interaction effect that accounted for 24.25% of the variance. Probing the interaction effect with the pick-a-point approache indicated that the relationship between REMS and anxiety is non-significant when help-seeking is 1SD below the mean, but is significant when help-seeking is at and above the mean. Results are listed in Table 4. As illustrated in Figure 1, the relationship between REMS and anxiety is the sharpest for those who are at +1SD above the mean on help-seeking. That is, the highest levels of anxiety are among those who experience the most racial and ethnic microaggressions and have the most favorable attitudes toward help-seeking.</p>
</div>
</div>
<div id="residual-and-related-questions-2" class="section level2" number="9.9">
<h2 number="9.9"><span class="header-section-number">9.9</span> Residual and Related Questions…</h2>
</div>
<div id="practice-problems-7" class="section level2" number="9.10">
<h2 number="9.10"><span class="header-section-number">9.10</span> Practice Problems</h2>
<p>The suggested practice problem for this chapter is to conduct a simple moderation with both the OLS/<em>lm()</em> approach and the MLE/<em>lavaan</em> approach.</p>
<div id="problem-1-rework-the-research-vignette-as-demonstrated-but-change-the-random-seed-3" class="section level3" number="9.10.1">
<h3 number="9.10.1"><span class="header-section-number">9.10.1</span> Problem #1: Rework the research vignette as demonstrated, but change the random seed</h3>
<p>If this topic feels a bit overwhelming, simply change the random seed in the data simulation, then rework the problem. This should provide minor changes to the data (maybe in the second or third decimal point), but the results will likely be very similar.</p>
<table>
<colgroup>
<col width="75%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, and W roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the OLS/<em>lm()</em> model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Probe the interaction with the pick-a-point and Johnson-Neyman approaches</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create an interaction figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Create a table (a package-produced table is fine)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Create an APA style write-up of the results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Repeat the analysis in <em>lavaan</em> (specify the model to include probing the interaction)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Create a model figure.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">9. Create a table.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">10. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">11. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-2-rework-the-research-vignette-but-swap-one-or-more-variables-3" class="section level3" number="9.10.2">
<h3 number="9.10.2"><span class="header-section-number">9.10.2</span> Problem #2: Rework the research vignette, but swap one or more variables</h3>
<p>Use the simulated data, but swap out at least one of the variables in the model to conduct the simple moderation using both approaches.</p>
<table>
<colgroup>
<col width="75%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, and W roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the OLS/<em>lm()</em> model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Probe the interaction with the pick-a-point and Johnson-Neyman approaches</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create an interaction figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Create a table (a package-produced table is fine)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Create an APA style write-up of the results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Repeat the analysis in <em>lavaan</em> (specify the model to include probing the interaction)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Create a model figure.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">9. Create a table.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">10. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">11. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
<div id="problem-3-use-other-data-that-is-available-to-you-3" class="section level3" number="9.10.3">
<h3 number="9.10.3"><span class="header-section-number">9.10.3</span> Problem #3: Use other data that is available to you</h3>
<p>Using data for which you have permission and access (e.g., IRB approved data you have collected or from your lab; data you simulate from a published article; data from an open science repository; data from other chapters in this OER), complete the simple moderation with both approaches.</p>
<table>
<colgroup>
<col width="75%" />
<col width="12%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Assignment Component</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1. Assign each variable to the X, Y, and W roles (ok but not required to include a cov)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">2. Specify and run the OLS/<em>lm()</em> model</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">3. Probe the interaction with the pick-a-point and Johnson-Neyman approaches</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">4. Create an interaction figure</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">5. Create a table (a package-produced table is fine)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">6. Create an APA style write-up of the results</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">7. Repeat the analysis in <em>lavaan</em> (specify the model to include probing the interaction)</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">8. Create a model figure.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">9. Create a table.</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="even">
<td align="left">10. Represent your work in an APA-style write-up</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
<tr class="odd">
<td align="left">11. Explanation to grader</td>
<td align="center">5</td>
<td align="center">_____</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="bonus-track-2" class="section level2" number="9.11">
<h2 number="9.11"><span class="header-section-number">9.11</span> Bonus Track:</h2>
<div class="figure">
<img src="images/film-strip-1.jpg" id="id" class="class" width="620" height="211" alt="" />
<p class="caption">Image of a filmstrip</p>
</div>
<p>Below is template for a simple moderation conducted with the OLS approach using the base R function, <em>lm()</em></p>
<div class="sourceCode" id="cb326"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(jtools) <span class="co">#the summ function creates a terrific regression table</span></span>
<span id="cb326-2"><a href="#cb326-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(interactions)</span>
<span id="cb326-3"><a href="#cb326-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb326-4"><a href="#cb326-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-5"><a href="#cb326-5" aria-hidden="true" tabindex="-1"></a><span class="co">#The regression</span></span>
<span id="cb326-6"><a href="#cb326-6" aria-hidden="true" tabindex="-1"></a><span class="co">#OLSmodel &lt;- lm(Y~X*W, data=my_df)</span></span>
<span id="cb326-7"><a href="#cb326-7" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(KimSimpMod)</span></span>
<span id="cb326-8"><a href="#cb326-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-9"><a href="#cb326-9" aria-hidden="true" tabindex="-1"></a><span class="co">#Cool Table</span></span>
<span id="cb326-10"><a href="#cb326-10" aria-hidden="true" tabindex="-1"></a><span class="co">#summ(KimSimpMod, digits = 3)</span></span>
<span id="cb326-11"><a href="#cb326-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-12"><a href="#cb326-12" aria-hidden="true" tabindex="-1"></a><span class="co">#Probe Simple Slopes</span></span>
<span id="cb326-13"><a href="#cb326-13" aria-hidden="true" tabindex="-1"></a><span class="co">#sim_slopes(OLSmodel, pred = X, modx = W)</span></span>
<span id="cb326-14"><a href="#cb326-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb326-15"><a href="#cb326-15" aria-hidden="true" tabindex="-1"></a><span class="co">#Figures</span></span>
<span id="cb326-16"><a href="#cb326-16" aria-hidden="true" tabindex="-1"></a><span class="co">#interact_plot(OLSmodel, pred = W, modx = X)</span></span>
<span id="cb326-17"><a href="#cb326-17" aria-hidden="true" tabindex="-1"></a><span class="co">#interact_plot(OLSmodel, pred = X, modx = W)</span></span></code></pre></div>
<p>Below is a template for a simple moderation conducted with the MLE approach using the package, <em>lavaan</em>.</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="#cb327-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb327-2"><a href="#cb327-2" aria-hidden="true" tabindex="-1"></a><span class="co">#set.seed(210501)</span></span>
<span id="cb327-3"><a href="#cb327-3" aria-hidden="true" tabindex="-1"></a><span class="co">#MLEmodel &lt;- &#39;</span></span>
<span id="cb327-4"><a href="#cb327-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Y ~ b1*X + b2*W + b3*X:W</span></span>
<span id="cb327-5"><a href="#cb327-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">#intercept (constant) of Y</span></span>
<span id="cb327-6"><a href="#cb327-6" aria-hidden="true" tabindex="-1"></a>    <span class="co">#Y ~ Y.mean*1</span></span>
<span id="cb327-7"><a href="#cb327-7" aria-hidden="true" tabindex="-1"></a>    <span class="co">#mean of W  for use in simple slopes</span></span>
<span id="cb327-8"><a href="#cb327-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">#W ~ W.mean*1</span></span>
<span id="cb327-9"><a href="#cb327-9" aria-hidden="true" tabindex="-1"></a>    <span class="co">#variance of W for use in simple slopes</span></span>
<span id="cb327-10"><a href="#cb327-10" aria-hidden="true" tabindex="-1"></a>    <span class="co">#W ~~ W .var*W</span></span>
<span id="cb327-11"><a href="#cb327-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb327-12"><a href="#cb327-12" aria-hidden="true" tabindex="-1"></a>    <span class="co">#simple slopes</span></span>
<span id="cb327-13"><a href="#cb327-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">#SD.below := b1 + b3*(W.mean - sqrt(W.var))</span></span>
<span id="cb327-14"><a href="#cb327-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">#mean := b1 + b3*(W.mean)</span></span>
<span id="cb327-15"><a href="#cb327-15" aria-hidden="true" tabindex="-1"></a>    <span class="co">#SD.above := b1 + b3*(W.mean + sqrt(W.var))</span></span>
<span id="cb327-16"><a href="#cb327-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&#39;</span></span>
<span id="cb327-17"><a href="#cb327-17" aria-hidden="true" tabindex="-1"></a><span class="co">#MLEmod_fit &lt;- sem(MLEmodel, data = my_df, missing = &#39;fiml&#39;, se = &quot;bootstrap&quot;, bootstrap = 1000)</span></span>
<span id="cb327-18"><a href="#cb327-18" aria-hidden="true" tabindex="-1"></a><span class="co">#MLEmod_fit_summary &lt;- summary(MLEmod_fit, standardized = TRUE, rsq=T, ci=TRUE)    </span></span>
<span id="cb327-19"><a href="#cb327-19" aria-hidden="true" tabindex="-1"></a><span class="co">#MLEmodParamEsts &lt;- parameterEstimates(MLEmod_fit, boot.ci.type = &quot;bca.simple&quot;, standardized=TRUE)</span></span>
<span id="cb327-20"><a href="#cb327-20" aria-hidden="true" tabindex="-1"></a><span class="co">#MLEmod_fit_summary</span></span>
<span id="cb327-21"><a href="#cb327-21" aria-hidden="true" tabindex="-1"></a><span class="co">#MLEmodParamEsts</span></span></code></pre></div>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="#cb328-1" aria-hidden="true" tabindex="-1"></a><span class="co">#library(semPlot)</span></span>
<span id="cb328-2"><a href="#cb328-2" aria-hidden="true" tabindex="-1"></a><span class="co">#semPaths(MLEmod_fit, #must identify the model you want to map</span></span>
<span id="cb328-3"><a href="#cb328-3" aria-hidden="true" tabindex="-1"></a>        <span class="co">#what = &quot;est&quot;, #&quot;est&quot; plots the estimates, but keeps it greyscale with no fading</span></span>
<span id="cb328-4"><a href="#cb328-4" aria-hidden="true" tabindex="-1"></a>         <span class="co">#whatLabels = &quot;stand&quot;, #&quot;stand&quot; changes to standardized values</span></span>
<span id="cb328-5"><a href="#cb328-5" aria-hidden="true" tabindex="-1"></a>         <span class="co">#layout = &#39;tree&#39;, rotation = 2, #together, puts predictors on left, IVs on right </span></span>
<span id="cb328-6"><a href="#cb328-6" aria-hidden="true" tabindex="-1"></a>         <span class="co">#layout = &#39;circle&#39;,</span></span>
<span id="cb328-7"><a href="#cb328-7" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.label.cex = 1.00, #font size of parameter values</span></span>
<span id="cb328-8"><a href="#cb328-8" aria-hidden="true" tabindex="-1"></a>         <span class="co">#edge.color = &quot;black&quot;, #overwrites the green/black coloring</span></span>
<span id="cb328-9"><a href="#cb328-9" aria-hidden="true" tabindex="-1"></a>         <span class="co">#sizeMan=10, #size of squares/observed/&quot;manifest&quot; variables</span></span>
<span id="cb328-10"><a href="#cb328-10" aria-hidden="true" tabindex="-1"></a>         <span class="co">#fade=FALSE, #if TRUE, there lines are faded such that weaker lines correspond with lower values -- a cool effect, but tough for journals</span></span>
<span id="cb328-11"><a href="#cb328-11" aria-hidden="true" tabindex="-1"></a>         <span class="co">#esize=2, </span></span>
<span id="cb328-12"><a href="#cb328-12" aria-hidden="true" tabindex="-1"></a>         <span class="co">#asize=3,</span></span>
<span id="cb328-13"><a href="#cb328-13" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.prop = .5,</span></span>
<span id="cb328-14"><a href="#cb328-14" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.font = 2.5, #controls size (I think) of font for labels</span></span>
<span id="cb328-15"><a href="#cb328-15" aria-hidden="true" tabindex="-1"></a>         <span class="co">#label.scale = TRUE, #if false, the labels will not scale to fit inside the nodes</span></span>
<span id="cb328-16"><a href="#cb328-16" aria-hidden="true" tabindex="-1"></a>         <span class="co">#nDigits = 3, #decimal places (default is 2)</span></span>
<span id="cb328-17"><a href="#cb328-17" aria-hidden="true" tabindex="-1"></a>         <span class="co">#residuals = FALSE,#excludes residuals (and variances) from the path diagram</span></span>
<span id="cb328-18"><a href="#cb328-18" aria-hidden="true" tabindex="-1"></a>         <span class="co">#nCharNodes = 0, #specifies how many characters to abbreviate variable lables; default is 3.  If 0, uses your entire variable label and adjusts fontsize (which could be a downside)</span></span>
<span id="cb328-19"><a href="#cb328-19" aria-hidden="true" tabindex="-1"></a>         <span class="co">#intercepts = FALSE, #gets rid of those annoying triangles (intercepts) in the path diagram)</span></span>
<span id="cb328-20"><a href="#cb328-20" aria-hidden="true" tabindex="-1"></a><span class="co">#)</span></span>
<span id="cb328-21"><a href="#cb328-21" aria-hidden="true" tabindex="-1"></a><span class="co">#title(&quot;Help Seeking as a Moderator in the Relationship between REMS and ANX&quot;)</span></span></code></pre></div>
<div class="sourceCode" id="cb329"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb329-1"><a href="#cb329-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sessionInfo</span>()</span></code></pre></div>
<pre><code>R version 4.0.4 (2021-02-15)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 18362)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252 
[2] LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
 [1] interactions_1.1.3 jtools_2.1.3       MASS_7.3-53.1      semTable_1.8      
 [5] semPlot_1.1.2      lavaan_0.6-8       apaTables_2.0.8    mice_3.13.0       
 [9] sjstats_0.18.1     formattable_0.2.1  qualtRics_3.1.4    forcats_0.5.1     
[13] stringr_1.4.0      dplyr_1.0.5        purrr_0.3.4        readr_1.4.0       
[17] tidyr_1.1.3        tibble_3.1.1       ggplot2_3.3.3      tidyverse_1.3.1   
[21] psych_2.1.3       

loaded via a namespace (and not attached):
  [1] readxl_1.3.1        backports_1.2.1     Hmisc_4.5-0        
  [4] systemfonts_1.0.1   igraph_1.2.6        plyr_1.8.6         
  [7] splines_4.0.4       TH.data_1.0-10      digest_0.6.27      
 [10] htmltools_0.5.1.1   matrixcalc_1.0-3    fansi_0.4.2        
 [13] magrittr_2.0.1      Rsolnp_1.16         checkmate_2.0.0    
 [16] lisrelToR_0.1.4     cluster_2.1.2       openxlsx_4.2.3     
 [19] modelr_0.1.8        sandwich_3.0-0      svglite_2.0.0      
 [22] jpeg_0.1-8.1        sem_3.1-11          MBESS_4.8.0        
 [25] colorspace_2.0-0    rvest_1.0.0         haven_2.4.1        
 [28] xfun_0.22           crayon_1.4.1        jsonlite_1.7.2     
 [31] lme4_1.1-26         regsem_1.6.2        survival_3.2-11    
 [34] zoo_1.8-9           glue_1.4.2          kableExtra_1.3.4   
 [37] gtable_0.3.0        emmeans_1.6.0       webshot_0.5.2      
 [40] mi_1.0              sjmisc_2.8.6        abind_1.4-5        
 [43] scales_1.1.1        mvtnorm_1.1-1       DBI_1.1.1          
 [46] Rcpp_1.0.6          viridisLite_0.4.0   xtable_1.8-4       
 [49] performance_0.7.1   htmlTable_2.1.0     tmvnsim_1.0-2      
 [52] foreign_0.8-81      Formula_1.2-4       stats4_4.0.4       
 [55] truncnorm_1.0-8     htmlwidgets_1.5.3   httr_1.4.2         
 [58] RColorBrewer_1.1-2  ellipsis_0.3.1      farver_2.1.0       
 [61] XML_3.99-0.6        pkgconfig_2.0.3     nnet_7.3-15        
 [64] sass_0.3.1          kutils_1.70         dbplyr_2.1.1       
 [67] utf8_1.2.1          labeling_0.4.2      reshape2_1.4.4     
 [70] tidyselect_1.1.1    rlang_0.4.11        effectsize_0.4.4-1 
 [73] munsell_0.5.0       cellranger_1.1.0    tools_4.0.4        
 [76] cli_2.5.0           generics_0.1.0      sjlabelled_1.1.7   
 [79] broom_0.7.6         fdrtool_1.2.16      evaluate_0.14      
 [82] arm_1.11-2          yaml_2.2.1          knitr_1.33         
 [85] fs_1.5.0            stationery_0.98.30  pander_0.6.3       
 [88] zip_2.1.1           glasso_1.11         pbapply_1.4-3      
 [91] nlme_3.1-151        xml2_1.3.2          compiler_4.0.4     
 [94] rstudioapi_0.13     curl_4.3.1          png_0.1-7          
 [97] reprex_2.0.0        statmod_1.4.35      bslib_0.2.4        
[100] pbivnorm_0.6.0      stringi_1.5.3       highr_0.9          
[103] parameters_0.13.0   qgraph_1.6.9        rockchalk_1.8.144  
[106] lattice_0.20-41     Matrix_1.2-18       nloptr_1.2.2.2     
[109] vctrs_0.3.7         pillar_1.6.0        lifecycle_1.0.0    
[112] jquerylib_0.1.4     OpenMx_2.19.5       estimability_1.3   
[115] corpcor_1.6.9       data.table_1.14.0   insight_0.13.2     
[118] R6_2.5.0            latticeExtra_0.6-29 bookdown_0.22      
[121] gridExtra_2.3       codetools_0.2-18    gtools_3.8.2       
[124] boot_1.3-27         assertthat_0.2.1    withr_2.4.2        
[127] mnormt_2.0.2        multcomp_1.4-17     bayestestR_0.9.0   
[130] parallel_4.0.4      hms_1.0.0           grid_4.0.4         
[133] rpart_4.1-15        coda_0.19-4         minqa_1.2.4        
[136] rmarkdown_2.7       carData_3.0-4       lubridate_1.7.10   
[139] base64enc_0.1-3    </code></pre>
</div>
</div>
<div id="refs" class="section level1 unnumbered">
<h1 class="unnumbered">References</h1>
<!--chapter:end:09-SimpleMod.Rmd-->
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-adames_fallacy_2021" class="csl-entry">
Adames, H. Y., Chavez-Dueñas, N. Y., &amp; Jernigan, M. M. (2021). The fallacy of a raceless <span>Latinidad</span>: <span>Action</span> guidelines for centering <span>Blackness</span> in <span>Latinx</span> psychology. <em>Journal of Latinx Psychology</em>, <em>9</em>(1), 26–44. <a href="https://doi.org/10.1037/lat0000179">https://doi.org/10.1037/lat0000179</a>
</div>
<div id="ref-baron_moderator-mediator_1986" class="csl-entry">
Baron, R. M., &amp; Kenny, D. A. (1986). The <span>Moderator</span>-<span>Mediator</span> <span>Variable</span> <span>Distinction</span> in <span>Social</span> <span>Psychological</span> <span>Research</span>: <span>Conceptual</span>, <span>Strategic</span>, and <span>Statistical</span> <span>Considerations</span>. <em>Journal of Personality and Social Psychology</em>, <em>51</em>(6), 1173–1182. <a href="https://doi.org/0022-3514/86">https://doi.org/0022-3514/86</a>
</div>
<div id="ref-bollen_perceived_1990" class="csl-entry">
Bollen, K. A., &amp; Hoyle, R. H. (1990). Perceived cohesion: <span>A</span> conceptual and empirical examination. <em>Social Forces</em>, <em>69</em>(2), 479–504. <a href="https://doi.org/10.2307/2579670">https://doi.org/10.2307/2579670</a>
</div>
<div id="ref-byrne_structural_2016" class="csl-entry">
Byrne, B. M. (2016). <em>Structural equation modeling with <span>AMOS</span>: <span>Basic</span> concepts, applications, and programming</em> (3rd ed.). Routledge. <a href="http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4556523">http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4556523</a>
</div>
<div id="ref-capielo_rosario_acculturation_2019" class="csl-entry">
Capielo Rosario, C., Adames, H. Y., Chavez-Dueñas, N. Y., &amp; Renteria, R. (2019). Acculturation <span>Profiles</span> of <span>Central</span> <span>Florida</span> <span>Puerto</span> <span>Ricans</span>: <span>Examining</span> the <span>Influence</span> of <span>Skin</span> <span>Color</span>, <span>Perceived</span> <span>Ethnic</span>-<span>Racial</span> <span>Discrimination</span>, and <span>Neighborhood</span> <span>Ethnic</span>-<span>Racial</span> <span>Composition</span>. <em>Journal of Cross-Cultural Psychology</em>, <em>50</em>(4), 556–576. <a href="https://doi.org/10.1177/0022022119835979">https://doi.org/10.1177/0022022119835979</a>
</div>
<div id="ref-carver_you_1997" class="csl-entry">
Carver, C. S. (1997). You want to measure coping but your protocol’s too long: <span>Consider</span> the <span>Brief</span> <span>COPE</span>. <em>International Journal of Behavioral Medicine</em>, <em>4</em>(1), 92–100. <a href="https://doi.org/10.1207/s15327558ijbm0401_6">https://doi.org/10.1207/s15327558ijbm0401_6</a>
</div>
<div id="ref-cohen_applied_2003" class="csl-entry">
Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). <em>Applied multiple regression/correlation analysis for the behavioral sciences</em> (3rd ed.). LErlbaum Associates.
</div>
<div id="ref-cohen_introduction_1934" class="csl-entry">
Cohen, M. R., &amp; Nagel, E. (1934). <em>An introduction to logic and scientific method</em>. Harcourt Brace.
</div>
<div id="ref-cortina_what_1993" class="csl-entry">
Cortina, J. M. (1993). What is coefficient alpha? <span>An</span> examination of theory and applications. <em>Journal of Applied Psychology</em>, <em>78</em>(1), 98–104. <a href="https://doi.org/10.1037/0021-9010.78.1.98">https://doi.org/10.1037/0021-9010.78.1.98</a>
</div>
<div id="ref-cumming_new_2014" class="csl-entry">
Cumming, G. (2014). The <span>New</span> <span>Statistics</span>: <span>Why</span> and <span>How</span>. <em>Psychological Science</em>, <em>25</em>(1), 7–29. <a href="https://doi.org/10.1177/0956797613504966">https://doi.org/10.1177/0956797613504966</a>
</div>
<div id="ref-enders_multiple_2017" class="csl-entry">
Enders, C. K. (2017). Multiple imputation as a flexible tool for missing data handling in clinical research. <em>Behaviour Research and Therapy</em>, <em>98</em>, 4–18. <a href="https://doi.org/10.1016/j.brat.2016.11.008">https://doi.org/10.1016/j.brat.2016.11.008</a>
</div>
<div id="ref-enders_applied_2010" class="csl-entry">
Enders, C. K. (2010). <em>Applied missing data analysis</em>. Guilford Press.
</div>
<div id="ref-noauthor_fact_nodate" class="csl-entry">
<em><span>FACT</span> <span>SHEET</span>: <span>Anti</span>-<span>Asian</span> <span>Prejudice</span> <span>March</span> 2020</em>. (n.d.). Center or the Study of Hate &amp; Extremism, California University System - Berkley. <a href="https://www.csusb.edu/sites/default/files/FACT%20SHEET-%20Anti-Asian%20Hate%202020%203.2.21.pdf">https://www.csusb.edu/sites/default/files/FACT%20SHEET-%20Anti-Asian%20Hate%202020%203.2.21.pdf</a>
</div>
<div id="ref-field_discovering_2012" class="csl-entry">
Field, A. P. (2012). <em>Discovering statistics using <span>R</span></em>. Sage.
</div>
<div id="ref-gladwell_outliers_2008" class="csl-entry">
Gladwell, M. (2008). <em>Outliers: The story of success</em> (First edition.). Little, Brown; Company.
</div>
<div id="ref-green_using_2014" class="csl-entry">
Green, S. B., &amp; Salkind, N. J. (2014). <em>Using <span>SPSS</span> for <span>Windows</span> and <span>Macintosh</span>: Analyzing and understanding data</em> (Seventh edition.). Pearson.
</div>
<div id="ref-hayes_introduction_2018" class="csl-entry">
Hayes, A. F. (2018). <em>Introduction to <span>Mediation</span>, <span>Moderation</span>, and <span>Conditional</span> <span>Process</span> <span>Analysis</span>, <span>Second</span> <span>Edition</span>: <span>A</span> <span>Regression</span>-<span>Based</span> <span>Approach</span></em>. Guilford Publications. <a href="http://ebookcentral.proquest.com/lib/spu/detail.action?docID=5109647">http://ebookcentral.proquest.com/lib/spu/detail.action?docID=5109647</a>
</div>
<div id="ref-hurtado_linking_2007" class="csl-entry">
Hurtado, S. (2007). Linking <span>Diversity</span> with the <span>Educational</span> and <span>Civic</span> <span>Missions</span> of <span>Higher</span> <span>Education</span>. <em>Review of Higher Education: Journal of the Association for the Study of Higher Education</em>, <em>30</em>(2), 185–196. <a href="https://doi.org/10.1353/rhe.2006.0070">https://doi.org/10.1353/rhe.2006.0070</a>
</div>
<div id="ref-hurtado_effects_1997" class="csl-entry">
Hurtado, S., &amp; Carter, D. F. (1997). Effects of college transition and perceptions of the campus racial climate on <span>Latino</span> college students’ sense of belonging. <em>Sociology of Education</em>, <em>70</em>, 324–345. <a href="https://doi.org/10.2307/2673270">https://doi.org/10.2307/2673270</a>
</div>
<div id="ref-iacovino_retaining_2016" class="csl-entry">
Iacovino, J. M., &amp; James, S. A. (2016). Retaining <span>Students</span> of <span>Color</span> in <span>Higher</span> <span>Education</span>: <span>Expanding</span> <span>Our</span> <span>Focus</span> to <span>Psychosocial</span> <span>Adjustment</span> and <span>Mental</span> <span>Health</span>. In <em>The <span>Crisis</span> of <span>Race</span> in <span>Higher</span> <span>Education</span>: <span>A</span> <span>Day</span> of <span>Discovery</span> and <span>Dialogue</span></em> (Vol. 19, pp. 61–84). Emerald Group Publishing Limited. <a href="https://doi.org/10.1108/S1479-364420160000019004">https://doi.org/10.1108/S1479-364420160000019004</a>
</div>
<div id="ref-jhangiani_research_2019" class="csl-entry">
Jhangiani, R. S., Chiang, I.-C. A., Cuttler, C., &amp; Leighton, D. C. (2019). <em>Research <span>Methods</span> in <span>Psychology</span></em>. <a href="https://doi.org/10.17605/OSF.IO/HF7DQ">https://doi.org/10.17605/OSF.IO/HF7DQ</a>
</div>
<div id="ref-bollen_testing_1993" class="csl-entry">
Joreskog, K. G. (1993). Testing structural equation models. In K. A. Bollen &amp; J. S. Long (Eds.), <em>Testing <span>Structural</span> <span>Equation</span> <span>Models</span></em>. SAGE.
</div>
<div id="ref-katitas_getting_2019" class="csl-entry">
Katitas, A. (2019). Getting <span>Started</span> with <span>Multiple</span> <span>Imputation</span> in <span>R</span>. In <em>University of Virginia Library: Research Data Services + Sciences</em>. <a href="https://uvastatlab.github.io/2019/05/01/getting-started-with-multiple-imputation-in-r/">https://uvastatlab.github.io/2019/05/01/getting-started-with-multiple-imputation-in-r/</a>
</div>
<div id="ref-kim_yes_2021" class="csl-entry">
Kim, P. (2021). Yes, <span>Asians</span> and <span>Asian</span> <span>Americans</span> experience racism. In <em>The Seattle Times</em>. <a href="https://www.seattletimes.com/opinion/yes-asians-and-asian-americans-experience-racism/">https://www.seattletimes.com/opinion/yes-asians-and-asian-americans-experience-racism/</a>
</div>
<div id="ref-kim_guest_2021" class="csl-entry">
Kim, Paul Y. (2021). Guest <span>Post</span>: <span>Anti</span>-<span>Asian</span> <span>Racism</span> during the <span>Pandemic</span>: <span>How</span> <span>Faculty</span> on <span>Christian</span> <span>Campuses</span> <span>Can</span> <span>Support</span> <span>Asian</span> and <span>Asian</span> <span>American</span> <span>Students</span>. In <em>Christian Scholar’s Review</em>. <a href="https://christianscholars.com/guest-post-anti-asian-racism-during-the-pandemic-how-faculty-on-christian-campuses-can-support-asian-and-asian-american-students/">https://christianscholars.com/guest-post-anti-asian-racism-during-the-pandemic-how-faculty-on-christian-campuses-can-support-asian-and-asian-american-students/</a>
</div>
<div id="ref-kim_racial_2017" class="csl-entry">
Kim, Paul Youngbin, Kendall, D. L., &amp; Cheon, H.-S. (2017). Racial microaggressions, cultural mistrust, and mental health outcomes among asian american college students. <em>American Journal of Orthopsychiatry</em>, <em>87</em>(6), 663–670. <a href="https://doi.org/10.1037/ort0000203">https://doi.org/10.1037/ort0000203</a>
</div>
<div id="ref-kline_mediation_2015" class="csl-entry">
Kline, R. B. (2015). The mediation myth. <em>Basic and Applied Social Psychology</em>, <em>37</em>(4), 202–213. <a href="https://doi.org/10.1080/01973533.2015.1049349">https://doi.org/10.1080/01973533.2015.1049349</a>
</div>
<div id="ref-kline_principles_2016" class="csl-entry">
Kline, R. B. (2016). <em>Principles and practice of structural equation modeling</em> (4th ed.). Guilford Publications. <a href="http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4000663">http://ebookcentral.proquest.com/lib/spu/detail.action?docID=4000663</a>
</div>
<div id="ref-lewis_construction_2015" class="csl-entry">
Lewis, J. A., &amp; Neville, H. A. (2015). Construction and initial validation of the <span>Gendered</span> <span>Racial</span> <span>Microaggressions</span> <span>Scale</span> for <span>Black</span> women. <em>Journal of Counseling Psychology</em>, <em>62</em>(2), 289–302. <a href="https://doi.org/10.1037/cou0000062">https://doi.org/10.1037/cou0000062</a>
</div>
<div id="ref-lewis_applying_2017" class="csl-entry">
Lewis, J. A., Williams, M. G., Peppers, E. J., &amp; Gadson, C. A. (2017). Applying intersectionality to explore the relations between gendered racism and health among <span>Black</span> women. <em>Journal of Counseling Psychology</em>, <em>64</em>(5), 475–486. <a href="https://doi.org/10.1037/cou0000231">https://doi.org/10.1037/cou0000231</a>
</div>
<div id="ref-lewis_black_2019" class="csl-entry">
Lewis, K. R., &amp; Shah, P. P. (2019). Black students’ narratives of diversity and inclusion initiatives and the campus racial climate: <span>An</span> interest-convergence analysis. <em>Journal of Diversity in Higher Education</em>. <a href="https://doi.org/10.1037/dhe0000147">https://doi.org/10.1037/dhe0000147</a>
</div>
<div id="ref-little_statistical_2002" class="csl-entry">
Little, R. J. A., &amp; Rubin, D. B. (2002). <em>Statistical analysis with missing data</em> (Second edition.). Wiley. <a href="http://site.ebrary.com/id/10921256">http://site.ebrary.com/id/10921256</a>
</div>
<div id="ref-little_missing_2008" class="csl-entry">
Little, T. D., Howard, W. J., McConnell, E. K., &amp; Stump, K. N. (2008). Missing data in large data projects: <span>Two</span> methods of missing data imputation when working with large data projects. <em>KUant Guides</em>, <em>011.3</em>, 10. <a href="https://crmda.dept.ku.edu/guides/11.ImputationWithLargeDataSets/11.ImputationWithLargeDataSets.pdf">https://crmda.dept.ku.edu/guides/11.ImputationWithLargeDataSets/11.ImputationWithLargeDataSets.pdf</a>
</div>
<div id="ref-mallinckrodt_advances_2006" class="csl-entry">
Mallinckrodt, B., Abraham, W. T., Wei, M., &amp; Russell, D. W. (2006). Advances in testing the statistical significance of mediation effects. <em>Journal of Counseling Psychology</em>, <em>53</em>(3), 372–378. <a href="https://doi.org/10.1037/0022-0167.53.3.372">https://doi.org/10.1037/0022-0167.53.3.372</a>
</div>
<div id="ref-mallinckrodt_scientist-practitioner-advocate_2014" class="csl-entry">
Mallinckrodt, B., Miles, J. R., &amp; Levy, J. J. (2014). The scientist-practitioner-advocate model: <span>Addressing</span> contemporary training needs for social justice advocacy. <em>Training and Education in Professional Psychology</em>, <em>8</em>(4), 303–311. <a href="https://doi.org/10.1037/tep0000045">https://doi.org/10.1037/tep0000045</a>
</div>
<div id="ref-mosley_critical_2021" class="csl-entry">
Mosley, D. V., Hargons, C. N., Meiller, C., Angyal, B., Wheeler, P., Davis, C., &amp; Stevens-Watkins, D. (2021). Critical consciousness of anti-<span>Black</span> racism: <span>A</span> practical model to prevent and resist racial trauma. <em>Journal of Counseling Psychology</em>, <em>68</em>(1), 1–16. <a href="https://doi.org/10.1037/cou0000430">https://doi.org/10.1037/cou0000430</a>
</div>
<div id="ref-mosley_radical_2020" class="csl-entry">
Mosley, D. V., Neville, H. A., Chavez‐Dueñas, N. Y., Adames, H. Y., Lewis, J. A., &amp; French, B. H. (2020). Radical hope in revolting times: <span>Proposing</span> a culturally relevant psychological framework. <em>Social and Personality Psychology Compass</em>, <em>14</em>(1). <a href="https://doi.org/10.1111/spc3.12512">https://doi.org/10.1111/spc3.12512</a>
</div>
<div id="ref-myung_tutorial_2003" class="csl-entry">
Myung, I. J. (2003). Tutorial on maximum likelihood estimation. <em>Journal of Mathematical Psychology</em>, <em>47</em>(1), 90–100. <a href="https://doi.org/10.1016/S0022-2496(02)00028-7">https://doi.org/10.1016/S0022-2496(02)00028-7</a>
</div>
<div id="ref-niemark_stimulus_1967" class="csl-entry">
Niemark, E. D., &amp; Estes, W. K. (1967). <em>Stimulus sampling theory</em>. Holden-Day.
</div>
<div id="ref-parent_handling_2013" class="csl-entry">
Parent, M. C. (2013). Handling item-level missing data: <span>Simpler</span> is just as good. <em>The Counseling Psychologist</em>, <em>41</em>(4), 568–600. <a href="https://doi.org/10.1177/0011000012445176">https://doi.org/10.1177/0011000012445176</a>
</div>
<div id="ref-pearl_causality_2000" class="csl-entry">
Pearl, J. (2000). <em>Causality: Models, reasoning, and inference</em>. Cambridge University Press.
</div>
<div id="ref-rodgers_epistemology_2010" class="csl-entry">
Rodgers, J. L. (2010). The epistemology of mathematical and statistical modeling: <span>A</span> quiet methodological revolution. <em>American Psychologist</em>, <em>65</em>(1), 1–12. <a href="https://doi.org/10.1037/a0018326">https://doi.org/10.1037/a0018326</a>
</div>
<div id="ref-rosseel_lavaan_2020" class="csl-entry">
Rosseel, Y. (2020). <em>The lavaan tutorial</em>. <a href="http://lavaan.ugent.be/tutorial/tutorial.pdf">http://lavaan.ugent.be/tutorial/tutorial.pdf</a>
</div>
<div id="ref-sellers_multidimensional_nodate" class="csl-entry">
Sellers, R. M., Rowley, S. A. J., Chavous, T. M., Shelton, J. N., &amp; Smith, M. A. (n.d.). <em>Multidimensional <span>Inventory</span> of <span>Black</span> <span>Identity</span>: <span>A</span> <span>Preliminary</span> <span>Investigation</span> of <span>Reliability</span> and <span>Construct</span> <span>Validity</span></em>. 11.
</div>
<div id="ref-sijtsma_use_2009" class="csl-entry">
Sijtsma, K. (2009). On the <span>Use</span>, the <span>Misuse</span>, and the <span>Very</span> <span>Limited</span> <span>Usefulness</span> of <span>Cronbach</span>’s <span>Alpha</span>. <em>Psychometrika</em>, <em>74</em>(1), 107–120. <a href="https://doi.org/10.1007/s11336-008-9101-0">https://doi.org/10.1007/s11336-008-9101-0</a>
</div>
<div id="ref-singh_building_2020" class="csl-entry">
Singh, A. (2020). Building a <span>Counseling</span> <span>Psychology</span> of <span>Liberation</span>: <span>The</span> <span>Path</span> <span>Behind</span> <span>Us</span>, <span>Under</span> <span>Us</span>, and <span>Before</span> <span>Us</span>. <em>The Counseling Psychologist</em>, <em>48</em>(8), 1109–1130. <a href="https://doi.org/10.1177/0011000020959007">https://doi.org/10.1177/0011000020959007</a>
</div>
<div id="ref-stone-romero_research_2010" class="csl-entry">
Stone-Romero, E., &amp; Rosopa, P. (2010). Research design options for testing mediation models and their implications for facets of validity. <em>Journal of Managerial Psychology</em>, <em>25</em>, 697–712. <a href="https://doi.org/10.1108/02683941011075256">https://doi.org/10.1108/02683941011075256</a>
</div>
<div id="ref-noauthor_stop_nodate" class="csl-entry">
<em><span>STOP</span> <span>AAPI</span> <span>HATE</span></em>. (n.d.). Retrieved March 19, 2021, from <a href="https://stopaapihate.org/">https://stopaapihate.org/</a>
</div>
<div id="ref-szymanski_perceptions_2020" class="csl-entry">
Szymanski, D. M., &amp; Bissonette, D. (2020). Perceptions of the <span>LGBTQ</span> <span>College</span> <span>Campus</span> <span>Climate</span> <span>Scale</span>: <span>Development</span> and <span>Psychometric</span> <span>Evaluation</span>. <em>Journal of Homosexuality</em>, <em>67</em>(10), 1412–1428. <a href="https://doi.org/10.1080/00918369.2019.1591788">https://doi.org/10.1080/00918369.2019.1591788</a>
</div>
<div id="ref-toffanin_multiple-mediator_2017" class="csl-entry">
Toffanin, P. (2017). Multiple-mediator analysis with lavaan. In <em>paolotoffanin</em>. <a href="https://paolotoffanin.wordpress.com/2017/05/06/multiple-mediator-analysis-with-lavaan/">https://paolotoffanin.wordpress.com/2017/05/06/multiple-mediator-analysis-with-lavaan/</a>
</div>
<div id="ref-ware_comparison_1995" class="csl-entry">
Ware, J. E., Kosinski, M., Bayliss, M. S., &amp; McHorney, C. A. (1995). Comparison of methods for the scoring and statistical analysis of <span>SF</span>-36 health profile and summary measures: <span>Summary</span> of results from the medical outcomes study. <em>Medical Care</em>, <em>33</em>(4, Suppl), 264–279. <a href="https://ezproxy.spu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&amp;AuthType=ip&amp;db=psyh&amp;AN=1995-35535-001&amp;site=ehost-live">https://ezproxy.spu.edu/login?url=http://search.ebscohost.com/login.aspx?direct=true&amp;AuthType=ip&amp;db=psyh&amp;AN=1995-35535-001&amp;site=ehost-live</a>
</div>
</div>
</div>
<!--bookdown:body:end-->
            </section>

          </div>
        </div>
      </div>
<!--bookdown:link_prev-->
<!--bookdown:link_next-->
    </div>
  </div>
<!--bookdown:config-->

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
